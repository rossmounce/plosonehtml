                </a></li></ul></div><p><strong>Figure 6. </strong></p><a id="article1.body1.sec3.sec2.sec2.fig1.caption1.p1" name="article1.body1.sec3.sec2.sec2.fig1.caption1.p1"></a><p>Regression analysis for representation of optic flow in M1R. Same data set as <a href="#pone-0000200-g004">Figs. 4</a> and <a href="#pone-0000200-g005">5</a>. Each pixel was fit as a function of each optic flow stimulus and eye position (see <a href="#s2">Methods</a>). The resulting parameters were used to construct six parameter maps. A. Intercept shows the modeled evoked visual response for the eyes at the primary position (0, 0°) and as if there was no optic flow motion. B. Eye position map: vertical slope of the dependence of the optical signal on the eye position. C. Rotation coefficient map: dependence of the optical signal upon the radial component of the optic flow. The rotation optic flow parameter was scaled to an arbitrary value of 10 “rotation units” to represent a motion rate of 6°/sec. D. Radial coefficient map: dependence of the optical signal upon the radial component of the optic flow. The radial parameter was scaled to an arbitrary value of 10 “radial units” to represent a motion rate of 6°/sec. E. Amplitude map, root mean square of the rotational and radial coefficients. F. Angle map. The amplitude of each pixel has been converted in angular coordinates in spiral space <a href="#pone.0000200-Graziano1">[25]</a>. The “spiral space” color coding represents the specific optic flow stimuli that maximally activate each pixel. The grey scale indicates the percentage of increase (bright) or decrease (dark) of the reflectance of the signal with respect to the baseline. Horizontal bar: 1 mm.</p>
