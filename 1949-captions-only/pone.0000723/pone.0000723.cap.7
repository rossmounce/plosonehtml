                </a></li></ul></div><p><strong>Figure 7.  <span>Simulations varying the number of training neurons and the number of supersynapses per neuron.</span></strong></p><a id="article1.body1.sec2.sec5.fig1.caption1.p1" name="article1.body1.sec2.sec5.fig1.caption1.p1"></a><p>(A) (Upper) Networks formed with three different numbers of training neurons (TN). After a few groups, the width of the synfire network returns to a steady state size. The color coding is identical to <a href="#pone-0000723-g003">Figure 3</a>. (Lower) The distribution of neurons in each group for four networks formed using different numbers of TN; line color and shape encode the different values of number of TN. The number of neurons per group quickly converges to the same number, independent of the number of TN. The inset shows the distribution for the first 7 groups. The curve with 10 TN is from <a href="#pone-0000723-g003">Figure 3</a>; the other three curves are from the networks above. (B) A network formed with the numbers of supersynapses and TN both set to 20; all other parameters were the same as in <a href="#pone-0000723-g003">Figure 3</a>. The major difference compared to the network shown in <a href="#pone-0000723-g003">Figure 3</a> is that the number of neurons per group is higher.</p>
<span>THISISTHEEND
