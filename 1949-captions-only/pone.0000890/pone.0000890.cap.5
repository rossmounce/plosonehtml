
<div id="section4" class="section"><a id="s4" name="s4" toc="s4" title="Discussion"></a><h3>Discussion</h3><a id="article1.body1.sec4.p1" name="article1.body1.sec4.p1"></a><p>This study is the first to show that visuo-haptic cross-modal object recognition is essentially viewpoint-independent. Both visual and haptic within-modal recognition were significantly reduced by rotation of the object away from the learned view. This was not so for the two cross-modal conditions. It is well established that, as here, cross-modal recognition comes at a cost compared to within-modal recognition [for example, 11–15], but there was no significant additional cost associated with object rotation. This finding is the more robust because the task in this study was more demanding than in the study of Newell et al. <a href="#pone.0000890-Newell1">[2]</a> and yet the additional difficulty of object rotation had little effect on cross-modal recognition. For example, although we used similar objects as Newell et al. <a href="#pone.0000890-Newell1">[2]</a> did (with the exception of the removal of a texture cue) we allowed only half the time for object learning. In addition, participants had to discriminate between specific objects rather than just make a new/old judgment between learned objects and unlearned distractors.</p>
<a id="article1.body1.sec4.p2" name="article1.body1.sec4.p2"></a><p>In vision, viewpoint-independence suggests mediation by a high-level, relatively abstract representation <a href="#pone.0000890-Riesenhuber1">[16]</a>. Viewpoint-independence can occur, more trivially, when all object views are familiar <a href="#pone.0000890-Tarr1">[17]</a>, perhaps because separate, lower-level representations have been established for each viewpoint; or when the object has very distinctive parts <a href="#pone.0000890-Biederman1">[18]</a> that are easily transformed to match the new viewpoint. However, the objects in the present study were unfamiliar and lacked distinctive parts because the component blocks were identical except in their relationships to one another. Thus, viewpoint-independence could not have arisen simply from object familiarity or distinctiveness of object parts. Rather, the findings of the present study favor the idea of an abstract, high-level, modality-independent representation underlying cross-modal object recognition. Such a representation could be constructed by integrating lower-level, unisensory, viewpoint-dependent representations <a href="#pone.0000890-Riesenhuber1">[16]</a>. Functional neuroimaging studies have demonstrated convergence of visual and haptic shape processing in the intraparietal sulcus (IPS) and the lateral occipital complex (LOC) <a href="#pone.0000890-Amedi1">[19]</a>–<a href="#pone.0000890-Peltier1">[22]</a>. The nature of the representations in these areas is, however, incompletely understood, and has only been studied using visual stimuli. Activity in parts of the IPS scales with the angle of mental rotation <a href="#pone.0000890-Gauthier1">[6]</a> and also appears to be viewpoint-dependent <a href="#pone.0000890-James2">[23]</a>. There is a difference of opinion as to whether LOC activity is viewpoint-dependent <a href="#pone.0000890-GrillSpector1">[24]</a> or viewpoint-independent <a href="#pone.0000890-James2">[23]</a>. Thus, at present, the locus of the modality- and viewpoint-independent, high-level representation underlying cross-modal object recognition is unknown.</p>
<a id="article1.body1.sec4.p3" name="article1.body1.sec4.p3"></a><p>The existence of the high-level, modality-independent representation inferred here was obscured in earlier work <a href="#pone.0000890-Newell1">[2]</a> using objects that were extended along the y-axis. Here, we removed the confounding near-far exchange inherent in this earlier study, by selecting a presentation axis that made all object surfaces more equally available to touch, and demonstrated that cross-modal object recognition is consistently viewpoint-independent across all three axes of rotation. This contrasts with within-modal recognition, where viewpoint-dependence suggests mediation by lower-level, unisensory representations that might feed into the high-level viewpoint-independent representation mediating cross-modal recognition. The correlation between spatial imagery scores and cross-modal, but not within-modal, accuracy, and the lack of any correlation of object imagery scores with performance, suggests that the ability to mentally image complex spatial transformations is linked to viewpoint-independent recognition and supports the view that cross-modal performance is served by an abstract spatial representation.</p>
<a id="article1.body1.sec4.p4" name="article1.body1.sec4.p4"></a><p>Our results are also the first to suggest differences between visual and haptic viewpoint-dependence. Rotating an object can occlude a surface and transform the global shape in different ways depending on the axis of rotation <a href="#pone.0000890-Gauthier1">[6]</a>, suggesting potentially different bases for viewpoint-dependence in vision and touch. Varying the axis of rotation may not matter to touch because the hands are free to move around the object or manipulate it into different orientations relative to the hand. Thus no surface is occluded in touch and it is only necessary to deal with shape transformations. However, these manipulations are not possible visually unless one physically changes location with respect to the object <a href="#pone.0000890-Pasqualotto1">[25]</a>, so that vision has to deal with both shape transformations and surface occlusion. <a href="#pone-0000890-g004">Figure 4</a> suggests that the axis of rotation affects vision but not touch. Visual recognition was best after z-rotation – although this occluded the top surface, the shape transformation is a simple left/right mirror-image in the picture-plane. The x- and y- rotations were more complex; the x-rotation occluded the top surface and produced a mirror-image in the depth-plane. The y-rotation did not occlude a surface but involved two shape transformations, reversing the object from left to right and in the depth-plane. Although it may be counterintuitive that a rotation involving the occlusion of a surface on the main information-bearing axis is easier to process, it should be borne in mind that shape information from the two side surfaces was still available. There is evidence that such picture-plane rotations are easier than depth-plane rotations <a href="#pone.0000890-Gauthier1">[6]</a>, <a href="#pone.0000890-Logothetis1">[26]</a>, <a href="#pone.0000890-Perrett1">[27]</a>. Monkey inferotemporal neurons show faster generalization and exhibit larger generalization fields for picture-plane rotations than depth-plane rotations <a href="#pone.0000890-Logothetis1">[26]</a>. Face-selective neurons are more sensitive to depth-plane rotations (faces tilted towards/away from the viewer) than to picture-plane rotations (horizontal or inverted faces) <a href="#pone.0000890-Perrett1">[27]</a>. Picture-plane (z-axis) rotations result in faster and more accurate performance than depth-plane (x- and y-axis) rotations in both object recognition and mental rotation tasks, even though these tasks involve distinct neural networks <a href="#pone.0000890-Gauthier1">[6]</a>. Thus the picture-plane advantage may be a fairly general one. However, further work is necessary to verify that the differences between vision and touch derive from the nature of shape transformations and the presence of surface occlusion.</p>
<a id="article1.body1.sec4.p5" name="article1.body1.sec4.p5"></a><p>Our main conclusion is to clarify an important point about visuo-haptic cross-modal object recognition: that the underlying representation is viewpoint-independent even for unfamiliar objects lacking distinctive local features. Further, despite the unisensory representations each being viewpoint-dependent, there are differences between modalities with the axis of rotation being important in vision but not touch.</p>
</div>



<div class="contributions"><a id="authcontrib" name="authcontrib" toc="authcontrib" title="Author Contributions"></a><h3>Author Contributions</h3><p>Conceived and designed the experiments: SL. Performed the experiments: AP. Analyzed the data: KS SL. Contributed reagents/materials/analysis tools: SL. Wrote the paper: KS SL AP.</p></div><div><a id="references" name="references" toc="references" title="References"></a><h3>References</h3><ol class="references"><li><span class="label">1.
              </span><a name="pone.0000890-Jolicoeur1" id="pone.0000890-Jolicoeur1"></a>Jolicoeur P (1985) The time to name disoriented objects. Mem Cognition,  13: 289–303.  <ul class="find" data-citedArticleID="991766" data-doi="10.3758/bf03202498"><li><a href="http://dx.doi.org/10.3758/bf03202498" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+time+to+name+disoriented+objects." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+time+to+name+disoriented+objects.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">2.
              </span><a name="pone.0000890-Newell1" id="pone.0000890-Newell1"></a>Newell FN, Ernst MO, Tjan BS, Bulthoff HH (2001) Viewpoint dependence in visual and haptic object recognition. Psychol Sci,  12: 37–42.  <ul class="find" data-citedArticleID="991776" data-doi="10.1111/1467-9280.00307"><li><a href="http://dx.doi.org/10.1111/1467-9280.00307" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Viewpoint+dependence+in+visual+and+haptic+object+recognition." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Viewpoint+dependence+in+visual+and+haptic+object+recognition.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">3.
              </span><a name="pone.0000890-Klatzky1" id="pone.0000890-Klatzky1"></a>Klatzky RL, Lederman S, Reed C (1987) There's more to touch than meets the eye: The salience of object attributes for haptics with and without vision. J Exp Psychol: Gen,  116: 356–369.  <ul class="find" data-citedArticleID="991768"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=There%27s+more+to+touch+than+meets+the+eye%3A+The+salience+of+object+attributes+for+haptics+with+and+without+vision.&amp;auth=&amp;atitle=There%27s+more+to+touch+than+meets+the+eye%3A+The+salience+of+object+attributes+for+haptics+with+and+without+vision." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=There%27s+more+to+touch+than+meets+the+eye%3A+The+salience+of+object+attributes+for+haptics+with+and+without+vision." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22There%27s+more+to+touch+than+meets+the+eye%3A+The+salience+of+object+attributes+for+haptics+with+and+without+vision.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">4.
              </span><a name="pone.0000890-Reales1" id="pone.0000890-Reales1"></a>Reales JM, Ballesteros S (1999) Implicit and explicit memory for visual and haptic objects: Cross-modal priming depends on structural descriptions. J Exp Psychol: Learn,  25: 644–663.  <ul class="find" data-citedArticleID="991790" data-doi="10.1037/0278-7393.25.3.644"><li><a href="http://dx.doi.org/10.1037/0278-7393.25.3.644" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Implicit+and+explicit+memory+for+visual+and+haptic+objects%3A+Cross-modal+priming+depends+on+structural+descriptions." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Implicit+and+explicit+memory+for+visual+and+haptic+objects%3A+Cross-modal+priming+depends+on+structural+descriptions.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">5.
              </span><a name="pone.0000890-Heller1" id="pone.0000890-Heller1"></a>Heller MA, Brackett DD, Scroggs E, Steffen H, Heatherly K, et al.  (2002) Tangible pictures: Viewpoint effects and linear perspective in visually impaired people. Perception,  31: 747–769.  <ul class="find" data-citedArticleID="991760" data-doi="10.1068/p3253"><li><a href="http://dx.doi.org/10.1068/p3253" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Tangible+pictures%3A+Viewpoint+effects+and+linear+perspective+in+visually+impaired+people." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Tangible+pictures%3A+Viewpoint+effects+and+linear+perspective+in+visually+impaired+people.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">6.
              </span><a name="pone.0000890-Gauthier1" id="pone.0000890-Gauthier1"></a>Gauthier I, Hayward WG, Tarr MJ, Anderson AW, Skudlarski P, et al.  (2002) BOLD activity during mental rotation and viewpoint-dependent object recognition. Neuron,  34: 161–171.  <ul class="find" data-citedArticleID="991756" data-doi="10.1016/s0896-6273(02)00622-0"><li><a href="http://dx.doi.org/10.1016/s0896-6273(02)00622-0" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=BOLD+activity+during+mental+rotation+and+viewpoint-dependent+object+recognition." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22BOLD+activity+during+mental+rotation+and+viewpoint-dependent+object+recognition.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">7.
              </span><a name="pone.0000890-Blajenkova1" id="pone.0000890-Blajenkova1"></a>Blajenkova O, Kozhevnikov M, Motes MA (2006) Object-spatial imagery: A new self-report questionnaire. Appl Cognit Psychol,  20: 239–263.  <ul class="find" data-citedArticleID="991748" data-doi="10.1002/acp.1182"><li><a href="http://dx.doi.org/10.1002/acp.1182" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Object-spatial+imagery%3A+A+new+self-report+questionnaire." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Object-spatial+imagery%3A+A+new+self-report+questionnaire.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">8.
              </span><a name="pone.0000890-Kozhevnikov1" id="pone.0000890-Kozhevnikov1"></a>Kozhevnikov M, Kosslyn S, Shephard J (2005) Spatial versus object visualizers: A new characterization of cognitive style. Mem Cognition,  33: 710–726.  <ul class="find" data-citedArticleID="991770" data-doi="10.3758/bf03195337"><li><a href="http://dx.doi.org/10.3758/bf03195337" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Spatial+versus+object+visualizers%3A+A+new+characterization+of+cognitive+style." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Spatial+versus+object+visualizers%3A+A+new+characterization+of+cognitive+style.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">9.
              </span><a name="pone.0000890-Lacey1" id="pone.0000890-Lacey1"></a>Lacey S, Campbell C (2006) Mental representation in visual/haptic crossmodal memory: Evidence from interference effects. Q J Exp Psychol,  59: 361–376.  <ul class="find" data-citedArticleID="991772" data-doi="10.1080/17470210500173232"><li><a href="http://dx.doi.org/10.1080/17470210500173232" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Mental+representation+in+visual%2Fhaptic+crossmodal+memory%3A+Evidence+from+interference+effects." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Mental+representation+in+visual%2Fhaptic+crossmodal+memory%3A+Evidence+from+interference+effects.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">10.
              </span><a name="pone.0000890-Freides1" id="pone.0000890-Freides1"></a>Freides D (1974) Human information processing and sensory modality: Cross-modal functions, information complexity, memory, and deficit. Psychol Bull,  8: 284–310.  <ul class="find" data-citedArticleID="991754" data-doi="10.1037/h0036331"><li><a href="http://dx.doi.org/10.1037/h0036331" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Human+information+processing+and+sensory+modality%3A+Cross-modal+functions%2C+information+complexity%2C+memory%2C+and+deficit." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Human+information+processing+and+sensory+modality%3A+Cross-modal+functions%2C+information+complexity%2C+memory%2C+and+deficit.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">11.
              </span><a name="pone.0000890-Casey1" id="pone.0000890-Casey1"></a>Casey SJ, Newell FN (2005) The role of long-term and short-term familiarity in visual and haptic face recognition. Exp Brain Res,  166: 583–591.  <ul class="find" data-citedArticleID="991752" data-doi="10.1007/s00221-005-2398-3"><li><a href="http://dx.doi.org/10.1007/s00221-005-2398-3" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+role+of+long-term+and+short-term+familiarity+in+visual+and+haptic+face+recognition." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+role+of+long-term+and+short-term+familiarity+in+visual+and+haptic+face+recognition.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">12.
              </span><a name="pone.0000890-Newell2" id="pone.0000890-Newell2"></a>Newell FN, Woods AT, Mernagh M, Bulthoff HH (2005) Visual, haptic and crossmodal recognition of scenes. Exp Brain Res,  161: 233–242.  <ul class="find" data-citedArticleID="991778" data-doi="10.1007/s00221-004-2067-y"><li><a href="http://dx.doi.org/10.1007/s00221-004-2067-y" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Visual%2C+haptic+and+crossmodal+recognition+of+scenes." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Visual%2C+haptic+and+crossmodal+recognition+of+scenes.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">13.
              </span><a name="pone.0000890-Norman1" id="pone.0000890-Norman1"></a>Norman JF, Norman HF, Clayton AM, Lianekhammy J, Zielke G (2004) The visual and haptic perception of natural object shape. Percept Psychophys,  66: 342–351.  <ul class="find" data-citedArticleID="991782" data-doi="10.3758/bf03194883"><li><a href="http://dx.doi.org/10.3758/bf03194883" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+visual+and+haptic+perception+of+natural+object+shape." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+visual+and+haptic+perception+of+natural+object+shape.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">14.
              </span><a name="pone.0000890-Bushnell1" id="pone.0000890-Bushnell1"></a>Bushnell EW, Baxt C (1999) Children's haptic and cross-modal recognition with familiar and unfamiliar objects. J Exp Psychol Human,  25: 1867–1881.  <ul class="find" data-citedArticleID="991750" data-doi="10.1037/0096-1523.25.6.1867"><li><a href="http://dx.doi.org/10.1037/0096-1523.25.6.1867" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Children%27s+haptic+and+cross-modal+recognition+with+familiar+and+unfamiliar+objects." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Children%27s+haptic+and+cross-modal+recognition+with+familiar+and+unfamiliar+objects.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">15.
              </span><a name="pone.0000890-Newell3" id="pone.0000890-Newell3"></a>Newell KM, Shapiro DC, Carlton MJ (1979) Coordinating visual and kinaesthetic memory codes. Brit J Psychol,  70: 87–96.  <ul class="find" data-citedArticleID="991780" data-doi="10.1111/j.2044-8295.1979.tb02147.x"><li><a href="http://dx.doi.org/10.1111/j.2044-8295.1979.tb02147.x" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Coordinating+visual+and+kinaesthetic+memory+codes." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Coordinating+visual+and+kinaesthetic+memory+codes.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">16.
              </span><a name="pone.0000890-Riesenhuber1" id="pone.0000890-Riesenhuber1"></a>Riesenhuber M, Poggio T (1999) Hierarchical models of object recognition in cortex. Nature Neurosci,  2: 1019–1025.  <ul class="find" data-citedArticleID="991792" data-doi="10.1038/14819"><li><a href="http://dx.doi.org/10.1038/14819" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Hierarchical+models+of+object+recognition+in+cortex." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Hierarchical+models+of+object+recognition+in+cortex.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">17.
              </span><a name="pone.0000890-Tarr1" id="pone.0000890-Tarr1"></a>Tarr MJ, Bulthoff HH (1995) Is human object recognition better described by geon structural descriptions or by multiple views: Comment on Biederman and Gerhardstein (1993). J Exp Psychol Human,  21: 1494–1505.  <ul class="find" data-citedArticleID="991794" data-doi="10.1037//0096-1523.21.6.1494"><li><a href="http://dx.doi.org/10.1037//0096-1523.21.6.1494" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Is+human+object+recognition+better+described+by+geon+structural+descriptions+or+by+multiple+views%3A+Comment+on+Biederman+and+Gerhardstein+%281993%29." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Is+human+object+recognition+better+described+by+geon+structural+descriptions+or+by+multiple+views%3A+Comment+on+Biederman+and+Gerhardstein+%281993%29.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">18.
              </span><a name="pone.0000890-Biederman1" id="pone.0000890-Biederman1"></a>Biederman I (1987) Recognition-by-components: A theory of human image understanding. Psychol Rev,  94: 115–147.  <ul class="find" data-citedArticleID="991746" data-doi="10.1037//0033-295x.94.2.115"><li><a href="http://dx.doi.org/10.1037//0033-295x.94.2.115" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Recognition-by-components%3A+A+theory+of+human+image+understanding." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Recognition-by-components%3A+A+theory+of+human+image+understanding.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">19.
              </span><a name="pone.0000890-Amedi1" id="pone.0000890-Amedi1"></a>Amedi A, Malach R, Hendler T, Peled S, Zohary E (2001) Visuo-haptic object-related activation in the ventral pathway. Nature Neurosci,  4: 324–330.  <ul class="find" data-citedArticleID="991744" data-doi="10.1038/85201"><li><a href="http://dx.doi.org/10.1038/85201" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Visuo-haptic+object-related+activation+in+the+ventral+pathway." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Visuo-haptic+object-related+activation+in+the+ventral+pathway.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">20.
              </span><a name="pone.0000890-James1" id="pone.0000890-James1"></a>James TW, Humphrey GK, Gati JS, Servos P, Menon RS, et al.  (2002) Haptic study of three-dimensional objects activates extrastriate visual areas. Neuropsychologia,  40: 1706–1714.  <ul class="find" data-citedArticleID="991762" data-doi="10.1016/s0028-3932(02)00017-9"><li><a href="http://dx.doi.org/10.1016/s0028-3932(02)00017-9" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Haptic+study+of+three-dimensional+objects+activates+extrastriate+visual+areas." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Haptic+study+of+three-dimensional+objects+activates+extrastriate+visual+areas.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">21.
              </span><a name="pone.0000890-Zhang1" id="pone.0000890-Zhang1"></a>Zhang M, Weisser VD, Stilla R, Prather SC, Sathian K (2004) Multisensory cortical processing of shape and its relation to mental imagery. Cogn Affect Behav Ne,  4: 251–259.  <ul class="find" data-citedArticleID="991796" data-doi="10.3758/cabn.4.2.251"><li><a href="http://dx.doi.org/10.3758/cabn.4.2.251" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Multisensory+cortical+processing+of+shape+and+its+relation+to+mental+imagery." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Multisensory+cortical+processing+of+shape+and+its+relation+to+mental+imagery.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">22.
              </span><a name="pone.0000890-Peltier1" id="pone.0000890-Peltier1"></a>Peltier S, Stilla R, Mariola E, LaConte S, Hu X, et al.  (2007) Activity and effective connectivity of parietal and occipital cortical regions during haptic shape perception. Neuropsychologia,  45: 476–483.  <ul class="find" data-citedArticleID="991786" data-doi="10.1016/j.neuropsychologia.2006.03.003"><li><a href="http://dx.doi.org/10.1016/j.neuropsychologia.2006.03.003" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Activity+and+effective+connectivity+of+parietal+and+occipital+cortical+regions+during+haptic+shape+perception." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Activity+and+effective+connectivity+of+parietal+and+occipital+cortical+regions+during+haptic+shape+perception.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">23.
              </span><a name="pone.0000890-James2" id="pone.0000890-James2"></a>James TW, Humphrey GK, Gati JS, Menon RS, Goodale MA (2002) Differential effects of viewpoint on object-driven activation in dorsal and ventral streams. Neuron,  35: 793–801.  <ul class="find" data-citedArticleID="991764" data-doi="10.1016/s0896-6273(02)00803-6"><li><a href="http://dx.doi.org/10.1016/s0896-6273(02)00803-6" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Differential+effects+of+viewpoint+on+object-driven+activation+in+dorsal+and+ventral+streams." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Differential+effects+of+viewpoint+on+object-driven+activation+in+dorsal+and+ventral+streams.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">24.
              </span><a name="pone.0000890-GrillSpector1" id="pone.0000890-GrillSpector1"></a>Grill-Spector K, Kushnir T, Edelman S, Avidan G, Itzchak Y, et al.  (1999) Differential processing of objects under various viewing conditions in the human lateral occipital complex. Neuron,  24: 187–203.  <ul class="find" data-citedArticleID="991758" data-doi="10.1016/s0896-6273(00)80832-6"><li><a href="http://dx.doi.org/10.1016/s0896-6273(00)80832-6" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Differential+processing+of+objects+under+various+viewing+conditions+in+the+human+lateral+occipital+complex." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Differential+processing+of+objects+under+various+viewing+conditions+in+the+human+lateral+occipital+complex.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">25.
              </span><a name="pone.0000890-Pasqualotto1" id="pone.0000890-Pasqualotto1"></a>Pasqualotto A, Finucane C, Newell FN (2005) Visual and haptic representations of scenes are updated with observer movement. Exp Brain Res,  166: 481–488.  <ul class="find" data-citedArticleID="991784" data-doi="10.1007/s00221-005-2388-5"><li><a href="http://dx.doi.org/10.1007/s00221-005-2388-5" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Visual+and+haptic+representations+of+scenes+are+updated+with+observer+movement." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Visual+and+haptic+representations+of+scenes+are+updated+with+observer+movement.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">26.
              </span><a name="pone.0000890-Logothetis1" id="pone.0000890-Logothetis1"></a>Logothetis NK, Pauls J, Poggio T (1995) Shape representation in the inferior temporal cortex of monkeys. Curr Biol,  5: 552–563.  <ul class="find" data-citedArticleID="991774" data-doi="10.1016/s0960-9822(95)00108-4"><li><a href="http://dx.doi.org/10.1016/s0960-9822(95)00108-4" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Shape+representation+in+the+inferior+temporal+cortex+of+monkeys." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Shape+representation+in+the+inferior+temporal+cortex+of+monkeys.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">27.
              </span><a name="pone.0000890-Perrett1" id="pone.0000890-Perrett1"></a>Perrett DI, Smith PAJ, Potter DD, Mistlin AJ, Head AS, et al.  (1985) Visual cells in the temporal cortex sensitive to face view and gaze direction. Proc R Soc Lond B,  223: 293–317.  <ul class="find" data-citedArticleID="991788" data-doi="10.1098/rspb.1985.0003"><li><a href="http://dx.doi.org/10.1098/rspb.1985.0003" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Visual+cells+in+the+temporal+cortex+sensitive+to+face+view+and+gaze+direction." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Visual+cells+in+the+temporal+cortex+sensitive+to+face+view+and+gaze+direction.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li></ol></div>

  </div>

      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.XML" value="53559"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.PDF" value="192669"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g001.PNG_L" value="2518984"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g001.PNG_M" value="366538"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g001.PNG_S" value="12131"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g001.TIF" value="3130216"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g001.PNG_I" value="104812"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g002.PNG_L" value="39988"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g002.PNG_M" value="40804"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g002.PNG_S" value="10399"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g002.TIF" value="246180"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g002.PNG_I" value="14734"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g003.PNG_L" value="49539"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g003.PNG_M" value="45239"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g003.PNG_S" value="11168"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g003.TIF" value="313126"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g003.PNG_I" value="16506"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g004.PNG_L" value="46800"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g004.PNG_M" value="28719"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g004.PNG_S" value="9014"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g004.TIF" value="286972"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g004.PNG_I" value="9729"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g005.PNG_L" value="1391534"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g005.PNG_M" value="121076"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g005.PNG_S" value="14684"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g005.TIF" value="2109616"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0000890.g005.PNG_I" value="41654"/>

</div>
<div class="sidebar">

  <div class="article-actions cf">
      <div class="download">
        <span class="btn"><a href="/article/fetchObject.action?uri=info%3Adoi%2F10.1371%2Fjournal.pone.0000890&amp;representation=PDF" title="Download" target="_blank">Download PDF</a></span>
      </div>
      <div class="btn-reveal dropdown">
        <div class="dropdown-icon">
          <span class="btn">&nbsp;</span>
        </div>

        <div class="content">
          <ul class="bullet">
            <li><a href="/article/citationList.action?articleURI=info%3Adoi%2F10.1371%2Fjournal.pone.0000890" title="Download citations">Citation</a></li>
            <li><a href="/article/fetchObjectAttachment.action?uri=info%3Adoi%2F10.1371%2Fjournal.pone.0000890&amp;representation=XML" title="Download article XML">XML</a></li>
          </ul>
        </div>
      </div> <!-- end btn-reveal dropdown-->


    <div class="btn-reveal flt-l">
        <span class="btn">Print</span>
        <div class="content">
            <ul class="bullet">
                <li id="print-article"><a href="#" onclick="if(typeof(_gaq) != 'undefined'){ _gaq.push(['_trackEvent','Article', 'Print', 'Click']); } window.print(); return false;" title="Print Article">Print article</a></li>
                <li>
                  <a href="https://www.odysseypress.com/onlinehost/reprint_order.php?type=A&page=0&journal=7&doi=10.1371/journal.pone.0000890&volume=&issue=&title=Cross-Modal Object Recognition Is Viewpoint-Independent&author_name=Simon%20Lacey%2C%20Andrew%20Peters%2C%20K.%20Sathian&start_page=1&end_page=6" title="Odyssey Press">EzReprint</a>
                </li>
            </ul>
        </div>
    </div>

    <div class="btn-reveal flt-r">
        <span class="btn">Share</span>
        <div class="content">
            <ul class="social">
                <li><a href="http://www.reddit.com/submit?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0000890" target="_blank" title="Submit to Reddit"><img src="/images/icon.reddit.16.png" width="16" height="16" alt="Reddit">Reddit</a></li>

                <li><a href="https://plus.google.com/share?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0000890" target="_blank" title="Share on Google+"><img src="/images/icon.gplus.16.png" width="16" height="16" alt="Google+">Google+</a></li>

                <li><a href="http://www.stumbleupon.com/submit?url=http%3A%2F%2Fwww.plosone.org%2Farticle%2Finfo%253Adoi%252F10.1371%252Fjournal.pone.0000890" target="_blank" title="Add to StumbleUpon"><img src="/images/icon.stumble.16.png" width="16" height="16" alt="StumbleUpon">StumbleUpon</a></li>

                <li><a href="http://www.facebook.com/share.php?u=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0000890&amp;t=Cross-Modal%20Object%20Recognition%20Is%20Viewpoint-Independent" target="_blank" title="Share on Facebook"><img src="/images/icon.fb.16.png" width="16" height="16" alt="Facebook">Facebook</a></li>

                <li><a href="http://www.linkedin.com/shareArticle?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0000890&title=Cross-Modal%20Object%20Recognition%20Is%20Viewpoint-Independent&summary=Checkout%20this%20article%20I%20found%20at%20PLOS" target="_blank" title="Add to LinkedIn"><img src="/images/icon.linkedin.16.png" width="16" height="16" alt="Mendeley">LinkedIn</a></li>

                <li><a href="http://www.citeulike.org/posturl?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0000890&amp;title=Cross-Modal%20Object%20Recognition%20Is%20Viewpoint-Independent" target="_blank" title="Add to CiteULike"><img src="/images/icon.cul.16.png" width="16" height="16" alt="CiteULike">CiteULike</a></li>

                <li><a href="http://www.mendeley.com/import/?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0000890" target="_blank" title="Add to Mendeley"><img src="/images/icon.mendeley.16.png" width="16" height="16" alt="Mendeley">Mendeley</a></li>

                <li><a href="https://www.pubchase.com/library?add_aid=10.1371%2Fjournal.pone.0000890&amp;source=plos" target="_blank" title="Add to PubChase"><img src="/images/icon.pc.16.png" width="16" height="16" alt="PubChase">PubChase</a></li>


                <script type="text/javascript">
                    // replace tweet with one that's pre-shortened to 140 chars
                    function truncateTweetText() {
                        var twtTitle = 'Cross-Modal Object Recognition Is Viewpoint-Independent';
                        var twtUrl = 'http://dx.plos.org/10.1371/journal.pone.0000890';
                        // all URLs posted to twitter get auto-shortened to 20 chars.
                        var maxLength = 140 - (20 + 1);
                        // truncate the title to include space for twtTag and ellipsis (here, 10 = tag length + space + ellipsis)
                        if (twtTitle.length > maxLength) { twtTitle = twtTitle.substr(0, (maxLength - 10)) + '...'; }
                        // set the href to use the shortened tweet
                        $('#twitter-share-link').prop('href', 'http://twitter.com/intent/tweet?text=' + encodeURIComponent('#PLOSONE: ' + twtTitle + ' ' + twtUrl));
                    }
                </script>
                <li><a href="http://twitter.com/intent/tweet?text=#PLOSONE%3A%20Cross-Modal%20Object%20Recognition%20Is%20Viewpoint-Independent http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0000890" onclick="truncateTweetText();" target="_blank" title="Share on Twitter" id="twitter-share-link"><img src="/images/icon.twtr.16.png" width="16" height="16" alt="Twitter">Twitter</a></li>

                <li><a href="/article/email/info%3Adoi%2F10.1371%2Fjournal.pone.0000890" title="Email this article"><img src="/images/icon.email.16.png" width="16" height="16" alt="Email">Email</a></li>
            </ul>
        </div>
    </div><!--end btn-reveal flt-r-->
</div><!-- end article-actions-->

<!-- begin Crossmark -->

<a id="open-crossmark" href="#" style="margin-top: -28px; display:block"><img style="border: 0; display: none;
 padding: 10px 0 18px 0;"  id="crossmark-icon" src="/images/logo-crossmark-bw.png" /></a>
<div id="crossmark-dialog" style="display: none;" title="">
    <!-- the external CrossMark data is loaded inside this iframe -->
    <iframe id="crossmark-dialog-frame" frameborder="0"></iframe>
</div>

<!-- end crossmark -->


<div class="block" id="subject-area-sidebar-block">
    <div class="header">
        <h3>Subject Areas</h3><div title="More information" id="subject-area-sidebar-block-help-icon"><img align="right"
                                                                                                           alt="info" src="/images/button_info.png"/><div id="subject-area-sidebar-block-help"><img align="right"
                                                                                                                                                                                                    src="/images/button_info.png"/><p>
        <b>We want your feedback.</b> Do these subject areas make sense for this article? If not, click the flag
        next to the incorrect subject area and we will review it. Thanks for your help!
    </p></div></div>
    </div>


    <ul id="subject-area-sidebar-list">

























          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Analysis+of+variance%22" title="Search for articles in the subject area:'Analysis of variance'"><div class="flagText">Analysis of variance</div></a>
              <div data-categoryid="42193" data-articleid="24618"
                   data-categoryname="Analysis of variance"
                   class="flagImage" title="Flag 'Analysis of variance' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Face+recognition%22" title="Search for articles in the subject area:'Face recognition'"><div class="flagText">Face recognition</div></a>
              <div data-categoryid="32737" data-articleid="24618"
                   data-categoryname="Face recognition"
                   class="flagImage" title="Flag 'Face recognition' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Learning%22" title="Search for articles in the subject area:'Learning'"><div class="flagText">Learning</div></a>
              <div data-categoryid="20059" data-articleid="24618"
                   data-categoryname="Learning"
                   class="flagImage" title="Flag 'Learning' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Neural+networks%22" title="Search for articles in the subject area:'Neural networks'"><div class="flagText">Neural networks</div></a>
              <div data-categoryid="1931" data-articleid="24618"
                   data-categoryname="Neural networks"
                   class="flagImage" title="Flag 'Neural networks' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Neurons%22" title="Search for articles in the subject area:'Neurons'"><div class="flagText">Neurons</div></a>
              <div data-categoryid="17179" data-articleid="24618"
                   data-categoryname="Neurons"
                   class="flagImage" title="Flag 'Neurons' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Object+recognition%22" title="Search for articles in the subject area:'Object recognition'"><div class="flagText">Object recognition</div></a>
              <div data-categoryid="20057" data-articleid="24618"
                   data-categoryname="Object recognition"
                   class="flagImage" title="Flag 'Object recognition' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Touch%22" title="Search for articles in the subject area:'Touch'"><div class="flagText">Touch</div></a>
              <div data-categoryid="21651" data-articleid="24618"
                   data-categoryname="Touch"
                   class="flagImage" title="Flag 'Touch' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Vision%22" title="Search for articles in the subject area:'Vision'"><div class="flagText">Vision</div></a>
              <div data-categoryid="17177" data-articleid="24618"
                   data-categoryname="Vision"
                   class="flagImage" title="Flag 'Vision' as inappropriate"></div>
          </li>
    </ul>
</div>

<div class="ad">
    <div class="title">Advertisement</div>






  <iframe id='a0852f54' name='a0852f54'
    src='http://ads.plos.org/www/delivery/afr.php?zoneid=381&amp;cb=6959'
    frameborder='0' scrolling='no' width='160' height='600'>
    <a href='http://ads.plos.org/www/delivery/ck.php?n=a0852f54&amp;cb=2433'
      target='_top'><img src='http://ads.plos.org/www/delivery/avw.php?zoneid=381&amp;cb=7776&amp;n=a0852f54'
      border='0' alt=''/>
    </a>
  </iframe>



</div>

<div id="twitter-alm-timeline" class="twitter-alm-timeline"></div>


</div><!-- sidebar -->
    </div>
  </div>
</div>
<script src="http://wl.figshare.com/static/p_widget.js" type="text/javascript"></script><div id="pageftr">
  <div class="ftr-cols cf">
    <div class="col col-1">
      <img src="/images/logo-plos-footer.png" alt="PLOS Logo" class="logo" />
      <p><a href="/static/releaseNotes">Ambra 2.9.16</a> Managed Colocation provided <br />by <a href="http://www.isc.org/">Internet Systems Consortium</a>.<p>
      <div class="nav nav-aux">
        <a href="/static/privacy">Privacy Policy</a> |
        <a href="/static/terms">Terms of Use</a> |
        <a href="http://www.plos.org/advertise/">Advertise</a> |
        <a href="http://www.plos.org/about/media-inquiries/">Media Inquiries</a>
      </div>
    </div>
    <div class="col col-2">
      <p><a href="http://www.plos.org/publications/journals/">Publications</a></p>
      <div class="nav">
        <ul>
          <li><a href="http://www.plosbiology.org">PLOS Biology</a></li>
          <li><a href="http://www.plosmedicine.org">PLOS Medicine</a></li>
          <li><a href="http://www.ploscompbiol.org">PLOS Computational Biology</a></li>
          <li><a href="http://currents.plos.org">PLOS Currents</a></li>
          <li><a href="http://www.plosgenetics.org">PLOS Genetics</a></li>
          <li><a href="http://www.plospathogens.org">PLOS Pathogens</a></li>
          <li><a href="http://www.plosone.org">PLOS ONE</a></li>
          <li><a href="http://www.plosntds.org">PLOS Neglected Tropical Diseases</a></li>
        </ul>
      </div>
    </div>
    <div class="col col-3">
      <div class="nav">
        <p><a href="http://www.plos.org">plos.org</a></p>
        <p><a href="http://blogs.plos.org">Blogs</a></p>
        <p><a href="http://www.ploscollections.org">Collections</a></p>
        <p><a href="/feedback/new">Send us feedback</a></p>

        <p>California (US) corporation #C2354500, based in San Francisco</p>
      </div>
    </div>
  </div>
</div><!-- pageftr -->

</div><!-- end page-wrap, this div is in header.ftl -->
<script type="text/javascript" src="/javascript/jquery-1.8.1-min.js?v=Tm7VCOzZz3lE03ghpkS6SWkHbyI"></script>
<script type="text/javascript" src="/javascript/ga-min.js?v=lNQ4gt8QcPDatjsdOFl_FGpPhLY"></script>
<script type="text/javascript" src="/javascript/jquery.hoverIntent-min.js?v=mRiGNYY9cIXxVb8u0K_MdW7hHnc"></script>
<script type="text/javascript" src="/javascript/jquery.placeholder-min.js?v=21Pn56Ur9h1N4K4VZDa0nqI3Pxo"></script>
<script type="text/javascript" src="/javascript/jquery.jsonp-2.4.0-min.js?v=lqTpzoHfSq3I5Ygo01qq5WankEo"></script>
<script type="text/javascript" src="/javascript/jquery-ui-1.9.2.custom-min.js?v=raSSlfNO0YsV5uUpAKmTB9n5VTc"></script>
<script type="text/javascript" src="/javascript/jquery.tooltip-min.js?v=cw+6Smh+mdryIA25xvqIvHMrnZM"></script>
<script type="text/javascript" src="/javascript/jquery.uniform-min.js?v=kYUAnX6W2W_2fK3RIuQ2m_YFG9U"></script>
<script type="text/javascript" src="/javascript/jquery.pjax-min.js?v=939kLBjL5_YKbx71T1RHjYaD4l8"></script>
<script type="text/javascript" src="/javascript/imagesloaded-min.js?v=XeuAp8Gc3mvQUo+wZCSF8ttPwvw"></script>
<script type="text/javascript" src="/javascript/figviewer-min.js?v=yPUa0sUQ_iHkI+IRv2i9bjyZJFo"></script>
<script type="text/javascript" src="/javascript/global-min.js?v=0Q3PwjeaWtXYDnqIsQvnL_ou0qs"></script>
<script type="text/javascript" src="/javascript/jquery.touchswipe-min.js?v=huaek_e6HqTduvCNAN91dJolTyw"></script>
<script type="text/javascript" src="/javascript/jquery.base64-min.js?v=VwV1zeVqKZj5FCAdlK0q5NRxbBg"></script>
<script type="text/javascript" src="/javascript/alm-min.js?v=Y5gm6B0b4Kx2YHNObNrgEeBgXlY"></script>
<script type="text/javascript" src="/javascript/taxonomy-browser-min.js?v=vBVMuDMYkGJCXIUxLe35GoyiJNw"></script>
<script type="text/javascript" src="/javascript/jquery.filterize-min.js?v=j0ZKVnHyk2nhFy8eIuNJkp7xaM0"></script>
<script type="text/javascript" src="/javascript/plosone-min.js?v=TK4H4arL_XBSwwJq+K1N3kqYfAI"></script>
<script type="text/javascript" src="/javascript/twitter-min.js?v=xKgcxLsQFXy+at1ao1NVke8nFlM"></script>
<script type="text/javascript" src="/javascript/crossmark.1.4-min.js?v=3FO4k0SjwTaGNnKGNSqthar1080"></script>
<script type="text/javascript">
  var _sf_async_config={uid:16579,domain:"plosone.org"};
  (function(){
    function loadChartbeat() {
      window._sf_endpt=(new Date()).getTime();
      var e = document.createElement('script');
      e.setAttribute('language', 'javascript');
      e.setAttribute('type', 'text/javascript');
      e.setAttribute('src',
          (("https:" == document.location.protocol) ? "https://a248.e.akamai.net/chartbeat.download.akamai.com/102508/" : "http://static.chartbeat.com/") +
              "js/chartbeat.js");
      document.body.appendChild(e);
    }
    var oldonload = window.onload;
    window.onload = (typeof window.onload != 'function') ?
        loadChartbeat : function() { oldonload(); loadChartbeat(); };
  })();
</script>
<!-- <script type="application/javascript" src="http://crossmark.crossref.org/javascripts/v1.3/crossmark.min.js"></script> -->

</body>
</html>
