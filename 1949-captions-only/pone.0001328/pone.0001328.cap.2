                </a></li></ul></div><p><strong>Figure 2.  <span>Information theoretical analysis.</span></strong></p><a id="article1.body1.sec2.sec1.fig1.caption1.p1" name="article1.body1.sec2.sec1.fig1.caption1.p1"></a><p>A S(f), the power spectral density of the signal (mean response, solid lines), and N(f), the power spectral density of noise (dashed lines), normalized to the signal or noise mean square amplitude. The inset assigns different colors to the different stimulus contrasts. B Signal-to-noise ratios at the six different contrasts used (same color code as in A). Dashed line indicates SNR of 1. C Shannon information as function of frequency at different contrasts (same color code as in A). Information estimated from signal-to-noise ratio as: log<sub>2</sub>[1+S(f)/N(f)]. All spectra were smoothed using a 4 point running average. D Shannon information capacity as a function of contrast; average Â±95% confidence interval (N = 12). At the 0.31 contrast 14 additional cells were analyzed. Abscissa is interrupted to display zero contrast on the logarithmic scale. Arrow marks the contrast induced by photon shot noise at the mean light intensity. Inset shows the dependence of the information capacity on the amount of data analyzed. The information capacities shown were calculated at zero contrast by using different numbers of trials to estimate the SNR.</p>
