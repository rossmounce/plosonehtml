
<h4>Data extraction</h4>
<a id="article1.body1.sec2.sec3.p1" name="article1.body1.sec2.sec3.p1"></a><p>We created and piloted a data extraction form with a subset of eligible studies. Based upon experience gained in the pilot study, the data extraction form was finalized. The final set of studies was assessed with the standardized form by two reviewers (DIL and LLF), and any differences were resolved by consensus. Many articles compared NAAT results to more than one reference standard, and we used a hierarchical approach to choose one comparison from each study: (1) culture result plus clinical data (most preferred reference standard) (2) culture result alone and (3) clinical data alone (least preferred reference standard). We used the specimen as the unit of analysis when possible. We also chose to use data that were not subject to discrepant analyses (i.e. unresolved data) when available, since resolved data after discrepant analyses are a potential source of bias and result in higher estimates of accuracy <a href="#pone.0001536-Hadgu1">[126]</a>. In addition, NTM and inhibited specimens were excluded if possible.</p>


<h4>Assessment of study quality</h4>
<a id="article1.body1.sec2.sec4.p1" name="article1.body1.sec2.sec4.p1"></a><p>We assessed the quality of studies using the following criteria, suggested as important for diagnostic studies <a href="#pone.0001536-Whiting1">[127]</a>: (1) Was there a comparison of the commercial NAAT with an independent, appropriate reference standard? (2) Was the NAAT result interpreted without knowledge of the results of the reference standard (blinded interpretation) and vice-versa? (3) Did the whole sample or a randomly selected subset of the sample receive verification using the reference standard? and (4) Did the study prospectively recruit consecutive patients suspected of having pulmonary tuberculosis (i.e. cross-sectional vs case-control design)?</p>


<h4>Data synthesis and meta-analysis</h4>
<a id="article1.body1.sec2.sec5.p1" name="article1.body1.sec2.sec5.p1"></a><p>Data were analyzed using Meta-Disc (version 1.4) software <a href="#pone.0001536-ZamoraJ1">[128]</a>. We pooled the data with the DerSimonian-Laird random effects model (REM) <a href="#pone.0001536-Deville1">[20]</a>, <a href="#pone.0001536-Collaboration1">[129]</a>–<a href="#pone.0001536-Pai7">[131]</a>. The REM gives more conservative estimates with wider confidence intervals because it assumes that the meta-analysis includes only a sample of all possible studies <a href="#pone.0001536-Egger1">[19]</a>, <a href="#pone.0001536-3">[132]</a>, <a href="#pone.0001536-Lau1">[133]</a>. In addition, the REM accounts for both within-study variability (random error) and between-study variability (heterogeneity). Accuracy measures include: sensitivity, specificity, positive likelihood ratio (LR+), negative likelihood ratio (LR-), and the diagnostic odds ratio (DOR). Sensitivity is the proportion of positive test results among those with the target disease. Specificity is the proportion of negative test results among those without the disease. In a clinical setting, likelihood ratios are considered useful. The LR+ measures how much more frequent a positive test is found in diseased versus non-diseased individuals. On the other hand, the LR- measures how more likely a negative result is found in diseased versus non-diseased individuals. The DOR, or the odds of a positive result in diseased individuals compared to the odds of a positive result in non-diseased individuals, combines both likelihood ratios and is a global measure of test performance <a href="#pone.0001536-Glas1">[134]</a>. A value of 1 would indicate that the test cannot discriminate between people with and without disease. The DOR is calculated by <em>LR+/LR−</em> or <em>[sensitivity/(1-specificity)]/[(1-sensit​ivity)/specificity]</em> <a href="#pone.0001536-Glas1">[134]</a>.</p>
<a id="article1.body1.sec2.sec5.p2" name="article1.body1.sec2.sec5.p2"></a><p>Each study in the meta-analysis contributed a pair of numbers: sensitivity and specificity. Since these measures tend to be strongly correlated and vary with the thresholds (cut-off values for determining test positives) used across the individual studies, it is standard practice to analyze sensitivity and specificity proportions as pairs, and to also explore the effect of the threshold on study results. To do this, we performed the summary receiver operating characteristic (SROC) curve analysis <a href="#pone.0001536-Pai7">[131]</a>, <a href="#pone.0001536-Littenberg1">[135]</a>. The SROC displays each study's sensitivity and specificity estimates within the ROC space. A regression curve is fitted through the distribution of pairs of sensitivity and specificity. A shoulder-like curve indicates that the variability between studies may be due to the threshold effect (i.e. variation in cut-off values used across studies) and that an underlying common DOR exists that does not change with the threshold <a href="#pone.0001536-Deeks1">[130]</a>, <a href="#pone.0001536-Littenberg1">[135]</a>, <a href="#pone.0001536-Irwig1">[136]</a>. A non shoulder-like curve shows that sensitivity and specificity are not correlated. The area under the regression curve also measures the overall accuracy of diagnostic tests. If the area under the curve (AUC) is 100%, then the test differentiates perfectly between diseased and non-diseased individuals. An AUC of 50% indicates poor diagnostic accuracy <a href="#pone.0001536-Deeks1">[130]</a>, <a href="#pone.0001536-Littenberg1">[135]</a>, <a href="#pone.0001536-Irwig1">[136]</a>.</p>


<h4>Meta-regression</h4>
<a id="article1.body1.sec2.sec6.p1" name="article1.body1.sec2.sec6.p1"></a><p>Heterogeneity in meta-analysis refers to a high degree of variability in study results (e.g. variability in sensitivity estimates). Such heterogeneity could be due to variability in thresholds (cut-off values), disease spectrum and populations studied, variations in NAAT protocols, and study quality across studies. When significant heterogeneity is present, summary estimates from meta-analyses are hard to interpret. We investigated heterogeneity using subgroup (stratified) analysis and meta-regression analysis <a href="#pone.0001536-Lijmer1">[137]</a>. In the subgroup analysis, we computed pooled DOR estimates in various strata to determine if accuracy is higher in specific subgroups.</p>
<a id="article1.body1.sec2.sec6.p2" name="article1.body1.sec2.sec6.p2"></a><p>The meta-regression analysis is an extension of the SROC model <a href="#pone.0001536-Littenberg1">[135]</a>. In this linear regression model, studies are the units of analysis. The DOR is the outcome (dependent) variable. The independent variables are the covariates that might be associated with the variability in the DOR. Based on previous meta-analyses <a href="#pone.0001536-Pai5">[12]</a>–<a href="#pone.0001536-Flores1">[14]</a>, potentially relevant covariates for our meta-regression model included: prospective or retrospective study direction, recruitment method, blinded interpretation, type of test, specimen type, reference standard, and data resolution. There were insufficient numbers to compare categories of differing study design, degree of verification, and smear status.</p>
<a id="article1.body1.sec2.sec6.p3" name="article1.body1.sec2.sec6.p3"></a><p>The meta-regression model generates relative diagnostic odds ratios (RDOR) as the output <a href="#pone.0001536-Glas1">[134]</a>, <a href="#pone.0001536-Lijmer1">[137]</a>. An RDOR is a ratio of two DORs. An RDOR of 1.0 indicates that a particular covariate (e.g. blinded study design) does not affect the overall DOR. An RDOR &gt;1.0 indicates that studies with a particular characteristic (e.g. those that employed a specific target sequence in the PCR) have a higher DOR than studies without this characteristic. For a RDOR &lt;1.0, the reverse holds.</p>

</div>

<div id="section3" class="section"><a id="s3" name="s3" toc="s3" title="Results"></a><h3>Results</h3><a id="article1.body1.sec3.p1" name="article1.body1.sec3.p1"></a><p>The average sample size of the included studies was 715 (range 57–7539). With the exception of one study, all of our studies were cross-sectional. A majority (86%) of the studies were prospective in design. A total of 45 (36%) studies used consecutive or random sampling, while 29 (23%) studies recruited patients using some convenient sampling. The convenient sample was chosen from a bigger group of patients or was selected from a screening program. All but two studies reported complete verification of NAAT results with the same reference standard. Most of the studies (96%) collected both smear-positive and smear-negative specimens, and 84% compared NAAT results to culture as the reference standard. Ninety-five (76%) studies tested respiratory specimens, while 30 (24%) studies only used sputum specimens. We were able to analyze unresolved data (i.e. not subjected to discrepant analyses) in 88 (70%) studies. Past evidence has shown that investigators do not report all the study components in their publications <a href="#pone.0001536-Pai2">[6]</a>, <a href="#pone.0001536-Rutjes1">[138]</a>. In our analysis, 103 (82%) studies did not report blinding status, and 51 (41%) studies did not explicitly report the method of patient recruitment. <a href="#pone-0001536-t002">Table 2</a> gives the characteristics of the studies in our meta-analysis.</p>
<div class="figure" id="pone-0001536-t002"><div class="img"><a name="pone-0001536-t002" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001536.t002&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001536" data-uri="info:doi/10.1371/journal.pone.0001536.t002"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001536.t002&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001536.t002/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001536.t002/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001536.t002/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001536.t002/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001536.t002.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001536.t002/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001536.t002/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001536.t002.TIF"></span>)
