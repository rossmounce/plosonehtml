                </a></li></ul></div><p><strong>Figure 3.  <span>Information-based conceptual schema for measuring memory in microbes.</span></strong></p><a id="article1.body1.sec2.sec1.sec2.fig1.caption1.p1" name="article1.body1.sec2.sec1.sec2.fig1.caption1.p1"></a><p>In communication theory (top), the informational entropy of the signal space H(<em>X</em>) captures the number of different messages <em>X</em> that can be communicated and their probabilistic dispersal; the mutual information I(<em>X,Y</em>) between transmitted and received signals quantifies the amount of information actually communicated. A memory experiment, in contrast, involves subjecting cells to distinct treatments <em>M</em> prior to time t0, followed by an identical treatment <em>S</em> after time t0, with cell behavior from t0 on monitored through temporal sampling of one or more observable variables <em>Y</em>. As applied to bacterial memory (bottom), the informational entropy of the cell history space H(<em>M</em>) captures the number of different cell histories prior to time t0 tested by the experimental compendium and their probabilistic dispersal; the mutual information I<sub>trans</sub>(<em>M;Y;t<sub>trans</sub></em>) between the transient response of the observable variable <em>Y</em> after time t0 and the cell history prior to time t0 captures the short-term memory of cell history exhibited by <em>Y</em> over the cell history space in response to treatment <em>S</em>. Likewise, the mutual information I<sub>asym</sub>(<em>M,Y</em>) between the long-term response of <em>Y</em> and cell history prior to t0 captures the long-term memory of cell history exhibited by <em>Y</em>.</p>
