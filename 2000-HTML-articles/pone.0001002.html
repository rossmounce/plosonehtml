

 



<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"
      xmlns:foaf="http://xmlns.com/foaf/0.1/"
      xmlns:dc="http://purl.org/dc/terms/"
      xmlns:doi="http://dx.doi.org/"
      xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
      xmlns:xsd="http://www.w3.org/2001/XMLSchema-datatypes#"
      lang="en" xml:lang="en"
      itemscope itemtype="http://schema.org/Article"
      class="no-js">
<head prefix="og: http://ogp.me/ns#">
  <title>PLOS ONE: Optimality Driven Nearest Centroid Classification from Genomic Data</title>


<link rel="stylesheet" type="text/css"  href="/css/global-min.css?v=izteQ6tu7kgsJZW_xmrYizvKiHM" />


    <!--[if lte IE 7]>
<link rel="stylesheet" type="text/css"  href="/css/lte_ie7-min.css?v=3bykQUyQmReeuobVyPozcJ9LxRc" />
    <![endif]-->


<link rel="stylesheet" type="text/css"  href="/css/jquery-ui-min.css?v=eXDHTEJM0lIAmDe5k0I0Ad4nxNo" />


<link rel="stylesheet" type="text/css"  href="/css/journal.css?v=T7ZVxJfgk9jNxLAJ2qHz1vZpgYU" />


<link rel="stylesheet" type="text/css" media="print" href="/css/print-min.css?v=T5lb0B3q6EXBsuDluc5V5w+AkRc" />


  <link rel="stylesheet" href="http://f.fontdeck.com/s/css/js/www.plosone.org/24557.css" type="text/css"/>

  <!--chartbeat -->
  <script type="text/javascript">var _sf_startpt = (new Date()).getTime()</script>
  <script>document.documentElement.className += ' js';</script>

  <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <meta http-equiv="X-UA-Compatible" content="IE=EmulateIE7; IE=EmulateIE9"/>
  <meta name="description" content="PLOS ONE: an inclusive, peer-reviewed, open-access resource from the PUBLIC LIBRARY OF SCIENCE. Reports of well-performed scientific studies from all disciplines freely available to the whole world."/>
  <meta name="keywords" content="PLOS, Public Library of Science, Open Access, Open-Access, Science, Medicine, Biology, Research, Peer-review, Inclusive, Interdisciplinary, Ante-disciplinary, Physics, Chemistry, Engineering"/>
  <meta name="almHost" content="http://alm.plos.org/api/v3/articles"/>
  <meta name="searchHost" content="http://api.plos.org/search" />
  <meta name="termsHost" content="http://api.plos.org/terms" />
  <meta name="solrApiKey" content="plos"/>
  <meta name="almAPIKey" content="3pezRBRXdyzYW6ztfwft" />
  <meta name="currentJournal" content="PLoSONE" />
  <meta name="almRequestBatchSize" content="" />

  <meta name="citation_publisher" content="Public Library of Science"/>
  <meta name="citation_doi" content="10.1371/journal.pone.0001002"/>
  <meta name="dc.identifier" content="10.1371/journal.pone.0001002" />

    <meta name="citation_title" content="Optimality Driven Nearest Centroid Classification from Genomic Data"/>
    <meta itemprop="name" content="Optimality Driven Nearest Centroid Classification from Genomic Data"/>

      <meta name="citation_author" content="Alan R. Dabney"/>
            <meta name="citation_author_institution" content="Department of Statistics, Texas A&M University, College Station, Texas, United States of America"/>
      <meta name="citation_author" content="John D. Storey"/>
            <meta name="citation_author_institution" content="Department of Biostatistics, University of Washington, Seattle, Washington, United States of America"/>
            <meta name="citation_author_institution" content="Department of Genome Sciences, University of Washington, Seattle, Washington, United States of America"/>

    <meta name="citation_date" content="2007/10/3"/>

  <meta name="citation_pdf_url" content="http://dx.plos.org/10.1371/journal.pone.0001002.pdf" />

      <meta name="citation_journal_title" content="PLOS ONE" />
    <meta name="citation_firstpage" content="e1002"/>
    <meta name="citation_issue" content="10"/>
    <meta name="citation_volume" content="2"/>
    <meta name="citation_issn" content="1932-6203"/>

    <meta name="citation_journal_abbrev" content="PLoS ONE" />

      <meta name="citation_reference" content="citation_author=K Mardia; citation_author=J Kent; citation_author=J Bibby; citation_number=1; citation_date=1979; citation_publisher=Academic Press; " />
      <meta name="citation_reference" content="citation_title=Comparison of discriminant methods for the classification of tumors using gene expression data.; citation_author=S Dudoit; citation_author=J Fridlyand; citation_author=T Speed; citation_journal_title=Journal of the American Statistical Association; citation_volume=97; citation_number=2; citation_pages=77-87; citation_date=2002; " />
      <meta name="citation_reference" content="citation_title=An extensive comparison of recent classification tools applied to microarray data.; citation_author=JW Lee; citation_author=JB Lee; citation_author=M Park; citation_author=SH Song; citation_journal_title=Computational Statistics and Data Analysis; citation_volume=48; citation_number=3; citation_pages=869-885; citation_date=2005; " />
      <meta name="citation_reference" content="citation_title=Least angle regression.; citation_author=B Efron; citation_author=T Hastie; citation_author=I Johnstone; citation_author=R Tibshirani; citation_journal_title=Annals of Statistics (with discussion); citation_volume=32; citation_number=4; citation_pages=407-499; citation_date=2004; " />
      <meta name="citation_reference" content="citation_title=Variable selection techniques in discriminant analysis. I: Description.; citation_author=RJ McKay; citation_author=NA Campbell; citation_journal_title=British Journal of Mathematical and Statistical Psychology; citation_volume=35; citation_number=5; citation_pages=1-29; citation_date=1982; " />
      <meta name="citation_reference" content="citation_title=Variable selection techniques in discriminant analysis. II: Allocation.; citation_author=RJ McKay; citation_author=NA Campbell; citation_journal_title=British Journal of Mathematical and Statistical Psychology; citation_volume=35; citation_number=6; citation_pages=30-41; citation_date=1982; " />
      <meta name="citation_reference" content="citation_title=Molecular classification of cancer: Class discovery and class prediction by gene expression monitoring.; citation_author=T Golub; citation_author=D Slonim; citation_author=P Tamayo; citation_author=C Huard; citation_author=M Gaasenbeek; citation_journal_title=Science; citation_volume=286; citation_number=7; citation_pages=531-536; citation_date=1999; " />
      <meta name="citation_reference" content="citation_title=Gene expression profiles in hereditary breast cancer.; citation_author=I Hedenfalk; citation_author=D Duggan; citation_author=Y Chen; citation_author=M Radmacher; citation_author=M Bittner; citation_journal_title=New England Journal of Medicine; citation_volume=344; citation_number=8; citation_pages=539-548; citation_date=2001; " />
      <meta name="citation_reference" content="citation_title=Diagnosis of multiple cancer types by shrunken centroids of gene expression.; citation_author=R Tibshirani; citation_author=T Hastie; citation_author=B Narasimhan; citation_author=G Chu; citation_journal_title=Proceedings of the National Academy of Sciences; citation_volume=99; citation_number=9; citation_pages=6567-6572; citation_date=2002; " />
      <meta name="citation_reference" content="citation_title=New feature subset selection procedures for classification of expression profiles.; citation_author=TH Bø; citation_author=I Jonassen; citation_journal_title=Genome Biology; citation_volume=3; citation_number=10; citation_pages=R17; citation_date=2002; " />
      <meta name="citation_reference" content="citation_title=Classification of microarrays to nearest centroids.; citation_author=AR Dabney; citation_journal_title=Bioinformatics; citation_volume=21; citation_number=11; citation_pages=4148-4154; citation_date=2005; " />
      <meta name="citation_reference" content="citation_title=Some theory for Fisher's linear discriminant function, ‘naive Bayes’, and some alternatives when there are many more variables than observations.; citation_author=P Bickel; citation_author=E Levina; citation_journal_title=Bernoulli; citation_volume=10; citation_number=12; citation_pages=989-1010; citation_date=2004; " />
      <meta name="citation_reference" content="citation_title=ClaNC Software.; citation_number=13; " />
      <meta name="citation_reference" content="citation_title=Inadmissability of the usual estimator for the mean of a multivariate distribution.; citation_author=C Stein; citation_journal_title=Proc Third Berkeley Symp Math Statist Prob; citation_volume=1; citation_number=14; citation_pages=197-206; citation_date=1956; " />
      <meta name="citation_reference" content="citation_title=Optimal feature selection for nearest centroid classifiers, with applications to gene expression microarrays. UW Biostatistics Working Paper Series, Working Paper:267.; citation_author=AR Dabney; citation_author=JD Storey; citation_number=15; citation_date=2005; " />
      <meta name="citation_reference" content="citation_title=Eigengene-based linear discriminant model for tumor classification using gene expression microarray data.; citation_author=R Shen; citation_author=D Ghosh; citation_author=A Chinnaiyan; citation_author=Z Meng; citation_journal_title=Bioinformatics; citation_volume=22; citation_number=16; citation_pages=2635-2642; citation_date=2006; " />
      <meta name="citation_reference" content="citation_title=Regularized discriminant analysis and its application in microarrays.; citation_author=Y Guo; citation_author=T Hastie; citation_author=R Tibshirani; citation_journal_title=Biostatistics; citation_volume=8; citation_number=17; citation_pages=86-100; citation_date=2007; " />
      <meta name="citation_reference" content="citation_title=A shrinkage approach to large-scale covariance matrix estimation and implacations for functional genomics.; citation_author=J Schäfer; citation_author=K Strimmer; citation_journal_title=Statistical Applications in Genetics and Molecular Biology; citation_volume=4; citation_number=18; citation_date=2005; " />
      <meta name="citation_reference" content="citation_title=Selection bias in gene extraction on the basis of microarray gene expression data.; citation_author=C Ambroise; citation_author=GJ McLachlan; citation_journal_title=Proceedings of the National Academy of Sciences; citation_volume=99; citation_number=19; citation_pages=6562-6566; citation_date=2002; " />
      <meta name="citation_reference" content="citation_title=Classification and diagnostic prediction of cancers using gene expression profiling and artificial neural networks.; citation_author=J Khan; citation_author=J Wei; citation_author=M Ringner; citation_author=L Saal; citation_author=M Ladanyi; citation_journal_title=Nature Medicine; citation_volume=7; citation_number=20; citation_pages=673-679; citation_date=2001; " />
      <meta name="citation_reference" content="citation_title=Distinct types of diffuse large B-cell lymphoma identified by gene expression profiling.; citation_author=A Alizadeh; citation_author=M Eisen; citation_author=R Davis; citation_author=C Ma; citation_author=I Lossos; citation_journal_title=Nature; citation_volume=403; citation_number=21; citation_pages=503-511; citation_date=2000; " />
      <meta name="citation_reference" content="citation_title=Systematic variation in gene expression patterns in human cancer cell lines.; citation_author=D Ross; citation_author=U Scherf; citation_author=M Eisen; citation_author=C Perou; citation_author=C Rees; citation_journal_title=Nature Genetics; citation_volume=24; citation_number=22; citation_pages=227-235; citation_date=2000; " />

  <link rel="canonical" href="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0001002" />

    <meta name="twitter:card" content="summary"/>
    <meta name="twitter:site" content="@plosone"/>
    <meta name="twitter:title" content="Optimality Driven Nearest Centroid Classification from Genomic Data"/>
    <meta name="twitter:description" content="Nearest-centroid classifiers have recently been successfully employed in high-dimensional applications, such as in genomics. A necessary step when building a classifier for high-dimensional data is feature selection. Feature selection is frequently carried out by computing univariate scores for each feature individually, without consideration for how a subset of features performs as a whole. We introduce a new feature selection approach for high-dimensional nearest centroid classifiers that instead is based on the theoretically optimal choice of a given number of features, which we determine directly here. This allows us to develop a new greedy algorithm to estimate this optimal nearest-centroid classifier with a given number of features. In addition, whereas the centroids are usually formed from maximum likelihood estimates, we investigate the applicability of high-dimensional shrinkage estimates of centroids. We apply the proposed method to clinical classification based on gene-expression microarrays, demonstrating that the proposed method can outperform existing nearest centroid classifiers."/>
      <meta name="twitter:image" content="http://dx.plos.org/10.1371/journal.pone.0001002.g003"/>

  <meta property="og:title" content="Optimality Driven Nearest Centroid Classification from Genomic Data" />
  <meta property="og:type" content="article" />
  <meta property="og:url" content="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0001002" />

 <!--end articleInfoX-->

  <link rel="pingback" href="http://www.plosone.org/pingback" />


  <link rel="shortcut icon" href="/images/favicon.ico" type="image/x-icon"/>
  <link rel="home" title="home" href="/"/>
  <link rel="alternate" type="application/rss+xml"
        title="PLOS ONE: New Articles"
        href="http://www.plosone.org/article/feed"/>
</head>
<body>

  <div id="page-wrap">
    <div id="topbanner" class="cf">

<!-- Div for the ad at the top of journal home page-->
<div class="center">
  <div class="title">Advertisement</div>
  <iframe id='a3ac9da4' name='a3ac9da4'
    src='http://ads.plos.org/www/delivery/afr.php?zoneid=345&amp;cb=7799'
    frameborder='0' scrolling='no' width='730' height='90'>
    <a href='http://ads.plos.org/www/delivery/ck.php?n=a3ac9da4&amp;cb=9020'
      target='_top'><img src='http://ads.plos.org/www/delivery/avw.php?zoneid=345&amp;cb=2043&amp;n=a3ac9da4'
      border='0' alt=''/>
    </a>
  </iframe>
</div>    </div>

    <div id="pagehdr-wrap">
      <div id="pagehdr">
        <div id="user" class="nav">
          <ul>
            <li><a href="http://www.plos.org">plos.org</a></li>
            <li><a href="https://register.plos.org/ambra-registration/register.action">create account</a></li>
            <li class="btn-style"><a
              href="/user/secure/secureRedirect.action?goTo=%2Farticle%2FfetchArticle.action%3FarticleURI%3Dinfo%253Adoi%252F10.1371%252Fjournal.pone.0001002">sign in</a>
            </li>
          </ul>
        </div>
        <div class="logo">
          <a href="/"><img src="/images/logo.png" alt="PLOS ONE"></a>
        </div>

<div id="nav-main" class="nav">
  <ul>
        <li id="mn-01"><a href="/taxonomy" class="areas-link">Subject Areas</a></li>
    <li id="mn-02"><a href="javascript:void(0);">For Authors</a>
      <div class="submenu" style="width: 540px; margin-left: -300px;">
        <div class="block">
          <div class="submit-script">
            <h3>Submit your Manuscript</h3>
            <ul>
              <li>Fair, rigorous peer review</li>
              <li>Broad scope and wide reach</li>
            </ul>
            <a href="/static/submissionInstructions" class="btn">get started</a>
          </div>
        </div>
        <div class="menu">
          <ul>
            <li><a href="/static/publish">Why Publish with PLOS ONE</a></li>
            <li><a href="/static/publication">Publication Criteria</a></li>
            <li><a href="/static/editorial">Editorial Policies</a></li>
            <li><a href="/static/guidelines">Preparing A Manuscript</a></li>
            <li><a href="/static/figureGuidelines">Figure and Table Guidelines</a></li>
          <li><a href="/static/supportingInformation">Supporting Information Guidelines</a></li>
            <li><a href="/static/submissionInstructions">Submitting a Manuscript</a></li>
          </ul>
        </div>
      </div>
    </li>

    <li id="mn-03"><a href="javascript:void(0);">About Us</a>
      <div class="submenu" style="width:248px; margin-left:-30px;">
        <div class="menu">
          <ul>
            <li><a href="/static/information">Journal Information</a></li>
            <li><a href="/static/edboard">Editorial Board</a></li>
            <li><a href="/static/reviewerGuidelines">Reviewer Guidelines</a></li>
            <li><a href="/static/almInfo">Article-Level Metrics</a></li>
            <li><a href="/static/license">Open-Access License</a></li>
            <li><a href="/static/downloads">Media Downloads</a></li>
            <li><a href="/static/commentGuidelines">Guidelines for Comments</a></li>
            <li><a href="/static/corrections">Corrections</a></li>
            <li><a href="/static/help">Help Using this Site</a></li>
            <li><a href="/static/contact">Contact Us</a></li>
          </ul>
        </div>
      </div>
    </li>
  </ul>
<div id="db">
  <form name="searchForm" action="/search/simple?noSearchFlag=true&amp;query=&amp;articleURI=info%3Adoi%2F10.1371%2Fjournal.pone.0001002" method="get" >
<input type="hidden" name="from" value="globalSimpleSearch" id="from"/><input type="hidden" name="filterJournals" value="PLoSONE" id="filterJournals"/>    <fieldset>
      <legend>Search</legend>
      <label for="search">Search</label>
      <div class="wrap">
        <input id="search" type="text" name="query" placeholder="Search">
        <input type="image" alt="SEARCH" src="/images/icon.search.gif">
      </div>
    </fieldset>
  </form>
    <a id="advSearch" href="/search/advanced?noSearchFlag=true&amp;query=&amp;articleURI=info%3Adoi%2F10.1371%2Fjournal.pone.0001002&filterJournals=PLoSONE">advanced search</a>
</div></div>

      </div>
      <!-- pagehdr-->
    </div>
    <!-- pagehdr-wrap -->

  <!--body and html tags gets closed in global_footer.ftl-->
<script type="text/javascript" src="/javascript/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<div id="pagebdy-wrap">
  <div id="pagebdy">

    <div id="article-block" class="cf">

<div class="article-meta cf">
  <ul id="almSignPost" style="display: none;"></ul>
  <div class="article-type">
    <span class="type oa">Open Access</span>
      <span class="type pr">Peer-Reviewed</span>
  </div>
</div>

<div class="header" id="hdr-article">

<div class="article-kicker">
      <span id="article-type-heading">
        Research Article
      </span>
</div>  <h1 property="dc:title" datatype="" rel="dc:type" href="http://purl.org/dc/dcmitype/Text">
    Optimality Driven Nearest Centroid Classification from Genomic Data
  </h1>

  <ul class="authors">
      <li>


        <span rel="dc:creator" class="author">
          <span class="person" property="foaf:name" typeof="foaf:Person">
            Alan R. Dabney
              <span class="corresponding">mail</span>, 
          </span>
        </span>

          <div class="author_meta">
            <div class="author_inner">


              
              <p><span class="email">*</span>To whom correspondence should be addressed. E-mail: <a href="mailto:adabney@stat.tamu.edu">adabney@stat.tamu.edu</a> (AD); <a href="mailto:jstorey@u.washington.edu">jstorey@u.washington.edu</a> (JS)</p>

                <p>Affiliation:
                  Department of Statistics, Texas A&M University, College Station, Texas, United States of America
                </p>


              <span class="close">X</span>

            </div>
          </div>
      </li>
      <li>


        <span rel="dc:creator" class="author">
          <span class="person" property="foaf:name" typeof="foaf:Person">
            John D. Storey
              <span class="corresponding">mail</span>
          </span>
        </span>

          <div class="author_meta">
            <div class="author_inner">


              
              <p><span class="email">*</span>To whom correspondence should be addressed. E-mail: <a href="mailto:adabney@stat.tamu.edu">adabney@stat.tamu.edu</a> (AD); <a href="mailto:jstorey@u.washington.edu">jstorey@u.washington.edu</a> (JS)</p>

                <p>Affiliations:
                  Department of Biostatistics, University of Washington, Seattle, Washington, United States of America, 
                  Department of Genome Sciences, University of Washington, Seattle, Washington, United States of America
                </p>


              <span class="close">X</span>

            </div>
          </div>
      </li>
  </ul>
  <ul class="date-doi-line">
    <li>Published: October 03, 2007</li>
    <li>DOI: 10.1371/journal.pone.0001002</li>
  </ul>


</div><!--end header-->
<div class="main cf" id="pjax-container">
  

<div class="nav items-5" id="nav-article">
  <ul>
  <li>
        <span class="active" name="article">Article</span>
  </li>
  <li>
      <a href="/article/authors/info%3Adoi%2F10.1371%2Fjournal.pone.0001002" name="authors">About the Authors</a>
  </li>
  <li>
      <a href="/article/metrics/info%3Adoi%2F10.1371%2Fjournal.pone.0001002" name="metrics">Metrics</a>
  </li>
  <li>
      <a href="/article/comments/info%3Adoi%2F10.1371%2Fjournal.pone.0001002" name="comments">Comments</a>
  </li>
  <li>
      <a href="/article/related/info%3Adoi%2F10.1371%2Fjournal.pone.0001002" name="related">Related Content</a>
  </li>
  </ul>
</div>

<script type="text/javascript">
  var selected_tab = "article";
</script>
  <div id="figure-thmbs" class="carousel cf">
    <div class="wrapper">
      <div class="slider">
              <div class="item">
                <a href="#pone-0001002-t001" data-doi="info:doi/10.1371/journal.pone.0001002" data-uri="info:doi/10.1371/journal.pone.0001002.t001" title="Table 1">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.t001&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001002-t002" data-doi="info:doi/10.1371/journal.pone.0001002" data-uri="info:doi/10.1371/journal.pone.0001002.t002" title="Table 2">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.t002&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001002-t003" data-doi="info:doi/10.1371/journal.pone.0001002" data-uri="info:doi/10.1371/journal.pone.0001002.t003" title="Table 3">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.t003&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001002-t004" data-doi="info:doi/10.1371/journal.pone.0001002" data-uri="info:doi/10.1371/journal.pone.0001002.t004" title="Table 4">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.t004&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001002-g001" data-doi="info:doi/10.1371/journal.pone.0001002" data-uri="info:doi/10.1371/journal.pone.0001002.g001" title="Figure 1">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.g001&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001002-g002" data-doi="info:doi/10.1371/journal.pone.0001002" data-uri="info:doi/10.1371/journal.pone.0001002.g002" title="Figure 2">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.g002&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001002-g003" data-doi="info:doi/10.1371/journal.pone.0001002" data-uri="info:doi/10.1371/journal.pone.0001002.g003" title="Figure 3">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.g003&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
      </div>
    </div>
  </div>

  <div class="nav-col">
    <div class="nav" id="nav-article-page">
      <ul>
        <li class="nav-col-comments"><a href="/article/comments/info%3Adoi%2F10.1371%2Fjournal.pone.0001002">Reader Comments (0)</a></li>
          <li id="nav-figures"><a data-doi="info:doi/10.1371/journal.pone.0001002" >Figures</a></li>
      </ul>
    </div>
  </div>

  <div class="article">







<div class="abstract"><a id="abstract0" name="abstract0" toc="abstract0" title="Abstract"></a><h2>Abstract</h2><a id="article1.front1.article-meta1.abstract1.p1" name="article1.front1.article-meta1.abstract1.p1"></a><p>Nearest-centroid classifiers have recently been successfully employed in high-dimensional applications, such as in genomics. A necessary step when building a classifier for high-dimensional data is feature selection. Feature selection is frequently carried out by computing univariate scores for each feature individually, without consideration for how a subset of features performs as a whole. We introduce a new feature selection approach for high-dimensional nearest centroid classifiers that instead is based on the theoretically optimal choice of a given number of features, which we determine directly here. This allows us to develop a new greedy algorithm to estimate this optimal nearest-centroid classifier with a given number of features. In addition, whereas the centroids are usually formed from maximum likelihood estimates, we investigate the applicability of high-dimensional shrinkage estimates of centroids. We apply the proposed method to clinical classification based on gene-expression microarrays, demonstrating that the proposed method can outperform existing nearest centroid classifiers.</p>
</div>


<div class="articleinfo"><p><strong>Citation: </strong>Dabney AR, Storey JD (2007) Optimality Driven Nearest Centroid Classification from Genomic Data. PLoS ONE 2(10):
          e1002.
            doi:10.1371/journal.pone.0001002</p><p><strong>Academic Editor: </strong>Ji Zhu, University of Michigan, United States of America</p><p><strong>Received:</strong> March 23, 2007; <strong>Accepted:</strong> September 7, 2007; <strong>Published:</strong> October 3, 2007</p><p><strong>Copyright:</strong> © 2007 Dabney, Storey. This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</p><p><strong>Funding: </strong>This research was supported in part by the Cancer-Epidemiology and Biostatistics Training Grant 5T32CA009168-29 and NIH grant 1 U54 GM2119.</p><p><strong>Competing interests:</strong> The authors have declared that no competing interests exist.</p></div>





<div id="section1" class="section"><a id="s1" name="s1" toc="s1" title="Introduction"></a><h3>Introduction</h3><a id="article1.body1.sec1.p1" name="article1.body1.sec1.p1"></a><p>Linear Discriminant Analysis (LDA) is a long-standing prediction method that has been well characterized when the number of features used for prediction is small <a href="#pone.0001002-Mardia1">[1]</a>. The method has recently been shown to compare favorably with more complicated classifiers in high-dimensional applications, where there are thousands of potential features to employ, but only a subset are used <a href="#pone.0001002-Dudoit1">[2]</a>, <a href="#pone.0001002-Lee1">[3]</a>. In the LDA setting, each class is characterized by its vector of average feature values (i.e., class centroid). A new observation is evaluated by computing the scaled distance between its profile and each class centroid. The observation is then assigned to the class to which it is nearest, allowing LDA to be interpreted as a “nearest centroid classifier.”</p>
<a id="article1.body1.sec1.p2" name="article1.body1.sec1.p2"></a><p>In high-dimensional applications, it is often desirable to build a classifier using only a subset of features due to the fact that (i) many of the features are not informative for classification and (ii) the number of training samples available for building the classifier is substantially smaller than the number of possible features. It can also be argued that a classifier built with a smaller number of features is preferable to an equally accurate classifier built with the complete set of features. This problem is analagous to, but in general distinct from, that of selecting variables in a regression model by, say, least angle regression (LARS) <a href="#pone.0001002-Efron1">[4]</a>. Early work on the feature selection problem in discriminant analysis has been summarized elsewhere <a href="#pone.0001002-McKay1">[5]</a>, <a href="#pone.0001002-McKay2">[6]</a>.</p>
<a id="article1.body1.sec1.p3" name="article1.body1.sec1.p3"></a><p>Several approaches have been recently proposed for nearest centroid classifiers that rely on univariate statistics for feature selection <a href="#pone.0001002-Dudoit1">[2]</a>, <a href="#pone.0001002-Golub1">[7]</a>–<a href="#pone.0001002-Tibshirani1">[9]</a>. These methods assess each feature individually by its ability to discriminate the classes. However, it has been noted that the features that best discriminate the classes individually are not necessarily the ones that work best <em>together</em> <a href="#pone.0001002-B1">[10]</a>. In the extremely simple case where features are uncorrelated and only two classes exist, it intuitively follows that the optimal set of features are those whose means are most different between the two classes. However, this intuition does not easily carry over to the more complicated case where features are correlated and/or there are more than two classes. For example, if we seek to classify among three classes, it has not been shown whether it is better to choose features that distinguish one class from the other two well or those that distinguish among all three classes well. The role of correlation between features is not currently well understood either.</p>
<a id="article1.body1.sec1.p4" name="article1.body1.sec1.p4"></a><p>In this paper, we provide a theoretical result showing how to determine the subset of features of a given size that minimizes the misclassification rate for a nearest-centroid classifier. For example, if 800 features are available, but one wants to build a classifier consisting of 12 features, we show which 12 provide the lowest misclassification rate. This optimal feature set takes into account the joint behavior of the features in two ways. First, it explicitly incorporates information about correlation between features. Second, it assesses how a group of features as a whole is capable of distinguishing between multiple classes. While we show how to define the theoretically optimal subset, we must <em>estimate</em> the optimal subset in practice. The benefit of characterizing the theoretically optimal target, and the novelty of our contribution, is that we provide the optimal criteria for comparing subsets. This reflects the basic motivation for the work presented here, to identify the theoretically optimal solution to the feature selection problem, then try to get as close to this solution as possible. For practical implementation, we propose a simple greedy algorithm for searching subsets and demonstrate its operating characteristics.</p>
<a id="article1.body1.sec1.p5" name="article1.body1.sec1.p5"></a><p>Two existing papers <a href="#pone.0001002-Dudoit1">[2]</a>, <a href="#pone.0001002-Dabney1">[11]</a> propose univariate feature selection techniques to build maximum likelihood estimate based nearest-centroid classifiers, the latter of which is called the “Classification to Nearest Centroids” (Clanc) method. The method proposed here is related to these, except that we propose a multivariate feature selection method and consider parameter estimation using a multivariate shrinkage technique.</p>
<a id="article1.body1.sec1.p6" name="article1.body1.sec1.p6"></a><p>Nearest centroid classifiers have been shown to perform well with gene-expression microarrays <a href="#pone.0001002-Dudoit1">[2]</a>, <a href="#pone.0001002-Lee1">[3]</a>, and we illustrate our findings in this setting. We compare our proposed classifier with existing nearest centroid classifiers in extensive simulations and on three previously-published microarray datasets. Our results demonstrate that improvements in prediction accuracy can be attained by estimating the optimal feature-selection criteria.</p>
</div>

<div id="section2" class="section"><a id="s2" name="s2" toc="s2" title="Methods"></a><h3>Methods</h3>
<h4>Background</h4>
<a id="article1.body1.sec2.sec1.p1" name="article1.body1.sec2.sec1.p1"></a><p>An LDA classifier is a canonical nearest centroid classifier. The problem it addresses is to classify unknown samples into one of <em>K</em> classes. To build a classifier, we obtain <em>n<sub>k</sub></em> training samples per class, with <em>m</em> features per sample. For each training sample, we observe class membership <em>Y</em> and profile <em>X</em>. For simplicity, we will represent the classes by the numbers <em>k</em>  =  1,2,…,<em>K</em>. Note that each profile is a vector of length <em>m</em>. We assume that profiles from class <em>k</em> are distributed as <em>N</em>(μ<em><sub>k</sub></em>,Σ), the multivariate normal distribution with mean vector μ<em><sub>k</sub></em> and covariance matrix Σ. Call <em>L</em>(<em>x</em>;μ<em><sub>k</sub></em>,Σ), the corresponding probability density function. Finally, let π<em><sub>k</sub></em> be the prior probability that an unknown sample comes from class <em>k</em>.</p>
<a id="article1.body1.sec2.sec1.p2" name="article1.body1.sec2.sec1.p2"></a><p>Bayes' Theorem states that the probability that an observed sample comes from class <em>k</em> is proportional to the product of the class density and prior probability:<a name="" id=""></a><span class="equation"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e001&amp;representation=PNG" class="inline-graphic"><span class="note">(1)</span></span><br>We call Pr(Y = <em>k</em>|<em>X</em> = <em>x</em>) the posterior probability that sample <em>x</em> comes from class <em>k</em>. LDA assigns the sample to the class with the largest posterior probability. This can be shown to be the rule that minimizes misclassification error <a href="#pone.0001002-Mardia1">[1]</a>. The rule can be written as:<a name="" id=""></a><span class="equation"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e002&amp;representation=PNG" class="inline-graphic"><span class="note">(2)</span></span><br>Thus, a sample is assigned to the class to which it is nearest, as measured by the metric <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e003&amp;representation=PNG" class="inline-graphic"></span>, where <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e004&amp;representation=PNG" class="inline-graphic"></span> is the square of the Mahalanobis distance between <em>x</em> and μ.</p>


<h4>Optimal Nearest Centroid Classifiers</h4>
<h5>Misclassification rates.</h5><a id="article1.body1.sec2.sec2.sec1.p1" name="article1.body1.sec2.sec2.sec1.p1"></a><p>A misclassification occurs when a sample is assigned to the incorrect class. The probability of making a classification error is:<a name="" id=""></a><span class="equation"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e005&amp;representation=PNG" class="inline-graphic"><span class="note">(3)</span></span><br>We can derive misclassification rates using the LDA rule in equation (2). In particular, we can calculate misclassification rates for any subset of features. An optimal subset can be found by simply assigning misclassification rates to all possible subsets of a given size and choosing the one with the lowest error rate.</p>
<a id="article1.body1.sec2.sec2.sec1.p2" name="article1.body1.sec2.sec2.sec1.p2"></a><p>The misclassification rate of a nearest-centroid (LDA) classifier can be shown to be<a name="" id=""></a><span class="equation"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e006&amp;representation=PNG" class="inline-graphic"><span class="note">(4)</span></span><br>where φ is the <em>cdf</em> of the standard normal distribution, and <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e007&amp;representation=PNG" class="inline-graphic"></span> is the square of the Mahalanobis distance between μ<em><sub>j</sub></em> and μ<em><sub>i</sub></em>; note that this assumes the data are Normally distributed, as stated by the model. The subset of features of size <em>m</em><sub>0</sub>≤<em>m</em> that minimizes the misclassification rate is the one with the lowest value of equation (4); note that the <em>m</em>−<em>m</em><sub>0</sub> features not included in the subset are not involved in the calculation. This defines the optimal subset of size <em>m</em><sub>0</sub>.</p>
<a id="article1.body1.sec2.sec2.sec1.p3" name="article1.body1.sec2.sec2.sec1.p3"></a><p>Equation (4) can be interpreted as measuring the collective distance between all of the class centroids. In general, the misclassification rate will be small when all of the class centroids are far away from each other. Note, however, that the score in (4) is actually a complicated combination of the pairwise differences between the centroids and the class priors. Furthermore, correlations between features are explicitly incorporated through the distance functions ||μ<em><sub>j</sub></em>−μ<em><sub>i</sub></em>||<sub>Σ</sub>. Further intuition into (4) can be attained by considering the following simple example.</p>

<h5>A Simple Example.</h5><a id="article1.body1.sec2.sec2.sec2.p1" name="article1.body1.sec2.sec2.sec2.p1"></a><p>The data in <a href="#pone-0001002-t001">Table 1</a> represent an artificial example with 10 features and 3 classes. The population means of each class are shown in columns two through four; we assume that each feature has variance 1 and that all features are uncorrelated. Suppose that we wish to select the five features that correspond to the lowest misclassification rate. The final column of the table lists univariate scores for each feature, where we have used the average squared difference from the overall feature mean as the score. A high value for a feature on this score indicates large overall differences between this feature's class means. The five largest univariate scores correspond to features 1, 2, 3, 4, and 5.</p>
<div class="figure" id="pone-0001002-t001"><div class="img"><a name="pone-0001002-t001" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.t001&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001002" data-uri="info:doi/10.1371/journal.pone.0001002.t001"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.t001&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001002.t001/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001002.t001/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001002.t001/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001002.t001/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001002.t001.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001002.t001/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001002.t001/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001002.t001.TIF"></span>)
                </a></li></ul></div><p><strong>Table 1.  <span>Class means with 10 features and 3 classes.</span></strong></p><span>doi:10.1371/journal.pone.0001002.t001</span></div><a id="article1.body1.sec2.sec2.sec2.p2" name="article1.body1.sec2.sec2.sec2.p2"></a><p>An alternative approach to using univariate scores to select features is to consider all 252 possible quintuplets and choose the set with the lowest overall misclassification rate. Note that, to do this, we must be able to assign misclassification probabilities to arbitrary feature subsets. This highlights the utility of the multivariate score (4). Using (4), we find that the set of features chosen by the univariate scores has an overall misclassification rate of 20%. Similarly, we find that the optimal set in this example contains features 1, 5, 6, 7, and 8, with an associated error rate of 13%. The most obvious difference between this subset and that chosen by univariate scores is the exclusion of features 2, 3, and 4. Apparently, class one can be sufficiently characterized by feature 1. The other features do not contain sufficient <em>additional</em> information to merit their selection. We note in this example that the optimal subset of size <em>m</em><sub>0</sub> + 1 contains the optimal subset of size <em>m</em><sub>0</sub>, <em>m</em><sub>0</sub> = 1, 2,…,9, although this need not be true in general.</p>

<h5>Correlation Between Features.</h5><a id="article1.body1.sec2.sec2.sec3.p1" name="article1.body1.sec2.sec2.sec3.p1"></a><p>An important aspect of the optimal feature-selection procedure is its explicit incorporation of correlation between features. It is not necessarily clear what effect correlation between features should have on a classifier. Intuitively, many weakly informative, correlated genes might be expected to collectively be highly informative. However, it has been shown <a href="#pone.0001002-Bickel1">[12]</a> that estimating correlations as zero, making Σ a diagonal matrix, can lead to better prediction when the number of features is large relative to the number of samples.</p>
<a id="article1.body1.sec2.sec2.sec3.p2" name="article1.body1.sec2.sec2.sec3.p2"></a><p>We investigate the effect of different correlation patterns in the example of <a href="#pone-0001002-t001">Table 1</a>. Let Σ be the 10×10 covariance matrix. In <a href="#pone-0001002-t002">Table 2</a>, we refer to the 4×4 block corresponding to features 1–4 as “Block 1.” The blocks corresponding to features 5–7 and 8–10 are similarly referred to as “Block 2” and “Block 3,” respectively. “Block 1~2” refers to the blocks specific to both features 1–4 and features 5–7, <em>etc.</em> In all cases, the selected block is given an autoregressive covariance structure with correlation parameter 0.9, meaning that the correlation between two correlated features <em>i</em> and <em>j</em> is 0.9<sup>|<em>i</em>-<em>j</em>|</sup>; no qualitative differences were found when considering negative correlation. We report the best subset under each correlation pattern (<em>S<sub>O</sub></em>), its error rate, and the error rate for the best subset chosen ignoring correlation (<em>S<sub>I</sub></em>). We also report the rank of the best subset ignoring correlation in each case.</p>
<div class="figure" id="pone-0001002-t002"><div class="img"><a name="pone-0001002-t002" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.t002&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001002" data-uri="info:doi/10.1371/journal.pone.0001002.t002"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.t002&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001002.t002/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001002.t002/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001002.t002/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001002.t002/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001002.t002.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001002.t002/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001002.t002/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001002.t002.TIF"></span>)
                </a></li></ul></div><p><strong>Table 2.  <span>The effect of covariance on the optimal feature-selection procedure.</span></strong></p><span>doi:10.1371/journal.pone.0001002.t002</span></div><a id="article1.body1.sec2.sec2.sec3.p3" name="article1.body1.sec2.sec2.sec3.p3"></a><p>In this example, correlations that affect features 5–7 change the entries of the best subset, as well as the associated error rates. For example, when there is correlation within features 5–7, the optimal subset includes features 1, 5, 8, 9, and 10, with an error rate of 14.9%. The set chosen ignoring correlation ranks 64th (out of 252 possible subsets), with an error rate of 18.2%. These results suggest that correlated features can be useful together. While there are many possible scenarios in which correlation could play a role, the main point is that the feature-selection procedure guided by (4) automatically identifies the optimal combination of features, even in the presence of correlation. Of course, in practice, there is the added challenge of estimating the class centroids and covariance matrix. In particular, when there are many more features than samples, it is not clear that covariances can be estimated well enough to make them worth the effort. We consider this further in the next section.</p>



<h4>Proposed Nearest Centroid Classifier</h4>
<a id="article1.body1.sec2.sec3.p1" name="article1.body1.sec2.sec3.p1"></a><p>In practice, unknown model parameters and the general impracticality of exhaustive searches with genomic data preclude our finding theoretically optimal subsets. Instead, we must <em>estimate</em> optimal subsets. A myriad of solutions for this problem have been proposed, particularly in the context of gene expression microarrays. The novelty of our proposed method is that we have provided the ideal target for estimation. Specifically, our goal in practice is to choose the subset that minimizes an estimated version of (4). To avoid the need for exhaustive searches, we propose a greedy search algorithm.</p>
<a id="article1.body1.sec2.sec3.p2" name="article1.body1.sec2.sec3.p2"></a><p>We consider several variations of our basic algorithm, employing different methods for estimating class centroids and covariance matrices. We compare the proposals with existing alternatives on both simulated and real datasets. Details of the proposed algorithms are given in what follows. Based on our comparisons, the final algorithm that we propose for nearest-centroid classification from genomic data uses shrunken centroids and a diagonal covariance matrix. The following is the proposed algorithm to build a classifier with <em>m</em><sub>0</sub> features:</p>


<ol class="order">

<li>Estimate the class centroids <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e008&amp;representation=PNG" class="inline-graphic"></span> by simple averaging using equation (5).</li>

<li>Estimate the pooled variances using equation (8) to form the diagonal covariance estimate <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e009&amp;representation=PNG" class="inline-graphic"></span>.</li>

<li>Using the estimated centroids and variances from Steps 1 and 2, find the single feature with the smallest estimated misclassification rate from equation (4).</li>

<li>For <em>b</em> = 2,3,…,<em>m</em><sub>0</sub>, consider each remaining feature separately:

<ol class="alpha-lower">

<li>Combine one remaining feature with the already selected feature(s) 1,2,…,<em>b</em>−1, and use these to form shrunken class centroid estimates <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e010&amp;representation=PNG" class="inline-graphic"></span> based on equations (6–7).</li>

<li>Find the single feature with the smallest estimated misclassification rate according to equation (4), when included with the already-selected feature(s) 1,2,…,<em>b</em>−1.</li>

</ol></li>

<li>The final nearest centroid classifier is composed of the subsets of <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e011&amp;representation=PNG" class="inline-graphic"></span> and <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e012&amp;representation=PNG" class="inline-graphic"></span> built from the <em>m</em><sub>0</sub> selected features.</li>

</ol><a id="article1.body1.sec2.sec3.p3" name="article1.body1.sec2.sec3.p3"></a><p>We call this method “Clanc”, as it is an extension of the Clanc procedure proposed earlier <a href="#pone.0001002-Dabney1">[11]</a>. The algorithm has also been implemented in the Clanc software <a href="#pone.0001002-1">[13]</a>.</p>
<h5>Estimating the Decision Rule.</h5><a id="article1.body1.sec2.sec3.sec1.p1" name="article1.body1.sec2.sec3.sec1.p1"></a><p>To estimate (4), we estimate the class centroids μ<em><sub>k</sub></em>, <em>k</em> = 1,2,…,<em>K</em>, and the common covariance matrix Σ. Reducing the MSE of each estimated centroid will bring us closer to (4) <a href="#pone.0001002-Dabney1">[11]</a>. According to Stein's Paradox of statistics <a href="#pone.0001002-Stein1">[14]</a>, we can reduce the MSEs by shrinking each centroid toward its overall mean (or any other constant). In our setting, this suggests shrinking each centroid estimate across its <em>m</em> components. We note that existing shrinkage proposals for nearest-centroid classifiers shrink each feature across the <em>K</em> classes <a href="#pone.0001002-Tibshirani1">[9]</a>. This makes the estimated centroids less distinguishable and tends to result in <em>increased</em> misclassification rates <a href="#pone.0001002-Dabney1">[11]</a>.</p>
<a id="article1.body1.sec2.sec3.sec1.p2" name="article1.body1.sec2.sec3.sec1.p2"></a><p>While there are many possible approaches to shrinking the centroids, we take the following simple approach. We begin with the usual centroid estimate <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e013&amp;representation=PNG" class="inline-graphic"></span>, an <em>m</em>-vector with <em>i</em>th component equal to the average expression for feature <em>i</em> in class <em>k</em>:<a name="" id=""></a><span class="equation"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e014&amp;representation=PNG" class="inline-graphic"><span class="note">(5)</span></span><br>where <em>x<sub>ijk</sub></em> is the expression for feature <em>i</em> in sample <em>j</em> of class <em>k</em>. Now let <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e015&amp;representation=PNG" class="inline-graphic"></span> be the <em>m</em>-vector with each of the <em>i</em> = 1,2,…,<em>m</em> components equal to the estimated overall mean for class <em>k</em>, <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e016&amp;representation=PNG" class="inline-graphic"></span>, and consider shrunken centroids of the form<a name="" id=""></a><span class="equation"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e017&amp;representation=PNG" class="inline-graphic"><span class="note">(6)</span></span><br>We choose ω<em><sub>k</sub></em> so that <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e018&amp;representation=PNG" class="inline-graphic"></span> is minimized. It can be shown that the desired value of ω<em><sub>k</sub></em> is<a name="" id=""></a><span class="equation"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e019&amp;representation=PNG" class="inline-graphic"><span class="note">(7)</span></span><br>where <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e020&amp;representation=PNG" class="inline-graphic"></span> is the <em>m</em>-vector with each component equal to the overall mean for class <em>k</em>, <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e021&amp;representation=PNG" class="inline-graphic"></span>, 1<em><sub>m</sub></em> is the <em>m</em>-vector of ones, and the <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e022&amp;representation=PNG" class="inline-graphic"></span> are the diagonal components of Σ. In practice, we use plug-in estimates for the unknown parameters.</p>
<a id="article1.body1.sec2.sec3.sec1.p3" name="article1.body1.sec2.sec3.sec1.p3"></a><p>Drawing from earlier versions of our work <a href="#pone.0001002-Dabney2">[15]</a>, a recent article has also considered the use of shrinkage across genes rather than across centroids <a href="#pone.0001002-Shen1">[16]</a>. Their shrinkage proposal is based on hard-thresholding.&nbsp;By contrast, we propose the shrinkage of each centroid toward a constant, as was originally considered by Stein <a href="#pone.0001002-Stein1">[14]</a>. Furthermore, the eigenvector-based selection routine proposed in reference <a href="#pone.0001002-Shen1">[16]</a> does not estimate the optimal selection, as we do here.</p>
<a id="article1.body1.sec2.sec3.sec1.p4" name="article1.body1.sec2.sec3.sec1.p4"></a><p>While we can form an unbiased estimate of the covariance matrix Σ, such an estimate will tend to be singular in the microarray setting, with many more features than samples. Furthermore, theoretical justification for shrinking the off-diagonal components of Σ to zero in such settings has recently been published <a href="#pone.0001002-Bickel1">[12]</a>. An alternative approach is to attempt to improve our estimate of Σ by shrinkage. Shrunken covariance matrices can be of the form <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e023&amp;representation=PNG" class="inline-graphic"></span>. Here, <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e024&amp;representation=PNG" class="inline-graphic"></span> is the usual unbiased empirical covariance matrix estimate, <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e025&amp;representation=PNG" class="inline-graphic"></span> is the estimate under some simplifying restriction (such as diagonal form), and ω is a constant that is used to multiply every matrix entry. For example, <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e026&amp;representation=PNG" class="inline-graphic"></span> has (<em>i</em>, <em>j</em>)th element<a name="" id=""></a><span class="equation"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e027&amp;representation=PNG" class="inline-graphic"><span class="note">(8)</span></span><br></p>
<a id="article1.body1.sec2.sec3.sec1.p5" name="article1.body1.sec2.sec3.sec1.p5"></a><p>This is a pooled version of the class-specific estimates, reflecting the model assumption of a common covariance matrix. In what follows, we define <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e028&amp;representation=PNG" class="inline-graphic"></span> as the diagonalized version of <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e029&amp;representation=PNG" class="inline-graphic"></span>, with diagonal elements equal to the diagonal elements of <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e030&amp;representation=PNG" class="inline-graphic"></span> and all off-diagonal elements set to zero.</p>
<a id="article1.body1.sec2.sec3.sec1.p6" name="article1.body1.sec2.sec3.sec1.p6"></a><p>The shrinkage parameter ω can be estimated using cross-validation on training data <a href="#pone.0001002-Guo1">[17]</a> or by computing the value that minimizes mean square error (MSE) <a href="#pone.0001002-Schfer1">[18]</a>. We follow the latter approach in the results below, as described in <a href="#pone-0001002-t001">Table 1</a> of reference <a href="#pone.0001002-Schfer1">[18]</a>. Specifically, denote the (<em>i</em>, <em>j</em>)th off-diagonal element of the covariance matrix as <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e031&amp;representation=PNG" class="inline-graphic"></span>, where <em>s<sub>ii</sub></em> and <em>r<sub>ij</sub></em> are the empirical variance and correlation, respectively. Shrinkage is applied to the correlation parameters, with the shrunken version of <em>r<sub>ij</sub></em> equal to<a name="" id=""></a><span class="equation"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e032&amp;representation=PNG" class="inline-graphic"><span class="note">(9)</span></span><br>The estimator <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e033&amp;representation=PNG" class="inline-graphic"></span> proposed in reference <a href="#pone.0001002-Schfer1">[18]</a> that approximately minimizes the MSE of the shrunken covariance matrix is<a name="" id=""></a><span class="equation"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e034&amp;representation=PNG" class="inline-graphic"><span class="note">(10)</span></span><br>Adapting the estimator in reference <a href="#pone.0001002-Schfer1">[18]</a> to our pooled covariance matrix setting, we have<a name="" id=""></a><span class="equation"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e035&amp;representation=PNG" class="inline-graphic"><span class="note">(11)</span></span><br>where <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e036&amp;representation=PNG" class="inline-graphic"></span> and <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.e037&amp;representation=PNG" class="inline-graphic"></span>.</p>

<h5>Searching for the Optimal Subset.</h5><a id="article1.body1.sec2.sec3.sec2.p1" name="article1.body1.sec2.sec3.sec2.p1"></a><p>We have characterized the theoretically optimal subset of given size by computing the misclassification rate (4) for nearest-centroid classifiers. Ideally, having estimated the decision rule, we would evaluate all subsets of given size and choose the one corresponding to the lowest estimated error rate. In high-dimensional settings, such an exhaustive search is not feasible. We now consider practical strategies for searching for the optimal subset. These are analogous to existing routines for selecting subsets in discriminant analysis <a href="#pone.0001002-McKay1">[5]</a>, <a href="#pone.0001002-McKay2">[6]</a>.</p>
<a id="article1.body1.sec2.sec3.sec2.p2" name="article1.body1.sec2.sec3.sec2.p2"></a><p>A simple approach to this problem is to rank each feature individually on its ability to discriminate between the classes and choose the top features from this list. Many previous publications use versions of univariate <em>t</em>-statistics or <em>F</em>-statistics to score features <a href="#pone.0001002-Dudoit1">[2]</a>, <a href="#pone.0001002-Golub1">[7]</a>–<a href="#pone.0001002-Tibshirani1">[9]</a>, <a href="#pone.0001002-Dabney1">[11]</a>. As discussed above, univariate selection procedures do not take into account the joint performance of a set of features. Thus, whereas the selected features will each <em>individually</em> discriminate well, the selected <em>set</em> of features may not.</p>
<a id="article1.body1.sec2.sec3.sec2.p3" name="article1.body1.sec2.sec3.sec2.p3"></a><p>As an alternative to univariate scoring, we might consider more computationally-intensive search algorithms. For example, a greedy forward-selection algorithm would (i) select the one feature that scores best individually according to some criterion, (ii) select the one feature that scores best together with the already chosen feature(s), (iii) repeat until the desired number of features have been chosen. The misclassification rate (4) itself is the ideal score to use for guiding the selection of a subset. As such, we propose the greedy forward-selection algorithm that proceeds as above, using an estimate of (4) to score each proposed subset. For reference, the greedy algorithm identifies the same subset as the exhaustive search algorithm in the example of <a href="#pone-0001002-t001">Table 1</a>.</p>


</div>

<div id="section3" class="section"><a id="s3" name="s3" toc="s3" title="Results"></a><h3>Results</h3>
<h4>Illustration on Simulated Examples</h4>
<a id="article1.body1.sec3.sec1.p1" name="article1.body1.sec3.sec1.p1"></a><p>We evaluate different methods for estimating the optimal subset of a given size with the following sets of simulations. There are 3 classes and 1000 genes, from which a subset of size 30 is desired. For each class, 15 training samples and 15 test samples are generated. In simulation set one (<a href="#pone-0001002-t003">Table 3</a>), the class centroids are equidistant from one another. In simulation set two (<a href="#pone-0001002-t004">Table 4</a>), class one is more easily distinguished than class two, which is more easily distinguished than class three. The second scenario is analogous to that described in <a href="#pone-0001002-t001">Table 1</a>. A univariate scoring procedure will prefer features from class one, since its features will score highest individually. A forward-selection procedure, on the other hand, will spread out the chosen features among the classes in such a way that the overall misclassification rate is approximately minimized. We also consider the effect of correlation among the features. Since the misclassification rate (4) explicitly incorporates correlations, we expect that using (4) to guide feature selection will achieve greater accuracy relative to its competitors.</p>
<div class="figure" id="pone-0001002-t003"><div class="img"><a name="pone-0001002-t003" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.t003&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001002" data-uri="info:doi/10.1371/journal.pone.0001002.t003"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.t003&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001002.t003/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001002.t003/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001002.t003/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001002.t003/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001002.t003.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001002.t003/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001002.t003/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001002.t003.TIF"></span>)
                </a></li></ul></div><p><strong>Table 3.  <span>Test error rates (standard errors): Classes equidistant.</span></strong></p><span>doi:10.1371/journal.pone.0001002.t003</span></div><div class="figure" id="pone-0001002-t004"><div class="img"><a name="pone-0001002-t004" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.t004&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001002" data-uri="info:doi/10.1371/journal.pone.0001002.t004"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.t004&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001002.t004/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001002.t004/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001002.t004/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001002.t004/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001002.t004.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001002.t004/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001002.t004/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001002.t004.TIF"></span>)
                </a></li></ul></div><p><strong>Table 4.  <span>Test error rates (standard errors): Classes not equidistant.</span></strong></p><span>doi:10.1371/journal.pone.0001002.t004</span></div><a id="article1.body1.sec3.sec1.p2" name="article1.body1.sec3.sec1.p2"></a><p>The details of the simulations are as follows. Twenty five percent of the genes are noise, with centroid components μ<em><sub>i</sub></em><sub>1</sub> = μ<em><sub>i</sub></em><sub>2</sub> = μ<em><sub>i</sub></em><sub>3</sub> = 0. Another 25% of the genes characterize class one, with centroid components μ<em><sub>i</sub></em><sub>1</sub> = 0.5 or 1 in simulation sets one and two, respectively, and μ<em><sub>i</sub></em><sub>2</sub> = μ<em><sub>i</sub></em><sub>3</sub> = 0. Another 25% of the genes characterize class two, with μ<em><sub>i</sub></em><sub>2</sub> = 0.5 and μ<em><sub>i</sub></em><sub>1</sub> = μ<em><sub>i</sub></em><sub>3</sub> = 0. The remaining genes characterize class three, with μ<em><sub>i</sub></em><sub>3</sub> = 0.5 or 0.25 in simulation sets one and two, respectively, and μ<em><sub>i</sub></em><sub>1</sub> = μ<em><sub>i</sub></em><sub>2</sub> = 0. In each simulation, the genes are randomly broken into 50 blocks of 20 genes. Within each block, an autoregressive covariance structure is used. Correlation (ρ) is positive in half of the blocks and negative in the other half. In each simulation set, four scenarios are presented: (i) independence (ρ = 0), (ii) low correlation (ρ = 0.4), (iii) medium correlation (ρ = 0.65), and (iv) high correlation (ρ = 0.9). Samples for class <em>k</em> are generated from <em>N<sub>m</sub></em>(μ<em><sub>k</sub></em>,Σ), the multivariate normal distributions with mean vector μ<em><sub>k</sub></em> and covariance matrix Σ.</p>
<a id="article1.body1.sec3.sec1.p3" name="article1.body1.sec3.sec1.p3"></a><p>For each of 50 simulations, we applied the following nearest centroid classification methods. We report the PAM method <a href="#pone.0001002-Tibshirani1">[9]</a>, which uses univariate statistics to score features individually, and several variants of our greedy algorithm. We evaluate the effect of shrinking the centroids using equations (6–7). We also evaluate different choices for the covariance matrix: unrestricted, diagonal, and shrunken <a href="#pone.0001002-Schfer1">[18]</a>. Precise expressions for each covariance matrix choice are given in equations (8–11).</p>
<a id="article1.body1.sec3.sec1.p4" name="article1.body1.sec3.sec1.p4"></a><p><a href="#pone-0001002-t003">Table 3</a> reports the results for simulation set one, and <a href="#pone-0001002-t004">Table 4</a> is for simulation set two. The second column indicates whether the centroids were shrunken; PAM is marked with an asterisk in these Tables due to its alternative approach to shrinking centroids across classes rather than across features. The third column indicates the form of the covariance matrix used. The remaining numbers report test error rates, averaged across the 50 simulations, for each of the considered levels of correlation. The numbers in parentheses next to the error rates are the estimated standard errors. The Clanc classifiers that estimate nonzero covariances increase in accuracy with higher levels of correlation. While slightly less accurate with high correlations, Clanc using a diagonal covariance matrix performs well in all simulations. When classes are equidistant, the classifiers based on univariate scoring perform well. When classes are not equidistant, a substantial increase in accuracy can be had by employing a greedy search. There is some evidence that using shrunken centroids improves accuracy.</p>


<h4>Illustration on Real Examples</h4>
<a id="article1.body1.sec3.sec2.p1" name="article1.body1.sec3.sec2.p1"></a><p>We now illustrate our methods on three previously published gene-expression microarray experiments. We compare the methods on the basis of error rates from five-fold cross-validation. We avoid gene-selection bias by completely rebuilding classifiers to identical specifications in each cross-validation iteration <a href="#pone.0001002-Ambroise1">[19]</a>. Cross-validated error rates are nearly unbiased, being slightly conservative, and they are thus sufficient for comparing classifiers. Note that the optimal subset depends on the prior probabilities π<em><sub>k</sub></em>, <em>k</em> = 1, 2,…, <em>K</em>. In what follows, we assume equal priors, although no substantial changes were seen when using priors that reflected the proportions observed in the samples.</p>
<a id="article1.body1.sec3.sec2.p2" name="article1.body1.sec3.sec2.p2"></a><p>The first example involves small round blue cell tumors (SRBCT) of childhood <a href="#pone.0001002-Khan1">[20]</a>. Expression measurements were made on 2,307 genes in 83 SRBCT samples. The tumors were classified as Burkitt lymphoma, Ewing sarcoma, neuroblastoma, or rhabdomyosarcoma. There are 11, 29, 18, and 25 samples in each respective class. In the second example, expression measurements were made on 4,026 genes in 58 lymphoma patients <a href="#pone.0001002-Alizadeh1">[21]</a>. The tumors were classified as diffuse large B-cell lymphoma and leukemia, follicular lymphoma, and chronic lymphocytic leukemia. There are 42, 6, and 10 samples in each respective class. The third example involves the cell lines used in the National Cancer Institute's screen for anti-cancer drugs <a href="#pone.0001002-Ross1">[22]</a>. Expression measurements were made on 6,830 genes in 60 cell tumors. There are representative cell lines for each of lung cancer, prostate cancer, CNS, colon cancer, leukemia, melanoma, NSCLC, ovarian cancer, renal cancer, and one unknown sample. We filtered out 988 genes for which 20% or more of the tumors had missing values. We also excluded samples from prostate cancer (due to there being only two samples) and the one unknown sample. There are 9, 6, 7, 6, 8, 7, 6, and 8 samples in each remaining respective class.</p>
<a id="article1.body1.sec3.sec2.p3" name="article1.body1.sec3.sec2.p3"></a><p>The results for the SRBCT data are shown in <a href="#pone-0001002-g001">Figure 1</a>, those for the lymphoma data in <a href="#pone-0001002-g002">Figure 2</a>, and those for the NCI data in <a href="#pone-0001002-g003">Figure 3</a>. The classifiers presented are identical to those in <a href="#pone-0001002-t003">Tables 3</a> and <a href="#pone-0001002-t004">4</a>, except that Clanc classifiers with unrestricted covariances are excluded. The Clanc classifiers indicated by “v1-v4” correspond to the last four classifiers reported in <a href="#pone-0001002-t003">Tables 3</a> and <a href="#pone-0001002-t004">4</a>. Clanc improves accuracy over the PAM approach using univariate scoring. Shrunken centroids in Clanc improve accuracy in the NCI example but make no difference in the other examples. Diagonal covariance matrices result in greater accuracy overall for these examples. Overall, we interpret these results as indicating that Clanc classifiers with greedy searches guided by (4) can outperform the existing PAM classification method. In particular, the results support the use of shrunken centroids and diagonal covariance matrices, and we have implemented this algorithm in the Clanc software <a href="#pone.0001002-1">[13]</a>.</p>
<div class="figure" id="pone-0001002-g001"><div class="img"><a name="pone-0001002-g001" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.g001&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001002" data-uri="info:doi/10.1371/journal.pone.0001002.g001"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.g001&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001002.g001/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001002.g001/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001002.g001/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001002.g001/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001002.g001.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001002.g001/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001002.g001/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001002.g001.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 1.  <span>Results for SRBCT data.</span></strong></p><a id="article1.body1.sec3.sec2.fig1.caption1.p1" name="article1.body1.sec3.sec2.fig1.caption1.p1"></a><p>Classifiers are identical to those in <a href="#pone-0001002-t003">Tables 3</a> and <a href="#pone-0001002-t004">4</a>, with Clanc v1-v4 corresponding to the last four variants reported there, respectively.</p>
<span>doi:10.1371/journal.pone.0001002.g001</span></div><div class="figure" id="pone-0001002-g002"><div class="img"><a name="pone-0001002-g002" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.g002&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001002" data-uri="info:doi/10.1371/journal.pone.0001002.g002"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.g002&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001002.g002/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001002.g002/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001002.g002/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001002.g002/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001002.g002.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001002.g002/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001002.g002/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001002.g002.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 2.  <span>Results for Lymphoma data.</span></strong></p><a id="article1.body1.sec3.sec2.fig2.caption1.p1" name="article1.body1.sec3.sec2.fig2.caption1.p1"></a><p>Classifiers are identical to those in <a href="#pone-0001002-t003">Tables 3</a> and <a href="#pone-0001002-t004">4</a>, with Clanc v1-v4 corresponding to the last four variants reported there, respectively.</p>
<span>doi:10.1371/journal.pone.0001002.g002</span></div><div class="figure" id="pone-0001002-g003"><div class="img"><a name="pone-0001002-g003" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.g003&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001002" data-uri="info:doi/10.1371/journal.pone.0001002.g003"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001002.g003&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001002.g003/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001002.g003/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001002.g003/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001002.g003/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001002.g003.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001002.g003/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001002.g003/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001002.g003.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 3.  <span>Results for NCI data.</span></strong></p><a id="article1.body1.sec3.sec2.fig3.caption1.p1" name="article1.body1.sec3.sec2.fig3.caption1.p1"></a><p>Classifiers are identical to those in <a href="#pone-0001002-t003">Tables 3</a> and <a href="#pone-0001002-t004">4</a>, with Clanc v1-v4 corresponding to the last four variants reported there, respectively.</p>
<span>doi:10.1371/journal.pone.0001002.g003</span></div>
</div>

<div id="section4" class="section"><a id="s4" name="s4" toc="s4" title="Discussion"></a><h3>Discussion</h3><a id="article1.body1.sec4.p1" name="article1.body1.sec4.p1"></a><p>We have characterized the theoretically optimal subset of a given size for a nearest centroid classifier. We have also considered the estimation of this optimal subset. Although an exhaustive search would be ideal, it is not generally practical in the genomic setting. We have thus proposed a greedy algorithm for estimating optimal subsets and demonstrated that the resulting classifier can produce more accurate classifiers in both simulated and real applications. Our results indicate that some improvement in accuracy can be had by shrinking class centroids, for which we have proposed a novel procedure. Although the theoretically optimal subset explicitly incorporates correlation between features, our results concur with those of others in suggesting that correlations should be shrunken to zero in settings with many more features than samples.</p>
<a id="article1.body1.sec4.p2" name="article1.body1.sec4.p2"></a><p>We note that our approach to estimating the optimal decision rule could likely be improved upon. In particular, while MLE estimators of the class centroids and common covariance matrix themselves have good properties, the resulting estimator of the decision rule may not. An alternative in the two class case would be to directly estimate the decision rule using a variant of logistic regression. The multiclass case would be more complicated. We intend to investigate these issues in future work.</p>
</div>



<div class="contributions"><a id="authcontrib" name="authcontrib" toc="authcontrib" title="Author Contributions"></a><h3>Author Contributions</h3><p>Conceived and designed the experiments: JS AD. Performed the experiments: JS AD. Analyzed the data: AD. Contributed reagents/materials/analysis tools: JS AD. Wrote the paper: JS AD.</p></div><div><a id="references" name="references" toc="references" title="References"></a><h3>References</h3><ol class="references"><li><span class="label">1.
              </span><a name="pone.0001002-Mardia1" id="pone.0001002-Mardia1"></a>Mardia K, Kent J, Bibby J (1979) Multivariate Analysis. London: Academic Press.   <ul class="find-nolinks"></ul></li><li><span class="label">2.
              </span><a name="pone.0001002-Dudoit1" id="pone.0001002-Dudoit1"></a>Dudoit S, Fridlyand J, Speed T (2002) Comparison of discriminant methods for the classification of tumors using gene expression data. Journal of the American Statistical Association  97: 77–87.  <ul class="find" data-citedArticleID="1002420" data-doi="10.1198/016214502753479248"><li><a href="http://dx.doi.org/10.1198/016214502753479248" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Comparison+of+discriminant+methods+for+the+classification+of+tumors+using+gene+expression+data." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Comparison+of+discriminant+methods+for+the+classification+of+tumors+using+gene+expression+data.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">3.
              </span><a name="pone.0001002-Lee1" id="pone.0001002-Lee1"></a>Lee JW, Lee JB, Park M, Song SH (2005) An extensive comparison of recent classification tools applied to microarray data. Computational Statistics and Data Analysis  48: 869–885.  <ul class="find" data-citedArticleID="1002432" data-doi="10.1016/j.csda.2004.03.017"><li><a href="http://dx.doi.org/10.1016/j.csda.2004.03.017" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=An+extensive+comparison+of+recent+classification+tools+applied+to+microarray+data." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22An+extensive+comparison+of+recent+classification+tools+applied+to+microarray+data.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">4.
              </span><a name="pone.0001002-Efron1" id="pone.0001002-Efron1"></a>Efron B, Hastie T, Johnstone I, Tibshirani R (2004) Least angle regression. Annals of Statistics (with discussion)  32: 407–499.  <ul class="find" data-citedArticleID="1002422" data-doi="10.1214/009053604000000067"><li><a href="http://dx.doi.org/10.1214/009053604000000067" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Least+angle+regression." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Least+angle+regression.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">5.
              </span><a name="pone.0001002-McKay1" id="pone.0001002-McKay1"></a>McKay RJ, Campbell NA (1982) Variable selection techniques in discriminant analysis. I: Description. British Journal of Mathematical and Statistical Psychology  35: 1–29.  <ul class="find" data-citedArticleID="1002436" data-doi="10.1111/j.2044-8317.1982.tb00638.x"><li><a href="http://dx.doi.org/10.1111/j.2044-8317.1982.tb00638.x" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Variable+selection+techniques+in+discriminant+analysis.+I%3A+Description." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Variable+selection+techniques+in+discriminant+analysis.+I%3A+Description.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">6.
              </span><a name="pone.0001002-McKay2" id="pone.0001002-McKay2"></a>McKay RJ, Campbell NA (1982) Variable selection techniques in discriminant analysis. II: Allocation. British Journal of Mathematical and Statistical Psychology  35: 30–41.  <ul class="find" data-citedArticleID="1002438" data-doi="10.1111/j.2044-8317.1982.tb00639.x"><li><a href="http://dx.doi.org/10.1111/j.2044-8317.1982.tb00639.x" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Variable+selection+techniques+in+discriminant+analysis.+II%3A+Allocation." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Variable+selection+techniques+in+discriminant+analysis.+II%3A+Allocation.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">7.
              </span><a name="pone.0001002-Golub1" id="pone.0001002-Golub1"></a>Golub T, Slonim D, Tamayo P, Huard C, Gaasenbeek M, et al.  (1999) Molecular classification of cancer: Class discovery and class prediction by gene expression monitoring. Science  286: 531–536.  <ul class="find" data-citedArticleID="1002424" data-doi="10.1126/science.286.5439.531"><li><a href="http://dx.doi.org/10.1126/science.286.5439.531" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Molecular+classification+of+cancer%3A+Class+discovery+and+class+prediction+by+gene+expression+monitoring." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Molecular+classification+of+cancer%3A+Class+discovery+and+class+prediction+by+gene+expression+monitoring.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">8.
              </span><a name="pone.0001002-Hedenfalk1" id="pone.0001002-Hedenfalk1"></a>Hedenfalk I, Duggan D, Chen Y, Radmacher M, Bittner M, et al.  (2001) Gene expression profiles in hereditary breast cancer. New England Journal of Medicine  344: 539–548.  <ul class="find" data-citedArticleID="1002428" data-doi="10.1056/nejm200102223440801"><li><a href="http://dx.doi.org/10.1056/nejm200102223440801" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Gene+expression+profiles+in+hereditary+breast+cancer." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Gene+expression+profiles+in+hereditary+breast+cancer.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">9.
              </span><a name="pone.0001002-Tibshirani1" id="pone.0001002-Tibshirani1"></a>Tibshirani R, Hastie T, Narasimhan B, Chu G (2002) Diagnosis of multiple cancer types by shrunken centroids of gene expression. Proceedings of the National Academy of Sciences  99: 6567–6572.  <ul class="find" data-citedArticleID="1002448" data-doi="10.1073/pnas.082099299"><li><a href="http://dx.doi.org/10.1073/pnas.082099299" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Diagnosis+of+multiple+cancer+types+by+shrunken+centroids+of+gene+expression." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Diagnosis+of+multiple+cancer+types+by+shrunken+centroids+of+gene+expression.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">10.
              </span><a name="pone.0001002-B1" id="pone.0001002-B1"></a>Bø TH, Jonassen I (2002) New feature subset selection procedures for classification of expression profiles. Genome Biology  3: R17.  <ul class="find" data-citedArticleID="1002412"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=New+feature+subset+selection+procedures+for+classification+of+expression+profiles.&amp;auth=&amp;atitle=New+feature+subset+selection+procedures+for+classification+of+expression+profiles." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=New+feature+subset+selection+procedures+for+classification+of+expression+profiles." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22New+feature+subset+selection+procedures+for+classification+of+expression+profiles.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">11.
              </span><a name="pone.0001002-Dabney1" id="pone.0001002-Dabney1"></a>Dabney AR (2005) Classification of microarrays to nearest centroids. Bioinformatics  21: 4148–4154.  <ul class="find" data-citedArticleID="1002416" data-doi="10.1093/bioinformatics/bti681"><li><a href="http://dx.doi.org/10.1093/bioinformatics/bti681" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Classification+of+microarrays+to+nearest+centroids." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Classification+of+microarrays+to+nearest+centroids.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">12.
              </span><a name="pone.0001002-Bickel1" id="pone.0001002-Bickel1"></a>Bickel P, Levina E (2004) Some theory for Fisher's linear discriminant function, ‘naive Bayes’, and some alternatives when there are many more variables than observations. Bernoulli  10: 989–1010.  <ul class="find" data-citedArticleID="1002414" data-doi="10.3150/bj/1106314847"><li><a href="http://dx.doi.org/10.3150/bj/1106314847" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Some+theory+for+Fisher%27s+linear+discriminant+function%2C+%E2%80%98naive+Bayes%E2%80%99%2C+and+some+alternatives+when+there+are+many+more+variables+than+observations." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Some+theory+for+Fisher%27s+linear+discriminant+function%2C+%E2%80%98naive+Bayes%E2%80%99%2C+and+some+alternatives+when+there+are+many+more+variables+than+observations.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">13.
              </span><a name="pone.0001002-1" id="pone.0001002-1"></a>ClaNC Software.  URL <a href="http://www.stat.tamu.edu/adabney/clanc">http://www.stat.tamu.edu/adabney/clanc</a>.  <ul class="find" data-citedArticleID="1002406" data-doi="10.1093/bioinformatics/bti756"><li><a href="http://dx.doi.org/10.1093/bioinformatics/bti756" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=ClaNC+Software." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22ClaNC+Software.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">14.
              </span><a name="pone.0001002-Stein1" id="pone.0001002-Stein1"></a>Stein C (1956) Inadmissability of the usual estimator for the mean of a multivariate distribution. Proc Third Berkeley Symp Math Statist Prob  1: 197–206.  <ul class="find" data-citedArticleID="1002446"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=Inadmissability+of+the+usual+estimator+for+the+mean+of+a+multivariate+distribution.&amp;auth=&amp;atitle=Inadmissability+of+the+usual+estimator+for+the+mean+of+a+multivariate+distribution." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Inadmissability+of+the+usual+estimator+for+the+mean+of+a+multivariate+distribution." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Inadmissability+of+the+usual+estimator+for+the+mean+of+a+multivariate+distribution.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">15.
              </span><a name="pone.0001002-Dabney2" id="pone.0001002-Dabney2"></a>Dabney AR, Storey JD (2005) Optimal feature selection for nearest centroid classifiers, with applications to gene expression microarrays. UW Biostatistics Working Paper Series, Working Paper:267.  URL <a href="http://www.bepress.com/uwbiostat/paper267/">http://www.bepress.com/uwbiostat/paper26​7/</a>.  <ul class="find" data-citedArticleID="1002418"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=Optimal+feature+selection+for+nearest+centroid+classifiers%2C+with+applications+to+gene+expression+microarrays.+UW+Biostatistics+Working+Paper+Series%2C+Working+Paper%3A267.&amp;auth=&amp;atitle=Optimal+feature+selection+for+nearest+centroid+classifiers%2C+with+applications+to+gene+expression+microarrays.+UW+Biostatistics+Working+Paper+Series%2C+Working+Paper%3A267." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Optimal+feature+selection+for+nearest+centroid+classifiers%2C+with+applications+to+gene+expression+microarrays.+UW+Biostatistics+Working+Paper+Series%2C+Working+Paper%3A267." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Optimal+feature+selection+for+nearest+centroid+classifiers%2C+with+applications+to+gene+expression+microarrays.+UW+Biostatistics+Working+Paper+Series%2C+Working+Paper%3A267.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">16.
              </span><a name="pone.0001002-Shen1" id="pone.0001002-Shen1"></a>Shen R, Ghosh D, Chinnaiyan A, Meng Z (2006) Eigengene-based linear discriminant model for tumor classification using gene expression microarray data. Bioinformatics  22: 2635–2642.  <ul class="find" data-citedArticleID="1002444" data-doi="10.1093/bioinformatics/btl442"><li><a href="http://dx.doi.org/10.1093/bioinformatics/btl442" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Eigengene-based+linear+discriminant+model+for+tumor+classification+using+gene+expression+microarray+data." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Eigengene-based+linear+discriminant+model+for+tumor+classification+using+gene+expression+microarray+data.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">17.
              </span><a name="pone.0001002-Guo1" id="pone.0001002-Guo1"></a>Guo Y, Hastie T, Tibshirani R (2007) Regularized discriminant analysis and its application in microarrays. Biostatistics  8: 86–100.  <ul class="find" data-citedArticleID="1002426" data-doi="10.1093/biostatistics/kxj035"><li><a href="http://dx.doi.org/10.1093/biostatistics/kxj035" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Regularized+discriminant+analysis+and+its+application+in+microarrays." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Regularized+discriminant+analysis+and+its+application+in+microarrays.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">18.
              </span><a name="pone.0001002-Schfer1" id="pone.0001002-Schfer1"></a>Schäfer J, Strimmer K (2005) A shrinkage approach to large-scale covariance matrix estimation and implacations for functional genomics. Statistical Applications in Genetics and Molecular Biology  4:  Article 32:   <ul class="find" data-citedArticleID="1002442" data-doi="10.2202/1544-6115.1175"><li><a href="http://dx.doi.org/10.2202/1544-6115.1175" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=A+shrinkage+approach+to+large-scale+covariance+matrix+estimation+and+implacations+for+functional+genomics." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22A+shrinkage+approach+to+large-scale+covariance+matrix+estimation+and+implacations+for+functional+genomics.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">19.
              </span><a name="pone.0001002-Ambroise1" id="pone.0001002-Ambroise1"></a>Ambroise C, McLachlan GJ (2002) Selection bias in gene extraction on the basis of microarray gene expression data. Proceedings of the National Academy of Sciences  99: 6562–6566.  <ul class="find" data-citedArticleID="1002410" data-doi="10.1073/pnas.102102699"><li><a href="http://dx.doi.org/10.1073/pnas.102102699" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Selection+bias+in+gene+extraction+on+the+basis+of+microarray+gene+expression+data." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Selection+bias+in+gene+extraction+on+the+basis+of+microarray+gene+expression+data.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">20.
              </span><a name="pone.0001002-Khan1" id="pone.0001002-Khan1"></a>Khan J, Wei J, Ringner M, Saal L, Ladanyi M, et al.  (2001) Classification and diagnostic prediction of cancers using gene expression profiling and artificial neural networks. Nature Medicine  7: 673–679.  <ul class="find" data-citedArticleID="1002430" data-doi="10.1240/sav_gbm_2002_h_000061"><li><a href="http://dx.doi.org/10.1240/sav_gbm_2002_h_000061" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Classification+and+diagnostic+prediction+of+cancers+using+gene+expression+profiling+and+artificial+neural+networks." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Classification+and+diagnostic+prediction+of+cancers+using+gene+expression+profiling+and+artificial+neural+networks.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">21.
              </span><a name="pone.0001002-Alizadeh1" id="pone.0001002-Alizadeh1"></a>Alizadeh A, Eisen M, Davis R, Ma C, Lossos I, et al.  (2000) Distinct types of diffuse large B-cell lymphoma identified by gene expression profiling. Nature  403: 503–511.  <ul class="find" data-citedArticleID="1002408" data-doi="10.1038/35000501"><li><a href="http://dx.doi.org/10.1038/35000501" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Distinct+types+of+diffuse+large+B-cell+lymphoma+identified+by+gene+expression+profiling." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Distinct+types+of+diffuse+large+B-cell+lymphoma+identified+by+gene+expression+profiling.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">22.
              </span><a name="pone.0001002-Ross1" id="pone.0001002-Ross1"></a>Ross D, Scherf U, Eisen M, Perou C, Rees C, et al.  (2000) Systematic variation in gene expression patterns in human cancer cell lines. Nature Genetics  24: 227–235.  <ul class="find" data-citedArticleID="1002440" data-doi="10.1038/73432"><li><a href="http://dx.doi.org/10.1038/73432" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Systematic+variation+in+gene+expression+patterns+in+human+cancer+cell+lines." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Systematic+variation+in+gene+expression+patterns+in+human+cancer+cell+lines.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li></ol></div>

  </div>

      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.XML" value="83259"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.PDF" value="136863"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e001.PNG" value="8925"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e001.TIF" value="24976"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e002.PNG" value="10724"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e002.TIF" value="26876"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e003.PNG" value="7766"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e003.TIF" value="23788"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e004.PNG" value="8333"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e004.TIF" value="24336"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e005.PNG" value="10464"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e005.TIF" value="26460"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e006.PNG" value="15299"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e006.TIF" value="32140"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e007.PNG" value="9243"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e007.TIF" value="25284"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.t001.PNG_L" value="51098"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.t001.PNG_M" value="72313"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.t001.PNG_S" value="12996"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.t001.TIF" value="291830"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.t001.PNG_I" value="23343"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.t002.PNG_L" value="60607"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.t002.PNG_M" value="79339"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.t002.PNG_S" value="13702"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.t002.TIF" value="279350"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.t002.PNG_I" value="25763"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e008.PNG" value="5174"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e008.TIF" value="21112"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e009.PNG" value="5030"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e009.TIF" value="20936"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e010.PNG" value="5131"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e010.TIF" value="21068"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e011.PNG" value="5131"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e011.TIF" value="21068"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e012.PNG" value="5030"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e012.TIF" value="20936"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e013.PNG" value="5174"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e013.TIF" value="21112"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e014.PNG" value="8307"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e014.TIF" value="24148"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e015.PNG" value="5308"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e015.TIF" value="21236"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e016.PNG" value="7623"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e016.TIF" value="23524"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e017.PNG" value="8690"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e017.TIF" value="24708"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e018.PNG" value="7645"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e018.TIF" value="23700"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e019.PNG" value="12429"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e019.TIF" value="28964"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e020.PNG" value="5232"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e020.TIF" value="21156"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e021.PNG" value="7470"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e021.TIF" value="23388"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e022.PNG" value="5128"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e022.TIF" value="21040"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e023.PNG" value="7858"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e023.TIF" value="23796"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e024.PNG" value="5030"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e024.TIF" value="20936"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e025.PNG" value="5340"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e025.TIF" value="21240"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e026.PNG" value="5030"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e026.TIF" value="20936"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e027.PNG" value="11897"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e027.TIF" value="27592"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e028.PNG" value="5351"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e028.TIF" value="21584"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e029.PNG" value="5030"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e029.TIF" value="20936"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e030.PNG" value="5030"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e030.TIF" value="20936"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e031.PNG" value="6171"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e031.TIF" value="22148"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e032.PNG" value="11004"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e032.TIF" value="26760"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e033.PNG" value="5002"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e033.TIF" value="20916"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e034.PNG" value="9957"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e034.TIF" value="25608"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e035.PNG" value="13487"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e035.TIF" value="29560"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e036.PNG" value="8927"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e036.TIF" value="24820"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e037.PNG" value="7319"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.e037.TIF" value="23260"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.t003.PNG_L" value="106701"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.t003.PNG_M" value="62613"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.t003.PNG_S" value="9570"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.t003.TIF" value="482080"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.t003.PNG_I" value="18753"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.t004.PNG_L" value="106738"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.t004.PNG_M" value="60980"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.t004.PNG_S" value="9571"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.t004.TIF" value="481662"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.t004.PNG_I" value="17989"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.g001.PNG_L" value="40995"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.g001.PNG_M" value="58861"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.g001.PNG_S" value="9960"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.g001.TIF" value="116728"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.g001.PNG_I" value="20591"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.g002.PNG_L" value="47160"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.g002.PNG_M" value="64056"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.g002.PNG_S" value="10881"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.g002.TIF" value="120742"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.g002.PNG_I" value="22137"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.g003.PNG_L" value="28950"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.g003.PNG_M" value="71688"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.g003.PNG_S" value="11727"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.g003.TIF" value="127892"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001002.g003.PNG_I" value="25204"/>

</div>
<div class="sidebar">

  <div class="article-actions cf">
      <div class="download">
        <span class="btn"><a href="/article/fetchObject.action?uri=info%3Adoi%2F10.1371%2Fjournal.pone.0001002&amp;representation=PDF" title="Download" target="_blank">Download PDF</a></span>
      </div>
      <div class="btn-reveal dropdown">
        <div class="dropdown-icon">
          <span class="btn">&nbsp;</span>
        </div>

        <div class="content">
          <ul class="bullet">
            <li><a href="/article/citationList.action?articleURI=info%3Adoi%2F10.1371%2Fjournal.pone.0001002" title="Download citations">Citation</a></li>
            <li><a href="/article/fetchObjectAttachment.action?uri=info%3Adoi%2F10.1371%2Fjournal.pone.0001002&amp;representation=XML" title="Download article XML">XML</a></li>
          </ul>
        </div>
      </div> <!-- end btn-reveal dropdown-->


    <div class="btn-reveal flt-l">
        <span class="btn">Print</span>
        <div class="content">
            <ul class="bullet">
                <li id="print-article"><a href="#" onclick="if(typeof(_gaq) != 'undefined'){ _gaq.push(['_trackEvent','Article', 'Print', 'Click']); } window.print(); return false;" title="Print Article">Print article</a></li>
                <li>
                  <a href="https://www.odysseypress.com/onlinehost/reprint_order.php?type=A&page=0&journal=7&doi=10.1371/journal.pone.0001002&volume=&issue=&title=Optimality Driven Nearest Centroid Classification from Genomic Data&author_name=Alan%20R.%20Dabney%2C%20John%20D.%20Storey&start_page=1&end_page=7" title="Odyssey Press">EzReprint</a>
                </li>
            </ul>
        </div>
    </div>

    <div class="btn-reveal flt-r">
        <span class="btn">Share</span>
        <div class="content">
            <ul class="social">
                <li><a href="http://www.reddit.com/submit?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001002" target="_blank" title="Submit to Reddit"><img src="/images/icon.reddit.16.png" width="16" height="16" alt="Reddit">Reddit</a></li>

                <li><a href="https://plus.google.com/share?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001002" target="_blank" title="Share on Google+"><img src="/images/icon.gplus.16.png" width="16" height="16" alt="Google+">Google+</a></li>

                <li><a href="http://www.stumbleupon.com/submit?url=http%3A%2F%2Fwww.plosone.org%2Farticle%2Finfo%253Adoi%252F10.1371%252Fjournal.pone.0001002" target="_blank" title="Add to StumbleUpon"><img src="/images/icon.stumble.16.png" width="16" height="16" alt="StumbleUpon">StumbleUpon</a></li>

                <li><a href="http://www.facebook.com/share.php?u=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001002&amp;t=Optimality%20Driven%20Nearest%20Centroid%20Classification%20from%20Genomic%20Data" target="_blank" title="Share on Facebook"><img src="/images/icon.fb.16.png" width="16" height="16" alt="Facebook">Facebook</a></li>

                <li><a href="http://www.linkedin.com/shareArticle?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001002&title=Optimality%20Driven%20Nearest%20Centroid%20Classification%20from%20Genomic%20Data&summary=Checkout%20this%20article%20I%20found%20at%20PLOS" target="_blank" title="Add to LinkedIn"><img src="/images/icon.linkedin.16.png" width="16" height="16" alt="Mendeley">LinkedIn</a></li>

                <li><a href="http://www.citeulike.org/posturl?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001002&amp;title=Optimality%20Driven%20Nearest%20Centroid%20Classification%20from%20Genomic%20Data" target="_blank" title="Add to CiteULike"><img src="/images/icon.cul.16.png" width="16" height="16" alt="CiteULike">CiteULike</a></li>

                <li><a href="http://www.mendeley.com/import/?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001002" target="_blank" title="Add to Mendeley"><img src="/images/icon.mendeley.16.png" width="16" height="16" alt="Mendeley">Mendeley</a></li>

                <li><a href="https://www.pubchase.com/library?add_aid=10.1371%2Fjournal.pone.0001002&amp;source=plos" target="_blank" title="Add to PubChase"><img src="/images/icon.pc.16.png" width="16" height="16" alt="PubChase">PubChase</a></li>


                <script type="text/javascript">
                    // replace tweet with one that's pre-shortened to 140 chars
                    function truncateTweetText() {
                        var twtTitle = 'Optimality Driven Nearest Centroid Classification from Genomic Data';
                        var twtUrl = 'http://dx.plos.org/10.1371/journal.pone.0001002';
                        // all URLs posted to twitter get auto-shortened to 20 chars.
                        var maxLength = 140 - (20 + 1);
                        // truncate the title to include space for twtTag and ellipsis (here, 10 = tag length + space + ellipsis)
                        if (twtTitle.length > maxLength) { twtTitle = twtTitle.substr(0, (maxLength - 10)) + '...'; }
                        // set the href to use the shortened tweet
                        $('#twitter-share-link').prop('href', 'http://twitter.com/intent/tweet?text=' + encodeURIComponent('#PLOSONE: ' + twtTitle + ' ' + twtUrl));
                    }
                </script>
                <li><a href="http://twitter.com/intent/tweet?text=#PLOSONE%3A%20Optimality%20Driven%20Nearest%20Centroid%20Classification%20from%20Genomic%20Data http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001002" onclick="truncateTweetText();" target="_blank" title="Share on Twitter" id="twitter-share-link"><img src="/images/icon.twtr.16.png" width="16" height="16" alt="Twitter">Twitter</a></li>

                <li><a href="/article/email/info%3Adoi%2F10.1371%2Fjournal.pone.0001002" title="Email this article"><img src="/images/icon.email.16.png" width="16" height="16" alt="Email">Email</a></li>
            </ul>
        </div>
    </div><!--end btn-reveal flt-r-->
</div><!-- end article-actions-->

<!-- begin Crossmark -->

<a id="open-crossmark" href="#" style="margin-top: -28px; display:block"><img style="border: 0; display: none;
 padding: 10px 0 18px 0;"  id="crossmark-icon" src="/images/logo-crossmark-bw.png" /></a>
<div id="crossmark-dialog" style="display: none;" title="">
    <!-- the external CrossMark data is loaded inside this iframe -->
    <iframe id="crossmark-dialog-frame" frameborder="0"></iframe>
</div>

<!-- end crossmark -->


<div class="block" id="subject-area-sidebar-block">
    <div class="header">
        <h3>Subject Areas</h3><div title="More information" id="subject-area-sidebar-block-help-icon"><img align="right"
                                                                                                           alt="info" src="/images/button_info.png"/><div id="subject-area-sidebar-block-help"><img align="right"
                                                                                                                                                                                                    src="/images/button_info.png"/><p>
        <b>We want your feedback.</b> Do these subject areas make sense for this article? If not, click the flag
        next to the incorrect subject area and we will review it. Thanks for your help!
    </p></div></div>
    </div>


    <ul id="subject-area-sidebar-list">











          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Algorithms%22" title="Search for articles in the subject area:'Algorithms'"><div class="flagText">Algorithms</div></a>
              <div data-categoryid="32621" data-articleid="24838"
                   data-categoryname="Algorithms"
                   class="flagImage" title="Flag 'Algorithms' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Covariance%22" title="Search for articles in the subject area:'Covariance'"><div class="flagText">Covariance</div></a>
              <div data-categoryid="33497" data-articleid="24838"
                   data-categoryname="Covariance"
                   class="flagImage" title="Flag 'Covariance' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Forecasting%22" title="Search for articles in the subject area:'Forecasting'"><div class="flagText">Forecasting</div></a>
              <div data-categoryid="34789" data-articleid="24838"
                   data-categoryname="Forecasting"
                   class="flagImage" title="Flag 'Forecasting' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Lymphomas%22" title="Search for articles in the subject area:'Lymphomas'"><div class="flagText">Lymphomas</div></a>
              <div data-categoryid="33151" data-articleid="24838"
                   data-categoryname="Lymphomas"
                   class="flagImage" title="Flag 'Lymphomas' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Microarrays%22" title="Search for articles in the subject area:'Microarrays'"><div class="flagText">Microarrays</div></a>
              <div data-categoryid="17255" data-articleid="24838"
                   data-categoryname="Microarrays"
                   class="flagImage" title="Flag 'Microarrays' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Normal+distribution%22" title="Search for articles in the subject area:'Normal distribution'"><div class="flagText">Normal distribution</div></a>
              <div data-categoryid="32203" data-articleid="24838"
                   data-categoryname="Normal distribution"
                   class="flagImage" title="Flag 'Normal distribution' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Probability+density%22" title="Search for articles in the subject area:'Probability density'"><div class="flagText">Probability density</div></a>
              <div data-categoryid="33821" data-articleid="24838"
                   data-categoryname="Probability density"
                   class="flagImage" title="Flag 'Probability density' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Simulation+and+modeling%22" title="Search for articles in the subject area:'Simulation and modeling'"><div class="flagText">Simulation and modeling</div></a>
              <div data-categoryid="8375" data-articleid="24838"
                   data-categoryname="Simulation and modeling"
                   class="flagImage" title="Flag 'Simulation and modeling' as inappropriate"></div>
          </li>
    </ul>
</div>

<div class="ad">
    <div class="title">Advertisement</div>






  <iframe id='a0852f54' name='a0852f54'
    src='http://ads.plos.org/www/delivery/afr.php?zoneid=381&amp;cb=8287'
    frameborder='0' scrolling='no' width='160' height='600'>
    <a href='http://ads.plos.org/www/delivery/ck.php?n=a0852f54&amp;cb=2015'
      target='_top'><img src='http://ads.plos.org/www/delivery/avw.php?zoneid=381&amp;cb=5516&amp;n=a0852f54'
      border='0' alt=''/>
    </a>
  </iframe>



</div>

<div id="twitter-alm-timeline" class="twitter-alm-timeline"></div>


</div><!-- sidebar -->
    </div>
  </div>
</div>
<script src="http://wl.figshare.com/static/p_widget.js" type="text/javascript"></script><div id="pageftr">
  <div class="ftr-cols cf">
    <div class="col col-1">
      <img src="/images/logo-plos-footer.png" alt="PLOS Logo" class="logo" />
      <p><a href="/static/releaseNotes">Ambra 2.9.16</a> Managed Colocation provided <br />by <a href="http://www.isc.org/">Internet Systems Consortium</a>.<p>
      <div class="nav nav-aux">
        <a href="/static/privacy">Privacy Policy</a> |
        <a href="/static/terms">Terms of Use</a> |
        <a href="http://www.plos.org/advertise/">Advertise</a> |
        <a href="http://www.plos.org/about/media-inquiries/">Media Inquiries</a>
      </div>
    </div>
    <div class="col col-2">
      <p><a href="http://www.plos.org/publications/journals/">Publications</a></p>
      <div class="nav">
        <ul>
          <li><a href="http://www.plosbiology.org">PLOS Biology</a></li>
          <li><a href="http://www.plosmedicine.org">PLOS Medicine</a></li>
          <li><a href="http://www.ploscompbiol.org">PLOS Computational Biology</a></li>
          <li><a href="http://currents.plos.org">PLOS Currents</a></li>
          <li><a href="http://www.plosgenetics.org">PLOS Genetics</a></li>
          <li><a href="http://www.plospathogens.org">PLOS Pathogens</a></li>
          <li><a href="http://www.plosone.org">PLOS ONE</a></li>
          <li><a href="http://www.plosntds.org">PLOS Neglected Tropical Diseases</a></li>
        </ul>
      </div>
    </div>
    <div class="col col-3">
      <div class="nav">
        <p><a href="http://www.plos.org">plos.org</a></p>
        <p><a href="http://blogs.plos.org">Blogs</a></p>
        <p><a href="http://www.ploscollections.org">Collections</a></p>
        <p><a href="/feedback/new">Send us feedback</a></p>

        <p>California (US) corporation #C2354500, based in San Francisco</p>
      </div>
    </div>
  </div>
</div><!-- pageftr -->

</div><!-- end page-wrap, this div is in header.ftl -->
<script type="text/javascript" src="/javascript/jquery-1.8.1-min.js?v=Tm7VCOzZz3lE03ghpkS6SWkHbyI"></script>
<script type="text/javascript" src="/javascript/ga-min.js?v=lNQ4gt8QcPDatjsdOFl_FGpPhLY"></script>
<script type="text/javascript" src="/javascript/jquery.hoverIntent-min.js?v=mRiGNYY9cIXxVb8u0K_MdW7hHnc"></script>
<script type="text/javascript" src="/javascript/jquery.placeholder-min.js?v=21Pn56Ur9h1N4K4VZDa0nqI3Pxo"></script>
<script type="text/javascript" src="/javascript/jquery.jsonp-2.4.0-min.js?v=lqTpzoHfSq3I5Ygo01qq5WankEo"></script>
<script type="text/javascript" src="/javascript/jquery-ui-1.9.2.custom-min.js?v=raSSlfNO0YsV5uUpAKmTB9n5VTc"></script>
<script type="text/javascript" src="/javascript/jquery.tooltip-min.js?v=cw+6Smh+mdryIA25xvqIvHMrnZM"></script>
<script type="text/javascript" src="/javascript/jquery.uniform-min.js?v=kYUAnX6W2W_2fK3RIuQ2m_YFG9U"></script>
<script type="text/javascript" src="/javascript/jquery.pjax-min.js?v=939kLBjL5_YKbx71T1RHjYaD4l8"></script>
<script type="text/javascript" src="/javascript/imagesloaded-min.js?v=XeuAp8Gc3mvQUo+wZCSF8ttPwvw"></script>
<script type="text/javascript" src="/javascript/figviewer-min.js?v=yPUa0sUQ_iHkI+IRv2i9bjyZJFo"></script>
<script type="text/javascript" src="/javascript/global-min.js?v=0Q3PwjeaWtXYDnqIsQvnL_ou0qs"></script>
<script type="text/javascript" src="/javascript/jquery.touchswipe-min.js?v=huaek_e6HqTduvCNAN91dJolTyw"></script>
<script type="text/javascript" src="/javascript/jquery.base64-min.js?v=VwV1zeVqKZj5FCAdlK0q5NRxbBg"></script>
<script type="text/javascript" src="/javascript/alm-min.js?v=Y5gm6B0b4Kx2YHNObNrgEeBgXlY"></script>
<script type="text/javascript" src="/javascript/taxonomy-browser-min.js?v=vBVMuDMYkGJCXIUxLe35GoyiJNw"></script>
<script type="text/javascript" src="/javascript/jquery.filterize-min.js?v=j0ZKVnHyk2nhFy8eIuNJkp7xaM0"></script>
<script type="text/javascript" src="/javascript/plosone-min.js?v=TK4H4arL_XBSwwJq+K1N3kqYfAI"></script>
<script type="text/javascript" src="/javascript/twitter-min.js?v=xKgcxLsQFXy+at1ao1NVke8nFlM"></script>
<script type="text/javascript" src="/javascript/crossmark.1.4-min.js?v=3FO4k0SjwTaGNnKGNSqthar1080"></script>
<script type="text/javascript">
  var _sf_async_config={uid:16579,domain:"plosone.org"};
  (function(){
    function loadChartbeat() {
      window._sf_endpt=(new Date()).getTime();
      var e = document.createElement('script');
      e.setAttribute('language', 'javascript');
      e.setAttribute('type', 'text/javascript');
      e.setAttribute('src',
          (("https:" == document.location.protocol) ? "https://a248.e.akamai.net/chartbeat.download.akamai.com/102508/" : "http://static.chartbeat.com/") +
              "js/chartbeat.js");
      document.body.appendChild(e);
    }
    var oldonload = window.onload;
    window.onload = (typeof window.onload != 'function') ?
        loadChartbeat : function() { oldonload(); loadChartbeat(); };
  })();
</script>
<!-- <script type="application/javascript" src="http://crossmark.crossref.org/javascripts/v1.3/crossmark.min.js"></script> -->

</body>
</html>
