

 



<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"
      xmlns:foaf="http://xmlns.com/foaf/0.1/"
      xmlns:dc="http://purl.org/dc/terms/"
      xmlns:doi="http://dx.doi.org/"
      xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
      xmlns:xsd="http://www.w3.org/2001/XMLSchema-datatypes#"
      lang="en" xml:lang="en"
      itemscope itemtype="http://schema.org/Article"
      class="no-js">
<head prefix="og: http://ogp.me/ns#">
  <title>PLOS ONE: Dynamic Perceptual Changes in Audiovisual Simultaneity</title>


<link rel="stylesheet" type="text/css"  href="/css/global-min.css?v=izteQ6tu7kgsJZW_xmrYizvKiHM" />


    <!--[if lte IE 7]>
<link rel="stylesheet" type="text/css"  href="/css/lte_ie7-min.css?v=3bykQUyQmReeuobVyPozcJ9LxRc" />
    <![endif]-->


<link rel="stylesheet" type="text/css"  href="/css/jquery-ui-min.css?v=eXDHTEJM0lIAmDe5k0I0Ad4nxNo" />


<link rel="stylesheet" type="text/css"  href="/css/journal.css?v=T7ZVxJfgk9jNxLAJ2qHz1vZpgYU" />


<link rel="stylesheet" type="text/css" media="print" href="/css/print-min.css?v=T5lb0B3q6EXBsuDluc5V5w+AkRc" />


  <link rel="stylesheet" href="http://f.fontdeck.com/s/css/js/www.plosone.org/24557.css" type="text/css"/>

  <!--chartbeat -->
  <script type="text/javascript">var _sf_startpt = (new Date()).getTime()</script>
  <script>document.documentElement.className += ' js';</script>

  <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <meta http-equiv="X-UA-Compatible" content="IE=EmulateIE7; IE=EmulateIE9"/>
  <meta name="description" content="PLOS ONE: an inclusive, peer-reviewed, open-access resource from the PUBLIC LIBRARY OF SCIENCE. Reports of well-performed scientific studies from all disciplines freely available to the whole world."/>
  <meta name="keywords" content="PLOS, Public Library of Science, Open Access, Open-Access, Science, Medicine, Biology, Research, Peer-review, Inclusive, Interdisciplinary, Ante-disciplinary, Physics, Chemistry, Engineering"/>
  <meta name="almHost" content="http://alm.plos.org/api/v3/articles"/>
  <meta name="searchHost" content="http://api.plos.org/search" />
  <meta name="termsHost" content="http://api.plos.org/terms" />
  <meta name="solrApiKey" content="plos"/>
  <meta name="almAPIKey" content="3pezRBRXdyzYW6ztfwft" />
  <meta name="currentJournal" content="PLoSONE" />
  <meta name="almRequestBatchSize" content="" />

  <meta name="citation_publisher" content="Public Library of Science"/>
  <meta name="citation_doi" content="10.1371/journal.pone.0001253"/>
  <meta name="dc.identifier" content="10.1371/journal.pone.0001253" />

    <meta name="citation_title" content="Dynamic Perceptual Changes in Audiovisual Simultaneity"/>
    <meta itemprop="name" content="Dynamic Perceptual Changes in Audiovisual Simultaneity"/>

      <meta name="citation_author" content="Ryota Kanai"/>
            <meta name="citation_author_institution" content="Division of Biology, California Institute of Technology, Pasadena, California, United States of America"/>
      <meta name="citation_author" content="Bhavin R. Sheth"/>
            <meta name="citation_author_institution" content="Department of Electrical and Computer Engineering, University of Houston, Houston, Texas, United States of America"/>
            <meta name="citation_author_institution" content="Center for NeuroEngineering and Cognitive Sciences, University of Houston, Houston, Texas, United States of America"/>
      <meta name="citation_author" content="Frans A. J. Verstraten"/>
            <meta name="citation_author_institution" content="Department of Experimental Psychology, Helmholtz Institute, Universiteit Utrecht, Utrecht, The Netherlands"/>
      <meta name="citation_author" content="Shinsuke Shimojo"/>
            <meta name="citation_author_institution" content="Division of Biology, California Institute of Technology, Pasadena, California, United States of America"/>

    <meta name="citation_date" content="2007/12/5"/>

  <meta name="citation_pdf_url" content="http://dx.plos.org/10.1371/journal.pone.0001253.pdf" />

      <meta name="citation_journal_title" content="PLOS ONE" />
    <meta name="citation_firstpage" content="e1253"/>
    <meta name="citation_issue" content="12"/>
    <meta name="citation_volume" content="2"/>
    <meta name="citation_issn" content="1932-6203"/>

    <meta name="citation_journal_abbrev" content="PLoS ONE" />

      <meta name="citation_reference" content="citation_title=Multisensory perception: Beyond modularity and convergence.; citation_author=J Driver; citation_author=C Spence; citation_journal_title=Curr Biol; citation_volume=10; citation_number=1; citation_pages=R731-R735; citation_date=2000; " />
      <meta name="citation_reference" content="citation_title=Multisensory integration: Maintaining the perception of synchrony.; citation_author=C Spence; citation_author=S Squire; citation_journal_title=Curr Biol; citation_volume=13; citation_number=2; citation_pages=R519-521; citation_date=2003; " />
      <meta name="citation_reference" content="citation_title=Visual-auditory distance constancy.; citation_author=GR Engel; citation_author=WG Dougherty; citation_journal_title=Nature; citation_volume=234; citation_number=3; citation_pages=308; citation_date=1971; " />
      <meta name="citation_reference" content="citation_title=Audiovisual perception: Implicit estimation of sound-arrival time.; citation_author=Y Sugita; citation_author=Y Suzuki; citation_journal_title=Nature; citation_volume=421; citation_number=4; citation_pages=911; citation_date=2003; " />
      <meta name="citation_reference" content="citation_title=Simultaneity constancy.; citation_author=A Kopinska; citation_author=LR Harris; citation_journal_title=Perception; citation_volume=33; citation_number=5; citation_pages=1049-1069; citation_date=2004; " />
      <meta name="citation_reference" content="citation_title=Synchronizing to real events: Subjective audiovisual alignment scales with perceived auditory depth and speed of sound.; citation_author=D Alais; citation_author=S Carlile; citation_journal_title=Proc Natl Acad Sci U S A; citation_volume=102; citation_number=6; citation_pages=2244-2247; citation_date=2005; " />
      <meta name="citation_reference" content="citation_title=Auditory-visual temporal integration as a function of distance: no compensation for sound-transmission time in human perception.; citation_author=J Lewald; citation_author=R Guski; citation_journal_title=Neurosci Lett; citation_volume=357; citation_number=7; citation_pages=119-122; citation_date=2004; " />
      <meta name="citation_reference" content="citation_title=Recalibration of audio-visual simultaneity.; citation_author=W Fujisaki; citation_author=S Shimojo; citation_author=M Kashino; citation_author=S Nishida; citation_journal_title=Nat Neurosci; citation_volume=7; citation_number=8; citation_pages=773-778; citation_date=2004; " />
      <meta name="citation_reference" content="citation_title=Exposure to asynchronous audiovisual speech extends the temporal window for audiovisual integration.; citation_author=J Navarra; citation_author=A Vatakis; citation_author=M Zampin; citation_author=S Soto-Faraco; citation_author=W Humphreys; citation_journal_title=Cogn Brain Res; citation_volume=25; citation_number=9; citation_pages=499-507; citation_date=2005; " />
      <meta name="citation_reference" content="citation_title=Motor-sensory recalibration leads to an illusory reversal of action and sensation.; citation_author=C Stetson; citation_author=C Xu; citation_author=PR Montague; citation_author=DM Eagleman; citation_journal_title=Neuron; citation_volume=51; citation_number=10; citation_pages=651-659; citation_date=2006; " />
      <meta name="citation_reference" content="citation_title=Bayesian calibration of simultaneity in tactile temporal order judgment.; citation_author=M Miyazaki; citation_author=S Yamamoto; citation_author=S Uchida; citation_author=S Kitazawa; citation_journal_title=Nat Neurosci; citation_volume=9; citation_number=11; citation_pages=875-877; citation_date=2006; " />
      <meta name="citation_reference" content="citation_title=Philosophische studien.; citation_author=WM Wundt; citation_number=12; citation_date=1883; citation_publisher=Wilhelm Engelmann; " />
      <meta name="citation_reference" content="citation_title=The determination of the position of a momentary impression in the temporal course of a moving impression.; citation_author=NT Burrow; citation_journal_title=Psychological Monographs; citation_volume=11; citation_number=13; citation_pages=163; citation_date=1909; " />
      <meta name="citation_reference" content="citation_title=The complication experiment and related phenomena.; citation_author=K Dunlap; citation_journal_title=Psychological Review; citation_volume=17; citation_number=14; citation_pages=157-191; citation_date=1910; " />
      <meta name="citation_reference" content="citation_title=The complication experiment uncomplicated.; citation_author=PT Cairney; citation_journal_title=Perception; citation_volume=4; citation_number=15; citation_pages=255-265; citation_date=1975; " />
      <meta name="citation_reference" content="citation_title=The sensations: Their functions, processes and mechanisms.; citation_author=H PiÃ©ron; citation_number=16; citation_date=1952; citation_publisher=Muller; " />
      <meta name="citation_reference" content="citation_title=The psychology of time.; citation_author=P Fraisse; citation_number=17; citation_date=1964; citation_publisher=Eyre & Spottiswoode; " />
      <meta name="citation_reference" content="citation_title=Temporal frequency characteristics of synchrony-asynchrony discrimination of audio-visual signals.; citation_author=W Fujisaki; citation_author=S Nishida; citation_journal_title=Exp Brain Res; citation_volume=166; citation_number=18; citation_pages=455-464; citation_date=2005; " />
      <meta name="citation_reference" content="citation_title=Multisensory prior entry.; citation_author=C Spence; citation_author=DI Shore; citation_author=RM Klein; citation_journal_title=J Exp Psychol: General; citation_volume=130; citation_number=19; citation_pages=799-832; citation_date=2001; " />
      <meta name="citation_reference" content="citation_title=Audio-visual simultaneity judgments.; citation_author=M Zampini; citation_author=S Guest; citation_author=DI Shore; citation_author=C Spence; citation_journal_title=Percept Psychophys; citation_volume=67; citation_number=20; citation_pages=531-544; citation_date=2005; " />
      <meta name="citation_reference" content="citation_title=Visual competition.; citation_author=R Blake; citation_author=NK Logothetis; citation_journal_title=Nat Rev Neurosci; citation_volume=3; citation_number=21; citation_pages=13-21; citation_date=2002; " />
      <meta name="citation_reference" content="citation_title=The temporal cross-capture of audition and vision.; citation_author=R Fendrich; citation_author=PM Corballis; citation_journal_title=Percept Psychophys; citation_volume=63; citation_number=22; citation_pages=719-725; citation_date=2001; " />
      <meta name="citation_reference" content="citation_title=Temporal-order judgments and reaction time for stimuli of different modalities.; citation_author=P Jaskowski; citation_author=F Jaroszyk; citation_author=D Hojan-Jezierska; citation_journal_title=Psychol Res; citation_volume=52; citation_number=23; citation_pages=35-38; citation_date=1990; " />
      <meta name="citation_reference" content="citation_title=When is now? Perception of simultaneity.; citation_author=JV Stone; citation_author=NM Hunkin; citation_author=J Porrill; citation_author=R Wood; citation_author=V Keeler; citation_journal_title=Proc Biol Sci; citation_volume=268; citation_number=24; citation_pages=31-38; " />
      <meta name="citation_reference" content="citation_title=Audiovisual temporal order judgments.; citation_author=M Zampini; citation_author=DI Shore; citation_author=C Spence; citation_journal_title=Exp Brain Res; citation_volume=152; citation_number=25; citation_pages=198-210; citation_date=2003; " />
      <meta name="citation_reference" content="citation_title=The relative quickness of visual and auditory perception.; citation_author=WF Smith; citation_journal_title=J Exp Psychol; citation_volume=16; citation_number=26; citation_pages=239-257; citation_date=1933; " />
      <meta name="citation_reference" content="citation_title=Perception of temporal order of stimuli differing in sense mode and simple reaction time.; citation_author=J Rutschmann; citation_author=R Link; citation_journal_title=Percept Mot Skills; citation_volume=18; citation_number=27; citation_pages=345-352; citation_date=1964; " />
      <meta name="citation_reference" content="citation_title=Lectures on the elementary psychology of feeling and attention.; citation_author=EB Titchener; citation_number=28; citation_date=1908; citation_publisher=Macmillan; " />
      <meta name="citation_reference" content="citation_title=Focal visual attention produces illusory temporal order and motion sensation.; citation_author=O Hikosaka; citation_author=S Miyauchi; citation_author=S Shimojo; citation_journal_title=Vision Res; citation_volume=33; citation_number=29; citation_pages=1219-1240; citation_date=1993; " />
      <meta name="citation_reference" content="citation_title=Cross-modal illusory conjunctions between vision and touch.; citation_author=C Cinel; citation_author=GW Humphreys; citation_author=R Poli; citation_journal_title=J Exp Psychol Hum Percept Perform; citation_volume=28; citation_number=30; citation_pages=1243-1266; citation_date=2002; " />
      <meta name="citation_reference" content="citation_title=Boundary conditions on parallel processing in human vision.; citation_author=J Duncan; citation_journal_title=Perception; citation_volume=18; citation_number=31; citation_pages=457-469; citation_date=1989; " />
      <meta name="citation_reference" content="citation_title=Orienting of attention. The VIIth Sir Frederic Barlett Lecture.; citation_author=MI Posner; citation_journal_title=Q J Exp Psychol; citation_volume=32; citation_number=32; citation_pages=3-25; citation_date=1980; " />
      <meta name="citation_reference" content="citation_title=A model of saccade generation based on parallel processing and competitive inhibition.; citation_author=JM Findlay; citation_author=R Walker; citation_journal_title=Behavioral Brain Science; citation_volume=22; citation_number=33; citation_pages=661-721; citation_date=1999; " />
      <meta name="citation_reference" content="citation_title=Infants' use of gaze direction to cue attention: The importance of perceived motion.; citation_author=T Farroni; citation_author=MH Johnson; citation_author=M Brockbank; citation_author=F Simion; citation_journal_title=Vis Cog; citation_volume=7; citation_number=34; citation_pages=705-718; citation_date=2000; " />
      <meta name="citation_reference" content="citation_title=Temporal ventriloquism: Sound modulates the flash-lag effect.; citation_author=J Vroomen; citation_author=B de Gelder; citation_journal_title=J Exp Psyhol Hum Percept Perform; citation_volume=30; citation_number=35; citation_pages=513-518; citation_date=2004; " />
      <meta name="citation_reference" content="citation_title=Auditory capture of vision: Examining temporal ventriloquism.; citation_author=S Morein-Zamir; citation_author=S Soto-Faraco; citation_author=A Kingstone; citation_journal_title=Cogn Brain Res; citation_volume=17; citation_number=36; citation_pages=154-163; citation_date=2003; " />
      <meta name="citation_reference" content="citation_title=The role of attention in temporal integration.; citation_author=TAW Visser; citation_author=JT Enns; citation_journal_title=Perception; citation_volume=30; citation_number=37; citation_pages=135-145; citation_date=2001; " />
      <meta name="citation_reference" content="citation_title=Transient spatial attention degrades temporal resolution.; citation_author=Y Yeshurun; citation_author=L Levy; citation_journal_title=Psychol Sci; citation_volume=14; citation_number=38; citation_pages=225-231; citation_date=2003; " />
      <meta name="citation_reference" content="citation_title=Attention and the subjective expansion of time.; citation_author=PU Tse; citation_author=J Intriligator; citation_author=J Rivest; citation_author=P Cavanagh; citation_journal_title=Percept Psychophys; citation_volume=66; citation_number=39; citation_pages=1171-1189; citation_date=2004; " />
      <meta name="citation_reference" content="citation_title=The dynamics of bi-stable alternation in ambiguous motion displays: a fresh look at plaids.; citation_author=JM HupÃ©; citation_author= Rubin; citation_author= N; citation_journal_title=Vision Res; citation_volume=43; citation_number=40; citation_pages=531-548; citation_date=2003; " />
      <meta name="citation_reference" content="citation_title=Temporal dynamics of auditory and visual bistability reveal common principles of perceptual organization.; citation_author=D Pressnitzer; citation_author=JM HupÃ©; citation_journal_title=Curr Biol; citation_volume=16; citation_number=41; citation_pages=1351-1357; citation_date=2006; " />

  <link rel="canonical" href="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0001253" />

    <meta name="twitter:card" content="summary"/>
    <meta name="twitter:site" content="@plosone"/>
    <meta name="twitter:title" content="Dynamic Perceptual Changes in Audiovisual Simultaneity"/>
    <meta name="twitter:description" content="BackgroundThe timing at which sensory input reaches the level of conscious perception is an intriguing question still awaiting an answer. It is often assumed that both visual and auditory percepts have a modality specific processing delay and their difference determines perceptual temporal offset.Methodology/Principal FindingsHere, we show that the perception of audiovisual simultaneity can change flexibly and fluctuates over a short period of time while subjects observe a constant stimulus. We investigated the mechanisms underlying the spontaneous alternations in this audiovisual illusion and found that attention plays a crucial role. When attention was distracted from the stimulus, the perceptual transitions disappeared. When attention was directed to a visual event, the perceived timing of an auditory event was attracted towards that event.Conclusions/SignificanceThis multistable display illustrates how flexible perceived timing can be, and at the same time offers a paradigm to dissociate perceptual from stimulus-driven factors in crossmodal feature binding. Our findings suggest that the perception of crossmodal synchrony depends on perceptual binding of audiovisual stimuli as a common event."/>
      <meta name="twitter:image" content="http://dx.plos.org/10.1371/journal.pone.0001253.g006"/>

  <meta property="og:title" content="Dynamic Perceptual Changes in Audiovisual Simultaneity" />
  <meta property="og:type" content="article" />
  <meta property="og:url" content="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0001253" />

 <!--end articleInfoX-->

  <link rel="pingback" href="http://www.plosone.org/pingback" />


  <link rel="shortcut icon" href="/images/favicon.ico" type="image/x-icon"/>
  <link rel="home" title="home" href="/"/>
  <link rel="alternate" type="application/rss+xml"
        title="PLOS ONE: New Articles"
        href="http://www.plosone.org/article/feed"/>
</head>
<body>

  <div id="page-wrap">
    <div id="topbanner" class="cf">

<!-- Div for the ad at the top of journal home page-->
<div class="center">
  <div class="title">Advertisement</div>
  <iframe id='a3ac9da4' name='a3ac9da4'
    src='http://ads.plos.org/www/delivery/afr.php?zoneid=345&amp;cb=5900'
    frameborder='0' scrolling='no' width='730' height='90'>
    <a href='http://ads.plos.org/www/delivery/ck.php?n=a3ac9da4&amp;cb=9186'
      target='_top'><img src='http://ads.plos.org/www/delivery/avw.php?zoneid=345&amp;cb=1979&amp;n=a3ac9da4'
      border='0' alt=''/>
    </a>
  </iframe>
</div>    </div>

    <div id="pagehdr-wrap">
      <div id="pagehdr">
        <div id="user" class="nav">
          <ul>
            <li><a href="http://www.plos.org">plos.org</a></li>
            <li><a href="https://register.plos.org/ambra-registration/register.action">create account</a></li>
            <li class="btn-style"><a
              href="/user/secure/secureRedirect.action?goTo=%2Farticle%2FfetchArticle.action%3FarticleURI%3Dinfo%253Adoi%252F10.1371%252Fjournal.pone.0001253">sign in</a>
            </li>
          </ul>
        </div>
        <div class="logo">
          <a href="/"><img src="/images/logo.png" alt="PLOS ONE"></a>
        </div>

<div id="nav-main" class="nav">
  <ul>
        <li id="mn-01"><a href="/taxonomy" class="areas-link">Subject Areas</a></li>
    <li id="mn-02"><a href="javascript:void(0);">For Authors</a>
      <div class="submenu" style="width: 540px; margin-left: -300px;">
        <div class="block">
          <div class="submit-script">
            <h3>Submit your Manuscript</h3>
            <ul>
              <li>Fair, rigorous peer review</li>
              <li>Broad scope and wide reach</li>
            </ul>
            <a href="/static/submissionInstructions" class="btn">get started</a>
          </div>
        </div>
        <div class="menu">
          <ul>
            <li><a href="/static/publish">Why Publish with PLOS ONE</a></li>
            <li><a href="/static/publication">Publication Criteria</a></li>
            <li><a href="/static/editorial">Editorial Policies</a></li>
            <li><a href="/static/guidelines">Preparing A Manuscript</a></li>
            <li><a href="/static/figureGuidelines">Figure and Table Guidelines</a></li>
          <li><a href="/static/supportingInformation">Supporting Information Guidelines</a></li>
            <li><a href="/static/submissionInstructions">Submitting a Manuscript</a></li>
          </ul>
        </div>
      </div>
    </li>

    <li id="mn-03"><a href="javascript:void(0);">About Us</a>
      <div class="submenu" style="width:248px; margin-left:-30px;">
        <div class="menu">
          <ul>
            <li><a href="/static/information">Journal Information</a></li>
            <li><a href="/static/edboard">Editorial Board</a></li>
            <li><a href="/static/reviewerGuidelines">Reviewer Guidelines</a></li>
            <li><a href="/static/almInfo">Article-Level Metrics</a></li>
            <li><a href="/static/license">Open-Access License</a></li>
            <li><a href="/static/downloads">Media Downloads</a></li>
            <li><a href="/static/commentGuidelines">Guidelines for Comments</a></li>
            <li><a href="/static/corrections">Corrections</a></li>
            <li><a href="/static/help">Help Using this Site</a></li>
            <li><a href="/static/contact">Contact Us</a></li>
          </ul>
        </div>
      </div>
    </li>
  </ul>
<div id="db">
  <form name="searchForm" action="/search/simple?noSearchFlag=true&amp;query=&amp;articleURI=info%3Adoi%2F10.1371%2Fjournal.pone.0001253" method="get" >
<input type="hidden" name="from" value="globalSimpleSearch" id="from"/><input type="hidden" name="filterJournals" value="PLoSONE" id="filterJournals"/>    <fieldset>
      <legend>Search</legend>
      <label for="search">Search</label>
      <div class="wrap">
        <input id="search" type="text" name="query" placeholder="Search">
        <input type="image" alt="SEARCH" src="/images/icon.search.gif">
      </div>
    </fieldset>
  </form>
    <a id="advSearch" href="/search/advanced?noSearchFlag=true&amp;query=&amp;articleURI=info%3Adoi%2F10.1371%2Fjournal.pone.0001253&filterJournals=PLoSONE">advanced search</a>
</div></div>

      </div>
      <!-- pagehdr-->
    </div>
    <!-- pagehdr-wrap -->

  <!--body and html tags gets closed in global_footer.ftl-->
<script type="text/javascript" src="/javascript/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<div id="pagebdy-wrap">
  <div id="pagebdy">

    <div id="article-block" class="cf">

<div class="article-meta cf">
  <ul id="almSignPost" style="display: none;"></ul>
  <div class="article-type">
    <span class="type oa">Open Access</span>
      <span class="type pr">Peer-Reviewed</span>
  </div>
</div>

<div class="header" id="hdr-article">

<div class="article-kicker">
      <span id="article-type-heading">
        Research Article
      </span>
</div>  <h1 property="dc:title" datatype="" rel="dc:type" href="http://purl.org/dc/dcmitype/Text">
    Dynamic Perceptual Changes in Audiovisual Simultaneity
  </h1>

  <ul class="authors">
      <li>


        <span rel="dc:creator" class="author">
          <span class="person" property="foaf:name" typeof="foaf:Person">
            Ryota Kanai
              <span class="corresponding">mail</span>, 
          </span>
        </span>

          <div class="author_meta">
            <div class="author_inner">


              
              <p><span class="email">*</span>To whom correspondence should be addressed. E-mail: <a href="mailto:kanair@gmail.com">kanair@gmail.com</a></p>

                <p>Affiliation:
                  Division of Biology, California Institute of Technology, Pasadena, California, United States of America
                </p>


              <span class="close">X</span>

            </div>
          </div>
      </li>
      <li>


        <span rel="dc:creator" class="author">
          <span class="person" property="foaf:name" typeof="foaf:Person">
            Bhavin R. Sheth, 
          </span>
        </span>

          <div class="author_meta">
            <div class="author_inner">


              
              

                <p>Affiliations:
                  Department of Electrical and Computer Engineering, University of Houston, Houston, Texas, United States of America, 
                  Center for NeuroEngineering and Cognitive Sciences, University of Houston, Houston, Texas, United States of America
                </p>


              <span class="close">X</span>

            </div>
          </div>
      </li>
      <li>


        <span rel="dc:creator" class="author">
          <span class="person" property="foaf:name" typeof="foaf:Person">
            Frans A. J. Verstraten, 
          </span>
        </span>

          <div class="author_meta">
            <div class="author_inner">


              
              

                <p>Affiliation:
                  Department of Experimental Psychology, Helmholtz Institute, Universiteit Utrecht, Utrecht, The Netherlands
                </p>


              <span class="close">X</span>

            </div>
          </div>
      </li>
      <li>


        <span rel="dc:creator" class="author">
          <span class="person" property="foaf:name" typeof="foaf:Person">
            Shinsuke Shimojo
          </span>
        </span>

          <div class="author_meta">
            <div class="author_inner">


              
              

                <p>Affiliation:
                  Division of Biology, California Institute of Technology, Pasadena, California, United States of America
                </p>


              <span class="close">X</span>

            </div>
          </div>
      </li>
  </ul>
  <ul class="date-doi-line">
    <li>Published: December 05, 2007</li>
    <li>DOI: 10.1371/journal.pone.0001253</li>
  </ul>


</div><!--end header-->
<div class="main cf" id="pjax-container">
  

<div class="nav items-5" id="nav-article">
  <ul>
  <li>
        <span class="active" name="article">Article</span>
  </li>
  <li>
      <a href="/article/authors/info%3Adoi%2F10.1371%2Fjournal.pone.0001253" name="authors">About the Authors</a>
  </li>
  <li>
      <a href="/article/metrics/info%3Adoi%2F10.1371%2Fjournal.pone.0001253" name="metrics">Metrics</a>
  </li>
  <li>
      <a href="/article/comments/info%3Adoi%2F10.1371%2Fjournal.pone.0001253" name="comments">Comments</a>
  </li>
  <li>
      <a href="/article/related/info%3Adoi%2F10.1371%2Fjournal.pone.0001253" name="related">Related Content</a>
  </li>
  </ul>
</div>

<script type="text/javascript">
  var selected_tab = "article";
</script>
  <div id="figure-thmbs" class="carousel cf">
    <div class="wrapper">
      <div class="slider">
              <div class="item">
                <a href="#pone-0001253-g001" data-doi="info:doi/10.1371/journal.pone.0001253" data-uri="info:doi/10.1371/journal.pone.0001253.g001" title="Figure 1">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001253.g001&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001253-g002" data-doi="info:doi/10.1371/journal.pone.0001253" data-uri="info:doi/10.1371/journal.pone.0001253.g002" title="Figure 2">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001253.g002&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001253-g003" data-doi="info:doi/10.1371/journal.pone.0001253" data-uri="info:doi/10.1371/journal.pone.0001253.g003" title="Figure 3">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001253.g003&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001253-g004" data-doi="info:doi/10.1371/journal.pone.0001253" data-uri="info:doi/10.1371/journal.pone.0001253.g004" title="Figure 4">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001253.g004&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001253-g005" data-doi="info:doi/10.1371/journal.pone.0001253" data-uri="info:doi/10.1371/journal.pone.0001253.g005" title="Figure 5">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001253.g005&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001253-g006" data-doi="info:doi/10.1371/journal.pone.0001253" data-uri="info:doi/10.1371/journal.pone.0001253.g006" title="Figure 6">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001253.g006&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
      </div>
    </div>
  </div>

  <div class="nav-col">
    <div class="nav" id="nav-article-page">
      <ul>
        <li class="nav-col-comments"><a href="/article/comments/info%3Adoi%2F10.1371%2Fjournal.pone.0001253">Reader Comments (1)</a></li>
          <li id="nav-figures"><a data-doi="info:doi/10.1371/journal.pone.0001253" >Figures</a></li>
      </ul>
    </div>
  </div>

  <div class="article">







<div class="abstract"><a id="abstract0" name="abstract0" toc="abstract0" title="Abstract"></a><h2>Abstract</h2>
<h3>Background</h3>
<a id="article1.front1.article-meta1.abstract1.sec1.p1" name="article1.front1.article-meta1.abstract1.sec1.p1"></a><p>The timing at which sensory input reaches the level of conscious perception is an intriguing question still awaiting an answer. It is often assumed that both visual and auditory percepts have a modality specific processing delay and their difference determines perceptual temporal offset.</p>


<h3>Methodology/Principal Findings</h3>
<a id="article1.front1.article-meta1.abstract1.sec2.p1" name="article1.front1.article-meta1.abstract1.sec2.p1"></a><p>Here, we show that the perception of audiovisual simultaneity can change flexibly and fluctuates over a short period of time while subjects observe a constant stimulus. We investigated the mechanisms underlying the spontaneous alternations in this audiovisual illusion and found that attention plays a crucial role. When attention was distracted from the stimulus, the perceptual transitions disappeared. When attention was directed to a visual event, the perceived timing of an auditory event was attracted towards that event.</p>


<h3>Conclusions/Significance</h3>
<a id="article1.front1.article-meta1.abstract1.sec3.p1" name="article1.front1.article-meta1.abstract1.sec3.p1"></a><p>This multistable display illustrates how flexible perceived timing can be, and at the same time offers a paradigm to dissociate perceptual from stimulus-driven factors in crossmodal feature binding. Our findings suggest that the perception of crossmodal synchrony depends on perceptual binding of audiovisual stimuli as a common event.</p>

</div>


<div class="articleinfo"><p><strong>Citation: </strong>Kanai R, Sheth BR, Verstraten FAJ, Shimojo S (2007) Dynamic Perceptual Changes in Audiovisual Simultaneity. PLoS ONE 2(12):
          e1253.
            doi:10.1371/journal.pone.0001253</p><p><strong>Academic Editor: </strong>Alex Holcombe, University of Sydney, Australia</p><p><strong>Received:</strong> May 22, 2007; <strong>Accepted:</strong> November 7, 2007; <strong>Published:</strong> December 5, 2007</p><p><strong>Copyright:</strong> Â© 2007 Kanai et al. This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</p><p><strong>Funding: </strong>This work was supported by Della Martin Fellowship (RK), by JST.ERATO (SS) and by NWO Pionier (FV).</p><p><strong>Competing interests:</strong> The authors have declared that no competing interests exist.</p></div>





<div id="section1" class="section"><a id="s1" name="s1" toc="s1" title="Introduction"></a><h3>Introduction</h3><a id="article1.body1.sec1.p1" name="article1.body1.sec1.p1"></a><p>Perception of crossmodal simultaneity is important for our perceptual system, as it indicates which information should be integrated across different sensory modalities <a href="#pone.0001253-Driver1">[1]</a>. Determining the temporal relationship between auditory and visual events, however, poses a challenge for our brain. The temporal relationship of the neuronal responses directly available does not correspond to the physical relationship. This is because the conduction times, both physical and neural, are different for visual and auditory stimuli. Moreover, in a natural environment, sensory stimuli of multiple sources can occur in close temporal proximity, imposing a correspondence problem in the time domain. Nevertheless, the brain has a remarkable ability to produce fairly good estimates of the actual temporal relationship across different modalities <a href="#pone.0001253-Spence1">[2]</a>: the brain can compensate for the signal conduction times dependent on the distance from the source audiovisual event <a href="#pone.0001253-Engel1">[3]</a>â<a href="#pone.0001253-Alais1">[6]</a>, <a href="#pone.0001253-Lewald1">[but see 7]</a>, and can constantly calibrate the point of AV synchrony as shown by adaptation to artificial temporal delays <a href="#pone.0001253-Fujisaki1">[8]</a>â<a href="#pone.0001253-Miyazaki1">[11]</a>.</p>
<a id="article1.body1.sec1.p2" name="article1.body1.sec1.p2"></a><p>In the present study, we investigate how our perceptual system determines temporal correspondences when confronted with ambiguity. We deliberately introduced ambiguity by presenting multiple visual targets for a single auditory click (<a href="#pone-0001253-g001">Figure 1A</a>). The visual targets were disks flashed sequentially at one of eight locations, producing the percept of a disk revolving around fixation. The auditory click was presented at the same point in every cycle (534 ms), as the disk came to a particular location (<a href="#pone-0001253-g001">Figure 1B</a>). This stimulus was essentially identical to the complication clocks in classical psychological studies in which the perceived timing of a discrete auditory or tactile event was compared with respect to the position of a continuously moving visual stimulus <a href="#pone.0001253-Wundt1">[12]</a>â<a href="#pone.0001253-Cairney1">[15]</a>. However, in our stimuli, the visual events were discrete as opposed to continuous, and observations were made continuously, even after the first perceptual judgment on AV synchrony was made.</p>
<div class="figure" id="pone-0001253-g001"><div class="img"><a name="pone-0001253-g001" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001253.g001&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001253" data-uri="info:doi/10.1371/journal.pone.0001253.g001"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001253.g001&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001253.g001/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001253.g001/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001253.g001/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001253.g001/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001253.g001.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001253.g001/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001253.g001/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001253.g001.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 1.  <span>Multistability in AV temporal matching.</span></strong></p><a id="article1.body1.sec1.fig1.caption1.p1" name="article1.body1.sec1.fig1.caption1.p1"></a><p>A. Multiple visual flashes are presented in close temporal proximity to produce ambiguity in AV temporal matching. Many cycles were repeated continuously. B. A typical trial was illustrated. The visual flashes were presented at one of eight locations equidistant from fixation, producing the percept of a moving disk. One cycle lasted 534 ms. On a single trial, 60 identical cycles were repeated. C. The report of a representative trial is plotted as a function of stimulus cycles.</p>
<span>doi:10.1371/journal.pone.0001253.g001</span></div><a id="article1.body1.sec1.p3" name="article1.body1.sec1.p3"></a><p>Although classical studies claim that sensations of simultaneity between different sensory modalities are less clear compared to sensations of simultaneity within the same modality <a href="#pone.0001253-Piron1">[16]</a>, <a href="#pone.0001253-Fraisse1">[17]</a>, more recent studies have demonstrated the ability to bind auditory clicks to visual events <a href="#pone.0001253-Driver1">[1]</a>, <a href="#pone.0001253-Fujisaki2">[18]</a>â<a href="#pone.0001253-Zampini1">[20]</a>. In our stimuli too, observers reported that it was easy to identify a perceptually synchronous disk. These perceptually synchronous disks were seen as brighter with a sharper on and offset. Importantly, the disk that is seen as perceptually synchronous does not remain constant across cycles. Typically, observers report that the position at which simultaneity is perceived changes every 5 to10 seconds (i.e., 10â20 cycles).</p>
<a id="article1.body1.sec1.p4" name="article1.body1.sec1.p4"></a><p>The existence of multistability in the perception of this stimulus illustrates that the perception of AV synchrony is not fixed to a single point, but can dynamically change. Here, we use this phenomenon to examine the potential impact of attention on AV synchrony. We find an effect of attentional attraction, where perceived AV synchrony is attracted towards a visually attended event, regardless of its actual timing relative to the auditory stimulus. This suggest that the perception of AV synchrony is not determined simply by the perceptual latency for each modality, but is contingent upon the perceptual binding of auditory and visual stimuli as originating from a common event.</p>
</div>

<div id="section2" class="section"><a id="s2" name="s2" toc="s2" title="Results"></a><h3>Results</h3>
<h4>Multistability in perceived AV synchrony</h4>
<a id="article1.body1.sec2.sec1.p1" name="article1.body1.sec2.sec1.p1"></a><p>To characterize the basic transition pattern, we measured responses from ten observers while they continuously indicated the perceptually synchronous disk by holding down a corresponding key. On each trial, 60 consecutive cycles (~32 s) were repeated, and each observer completed 32 trials.</p>
<a id="article1.body1.sec2.sec1.p2" name="article1.body1.sec2.sec1.p2"></a><p>The results show that the initial perceived location of AV synchrony was biased towards a location in the disk sequence that occurred earlier than the physically synchronous location (<a href="#pone-0001253-g002">Figure 2A</a>). This is consistent with a number of studies showing that an auditory event is generally perceived earlier than a simultaneous visual event <a href="#pone.0001253-Sugita1">[4]</a>, <a href="#pone.0001253-Fendrich1">[ 22]</a>â<a href="#pone.0001253-Zampini2">[25]</a>, <a href="#pone.0001253-Smith1">[but see 26]</a>, <a href="#pone.0001253-Rutschmann1">[27]</a>.</p>
<div class="figure" id="pone-0001253-g002"><div class="img"><a name="pone-0001253-g002" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001253.g002&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001253" data-uri="info:doi/10.1371/journal.pone.0001253.g002"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001253.g002&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001253.g002/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001253.g002/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001253.g002/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001253.g002/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001253.g002.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001253.g002/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001253.g002/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001253.g002.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 2.  <span>The basic characteristics of perceptual transitions in AV synchrony.</span></strong></p><a id="article1.body1.sec2.sec1.fig1.caption1.p1" name="article1.body1.sec2.sec1.fig1.caption1.p1"></a><p>A. The mean AV synchrony relative to the veridical position (n = 10). Positive values indicate forward shifts of perceived audiovisual synchrony. The gray zone represents one standard error of the mean. The data are plotted from the third cycle onwards as there was no response in earlier cycles due to response latency. B. Probability that a transition occurs in the forward (step size: +1, +2, or +3), backward (step size: â1, â2, or â3) or to the 180Â° opposite position (Â±4), which is directionally uncategorizable either as forward or backward, as a function of cycle number is shown. The black line is the probability sum of all transitions. The smooth curves are obtained by convolving the point (event) data with a Gaussian kernel (Ï = 2 cycles). C. The mean dwell time is plotted as a function of disk position. The error bars indicate one s.e.m. (n = 10).</p>
<span>doi:10.1371/journal.pone.0001253.g002</span></div><a id="article1.body1.sec2.sec1.p3" name="article1.body1.sec2.sec1.p3"></a><p>However, the position of perceived AV synchrony did change over time: As the stimulus cycles repeated, the perceived location of AV synchrony started shifting to other positions. The grand mean across all the observers and trials revealed a general tendency for the perceived AV synchrony to drift forward from the initial position, which is earlier than the position of physical synchrony. The dominance of the forward shift can be seen in <a href="#pone-0001253-g002">Figure 2B</a>: transitions occurred more frequently along the motion direction, especially for the early cycles of each trial.</p>
<a id="article1.body1.sec2.sec1.p4" name="article1.body1.sec2.sec1.p4"></a><p>The mean duration of each percept before the next transition is plotted as a function of the temporal position relative to the synchronous disk in <a href="#pone-0001253-g002">Figure 2C</a>. Not surprisingly, the percept dwelled longer at the near-veridical positions (over 8 s at disk positions â1 and 0), and the stability decreased for temporally more distant positions.</p>
<a id="article1.body1.sec2.sec1.p5" name="article1.body1.sec2.sec1.p5"></a><p>The analyses above suggest that some systematic trends are present in the perceptual switches. To fully characterize the transition pattern, we constructed a transition probability matrix from the data (<a href="#pone-0001253-g003">Figure 3A</a>). This representation of the data helps us to identify the dependency of the next position of perceived AV synchrony on the previous position. As can be seen in the probability distribution marginalized over current positions (<a href="#pone-0001253-g003">Figure 3C</a>), transitions were made most frequently to the near-veridical positions.</p>
<div class="figure" id="pone-0001253-g003"><div class="img"><a name="pone-0001253-g003" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001253.g003&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001253" data-uri="info:doi/10.1371/journal.pone.0001253.g003"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001253.g003&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001253.g003/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001253.g003/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001253.g003/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001253.g003/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001253.g003.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001253.g003/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001253.g003/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001253.g003.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 3.  <span>Characteristics of the group transition pattern.</span></strong></p><a id="article1.body1.sec2.sec1.fig2.caption1.p1" name="article1.body1.sec2.sec1.fig2.caption1.p1"></a><p>A. Transition probabilities are shown for all possible transition combinations. The diagonal elements signifying no perceptual shifts (red crosses) are not shown. B. The same data are represented relative to current position emphasize the directionality of the shifts. C. Transition probability marginalized across all current positions is plotted as a function of the absolute disk position. D. Transition probability marginalized across all current positions is plotted as a function of the relative disk position.</p>
<span>doi:10.1371/journal.pone.0001253.g003</span></div><a id="article1.body1.sec2.sec1.p6" name="article1.body1.sec2.sec1.p6"></a><p>Realigning the matrix with respect to the current state (<a href="#pone-0001253-g003">Figure 3B</a>), it can be seen that the most frequent transitions were typically one-step forward from the current position (<a href="#pone-0001253-g003">Figure 3D</a>). This directionality is due to the bias in the forward transitions during the early cycles (see <a href="#pone-0001253-g002">Figure 2A</a> and <a href="#pone-0001253-g002">Figure 2B</a>). These two trends, that is, transitions towards the near-veridical positions, and forward transitions with respect to the current position signify, respectively, constraints on the flexibility of perception by bottom-up sensory signals and the contribution of current perceptual or attentional states.</p>


<h4>Sensory adaptation</h4>
<a id="article1.body1.sec2.sec2.p1" name="article1.body1.sec2.sec2.p1"></a><p>What is the driving mechanism underlying the forward transition? The first possibility that may occur to one's mind is that the initial judgment is inaccurate because the task is too difficult and the sensory signals are too noisy, and repeated observations made the judgments more and more accurate over time. This is possible, but unlikely, because it cannot explain the initial bias and the systematic drift towards the more veridical range: that is, the observed shift was more systematic than just from a less accurate to a more accurate judgment.</p>
<a id="article1.body1.sec2.sec2.p2" name="article1.body1.sec2.sec2.p2"></a><p>A more plausible mechanism is sensory adaptation. Inspection of <a href="#pone-0001253-g002">Figure 2A</a> shows that most forward transitions occurred in the initially 20 cycles (~10 s) and then leveled off. The gradual leveling off is consistent with the general concept of adaptation. Possible effects of unimodal adaptation to either the visual or the auditory stimuli are illustrated in <a href="#pone-0001253-g004">Figure 4A</a>. If adaptation to the auditory click systematically delays the perceived timing of the auditory click, forward shifts would be observed by presenting the auditory click alone without the visual stimuli (<a href="#pone-0001253-g004">Figure 4A</a>, second row). Delays in processing the visual flash due to visual adaptation, however, would result in backward transitions (<a href="#pone-0001253-g004">Figure 4A</a>, third row)âan effect opposite to what was observed in the first experiment. Thus, a simple form of visual adaptation does not seem to account for the forward shift. Though unlikely, the hypothetical facilitation of visual processing speed by continuous exposures to the visual flashes could also result in a forward shift (<a href="#pone-0001253-g004">Figure 4A</a>, bottom row).</p>
<div class="figure" id="pone-0001253-g004"><div class="img"><a name="pone-0001253-g004" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001253.g004&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001253" data-uri="info:doi/10.1371/journal.pone.0001253.g004"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001253.g004&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001253.g004/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001253.g004/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001253.g004/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001253.g004/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001253.g004.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001253.g004/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001253.g004/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001253.g004.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 4.  <span>The experiment with a physical disruption of stimulus continuity.</span></strong></p><a id="article1.body1.sec2.sec2.fig1.caption1.p1" name="article1.body1.sec2.sec2.fig1.caption1.p1"></a><p>A. Hypothetical effects of adaptation are illustrated. Without adaptation, the auditory click is temporally aligned with the visual disk just prior to the veridically synchronous disk (top row). If audiotry adaptation would increase the processing latency for the auditory click, the position of the perceptually synchronous disk would shift forward (second row). Likewise, if adaptation to visual stimuli would increase the latency for vision, the position of the perceptually synchronous disk would shift backward (third row). If continuous presentation of visual disks would result in a shortening of processing latency, the position of the perceptually synchronous disk would shift forward. B. Three experimental conditions are schematically illustrated. In the flash off condition (top), the visual stimulus was turned off during the middle cycles and returned to the screen during the last five cycles. In the sound off condition (middle), the click sound was turned off during the middle cycles. In the control condition (botttom), there was no disruption during the middle cycles. C. The mean synchronous positions for the initial and the final cycles are plotted for each condition. The error bars indicate one s.e.m. (n = 6).</p>
<span>doi:10.1371/journal.pone.0001253.g004</span></div><a id="article1.body1.sec2.sec2.p3" name="article1.body1.sec2.sec2.p3"></a><p>To examine these possibilities, we presented trials of 20 stimulus-cycles in which either the visual or auditory component was omitted for the middle 10 trials (<a href="#pone-0001253-g004">Figure 4B</a>). Compared to control trials in which both components were present throughout, these experimental trials had reduced levels of either visual or auditory adaptation leading into the final five stimulus cycles. The observer (n = 8) reported the position of AV synchrony only for the initial and the final cycle. The auditory adaptation hypothesis predicts that even in the reduced visual adaptation condition, continuous presentation of the auditory click during the middle cycles should produce the forward shift. On the other hand, if exposure to visual flashes is important for forward transitions, visual stimulation in the reduced auditory adaptation condition should still produce a forward shift.</p>
<a id="article1.body1.sec2.sec2.p4" name="article1.body1.sec2.sec2.p4"></a><p>The results are shown in <a href="#pone-0001253-g004">Figure 4C</a>. As expected, a clear forward transition was observed in the control condition (shift amount, 1.22Â±0.24 disk positions; paired t-test, t(7) = 5.19, p&lt;0.01). However, forward transitions were hardly observed in conditions where either the visual or the auditory stimulus was turned off during the middle cycles. The transition was not significant in the reduced auditory adaptation condition (shift amount, 0.13Â±0.12 disk positions; paired t-test, t(7) = 1.089, p = 0.312). In the reduced visual adaptation condition, the transition was present (shift amount, 0.25Â±0.07 disk positions; paired t-test, t(7) = 3.654, p&lt;0.01), but accounts for only 20% of the forward transition in the control condition (0.25 versus 1.22; paired t-test, t(7) = 5.41, p&lt;0.001). These results indicate that when either visual or auditory stimuli were omitted for the intermediate cycles, the late cycles were judged essentially the same as the initial cyclesâalmost as if it was a fresh start of the stimulus. Therefore, adaptation to either of the modalities by themselves seems to play little role in producing the forward transition. Moreover, the similarity between the results of the reduced auditory or visual adaptation conditions makes it highly unlikely that the forward shift is merely due to a linear summation of these two adaptations. Thus, it is the simultaneous presentation of both modalities that seems to be critical, and the underlying mechanism should be something other than adaptation within a modality.</p>


<h4>Attentional distraction</h4>
<a id="article1.body1.sec2.sec3.p1" name="article1.body1.sec2.sec3.p1"></a><p>The requirement that both audio and visual signals be simultaneously present implies that the forward transition effect is based on a continual process of crossmodal integration. Moreover, the state-transition analysis (<a href="#pone-0001253-g003">Figure 3</a>) showed that the percepts had a path dependency based on the observer's prior internal state. One possibility is that these internal states are mostly under bottom-up control and the transition pattern emerges automatically when observers are exposed to the stimuli. Another possibility is that these internal states reflect the attentional tracking of the simultaneity percept, and thus would be influenced by disruptions in attention. The disruption of forward shifts either by the omission of the visual or the auditory stimulus could be attributed to the fact that in those conditions, the position of current AV synchrony cannot be tracked with attention.</p>
<a id="article1.body1.sec2.sec3.p2" name="article1.body1.sec2.sec3.p2"></a><p>To test for the involvement of attention in the forward transition more directly, we examined whether distracting attention <em>away</em> from the stimuli could disrupt the forward shift. For this, we added a concurrent attentional task during the middle cycles. Observers were asked to count the number of âXâs in a letter stream. On half of the trials, the observers were required to perform this attention task, and on the other half, they were asked to ignore the letter stream.</p>
<a id="article1.body1.sec2.sec3.p3" name="article1.body1.sec2.sec3.p3"></a><p>The results are shown in <a href="#pone-0001253-g005">Figure 5B</a>: When the observers performed the attentional task, the forward transition was completely abolished (paired t-test, t(5) = 0.474, p = 0.656). This is in contrast to the single-task condition in which a significant forward transition was obtained (paired t-test, t(5) = 5.772, p&lt;0.01). The results indicate that AV synchrony needs to be tracked with attention for the forward transition to occur.</p>
<div class="figure" id="pone-0001253-g005"><div class="img"><a name="pone-0001253-g005" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001253.g005&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001253" data-uri="info:doi/10.1371/journal.pone.0001253.g005"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001253.g005&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001253.g005/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001253.g005/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001253.g005/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001253.g005/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001253.g005.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001253.g005/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001253.g005/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001253.g005.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 5.  <span>Attentional distraction experiment.</span></strong></p><a id="article1.body1.sec2.sec3.fig1.caption1.p1" name="article1.body1.sec2.sec3.fig1.caption1.p1"></a><p>A. A trial consisted of 20 cycles, and the letter stream was presented during the middle ten trials. The observers were asked to report the position of the position of perceptually synchronous disk for the initial five and the final five cycles. B. The perceptually synchronous positions for the initial and final cycles are plotted separately for the dual-task condition (open red circles) and for the single-task condition (solid blue circles). The error bars indicate one SEM (n = 6).</p>
<span>doi:10.1371/journal.pone.0001253.g005</span></div>

<h4>Attentional modulation of AV synchrony</h4>
<a id="article1.body1.sec2.sec4.p1" name="article1.body1.sec2.sec4.p1"></a><p>While the experiment above suggests some involvement of attention in the forward transition, the exact role it plays in the perception of AV synchrony remains unclear. In light of the known effects of attention on perception, two alternative hypotheses need to be considered. First, attention to a stimulus is known to speed up its processing and render its percept earlier than the percepts of unattended stimuliâa phenomenon known as <em>prior entry</em> <a href="#pone.0001253-Spence2">[19]</a>, <a href="#pone.0001253-Titchener1">[28]</a>, <a href="#pone.0001253-Hikosaka1">[29]</a>. A hypothesis derived on the basis of prior entry is that attention to a disk presented later than the physically synchronous disk should shift AV synchrony towards a later disk, whereas attention to a disk presented earlier than the synchronous disk should have little effect on the position of AV synchrony or possibly prevent the disk from perceived as synchronous with the auditory click.</p>
<a id="article1.body1.sec2.sec4.p2" name="article1.body1.sec2.sec4.p2"></a><p>An alternative possibility is that attention facilitates the binding between different modalities <a href="#pone.0001253-Cinel1">[30]</a>, that is, an attended disk is more preferentially bound to the auditory click. The binding hypothesis predicts that attention to a disk presented later than the physically synchronous disk should delay AV synchrony towards a later disk, whereas attention to a disk presented earlier than the synchronous disk should advance the position of AV synchrony to an earlier disk.</p>
<a id="article1.body1.sec2.sec4.p3" name="article1.body1.sec2.sec4.p3"></a><p>To examine these alternative hypotheses, we tested the effects of attention using three representative attention manipulation methods. First (pop-out experiment), we used a salient, pop-out stimulus: We presented a red disk at one of the eight locations and green disks at the other locations. This manipulation is expected to attract attention to the pop-out stimulus <a href="#pone.0001253-Duncan1">[31]</a>. Second, we presented a cue (a small white disk lasting 40 ms) at one of the eight positions, just before the first cycle of a trial. This type of spatial cuing is known to grab attention <a href="#pone.0001253-Posner1">[32]</a>. Third, we manipulated the observers' overt attention, that is, we had the observers fixate directly on one of the disk locations <a href="#pone.0001253-Findlay1">[33]</a>. In all three experiments, the relative positions of the attended target disk and the disk physically synchronous with the click were randomized across trials. Observers (n = 6) had to report the location of AV synchrony after five cycles of viewing.</p>
<a id="article1.body1.sec2.sec4.p4" name="article1.body1.sec2.sec4.p4"></a><p>The results are shown in <a href="#pone-0001253-g006">Figure 6</a>. In all three experiments, perceived AV synchrony was systematically biased towards the position of the attended disk (repeated measures ANOVAs: pop-out, F(5,35) = 5.00, p&lt;0.01; cueing, F(5,35) = 27.60, p&lt;0.001; fixation, F(5,35) = 18.97, p&lt;0.001). When attention was directed to a disk presented earlier than the click, perceived AV synchrony was shifted to an earlier position. On the other hand, when attention was directed to a disk later than the click, perceived AV synchrony was shifted to a later position. In other words, AV synchrony was attracted towards the attended position. However, the effects of this attentional attraction were limited to the conditions in which attention was directed relatively close (&lt;100 ms) to the physically synchronous disk.</p>
<div class="figure" id="pone-0001253-g006"><div class="img"><a name="pone-0001253-g006" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001253.g006&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001253" data-uri="info:doi/10.1371/journal.pone.0001253.g006"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001253.g006&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001253.g006/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001253.g006/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001253.g006/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001253.g006/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001253.g006.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001253.g006/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001253.g006/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001253.g006.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 6.  <span>Results of the attentional manipulation experiments.</span></strong></p><a id="article1.body1.sec2.sec4.fig1.caption1.p1" name="article1.body1.sec2.sec4.fig1.caption1.p1"></a><p>(AâC) The mean PSP is plotted as a function of attended position for the pop-out (A), cueing (B) and fixation (C) experiments. The left most data points are the results of the control conditions in which no attentional manipulations were made. In all attentional manipulations, the position of a perceptually sycnhronous disk was most shifted in the forward direction and reached close to the veridical position when observers attended to the disk that occurred one disk later than the veridically synchronous disk. Error bars indicate one s.e.m. (n = 6).</p>
<span>doi:10.1371/journal.pone.0001253.g006</span></div><a id="article1.body1.sec2.sec4.p5" name="article1.body1.sec2.sec4.p5"></a><p>One concern regarding the effect of attention is that observers reported the attended position when they were uncertain about the target position. Such a response bias might contribute to the attraction of AV synchrony towards attended position. One reason why we believe that the attraction effect is not simply due to the response bias is that the attraction was observed only in the cases where attention was directed to a disk near the veridically synchronous disk. If response bias was the only cause of the attraction effect, then attraction should have occurred regardless of the attended position relative to the veridically synchronous disk. However, this was not the case. In addition, in most conditions, the response was not peaked at the attended location, but a location between the veridical position and the attended location. This suggests that the attraction effect was a result of the interaction between low-level sensory signals and attention.</p>
<a id="article1.body1.sec2.sec4.p6" name="article1.body1.sec2.sec4.p6"></a><p>These results show that attention can both advance and delay the perceived timing of the attended visual stimulus relative to the timing of the sound. This argues against the idea that perceived AV synchrony was modulated by a simple facilitation of the processing speed for attended visual stimuli. Instead, the results support the hypothesis that attention facilitates the binding of a sound to the attended visual event regardless of its timing relative to that of the sounds.</p>
<a id="article1.body1.sec2.sec4.p7" name="article1.body1.sec2.sec4.p7"></a><p>The above results showing attraction of AV synchrony towards the locus of attention offers insights into the mechanisms underlying the forward transition. The forward shift can be accounted for by a combination of the attentional attraction effect and a tendency for observers' attention to be dragged forward in the direction of the visual motion. Visual motion would bias attention toward a slightly forward position from the currently attended, synchronous position <a href="#pone.0001253-Farroni1">[34]</a>, and thus one's percept of AV synchrony would more likely be pulled forward, and not backward, in the direction of motion. Once AV synchrony shifts to a new position, attention would also shift to that location with an additional bias in the forward direction. This recurring cycle of shifts in AV synchrony and attentional re-focusing can account for the dominance of the forward shift. The occasional backward transitions may occur when the current position of AV synchrony deviates from the near-veridical positions.</p>

</div>

<div id="section3" class="section"><a id="s3" name="s3" toc="s3" title="Discussion"></a><h3>Discussion</h3><a id="article1.body1.sec3.p1" name="article1.body1.sec3.p1"></a><p>In this study, we reported a novel crossmodal illusion whereby the perception of AV synchrony fluctuates between different temporal positions. Perceptual alternations in multistable stimuli have been widely used in visual neurosciences to investigate the neural correlates of subjective perception under the presentation of a constant stimulus <a href="#pone.0001253-Blake1">[21]</a>. The multi-sensory display reported here can be used in a similar fashion to dissociate perceptual from stimulus-driven factors when one searches for the neural correlates of crossmodal temporal binding.</p>
<a id="article1.body1.sec3.p2" name="article1.body1.sec3.p2"></a><p>Our analyses revealed systematic transition patterns such as the cumulative forward shifts and the perceptual stability of each position of AV synchrony (&gt;5 s; see <a href="#pone-0001253-g002">Figure 2C</a>). These patterns would not have been found if transitions were caused merely by random fluctuations in bottom-up signals. Rather, these systematic patterns indicate a dependency of subsequent perceptual state on the present perceptual/attentional state. The dominance of forward transitions over the entire period of a trial (<a href="#pone-0001253-g002">Figure 2A</a> and <a href="#pone-0001253-g002">Figure 2B</a>) can be taken as a signature of attentional involvement in the perceptual transitions of AV synchrony.</p>
<a id="article1.body1.sec3.p3" name="article1.body1.sec3.p3"></a><p>Perceptual binding across modalities seems to influence perceived timing: when visual and auditory stimuli are bound as a single event, their perceived timing is modulated to become simultaneous. In our experiments, the perceived timing of a disk relative to the timing of the click could both be advanced and delayed depending on where attention was directed. This finding defies a simple explanation based on facilitation of processing speed. Instead, it is better explained by the idea that attention facilitates the binding of the attended disk to the click and thus the point of perceptual simultaneity is attracted towards the attended stimulus. The importance of cross-modal binding in perceived timing has been suggested in earlier studies. A phenomenon relevant to the present study is temporal ventriloquism in which the perceived timing of a visual stimulus is typically attracted to that of the sound that the visual stimulus is bound with <a href="#pone.0001253-Vroomen1">[35]</a>â<a href="#pone.0001253-MoreinZamir1">[36]</a>. Another example is a spatial congruency effect: when a pair of AV stimuli come from the same spatial location, they are more likely to be judged as simultaneous than when they come from different locations <a href="#pone.0001253-Zampini1">[20]</a>. These examples, among others, support the idea that when attention binds auditory and visual stimuli as originating from a common event, their relative timing is perceived as simultaneous.</p>
<a id="article1.body1.sec3.p4" name="article1.body1.sec3.p4"></a><p>At present, it is unclear what kind of mechanism underlies the attentional facilitation of audiovisual temporal matching. One possibility is that attention expands the temporal window of visual events <a href="#pone.0001253-Visser1">[37]</a>, <a href="#pone.0001253-Yeshurun1">[38]</a>, as it does for perceived durations <a href="#pone.0001253-Tse1">[39]</a>. This might in turn increase the chance that the signals of attended visual stimuli temporally overlap with the auditory signals.</p>
<a id="article1.body1.sec3.p5" name="article1.body1.sec3.p5"></a><p>Inasmuch as this phenomenon involves spontaneous alternations between a number of mutually exclusive perceptual states, it resembles the class of multistable stimuli widely used in studies of visual perception <a href="#pone.0001253-Blake1">[21]</a>, and might prove similarly useful for dissociating subjective report from physical stimulus input. However, it remains an open question whether the illusion reported here shares common mechanisms with classical rivalry stimuli such as binocular rivalry and moving plaids <a href="#pone.0001253-Hup1">[40]</a> as well as auditory bistable stimuli <a href="#pone.0001253-Pressnitzer1">[41]</a>.</p>
<a id="article1.body1.sec3.p6" name="article1.body1.sec3.p6"></a><p>In summary, our present multistable illusion demonstrates that perception of simultaneity has a flexible nature, and is highly susceptible to attentional modulation. Moreover, our findings suggest that the perception of AV synchrony is not simply determined by the processing latency for each modality alone, but is constructed based upon perceptual binding of multisensory information as a common event. How exactly feature binding occurs across sensory modalities is a challenging problem, but the multistable stimuli reported in our present study may provide both an insight, and a paradigm for further studies into this issue.</p>
</div>

<div id="section4" class="section"><a id="s4" name="s4" toc="s4" title="Materials and Methods"></a><h3>Materials and Methods</h3>
<h4>Apparatus</h4>
<a id="article1.body1.sec4.sec1.p1" name="article1.body1.sec4.sec1.p1"></a><p>The stimuli were generated on a G4 Macintosh computer and presented on a 22-inch CRT monitor (LaCie Blue Electron). The stimuli were viewed at a distance of 57 cm and head movements were restrained using a chinrest. The resolution of the monitor was 1024 by 768 pixels, and the refresh rate was 75 Hz. The auditory stimuli were presented through headphones (MDR-CD270, Sony Inc., Japan). The simultaneity of auditory and visual stimuli was assessed with a digital oscilloscope (Tektroniks TDS 210) and was accurate and stable over time.</p>


<h4>Continuous tracking</h4>
<a id="article1.body1.sec4.sec2.p1" name="article1.body1.sec4.sec2.p1"></a><p>Ten observers (nine naÃ¯ve observers and one of the authors, RK) participated. A white disk on a black background revolved about the fixation. The radius of the disks was 0.78 deg and the disks were presented at an eccentricity of 5.86 deg. The movement of the disk was a discrete apparent motion consisting of a sequential presentation of a disk at eight positions. Each disk was presented for 53.3 ms and there was a blank interval of 13.3 ms before the onset of the next disk (See, <a href="#pone-0001253-g001">Figure 1a</a>). The initial position of the disk was randomly chosen from the eight positions and the direction was randomly chosen from either clockwise or counter-clockwise. In each cycle, the onset of the 4th or 5th disk position from the initial disk position of a trial was accompanied by a click sound (approximately 70dB SPL). A new click sound was generated for each trial by assigning each sound frame a value randomly sampled from zero-centered Gaussian distribution with a sigma being half of the maximum intensity. The duration of the sound was 1 ms.</p>
<a id="article1.body1.sec4.sec2.p2" name="article1.body1.sec4.sec2.p2"></a><p>The factors defining a trial were counterbalanced within observer, resulting in a total number of 32 trials/observer ( = 8 [initial positions]Ã2 [sound locations]Ã2 [directions of rotation]). In a single trial, the stimulus sweep was repeated for 60 cycles. The task was to report the position of the synchronous disk continuously throughout the trial by pressing a key corresponding to the location. From the ten observers, we obtained the data of a total of 19200 cycles.</p>
<a id="article1.body1.sec4.sec2.p3" name="article1.body1.sec4.sec2.p3"></a><p>Unimodal adaptation experiments: The parameters for the stimuli were identical to the experiment above, but only 20 cycles were presented in a trial. The observers were asked to report the initial and final positions of the disk, which was perceived as synchronous with the click. For each observer, the initial and final estimates were calculated as the circular mean of the reported positions. In the reduced auditory adaptation condition, the click was not presented during the middle 10 cycles, and in the reduced visual adaptation condition, no visual stimulus but the fixation marker was shown during the middle 10 cycles. Eight observers including one of the authors (RK) participated. Each observer completed a total of 96 trials ( = 8 [initial positions]Ã2 [sound locations]Ã2 [directions of rotation]Ã3 [conditions]).</p>
<a id="article1.body1.sec4.sec2.p4" name="article1.body1.sec4.sec2.p4"></a><p>Attentional distraction experiment: For the dual task experiment, a letter stream was presented during the middle 10 cycles. The letters were presented in Helvetica font and their size was 1.0Ã1.2 on average. Each letter was presented for 120 ms. The observers were asked to report the number of occurrences of the letter âXâ in the stream. The number of Xs was varied between 3, 4 and 5. The mean performance was 92.2%. In the control conditions, the observers were encouraged to track the position of synchronous flash, while ignoring the letters. The order of these two conditions was counterbalanced across observers. Six observers including one of the authors (RK) participated in these experiments.</p>
<a id="article1.body1.sec4.sec2.p5" name="article1.body1.sec4.sec2.p5"></a><p>Attention manipulation experiments: Six naÃ¯ve observers participated. The stimulus parameters for the disks and the sound were identical as the other experiments. For the pop-out condition, one of the disks was red, while other disks were all green. The luminance of the red and green were adjusted to near-isoluminant level. A control condition was intermixed in which all the disks were green. In the cue condition, the cue was a white disk with a diameter of 0.39 deg and was presented at the center of one of the disks 120 ms before the onset of the first disk in a trial. The disks were presented all in green (the same luminance was the pop-out experiment). In the control trials, no cue was presented. In the fixation experiment, the fixation marker was drawn directly on the one of the disk positions, and observers were required to fixate on the marker during a trial. In the control trials, the fixation marker remained in the center of the display.</p>

</div>





<div><a id="ack" name="ack" toc="ack" title="Acknowledgments"></a><h3>Acknowledgments</h3>
<a id="article1.back1.ack1.p1" name="article1.back1.ack1.p1"></a><p>The authors would like to thank David Alais, Charles Spence, Jordi Navarra and Daw-An Wu for their critical comments on the manuscript.</p>
</div><div class="contributions"><a id="authcontrib" name="authcontrib" toc="authcontrib" title="Author Contributions"></a><h3>Author Contributions</h3><p>Conceived and designed the experiments: RK BS. Performed the experiments: RK. Analyzed the data: RK BS. Contributed reagents/materials/analysis tools: SS FV. Wrote the paper: RK SS FV BS.</p></div><div><a id="references" name="references" toc="references" title="References"></a><h3>References</h3><ol class="references"><li><span class="label">1.
              </span><a name="pone.0001253-Driver1" id="pone.0001253-Driver1"></a>Driver J, Spence C (2000) Multisensory perception: Beyond modularity and convergence. Curr Biol  10: R731âR735.  <ul class="find" data-citedArticleID="1025056" data-doi="10.1016/s0960-9822(00)00740-5"><li><a href="http://dx.doi.org/10.1016/s0960-9822(00)00740-5" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Multisensory+perception%3A+Beyond+modularity+and+convergence." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Multisensory+perception%3A+Beyond+modularity+and+convergence.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">2.
              </span><a name="pone.0001253-Spence1" id="pone.0001253-Spence1"></a>Spence C, Squire S (2003) Multisensory integration: Maintaining the perception of synchrony. Curr Biol  13: R519â521.  <ul class="find" data-citedArticleID="1025102" data-doi="10.1016/s0960-9822(03)00445-7"><li><a href="http://dx.doi.org/10.1016/s0960-9822(03)00445-7" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Multisensory+integration%3A+Maintaining+the+perception+of+synchrony." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Multisensory+integration%3A+Maintaining+the+perception+of+synchrony.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">3.
              </span><a name="pone.0001253-Engel1" id="pone.0001253-Engel1"></a>Engel GR, Dougherty WG (1971) Visual-auditory distance constancy. Nature  234: 308.  <ul class="find" data-citedArticleID="1025062" data-doi="10.1038/234308a0"><li><a href="http://dx.doi.org/10.1038/234308a0" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Visual-auditory+distance+constancy." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Visual-auditory+distance+constancy.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">4.
              </span><a name="pone.0001253-Sugita1" id="pone.0001253-Sugita1"></a>Sugita Y, Suzuki Y (2003) Audiovisual perception: Implicit estimation of sound-arrival time. Nature  421: 911.  <ul class="find" data-citedArticleID="1025110" data-doi="10.1038/421911a"><li><a href="http://dx.doi.org/10.1038/421911a" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Audiovisual+perception%3A+Implicit+estimation+of+sound-arrival+time." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Audiovisual+perception%3A+Implicit+estimation+of+sound-arrival+time.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">5.
              </span><a name="pone.0001253-Kopinska1" id="pone.0001253-Kopinska1"></a>Kopinska A, Harris LR (2004) Simultaneity constancy. Perception  33: 1049â1069.  <ul class="find" data-citedArticleID="1025082" data-doi="10.1068/p5169"><li><a href="http://dx.doi.org/10.1068/p5169" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Simultaneity+constancy." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Simultaneity+constancy.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">6.
              </span><a name="pone.0001253-Alais1" id="pone.0001253-Alais1"></a>Alais D, Carlile S (2005) Synchronizing to real events: Subjective audiovisual alignment scales with perceived auditory depth and speed of sound. Proc Natl Acad Sci U S A  102: 2244â2247.  <ul class="find" data-citedArticleID="1025046" data-doi="10.1073/pnas.0407034102"><li><a href="http://dx.doi.org/10.1073/pnas.0407034102" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Synchronizing+to+real+events%3A+Subjective+audiovisual+alignment+scales+with+perceived+auditory+depth+and+speed+of+sound." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Synchronizing+to+real+events%3A+Subjective+audiovisual+alignment+scales+with+perceived+auditory+depth+and+speed+of+sound.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">7.
              </span><a name="pone.0001253-Lewald1" id="pone.0001253-Lewald1"></a>Lewald J, Guski R (2004) Auditory-visual temporal integration as a function of distance: no compensation for sound-transmission time in human perception. Neurosci Lett  357: 119â122.  <ul class="find" data-citedArticleID="1025084" data-doi="10.1016/j.neulet.2003.12.045"><li><a href="http://dx.doi.org/10.1016/j.neulet.2003.12.045" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Auditory-visual+temporal+integration+as+a+function+of+distance%3A+no+compensation+for+sound-transmission+time+in+human+perception." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Auditory-visual+temporal+integration+as+a+function+of+distance%3A+no+compensation+for+sound-transmission+time+in+human+perception.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">8.
              </span><a name="pone.0001253-Fujisaki1" id="pone.0001253-Fujisaki1"></a>Fujisaki W, Shimojo S, Kashino M, Nishida S (2004) Recalibration of audio-visual simultaneity. Nat Neurosci  7: 773â778.  <ul class="find" data-citedArticleID="1025072" data-doi="10.1038/nn1268"><li><a href="http://dx.doi.org/10.1038/nn1268" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Recalibration+of+audio-visual+simultaneity." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Recalibration+of+audio-visual+simultaneity.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">9.
              </span><a name="pone.0001253-Navarra1" id="pone.0001253-Navarra1"></a>Navarra J, Vatakis A, Zampin M, Soto-Faraco S, Humphreys W, et al.  (2005) Exposure to asynchronous audiovisual speech extends the temporal window for audiovisual integration. Cogn Brain Res  25: 499â507.  <ul class="find" data-citedArticleID="1025090" data-doi="10.1016/j.cogbrainres.2005.07.009"><li><a href="http://dx.doi.org/10.1016/j.cogbrainres.2005.07.009" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Exposure+to+asynchronous+audiovisual+speech+extends+the+temporal+window+for+audiovisual+integration." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Exposure+to+asynchronous+audiovisual+speech+extends+the+temporal+window+for+audiovisual+integration.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">10.
              </span><a name="pone.0001253-Stetson1" id="pone.0001253-Stetson1"></a>Stetson C, Xu C, Montague PR, Eagleman DM (2006) Motor-sensory recalibration leads to an illusory reversal of action and sensation. Neuron  51: 651â659.  <ul class="find" data-citedArticleID="1025106" data-doi="10.1016/j.neuron.2006.08.006"><li><a href="http://dx.doi.org/10.1016/j.neuron.2006.08.006" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Motor-sensory+recalibration+leads+to+an+illusory+reversal+of+action+and+sensation." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Motor-sensory+recalibration+leads+to+an+illusory+reversal+of+action+and+sensation.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">11.
              </span><a name="pone.0001253-Miyazaki1" id="pone.0001253-Miyazaki1"></a>Miyazaki M, Yamamoto S, Uchida S, Kitazawa S (2006) Bayesian calibration of simultaneity in tactile temporal order judgment. Nat Neurosci  9: 875â877.  <ul class="find" data-citedArticleID="1025086" data-doi="10.1038/nn1712"><li><a href="http://dx.doi.org/10.1038/nn1712" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Bayesian+calibration+of+simultaneity+in+tactile+temporal+order+judgment." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Bayesian+calibration+of+simultaneity+in+tactile+temporal+order+judgment.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">12.
              </span><a name="pone.0001253-Wundt1" id="pone.0001253-Wundt1"></a>Wundt WM (1883) Philosophische studien. Leipzig: Wilhelm Engelmann.   <ul class="find-nolinks"></ul></li><li><span class="label">13.
              </span><a name="pone.0001253-Burrow1" id="pone.0001253-Burrow1"></a>Burrow NT (1909) The determination of the position of a momentary impression in the temporal course of a moving impression. Psychological Monographs  11: 163.  <ul class="find" data-citedArticleID="1025050" data-doi="10.1037/h0093030"><li><a href="http://dx.doi.org/10.1037/h0093030" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+determination+of+the+position+of+a+momentary+impression+in+the+temporal+course+of+a+moving+impression." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+determination+of+the+position+of+a+momentary+impression+in+the+temporal+course+of+a+moving+impression.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">14.
              </span><a name="pone.0001253-Dunlap1" id="pone.0001253-Dunlap1"></a>Dunlap K (1910) The complication experiment and related phenomena. Psychological Review  17: 157â191.  <ul class="find" data-citedArticleID="1025060" data-doi="10.1037/h0073064"><li><a href="http://dx.doi.org/10.1037/h0073064" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+complication+experiment+and+related+phenomena." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+complication+experiment+and+related+phenomena.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">15.
              </span><a name="pone.0001253-Cairney1" id="pone.0001253-Cairney1"></a>Cairney PT (1975) The complication experiment uncomplicated. Perception  4: 255â265.  <ul class="find" data-citedArticleID="1025052" data-doi="10.1068/p040255"><li><a href="http://dx.doi.org/10.1068/p040255" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+complication+experiment+uncomplicated." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+complication+experiment+uncomplicated.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">16.
              </span><a name="pone.0001253-Piron1" id="pone.0001253-Piron1"></a>PiÃ©ron H (1952) The sensations: Their functions, processes and mechanisms. London: Muller.   <ul class="find-nolinks"></ul></li><li><span class="label">17.
              </span><a name="pone.0001253-Fraisse1" id="pone.0001253-Fraisse1"></a>Fraisse P (1964) The psychology of time. London: Eyre &amp; Spottiswoode.   <ul class="find-nolinks"></ul></li><li><span class="label">18.
              </span><a name="pone.0001253-Fujisaki2" id="pone.0001253-Fujisaki2"></a>Fujisaki W, Nishida S (2005) Temporal frequency characteristics of synchrony-asynchrony discrimination of audio-visual signals. Exp Brain Res  166: 455â464.  <ul class="find" data-citedArticleID="1025074" data-doi="10.1007/s00221-005-2385-8"><li><a href="http://dx.doi.org/10.1007/s00221-005-2385-8" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Temporal+frequency+characteristics+of+synchrony-asynchrony+discrimination+of+audio-visual+signals." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Temporal+frequency+characteristics+of+synchrony-asynchrony+discrimination+of+audio-visual+signals.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">19.
              </span><a name="pone.0001253-Spence2" id="pone.0001253-Spence2"></a>Spence C, Shore DI, Klein RM (2001) Multisensory prior entry. J Exp Psychol: General  130: 799â832.  <ul class="find" data-citedArticleID="1025104"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=Multisensory+prior+entry.&amp;auth=&amp;atitle=Multisensory+prior+entry." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Multisensory+prior+entry." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Multisensory+prior+entry.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">20.
              </span><a name="pone.0001253-Zampini1" id="pone.0001253-Zampini1"></a>Zampini M, Guest S, Shore DI, Spence C (2005) Audio-visual simultaneity judgments. Percept Psychophys  67: 531â544.  <ul class="find" data-citedArticleID="1025124" data-doi="10.3758/bf03193329"><li><a href="http://dx.doi.org/10.3758/bf03193329" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Audio-visual+simultaneity+judgments." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Audio-visual+simultaneity+judgments.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">21.
              </span><a name="pone.0001253-Blake1" id="pone.0001253-Blake1"></a>Blake R, Logothetis NK (2002) Visual competition. Nat Rev Neurosci  3: 13â21.  <ul class="find" data-citedArticleID="1025048" data-doi="10.1038/nrn701"><li><a href="http://dx.doi.org/10.1038/nrn701" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Visual+competition." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Visual+competition.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">22.
              </span><a name="pone.0001253-Fendrich1" id="pone.0001253-Fendrich1"></a>Fendrich R, Corballis PM (2001) The temporal cross-capture of audition and vision. Percept Psychophys  63: 719â725.  <ul class="find" data-citedArticleID="1025066" data-doi="10.3758/bf03194432"><li><a href="http://dx.doi.org/10.3758/bf03194432" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+temporal+cross-capture+of+audition+and+vision." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+temporal+cross-capture+of+audition+and+vision.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">23.
              </span><a name="pone.0001253-Jaskowski1" id="pone.0001253-Jaskowski1"></a>Jaskowski P, Jaroszyk F, Hojan-Jezierska D (1990) Temporal-order judgments and reaction time for stimuli of different modalities. Psychol Res  52: 35â38.  <ul class="find" data-citedArticleID="1025080" data-doi="10.1007/bf00867209"><li><a href="http://dx.doi.org/10.1007/bf00867209" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Temporal-order+judgments+and+reaction+time+for+stimuli+of+different+modalities." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Temporal-order+judgments+and+reaction+time+for+stimuli+of+different+modalities.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">24.
              </span><a name="pone.0001253-Stone1" id="pone.0001253-Stone1"></a>Stone JV, Hunkin NM, Porrill J, Wood R, Keeler V, et al. When is now? Perception of simultaneity. Proc Biol Sci  268: 31â38.  <ul class="find" data-citedArticleID="1025108" data-doi="10.1098/rspb.2000.1326"><li><a href="http://dx.doi.org/10.1098/rspb.2000.1326" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=When+is+now%3F+Perception+of+simultaneity." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22When+is+now%3F+Perception+of+simultaneity.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">25.
              </span><a name="pone.0001253-Zampini2" id="pone.0001253-Zampini2"></a>Zampini M, Shore DI, Spence C (2003) Audiovisual temporal order judgments. Exp Brain Res  152: 198â210.  <ul class="find" data-citedArticleID="1025126" data-doi="10.1007/s00221-003-1536-z"><li><a href="http://dx.doi.org/10.1007/s00221-003-1536-z" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Audiovisual+temporal+order+judgments." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Audiovisual+temporal+order+judgments.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">26.
              </span><a name="pone.0001253-Smith1" id="pone.0001253-Smith1"></a>Smith WF (1933) The relative quickness of visual and auditory perception. J Exp Psychol  16: 239â257.  <ul class="find" data-citedArticleID="1025100" data-doi="10.1037/h0071379"><li><a href="http://dx.doi.org/10.1037/h0071379" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+relative+quickness+of+visual+and+auditory+perception." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+relative+quickness+of+visual+and+auditory+perception.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">27.
              </span><a name="pone.0001253-Rutschmann1" id="pone.0001253-Rutschmann1"></a>Rutschmann J, Link R (1964) Perception of temporal order of stimuli differing in sense mode and simple reaction time. Percept Mot Skills  18: 345â352.  <ul class="find" data-citedArticleID="1025098" data-doi="10.2466/pms.1964.18.2.345"><li><a href="http://dx.doi.org/10.2466/pms.1964.18.2.345" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Perception+of+temporal+order+of+stimuli+differing+in+sense+mode+and+simple+reaction+time." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Perception+of+temporal+order+of+stimuli+differing+in+sense+mode+and+simple+reaction+time.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">28.
              </span><a name="pone.0001253-Titchener1" id="pone.0001253-Titchener1"></a>Titchener EB (1908) Lectures on the elementary psychology of feeling and attention. New York: Macmillan.   <ul class="find-nolinks"></ul></li><li><span class="label">29.
              </span><a name="pone.0001253-Hikosaka1" id="pone.0001253-Hikosaka1"></a>Hikosaka O, Miyauchi S, Shimojo S (1993) Focal visual attention produces illusory temporal order and motion sensation. Vision Res  33: 1219â1240.  <ul class="find" data-citedArticleID="1025076" data-doi="10.1016/0042-6989(93)90210-n"><li><a href="http://dx.doi.org/10.1016/0042-6989(93)90210-n" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Focal+visual+attention+produces+illusory+temporal+order+and+motion+sensation." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Focal+visual+attention+produces+illusory+temporal+order+and+motion+sensation.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">30.
              </span><a name="pone.0001253-Cinel1" id="pone.0001253-Cinel1"></a>Cinel C, Humphreys GW, Poli R (2002) Cross-modal illusory conjunctions between vision and touch. J Exp Psychol Hum Percept Perform  28: 1243â1266.  <ul class="find" data-citedArticleID="1025054" data-doi="10.1037/0096-1523.28.5.1243"><li><a href="http://dx.doi.org/10.1037/0096-1523.28.5.1243" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Cross-modal+illusory+conjunctions+between+vision+and+touch." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Cross-modal+illusory+conjunctions+between+vision+and+touch.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">31.
              </span><a name="pone.0001253-Duncan1" id="pone.0001253-Duncan1"></a>Duncan J (1989) Boundary conditions on parallel processing in human vision. Perception  18: 457â469.  <ul class="find" data-citedArticleID="1025058" data-doi="10.1068/p180457"><li><a href="http://dx.doi.org/10.1068/p180457" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Boundary+conditions+on+parallel+processing+in+human+vision." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Boundary+conditions+on+parallel+processing+in+human+vision.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">32.
              </span><a name="pone.0001253-Posner1" id="pone.0001253-Posner1"></a>Posner MI (1980) Orienting of attention. The VIIth Sir Frederic Barlett Lecture. Q J Exp Psychol  32: 3â25.  <ul class="find" data-citedArticleID="1025094"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=Orienting+of+attention.+The+VIIth+Sir+Frederic+Barlett+Lecture.&amp;auth=&amp;atitle=Orienting+of+attention.+The+VIIth+Sir+Frederic+Barlett+Lecture." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Orienting+of+attention.+The+VIIth+Sir+Frederic+Barlett+Lecture." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Orienting+of+attention.+The+VIIth+Sir+Frederic+Barlett+Lecture.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">33.
              </span><a name="pone.0001253-Findlay1" id="pone.0001253-Findlay1"></a>Findlay JM, Walker R (1999) A model of saccade generation based on parallel processing and competitive inhibition. Behavioral Brain Science  22: 661â721.  <ul class="find" data-citedArticleID="1025068" data-doi="10.1017/s0140525x99002150"><li><a href="http://dx.doi.org/10.1017/s0140525x99002150" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=A+model+of+saccade+generation+based+on+parallel+processing+and+competitive+inhibition." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22A+model+of+saccade+generation+based+on+parallel+processing+and+competitive+inhibition.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">34.
              </span><a name="pone.0001253-Farroni1" id="pone.0001253-Farroni1"></a>Farroni T, Johnson MH, Brockbank M, Simion F (2000) Infants' use of gaze direction to cue attention: The importance of perceived motion. Vis Cog  7: 705â718.  <ul class="find" data-citedArticleID="1025064" data-doi="10.1080/13506280050144399"><li><a href="http://dx.doi.org/10.1080/13506280050144399" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Infants%27+use+of+gaze+direction+to+cue+attention%3A+The+importance+of+perceived+motion." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Infants%27+use+of+gaze+direction+to+cue+attention%3A+The+importance+of+perceived+motion.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">35.
              </span><a name="pone.0001253-Vroomen1" id="pone.0001253-Vroomen1"></a>Vroomen J, de Gelder B (2004) Temporal ventriloquism: Sound modulates the flash-lag effect. J Exp Psyhol Hum Percept Perform  30: 513â518.  <ul class="find" data-citedArticleID="1025118" data-doi="10.1037/0096-1523.30.3.513"><li><a href="http://dx.doi.org/10.1037/0096-1523.30.3.513" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Temporal+ventriloquism%3A+Sound+modulates+the+flash-lag+effect." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Temporal+ventriloquism%3A+Sound+modulates+the+flash-lag+effect.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">36.
              </span><a name="pone.0001253-MoreinZamir1" id="pone.0001253-MoreinZamir1"></a>Morein-Zamir S, Soto-Faraco S, Kingstone A (2003) Auditory capture of vision: Examining temporal ventriloquism. Cogn Brain Res  17: 154â163.  <ul class="find" data-citedArticleID="1025088" data-doi="10.1016/s0926-6410(03)00089-2"><li><a href="http://dx.doi.org/10.1016/s0926-6410(03)00089-2" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Auditory+capture+of+vision%3A+Examining+temporal+ventriloquism." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Auditory+capture+of+vision%3A+Examining+temporal+ventriloquism.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">37.
              </span><a name="pone.0001253-Visser1" id="pone.0001253-Visser1"></a>Visser TAW, Enns JT (2001) The role of attention in temporal integration. Perception  30: 135â145.  <ul class="find" data-citedArticleID="1025116" data-doi="10.1068/p3089"><li><a href="http://dx.doi.org/10.1068/p3089" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+role+of+attention+in+temporal+integration." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+role+of+attention+in+temporal+integration.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">38.
              </span><a name="pone.0001253-Yeshurun1" id="pone.0001253-Yeshurun1"></a>Yeshurun Y, Levy L (2003) Transient spatial attention degrades temporal resolution. Psychol Sci  14: 225â231.  <ul class="find" data-citedArticleID="1025122" data-doi="10.1111/1467-9280.02436"><li><a href="http://dx.doi.org/10.1111/1467-9280.02436" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Transient+spatial+attention+degrades+temporal+resolution." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Transient+spatial+attention+degrades+temporal+resolution.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">39.
              </span><a name="pone.0001253-Tse1" id="pone.0001253-Tse1"></a>Tse PU, Intriligator J, Rivest J, Cavanagh P (2004) Attention and the subjective expansion of time. Percept Psychophys  66: 1171â1189.  <ul class="find" data-citedArticleID="1025114" data-doi="10.3758/bf03196844"><li><a href="http://dx.doi.org/10.3758/bf03196844" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Attention+and+the+subjective+expansion+of+time." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Attention+and+the+subjective+expansion+of+time.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">40.
              </span><a name="pone.0001253-Hup1" id="pone.0001253-Hup1"></a>HupÃ© JM, Rubin , N  (2003) The dynamics of bi-stable alternation in ambiguous motion displays: a fresh look at plaids. Vision Res  43: 531â548.  <ul class="find" data-citedArticleID="1025078" data-doi="10.1016/s0042-6989(02)00593-x"><li><a href="http://dx.doi.org/10.1016/s0042-6989(02)00593-x" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+dynamics+of+bi-stable+alternation+in+ambiguous+motion+displays%3A+a+fresh+look+at+plaids." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+dynamics+of+bi-stable+alternation+in+ambiguous+motion+displays%3A+a+fresh+look+at+plaids.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">41.
              </span><a name="pone.0001253-Pressnitzer1" id="pone.0001253-Pressnitzer1"></a>Pressnitzer D, HupÃ© JM (2006) Temporal dynamics of auditory and visual bistability reveal common principles of perceptual organization. Curr Biol  16: 1351â1357.  <ul class="find" data-citedArticleID="1025096" data-doi="10.1016/j.cub.2006.05.054"><li><a href="http://dx.doi.org/10.1016/j.cub.2006.05.054" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Temporal+dynamics+of+auditory+and+visual+bistability+reveal+common+principles+of+perceptual+organization." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Temporal+dynamics+of+auditory+and+visual+bistability+reveal+common+principles+of+perceptual+organization.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li></ol></div>

  </div>

      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.XML" value="71926"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.PDF" value="387714"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g001.PNG_L" value="136199"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g001.PNG_M" value="79781"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g001.PNG_S" value="12379"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g001.TIF" value="554526"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g001.PNG_I" value="31367"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g002.PNG_L" value="224268"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g002.PNG_M" value="69328"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g002.PNG_S" value="8796"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g002.TIF" value="349370"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g002.PNG_I" value="23673"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g003.PNG_L" value="166827"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g003.PNG_M" value="115840"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g003.PNG_S" value="14248"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g003.TIF" value="547070"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g003.PNG_I" value="41461"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g004.PNG_L" value="226738"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g004.PNG_M" value="78359"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g004.PNG_S" value="10197"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g004.TIF" value="416860"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g004.PNG_I" value="26787"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g005.PNG_L" value="72835"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g005.PNG_M" value="67546"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g005.PNG_S" value="14720"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g005.TIF" value="197020"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g005.PNG_I" value="51980"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g006.PNG_L" value="195142"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g006.PNG_M" value="71865"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g006.PNG_S" value="9846"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g006.TIF" value="427224"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001253.g006.PNG_I" value="24920"/>

</div>
<div class="sidebar">

  <div class="article-actions cf">
      <div class="download">
        <span class="btn"><a href="/article/fetchObject.action?uri=info%3Adoi%2F10.1371%2Fjournal.pone.0001253&amp;representation=PDF" title="Download" target="_blank">Download PDF</a></span>
      </div>
      <div class="btn-reveal dropdown">
        <div class="dropdown-icon">
          <span class="btn">&nbsp;</span>
        </div>

        <div class="content">
          <ul class="bullet">
            <li><a href="/article/citationList.action?articleURI=info%3Adoi%2F10.1371%2Fjournal.pone.0001253" title="Download citations">Citation</a></li>
            <li><a href="/article/fetchObjectAttachment.action?uri=info%3Adoi%2F10.1371%2Fjournal.pone.0001253&amp;representation=XML" title="Download article XML">XML</a></li>
          </ul>
        </div>
      </div> <!-- end btn-reveal dropdown-->


    <div class="btn-reveal flt-l">
        <span class="btn">Print</span>
        <div class="content">
            <ul class="bullet">
                <li id="print-article"><a href="#" onclick="if(typeof(_gaq) != 'undefined'){ _gaq.push(['_trackEvent','Article', 'Print', 'Click']); } window.print(); return false;" title="Print Article">Print article</a></li>
                <li>
                  <a href="https://www.odysseypress.com/onlinehost/reprint_order.php?type=A&page=0&journal=7&doi=10.1371/journal.pone.0001253&volume=&issue=&title=Dynamic Perceptual Changes in Audiovisual Simultaneity&author_name=Ryota%20Kanai%2C%20Bhavin%20R.%20Sheth%2C%20Frans%20A.%20J.%20Verstraten%2C%20Shinsuke%20Shimojo&start_page=1&end_page=8" title="Odyssey Press">EzReprint</a>
                </li>
            </ul>
        </div>
    </div>

    <div class="btn-reveal flt-r">
        <span class="btn">Share</span>
        <div class="content">
            <ul class="social">
                <li><a href="http://www.reddit.com/submit?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001253" target="_blank" title="Submit to Reddit"><img src="/images/icon.reddit.16.png" width="16" height="16" alt="Reddit">Reddit</a></li>

                <li><a href="https://plus.google.com/share?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001253" target="_blank" title="Share on Google+"><img src="/images/icon.gplus.16.png" width="16" height="16" alt="Google+">Google+</a></li>

                <li><a href="http://www.stumbleupon.com/submit?url=http%3A%2F%2Fwww.plosone.org%2Farticle%2Finfo%253Adoi%252F10.1371%252Fjournal.pone.0001253" target="_blank" title="Add to StumbleUpon"><img src="/images/icon.stumble.16.png" width="16" height="16" alt="StumbleUpon">StumbleUpon</a></li>

                <li><a href="http://www.facebook.com/share.php?u=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001253&amp;t=Dynamic%20Perceptual%20Changes%20in%20Audiovisual%20Simultaneity" target="_blank" title="Share on Facebook"><img src="/images/icon.fb.16.png" width="16" height="16" alt="Facebook">Facebook</a></li>

                <li><a href="http://www.linkedin.com/shareArticle?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001253&title=Dynamic%20Perceptual%20Changes%20in%20Audiovisual%20Simultaneity&summary=Checkout%20this%20article%20I%20found%20at%20PLOS" target="_blank" title="Add to LinkedIn"><img src="/images/icon.linkedin.16.png" width="16" height="16" alt="Mendeley">LinkedIn</a></li>

                <li><a href="http://www.citeulike.org/posturl?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001253&amp;title=Dynamic%20Perceptual%20Changes%20in%20Audiovisual%20Simultaneity" target="_blank" title="Add to CiteULike"><img src="/images/icon.cul.16.png" width="16" height="16" alt="CiteULike">CiteULike</a></li>

                <li><a href="http://www.mendeley.com/import/?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001253" target="_blank" title="Add to Mendeley"><img src="/images/icon.mendeley.16.png" width="16" height="16" alt="Mendeley">Mendeley</a></li>

                <li><a href="https://www.pubchase.com/library?add_aid=10.1371%2Fjournal.pone.0001253&amp;source=plos" target="_blank" title="Add to PubChase"><img src="/images/icon.pc.16.png" width="16" height="16" alt="PubChase">PubChase</a></li>


                <script type="text/javascript">
                    // replace tweet with one that's pre-shortened to 140 chars
                    function truncateTweetText() {
                        var twtTitle = 'Dynamic Perceptual Changes in Audiovisual Simultaneity';
                        var twtUrl = 'http://dx.plos.org/10.1371/journal.pone.0001253';
                        // all URLs posted to twitter get auto-shortened to 20 chars.
                        var maxLength = 140 - (20 + 1);
                        // truncate the title to include space for twtTag and ellipsis (here, 10 = tag length + space + ellipsis)
                        if (twtTitle.length > maxLength) { twtTitle = twtTitle.substr(0, (maxLength - 10)) + '...'; }
                        // set the href to use the shortened tweet
                        $('#twitter-share-link').prop('href', 'http://twitter.com/intent/tweet?text=' + encodeURIComponent('#PLOSONE: ' + twtTitle + ' ' + twtUrl));
                    }
                </script>
                <li><a href="http://twitter.com/intent/tweet?text=#PLOSONE%3A%20Dynamic%20Perceptual%20Changes%20in%20Audiovisual%20Simultaneity http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001253" onclick="truncateTweetText();" target="_blank" title="Share on Twitter" id="twitter-share-link"><img src="/images/icon.twtr.16.png" width="16" height="16" alt="Twitter">Twitter</a></li>

                <li><a href="/article/email/info%3Adoi%2F10.1371%2Fjournal.pone.0001253" title="Email this article"><img src="/images/icon.email.16.png" width="16" height="16" alt="Email">Email</a></li>
            </ul>
        </div>
    </div><!--end btn-reveal flt-r-->
</div><!-- end article-actions-->

<!-- begin Crossmark -->

<a id="open-crossmark" href="#" style="margin-top: -28px; display:block"><img style="border: 0; display: none;
 padding: 10px 0 18px 0;"  id="crossmark-icon" src="/images/logo-crossmark-bw.png" /></a>
<div id="crossmark-dialog" style="display: none;" title="">
    <!-- the external CrossMark data is loaded inside this iframe -->
    <iframe id="crossmark-dialog-frame" frameborder="0"></iframe>
</div>

<!-- end crossmark -->


<div class="block" id="subject-area-sidebar-block">
    <div class="header">
        <h3>Subject Areas</h3><div title="More information" id="subject-area-sidebar-block-help-icon"><img align="right"
                                                                                                           alt="info" src="/images/button_info.png"/><div id="subject-area-sidebar-block-help"><img align="right"
                                                                                                                                                                                                    src="/images/button_info.png"/><p>
        <b>We want your feedback.</b> Do these subject areas make sense for this article? If not, click the flag
        next to the incorrect subject area and we will review it. Thanks for your help!
    </p></div></div>
    </div>


    <ul id="subject-area-sidebar-list">



















          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Acoustic+signals%22" title="Search for articles in the subject area:'Acoustic signals'"><div class="flagText">Acoustic signals</div></a>
              <div data-categoryid="20989" data-articleid="25338"
                   data-categoryname="Acoustic signals"
                   class="flagImage" title="Flag 'Acoustic signals' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Attention%22" title="Search for articles in the subject area:'Attention'"><div class="flagText">Attention</div></a>
              <div data-categoryid="33353" data-articleid="25338"
                   data-categoryname="Attention"
                   class="flagImage" title="Flag 'Attention' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Audio+signal+processing%22" title="Search for articles in the subject area:'Audio signal processing'"><div class="flagText">Audio signal processing</div></a>
              <div data-categoryid="20991" data-articleid="25338"
                   data-categoryname="Audio signal processing"
                   class="flagImage" title="Flag 'Audio signal processing' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Perception%22" title="Search for articles in the subject area:'Perception'"><div class="flagText">Perception</div></a>
              <div data-categoryid="21209" data-articleid="25338"
                   data-categoryname="Perception"
                   class="flagImage" title="Flag 'Perception' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Sensory+perception%22" title="Search for articles in the subject area:'Sensory perception'"><div class="flagText">Sensory perception</div></a>
              <div data-categoryid="46099" data-articleid="25338"
                   data-categoryname="Sensory perception"
                   class="flagImage" title="Flag 'Sensory perception' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22System+stability%22" title="Search for articles in the subject area:'System stability'"><div class="flagText">System stability</div></a>
              <div data-categoryid="32597" data-articleid="25338"
                   data-categoryname="System stability"
                   class="flagImage" title="Flag 'System stability' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Vision%22" title="Search for articles in the subject area:'Vision'"><div class="flagText">Vision</div></a>
              <div data-categoryid="32965" data-articleid="25338"
                   data-categoryname="Vision"
                   class="flagImage" title="Flag 'Vision' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Visual+signals%22" title="Search for articles in the subject area:'Visual signals'"><div class="flagText">Visual signals</div></a>
              <div data-categoryid="35641" data-articleid="25338"
                   data-categoryname="Visual signals"
                   class="flagImage" title="Flag 'Visual signals' as inappropriate"></div>
          </li>
    </ul>
</div>

<div class="ad">
    <div class="title">Advertisement</div>






  <iframe id='a0852f54' name='a0852f54'
    src='http://ads.plos.org/www/delivery/afr.php?zoneid=381&amp;cb=3881'
    frameborder='0' scrolling='no' width='160' height='600'>
    <a href='http://ads.plos.org/www/delivery/ck.php?n=a0852f54&amp;cb=3690'
      target='_top'><img src='http://ads.plos.org/www/delivery/avw.php?zoneid=381&amp;cb=4703&amp;n=a0852f54'
      border='0' alt=''/>
    </a>
  </iframe>



</div>

<div id="twitter-alm-timeline" class="twitter-alm-timeline"></div>

<div class="block sidebar-comments">
    <div class="header">
        <h3>Comments</h3>
    </div>
      <p><a href="/annotation/listThread.action?root=20627">perspective from the academic editor</a><br>Posted by holcombea</p>
</div>

</div><!-- sidebar -->
    </div>
  </div>
</div>
<script src="http://wl.figshare.com/static/p_widget.js" type="text/javascript"></script><div id="pageftr">
  <div class="ftr-cols cf">
    <div class="col col-1">
      <img src="/images/logo-plos-footer.png" alt="PLOS Logo" class="logo" />
      <p><a href="/static/releaseNotes">Ambra 2.9.16</a> Managed Colocation provided <br />by <a href="http://www.isc.org/">Internet Systems Consortium</a>.<p>
      <div class="nav nav-aux">
        <a href="/static/privacy">Privacy Policy</a> |
        <a href="/static/terms">Terms of Use</a> |
        <a href="http://www.plos.org/advertise/">Advertise</a> |
        <a href="http://www.plos.org/about/media-inquiries/">Media Inquiries</a>
      </div>
    </div>
    <div class="col col-2">
      <p><a href="http://www.plos.org/publications/journals/">Publications</a></p>
      <div class="nav">
        <ul>
          <li><a href="http://www.plosbiology.org">PLOS Biology</a></li>
          <li><a href="http://www.plosmedicine.org">PLOS Medicine</a></li>
          <li><a href="http://www.ploscompbiol.org">PLOS Computational Biology</a></li>
          <li><a href="http://currents.plos.org">PLOS Currents</a></li>
          <li><a href="http://www.plosgenetics.org">PLOS Genetics</a></li>
          <li><a href="http://www.plospathogens.org">PLOS Pathogens</a></li>
          <li><a href="http://www.plosone.org">PLOS ONE</a></li>
          <li><a href="http://www.plosntds.org">PLOS Neglected Tropical Diseases</a></li>
        </ul>
      </div>
    </div>
    <div class="col col-3">
      <div class="nav">
        <p><a href="http://www.plos.org">plos.org</a></p>
        <p><a href="http://blogs.plos.org">Blogs</a></p>
        <p><a href="http://www.ploscollections.org">Collections</a></p>
        <p><a href="/feedback/new">Send us feedback</a></p>

        <p>California (US) corporation #C2354500, based in San Francisco</p>
      </div>
    </div>
  </div>
</div><!-- pageftr -->

</div><!-- end page-wrap, this div is in header.ftl -->
<script type="text/javascript" src="/javascript/jquery-1.8.1-min.js?v=Tm7VCOzZz3lE03ghpkS6SWkHbyI"></script>
<script type="text/javascript" src="/javascript/ga-min.js?v=lNQ4gt8QcPDatjsdOFl_FGpPhLY"></script>
<script type="text/javascript" src="/javascript/jquery.hoverIntent-min.js?v=mRiGNYY9cIXxVb8u0K_MdW7hHnc"></script>
<script type="text/javascript" src="/javascript/jquery.placeholder-min.js?v=21Pn56Ur9h1N4K4VZDa0nqI3Pxo"></script>
<script type="text/javascript" src="/javascript/jquery.jsonp-2.4.0-min.js?v=lqTpzoHfSq3I5Ygo01qq5WankEo"></script>
<script type="text/javascript" src="/javascript/jquery-ui-1.9.2.custom-min.js?v=raSSlfNO0YsV5uUpAKmTB9n5VTc"></script>
<script type="text/javascript" src="/javascript/jquery.tooltip-min.js?v=cw+6Smh+mdryIA25xvqIvHMrnZM"></script>
<script type="text/javascript" src="/javascript/jquery.uniform-min.js?v=kYUAnX6W2W_2fK3RIuQ2m_YFG9U"></script>
<script type="text/javascript" src="/javascript/jquery.pjax-min.js?v=939kLBjL5_YKbx71T1RHjYaD4l8"></script>
<script type="text/javascript" src="/javascript/imagesloaded-min.js?v=XeuAp8Gc3mvQUo+wZCSF8ttPwvw"></script>
<script type="text/javascript" src="/javascript/figviewer-min.js?v=yPUa0sUQ_iHkI+IRv2i9bjyZJFo"></script>
<script type="text/javascript" src="/javascript/global-min.js?v=0Q3PwjeaWtXYDnqIsQvnL_ou0qs"></script>
<script type="text/javascript" src="/javascript/jquery.touchswipe-min.js?v=huaek_e6HqTduvCNAN91dJolTyw"></script>
<script type="text/javascript" src="/javascript/jquery.base64-min.js?v=VwV1zeVqKZj5FCAdlK0q5NRxbBg"></script>
<script type="text/javascript" src="/javascript/alm-min.js?v=Y5gm6B0b4Kx2YHNObNrgEeBgXlY"></script>
<script type="text/javascript" src="/javascript/taxonomy-browser-min.js?v=vBVMuDMYkGJCXIUxLe35GoyiJNw"></script>
<script type="text/javascript" src="/javascript/jquery.filterize-min.js?v=j0ZKVnHyk2nhFy8eIuNJkp7xaM0"></script>
<script type="text/javascript" src="/javascript/plosone-min.js?v=TK4H4arL_XBSwwJq+K1N3kqYfAI"></script>
<script type="text/javascript" src="/javascript/twitter-min.js?v=xKgcxLsQFXy+at1ao1NVke8nFlM"></script>
<script type="text/javascript" src="/javascript/crossmark.1.4-min.js?v=3FO4k0SjwTaGNnKGNSqthar1080"></script>
<script type="text/javascript">
  var _sf_async_config={uid:16579,domain:"plosone.org"};
  (function(){
    function loadChartbeat() {
      window._sf_endpt=(new Date()).getTime();
      var e = document.createElement('script');
      e.setAttribute('language', 'javascript');
      e.setAttribute('type', 'text/javascript');
      e.setAttribute('src',
          (("https:" == document.location.protocol) ? "https://a248.e.akamai.net/chartbeat.download.akamai.com/102508/" : "http://static.chartbeat.com/") +
              "js/chartbeat.js");
      document.body.appendChild(e);
    }
    var oldonload = window.onload;
    window.onload = (typeof window.onload != 'function') ?
        loadChartbeat : function() { oldonload(); loadChartbeat(); };
  })();
</script>
<!-- <script type="application/javascript" src="http://crossmark.crossref.org/javascripts/v1.3/crossmark.min.js"></script> -->

</body>
</html>
