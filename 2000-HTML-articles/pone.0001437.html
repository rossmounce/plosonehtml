

 



<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"
      xmlns:foaf="http://xmlns.com/foaf/0.1/"
      xmlns:dc="http://purl.org/dc/terms/"
      xmlns:doi="http://dx.doi.org/"
      xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
      xmlns:xsd="http://www.w3.org/2001/XMLSchema-datatypes#"
      lang="en" xml:lang="en"
      itemscope itemtype="http://schema.org/Article"
      class="no-js">
<head prefix="og: http://ogp.me/ns#">
  <title>PLOS ONE: Distortions of Subjective Time Perception Within and Across Senses</title>


<link rel="stylesheet" type="text/css"  href="/css/global-min.css?v=izteQ6tu7kgsJZW_xmrYizvKiHM" />


    <!--[if lte IE 7]>
<link rel="stylesheet" type="text/css"  href="/css/lte_ie7-min.css?v=3bykQUyQmReeuobVyPozcJ9LxRc" />
    <![endif]-->


<link rel="stylesheet" type="text/css"  href="/css/jquery-ui-min.css?v=eXDHTEJM0lIAmDe5k0I0Ad4nxNo" />


<link rel="stylesheet" type="text/css"  href="/css/journal.css?v=T7ZVxJfgk9jNxLAJ2qHz1vZpgYU" />


<link rel="stylesheet" type="text/css" media="print" href="/css/print-min.css?v=T5lb0B3q6EXBsuDluc5V5w+AkRc" />


  <link rel="stylesheet" href="http://f.fontdeck.com/s/css/js/www.plosone.org/24557.css" type="text/css"/>

  <!--chartbeat -->
  <script type="text/javascript">var _sf_startpt = (new Date()).getTime()</script>
  <script>document.documentElement.className += ' js';</script>

  <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <meta http-equiv="X-UA-Compatible" content="IE=EmulateIE7; IE=EmulateIE9"/>
  <meta name="description" content="PLOS ONE: an inclusive, peer-reviewed, open-access resource from the PUBLIC LIBRARY OF SCIENCE. Reports of well-performed scientific studies from all disciplines freely available to the whole world."/>
  <meta name="keywords" content="PLOS, Public Library of Science, Open Access, Open-Access, Science, Medicine, Biology, Research, Peer-review, Inclusive, Interdisciplinary, Ante-disciplinary, Physics, Chemistry, Engineering"/>
  <meta name="almHost" content="http://alm.plos.org/api/v3/articles"/>
  <meta name="searchHost" content="http://api.plos.org/search" />
  <meta name="termsHost" content="http://api.plos.org/terms" />
  <meta name="solrApiKey" content="plos"/>
  <meta name="almAPIKey" content="3pezRBRXdyzYW6ztfwft" />
  <meta name="currentJournal" content="PLoSONE" />
  <meta name="almRequestBatchSize" content="" />

  <meta name="citation_publisher" content="Public Library of Science"/>
  <meta name="citation_doi" content="10.1371/journal.pone.0001437"/>
  <meta name="dc.identifier" content="10.1371/journal.pone.0001437" />

    <meta name="citation_title" content="Distortions of Subjective Time Perception Within and Across Senses"/>
    <meta itemprop="name" content="Distortions of Subjective Time Perception Within and Across Senses"/>

      <meta name="citation_author" content="Virginie van Wassenhove"/>
            <meta name="citation_author_institution" content="Division of Biology, California Institute of Technology, Pasadena, California, United States of America"/>
      <meta name="citation_author" content="Dean V. Buonomano"/>
            <meta name="citation_author_institution" content="Department of Psychology, University of California at Los Angeles, Los Angeles, California, United States of America"/>
            <meta name="citation_author_institution" content="Department of Neurobiology, University of California at Los Angeles, Los Angeles, California, United States of America"/>
      <meta name="citation_author" content="Shinsuke Shimojo"/>
            <meta name="citation_author_institution" content="Division of Biology, California Institute of Technology, Pasadena, California, United States of America"/>
      <meta name="citation_author" content="Ladan Shams"/>
            <meta name="citation_author_institution" content="Department of Psychology, University of California at Los Angeles, Los Angeles, California, United States of America"/>

    <meta name="citation_date" content="2008/1/16"/>

  <meta name="citation_pdf_url" content="http://dx.plos.org/10.1371/journal.pone.0001437.pdf" />

      <meta name="citation_journal_title" content="PLOS ONE" />
    <meta name="citation_firstpage" content="e1437"/>
    <meta name="citation_issue" content="1"/>
    <meta name="citation_volume" content="3"/>
    <meta name="citation_issn" content="1932-6203"/>

    <meta name="citation_journal_abbrev" content="PLoS ONE" />

      <meta name="citation_reference" content="citation_title=The minimum duration of a perception.; citation_author=R Efron; citation_journal_title=Neuropsychologia; citation_volume=8; citation_number=1; citation_pages=57-63; citation_date=1970; " />
      <meta name="citation_reference" content="citation_title=Attention and the subjective expansion of time.; citation_author=PU Tse; citation_author=J Intriligator; citation_author=J Rivest; citation_author=P Cavanagh; citation_journal_title=Perception and Psychophysics; citation_volume=66; citation_number=2; citation_pages=1171-1189; citation_date=2004; " />
      <meta name="citation_reference" content="citation_title=Auditory chronostasis: hanging on the telephone.; citation_author=I Hodinott-Hill; citation_author=KV Thilo; citation_author=A Conwey; citation_author=V Walsh; citation_journal_title=Current Biology; citation_volume=12; citation_number=3; citation_pages=1779-1781; citation_date=2002; " />
      <meta name="citation_reference" content="citation_title=Manual chronostasis: tactile perception precedes physical contact.; citation_author=K Yarrow; citation_author=JC Rothwell; citation_journal_title=Current Biology; citation_volume=13; citation_number=4; citation_pages=1134-1139; citation_date=2003; " />
      <meta name="citation_reference" content="citation_title=Illusory perceptions of space and time preserve cross-saccadic perceptual continuity.; citation_author=K Yarrow; citation_author=K Haggard; citation_author=R Heal; citation_author=P Brown; citation_author=JC Rothwell; citation_journal_title=Nature; citation_number=5; citation_pages=302-305; citation_date=2001; " />
      <meta name="citation_reference" content="citation_title=Saccadic eye movements cause compression of time as well as space.; citation_author=MC Morrone; citation_author=J Ross; citation_author=D Burr; citation_journal_title=Nature Neuroscience; citation_volume=8; citation_number=6; citation_pages=950-954; citation_date=2005; " />
      <meta name="citation_reference" content="citation_title=Voluntary action expands perceived duration of its sensory consequences.; citation_author=J Park; citation_author=M Schlag-Rey; citation_author=J Schlag; citation_journal_title=Experimental Brain Research; citation_volume=149; citation_number=7; citation_pages=527-529; citation_date=2003; " />
      <meta name="citation_reference" content="citation_title=The principles of psychology.; citation_author=W James; citation_number=8; citation_date=1890; citation_publisher=Henry Holt and Company; " />
      <meta name="citation_reference" content="citation_title=Psychologie du temps.; citation_author=P Fraisse; citation_number=9; citation_date=1957; citation_publisher=Presses Universitaires de France; " />
      <meta name="citation_reference" content="citation_title=Temporal cognition.; citation_author=D Zakay; citation_author=RA Block; citation_journal_title=Current Directions in Psychological Science; citation_volume=6; citation_number=10; citation_pages=12-16; citation_date=1997; " />
      <meta name="citation_reference" content="citation_title=A hierarchical model of temporal perception.; citation_author=E Pöppel; citation_journal_title=Trends in Cognitive Sciences; citation_volume=1; citation_number=11; citation_pages=56-61; citation_date=1997; " />
      <meta name="citation_reference" content="citation_title=Distinct systems for automatic and cognitively controlled time measurement: evidence for neuroimaging.; citation_author=PA Lewis; citation_author=RC Miall; citation_journal_title=Current Opinion in Neurobiology; citation_volume=13; citation_number=12; citation_pages=250-255; citation_date=2003; " />
      <meta name="citation_reference" content="citation_title=Time perception and temporal processing levels of the brain.; citation_author=M Wittmann; citation_journal_title=Chronobiology International; citation_volume=16; citation_number=13; citation_pages=17-32; citation_date=1999; " />
      <meta name="citation_reference" content="citation_title=The neural basis of temporal processing.; citation_author=MD Mauk; citation_author=D Buonomano; citation_journal_title=Annual Reviews in Neurosciences; citation_volume=27; citation_number=14; citation_pages=307-340; citation_date=2004; " />
      <meta name="citation_reference" content="citation_title=Time Perception.; citation_author=E Pöppel; citation_number=15; citation_pages=713-729; citation_date=1978; citation_publisher=Springer-Verlag; " />
      <meta name="citation_reference" content="citation_title=Prospective and retrospective duration judgments: a meta-analytic review.; citation_author=RA Block; citation_author=D Zakay; citation_journal_title=Psychonomic Bulletin and Review; citation_volume=4; citation_number=16; citation_pages=184-197; citation_date=1997; " />
      <meta name="citation_reference" content="citation_title=Changes in visual perception at the time of saccades.; citation_author=J Ross; citation_author=MC Morrone; citation_author=ME Goldberg; citation_author=DC Burr; citation_journal_title=Trends in Neurosciences; citation_volume=24; citation_number=17; citation_pages=113-121; citation_date=2001; " />
      <meta name="citation_reference" content="citation_title=The effect of predictability on subjective duration; citation_author=V Pariyadath; citation_author=D Eagleman; citation_journal_title=PLoS ONE; citation_volume=2; citation_number=18; citation_pages=e1264; citation_date=2007; " />
      <meta name="citation_reference" content="citation_title=The perception of time.; citation_author=L Allan; citation_journal_title=Perception and Psychophysics; citation_volume=26; citation_number=19; citation_pages=340-354; citation_date=1979; " />
      <meta name="citation_reference" content="citation_title=Temporal discrimination and the indifference interval: implications for a model of the ‘internal clock’.; citation_author=M Treisman; citation_journal_title=Psychological Monographs; citation_volume=77; citation_number=20; citation_pages=1-31; citation_date=1963; " />
      <meta name="citation_reference" content="citation_title=The neural representation of time.; citation_author=RB Ivry; citation_author=RM Spencer; citation_journal_title=Current Opinion in Neurobiology; citation_volume=14; citation_number=21; citation_pages=225-232; citation_date=2004; " />
      <meta name="citation_reference" content="citation_title=Les effets de la modalité sensorielle sur la perception du temps.; citation_author=TB Penney; citation_author=S Tourret; citation_journal_title=Psychologie Française; citation_volume=50; citation_number=22; citation_pages=131-143; citation_date=2005; " />
      <meta name="citation_reference" content="citation_title=Judgment of filled and unfilled durations: intersensory factors.; citation_author=S Goldstone; citation_author=JL Goldfarb; citation_journal_title=Perceptual and Motor Skills; citation_volume=17; citation_number=23; citation_pages=763-774; citation_date=1963; " />
      <meta name="citation_reference" content="citation_title=Why “sounds are judged longer than lights”: application of a modal of the internal clock in humans.; citation_author=JH Wearden; citation_author=H Edwards; citation_author=M Fakhri; citation_author=A Percival; citation_journal_title=Quaterly Journal of Experimental Psychology; citation_volume=51B; citation_number=24; citation_pages=97-120; citation_date=1998; " />
      <meta name="citation_reference" content="citation_title=Differential effects of auditory and visual signals on clock speed and temporal memory.; citation_author=TB Penney; citation_author=J Gibbon; citation_author=WH Meck; citation_journal_title=Journal of Experimental Psychology: Human Perception and Performance; citation_volume=26; citation_number=25; citation_pages=1770-1787; citation_date=2000; " />
      <meta name="citation_reference" content="citation_title=Sensory modality and time perception in children and adults.; citation_author=S Droit-Volet; citation_author=WH Meck; citation_author=TB Penney; citation_journal_title=Behavioral Processes Epub; citation_number=26; citation_date=2006; " />
      <meta name="citation_reference" content="citation_title=Practice-related improvements in somatosensory interval discrimination are temporally specific but generalize across location, hemisphere, and modality.; citation_author=SS Nagarajan; citation_author=DT Blake; citation_author=BA Wright; citation_author=N Byl; citation_author=MM Merzenich; citation_journal_title=Journal of Neuroscience; citation_volume=18; citation_number=27; citation_pages=1559-1570; citation_date=1998; " />
      <meta name="citation_reference" content="citation_title=Learning and generalization of auditory temporal-interval discrimination in humans.; citation_author=BA Wright; citation_author=DV Buonomano; citation_author=HW Mahncke; citation_author=MM Merzenich; citation_journal_title=Journal of Neuroscience; citation_volume=17; citation_number=28; citation_pages=3956-3963; citation_date=1997; " />
      <meta name="citation_reference" content="citation_title=Temporal specificity of perceptual learning in an auditory discrimination task.; citation_author=UR Karmarkar; citation_author=DV Buonomano; citation_journal_title=Learning and Memory; citation_volume=10; citation_number=29; citation_pages=141-147; citation_date=2003; " />
      <meta name="citation_reference" content="citation_title=Auditory cortical plasticity in learning to discriminate modulation rate.; citation_author=V van Wassenhove; citation_author=SS Nagarajan; citation_journal_title=Journal of Neuroscience; citation_volume=27; citation_number=30; citation_pages=2663-2672; citation_date=2007; " />
      <meta name="citation_reference" content="citation_title=Discrimination of short time intervals by the human observer; citation_author=G Westheimer; citation_journal_title=Experimental Brain Research; citation_volume=129; citation_number=31; citation_pages=121-126; citation_date=1999; " />
      <meta name="citation_reference" content="citation_title=Spatially localized distortions of event time.; citation_author=A Johnston; citation_author=DH Arnold; citation_author=S Nishida; citation_journal_title=Current Biology; citation_volume=16; citation_number=32; citation_pages=472-479; citation_date=2006; " />
      <meta name="citation_reference" content="citation_title=Neural mechanisms for timing visual events are spatially selective in real-world coordinates.; citation_author=D Burr; citation_author=AM Tozzi; citation_author= Concetta; citation_journal_title=Nature Neuroscience; citation_number=33; citation_pages=423-425; citation_date=2007; " />
      <meta name="citation_reference" content="citation_title=Perceived luminance depends on temporal context.; citation_author=DM Eagleman; citation_author=JE Jacobson; citation_author=TJ Sejnowski; citation_journal_title=Nature; citation_volume=428; citation_number=34; citation_pages=854-856; citation_date=2004; " />
      <meta name="citation_reference" content="citation_title=Influence de l'intensité d'un son sur l'estimation de sa durée apparente.; citation_author=G Oléron; citation_journal_title=L'année Psychologique; citation_volume=52; citation_number=35; citation_pages=383-392; citation_date=1952; " />
      <meta name="citation_reference" content="citation_title=Persistent fear responses in Rhesus monkeys to the optical stimulus of “looming”.; citation_author=W Schiff; citation_author=JA Caviness; citation_author=JJ Gibson; citation_journal_title=Science; citation_volume=136; citation_number=36; citation_pages=982-983; citation_date=1962; " />
      <meta name="citation_reference" content="citation_title=Multisensory integration of looming signals by Rhesus monkeys.; citation_author=JX Maier; citation_author=JG Neuhoff; citation_author=NK Logothetis; citation_author=AA Ghazanfar; citation_journal_title=Neuron; citation_volume=43; citation_number=37; citation_pages=177-181; citation_date=2004; " />
      <meta name="citation_reference" content="citation_title=Infant Responses to Impending Collision: Optical and Real.; citation_author=W Ball; citation_author=E Tronick; citation_journal_title=Science; citation_volume=171; citation_number=38; citation_pages=818; citation_date=1971; " />
      <meta name="citation_reference" content="citation_title=Moving and looming stimuli capture attention.; citation_author=SL Franconeri; citation_author=DJ Simons; citation_journal_title=Perception & Psychophysics; citation_volume=65; citation_number=39; citation_pages=999-1010; citation_date=2003; " />
      <meta name="citation_reference" content="citation_title=Do new objects capture attention?; citation_author=SL Franconeri; citation_author=A Hollingworth; citation_author=DJ Simons; citation_journal_title=Psychological Research; citation_volume=16; citation_number=40; citation_date=2005; " />
      <meta name="citation_reference" content="citation_title=Immediate perceptual response to intersensory discrepancy.; citation_author=R Welch; citation_author=D Warren; citation_journal_title=Psychological Bulletin; citation_volume=88; citation_number=41; citation_pages=638-667; citation_date=1980; " />
      <meta name="citation_reference" content="citation_title=On discriminating the rate of visual flicker and auditory flutter.; citation_author=J Gebhard; citation_author=G Mowbray; citation_journal_title=American Journal of Psychology; citation_volume=72; citation_number=42; citation_pages=521-528; citation_date=1959; " />
      <meta name="citation_reference" content="citation_title=Auditory flutter-driving of visual flicker.; citation_author=T Shipley; citation_journal_title=Science; citation_volume=145; citation_number=43; citation_pages=1328-1330; citation_date=1964; " />
      <meta name="citation_reference" content="citation_title=Auditory influences on visual temporal rate perception.; citation_author=GH Recanzone; citation_journal_title=Journal of Neurophysiology; citation_volume=89; citation_number=44; citation_pages=1078-1093; citation_date=2003; " />
      <meta name="citation_reference" content="citation_title=Hearing what the eyes see: auditory encoding of visual temporal sequences.; citation_author=SE Guttman; citation_author=LA Gilroy; citation_author=R Blake; citation_journal_title=Psychological Science; citation_volume=16; citation_number=45; citation_pages=228-235; citation_date=2005; " />
      <meta name="citation_reference" content="citation_title=Causal inference in multisensory perception. Manuscript submitted for publication.; citation_author=KP Kording; citation_author=U Beierholm; citation_author=WJ Ma; citation_author=S Quartz; citation_author=JB Tenenbaum; citation_number=46; citation_date=2007; " />
      <meta name="citation_reference" content="citation_title=Humans integrate visual and haptic information in a statistically optimal fashion.; citation_author=MO Ernst; citation_author=MS Banks; citation_journal_title=Nature; citation_volume=415; citation_number=47; citation_pages=429-433; citation_date=2002; " />
      <meta name="citation_reference" content="citation_title=Meging the senses into a robust percept.; citation_author=MO Ernst; citation_author=HH Bülthoff; citation_journal_title=Trends in Cognitive Sciences; citation_volume=8; citation_number=48; citation_pages=162-169; citation_date=2004; " />
      <meta name="citation_reference" content="citation_title=Bayesian multisensory integration and cross-modal spatial links.; citation_author=S Denève; citation_author=A Pouget; citation_journal_title=Journal of Physiology Paris; citation_volume=98; citation_number=49; citation_pages=249-258; citation_date=2004; " />
      <meta name="citation_reference" content="citation_title=Perceiving Talking Faces: From Speech Perception to a Behavioral Principle: Mit Pr.; citation_author=DW Massaro; citation_number=50; citation_date=1998; " />
      <meta name="citation_reference" content="citation_title=Integration of proprioceptive and visual position-information: an experimentally supported model.; citation_author=R van Beers; citation_author=A Sittig; citation_author=J Gon; citation_journal_title=Journal of Neurophysiology; citation_volume=81; citation_number=51; citation_pages=1355-1364; citation_date=1999; " />
      <meta name="citation_reference" content="citation_title=Sound-induced flash illusion as an optimal percept.; citation_author=L Shams; citation_author=U Beierholm; citation_journal_title=Neuroreport; citation_volume=16; citation_number=52; citation_pages=1923-1927; citation_date=2005; " />
      <meta name="citation_reference" content="citation_title=The ventriloquist effect results from near-optimal bimodal integration.; citation_author=D Alais; citation_author=D Burr; citation_journal_title=Current Biology; citation_volume=14; citation_number=53; citation_pages=257-262; citation_date=2004; " />
      <meta name="citation_reference" content="citation_title=Perception of the duration of emotional events.; citation_author=S Droit-Volet; citation_author=S Brunot; citation_author=PM Niendenthal; citation_journal_title=Cognition and Emotion; citation_volume=18; citation_number=54; citation_pages=849-858; citation_date=2004; " />
      <meta name="citation_reference" content="citation_title=Decoding temporal information: a modal based on short-term synaptic plasticity.; citation_author=D Buonomano; citation_journal_title=Journal of Neuroscience; citation_volume=20; citation_number=55; citation_pages=1129-1141; citation_date=2000; " />
      <meta name="citation_reference" content="citation_title=Timing in the absence of clocks: encoding time in neural network states.; citation_author=UR Karmarkar; citation_author=DV Buonomano; citation_journal_title=Neuron; citation_volume=53; citation_number=56; citation_pages=427-238; citation_date=2007; " />
      <meta name="citation_reference" content="citation_title=Time dilation in dynamic visual displays.; citation_author=R Kanai; citation_author=CLE Paffen; citation_author=H Hogendoorn; citation_author=FA Verstraten; citation_journal_title=Journal of Vision; citation_number=57; citation_pages=1-10; citation_date=2006; " />
      <meta name="citation_reference" content="citation_title=What is common to brain activity evoked by the perceptio of visual and auditory filled durations? A study with MEG and EEG co-recordings.; citation_author=K N'Diaye; citation_author=R Ragot; citation_author=L Garnero; citation_author=V Pouthas; citation_journal_title=Cognitive Brain Research; citation_volume=21; citation_number=58; citation_pages=250-268; citation_date=2004; " />
      <meta name="citation_reference" content="citation_title=Role of Prefrontal Cortex in Generation of the Contingent Negative Variation.; citation_author=SK Rosahl; citation_author=RT Knight; citation_journal_title=Cerebral Cortex; citation_volume=5; citation_number=59; citation_pages=123-134; citation_date=2002; " />
      <meta name="citation_reference" content="citation_title=Human auditory event-related potentials predict duration judgments.; citation_author=A Bendixen; citation_author=S Grimm; citation_author=E Schröger; citation_journal_title=Neuroscience Letters; citation_volume=383; citation_number=60; citation_pages=284-288; citation_date=2005; " />
      <meta name="citation_reference" content="citation_title=The ‘when’ pathway of the right parietal lobe.; citation_author=L Battelli; citation_author=A Pascual-Leone; citation_author=P Cavanagh; citation_journal_title=Trends in Cognitive Sciences; citation_volume=11; citation_number=61; citation_pages=204-210; citation_date=2007; " />
      <meta name="citation_reference" content="citation_title=Where and when to pay attention: the neural systems for directing attention to spatial locations and to time intervals as revealed by both PET and fMRI.; citation_author=JT Coull; citation_author=AC Nobre; citation_journal_title=Journal of Neuroscience; citation_volume=18; citation_number=62; citation_pages=7426-7435; citation_date=1998; " />
      <meta name="citation_reference" content="citation_title=Functional anatomy of the attentional modulation of time estimation.; citation_author=JT Coull; citation_author=F Vidal; citation_author=B Nazarian; citation_author=F Macar; citation_journal_title=Science; citation_volume=303; citation_number=63; citation_pages=1506-1508; citation_date=2004; " />
      <meta name="citation_reference" content="citation_title=Multisensory intergation for timing engages different brain networks.; citation_author=M Dhamala; citation_author=CG Assisi; citation_author=VK Jirsa; citation_author=FL Steinberg; citation_author=JAS Kelso; citation_journal_title=NeuroImage; citation_volume=34; citation_number=64; citation_pages=764-773; citation_date=2007; " />
      <meta name="citation_reference" content="citation_title=Representation of time by neurons in the posterior parietal cortex of the Macaque.; citation_author=MI Leon; citation_author=MN Shadlen; citation_journal_title=Neuron; citation_volume=38; citation_number=65; citation_pages=317-327; citation_date=2002; " />
      <meta name="citation_reference" content="citation_title=The metamodal organization of the brain.; citation_author=A Pascual-Leone; citation_author=R Hamilton; citation_journal_title=Progress in Brain Research; citation_volume=134; citation_number=66; citation_pages=427-445; citation_date=2001; " />
      <meta name="citation_reference" content="citation_title=Rate of decay of auditory sensation.; citation_author=R Plomp; citation_journal_title=Journal of the Acoustical Society of America; citation_volume=36; citation_number=67; citation_pages=277-282; citation_date=1964; " />
      <meta name="citation_reference" content="citation_title=Detection of temporal gaps in noise as a measure of the decay of auditory sensation.; citation_author=MJ Penner; citation_journal_title=Journal of the Acoustical Society of America; citation_volume=61; citation_number=68; citation_pages=552-557; citation_date=1977; " />
      <meta name="citation_reference" content="citation_title=Resolving multisensory conflict: a strategy for balancing the costs and benefitrs of audio-visual integration.; citation_author=N Roach; citation_author=J Heron; citation_author=P McGraw; citation_journal_title=Proceedings of the Royal Society Biological Sciences; citation_volume=273; citation_number=69; citation_pages=2159-2168; citation_date=2006; " />
      <meta name="citation_reference" content="citation_title=Vision and touch are automatically integrated for the perception of sequences of events.; citation_author=J Bresciani; citation_author=F Dammeier; citation_author=MO Ernst; citation_journal_title=Journal of Vision; citation_volume=6; citation_number=70; citation_pages=554-564; citation_date=2006; " />
      <meta name="citation_reference" content="citation_title=When sound affects vision: effects of auditory grouping on visual motion perception.; citation_author=K Watanabe; citation_author=S Shimojo; citation_journal_title=Journal of Psychological Science; citation_volume=12; citation_number=71; citation_pages=109-116; citation_date=2001; " />
      <meta name="citation_reference" content="citation_title=The Psychophysics Toolbox.; citation_author=D Brainard; citation_journal_title=Spatial Vision; citation_volume=10; citation_number=72; citation_pages=433-436; citation_date=1997; " />
      <meta name="citation_reference" content="citation_title=The VideoToolbox software for visual psychophysics: transforming numbers into movies.; citation_author=D Pelli; citation_journal_title=Spatial Vision; citation_volume=10; citation_number=73; citation_pages=437-442; citation_date=1997; " />
      <meta name="citation_reference" content="citation_title=Duration illusions in a train of visual stimuli.; citation_author=D Rose; citation_author=J Summers; citation_journal_title=Perception; citation_volume=24; citation_number=74; citation_pages=1177-1187; citation_date=1995; " />

  <link rel="canonical" href="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0001437" />

    <meta name="twitter:card" content="summary"/>
    <meta name="twitter:site" content="@plosone"/>
    <meta name="twitter:title" content="Distortions of Subjective Time Perception Within and Across Senses"/>
    <meta name="twitter:description" content="BackgroundThe ability to estimate the passage of time is of fundamental importance for perceptual and cognitive processes. One experience of time is the perception of duration, which is not isomorphic to physical duration and can be distorted by a number of factors. Yet, the critical features generating these perceptual shifts in subjective duration are not understood.Methodology/FindingsWe used prospective duration judgments within and across sensory modalities to examine the effect of stimulus predictability and feature change on the perception of duration. First, we found robust distortions of perceived duration in auditory, visual and auditory-visual presentations despite the predictability of the feature changes in the stimuli. For example, a looming disc embedded in a series of steady discs led to time dilation, whereas a steady disc embedded in a series of looming discs led to time compression. Second, we addressed whether visual (auditory) inputs could alter the perception of duration of auditory (visual) inputs. When participants were presented with incongruent audio-visual stimuli, the perceived duration of auditory events could be shortened or lengthened by the presence of conflicting visual information; however, the perceived duration of visual events was seldom distorted by the presence of auditory information and was never perceived shorter than their actual durations.Conclusions/SignificanceThese results support the existence of multisensory interactions in the perception of duration and, importantly, suggest that vision can modify auditory temporal perception in a pure timing task. Insofar as distortions in subjective duration can neither be accounted for by the unpredictability of an auditory, visual or auditory-visual event, we propose that it is the intrinsic features of the stimulus that critically affect subjective time distortions."/>
      <meta name="twitter:image" content="http://dx.plos.org/10.1371/journal.pone.0001437.g006"/>

  <meta property="og:title" content="Distortions of Subjective Time Perception Within and Across Senses" />
  <meta property="og:type" content="article" />
  <meta property="og:url" content="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0001437" />

 <!--end articleInfoX-->

  <link rel="pingback" href="http://www.plosone.org/pingback" />


  <link rel="shortcut icon" href="/images/favicon.ico" type="image/x-icon"/>
  <link rel="home" title="home" href="/"/>
  <link rel="alternate" type="application/rss+xml"
        title="PLOS ONE: New Articles"
        href="http://www.plosone.org/article/feed"/>
</head>
<body>

  <div id="page-wrap">
    <div id="topbanner" class="cf">

<!-- Div for the ad at the top of journal home page-->
<div class="center">
  <div class="title">Advertisement</div>
  <iframe id='a3ac9da4' name='a3ac9da4'
    src='http://ads.plos.org/www/delivery/afr.php?zoneid=345&amp;cb=3327'
    frameborder='0' scrolling='no' width='730' height='90'>
    <a href='http://ads.plos.org/www/delivery/ck.php?n=a3ac9da4&amp;cb=4762'
      target='_top'><img src='http://ads.plos.org/www/delivery/avw.php?zoneid=345&amp;cb=1680&amp;n=a3ac9da4'
      border='0' alt=''/>
    </a>
  </iframe>
</div>    </div>

    <div id="pagehdr-wrap">
      <div id="pagehdr">
        <div id="user" class="nav">
          <ul>
            <li><a href="http://www.plos.org">plos.org</a></li>
            <li><a href="https://register.plos.org/ambra-registration/register.action">create account</a></li>
            <li class="btn-style"><a
              href="/user/secure/secureRedirect.action?goTo=%2Farticle%2FfetchArticle.action%3FarticleURI%3Dinfo%253Adoi%252F10.1371%252Fjournal.pone.0001437">sign in</a>
            </li>
          </ul>
        </div>
        <div class="logo">
          <a href="/"><img src="/images/logo.png" alt="PLOS ONE"></a>
        </div>

<div id="nav-main" class="nav">
  <ul>
        <li id="mn-01"><a href="/taxonomy" class="areas-link">Subject Areas</a></li>
    <li id="mn-02"><a href="javascript:void(0);">For Authors</a>
      <div class="submenu" style="width: 540px; margin-left: -300px;">
        <div class="block">
          <div class="submit-script">
            <h3>Submit your Manuscript</h3>
            <ul>
              <li>Fair, rigorous peer review</li>
              <li>Broad scope and wide reach</li>
            </ul>
            <a href="/static/submissionInstructions" class="btn">get started</a>
          </div>
        </div>
        <div class="menu">
          <ul>
            <li><a href="/static/publish">Why Publish with PLOS ONE</a></li>
            <li><a href="/static/publication">Publication Criteria</a></li>
            <li><a href="/static/editorial">Editorial Policies</a></li>
            <li><a href="/static/guidelines">Preparing A Manuscript</a></li>
            <li><a href="/static/figureGuidelines">Figure and Table Guidelines</a></li>
          <li><a href="/static/supportingInformation">Supporting Information Guidelines</a></li>
            <li><a href="/static/submissionInstructions">Submitting a Manuscript</a></li>
          </ul>
        </div>
      </div>
    </li>

    <li id="mn-03"><a href="javascript:void(0);">About Us</a>
      <div class="submenu" style="width:248px; margin-left:-30px;">
        <div class="menu">
          <ul>
            <li><a href="/static/information">Journal Information</a></li>
            <li><a href="/static/edboard">Editorial Board</a></li>
            <li><a href="/static/reviewerGuidelines">Reviewer Guidelines</a></li>
            <li><a href="/static/almInfo">Article-Level Metrics</a></li>
            <li><a href="/static/license">Open-Access License</a></li>
            <li><a href="/static/downloads">Media Downloads</a></li>
            <li><a href="/static/commentGuidelines">Guidelines for Comments</a></li>
            <li><a href="/static/corrections">Corrections</a></li>
            <li><a href="/static/help">Help Using this Site</a></li>
            <li><a href="/static/contact">Contact Us</a></li>
          </ul>
        </div>
      </div>
    </li>
  </ul>
<div id="db">
  <form name="searchForm" action="/search/simple?noSearchFlag=true&amp;query=&amp;articleURI=info%3Adoi%2F10.1371%2Fjournal.pone.0001437" method="get" >
<input type="hidden" name="from" value="globalSimpleSearch" id="from"/><input type="hidden" name="filterJournals" value="PLoSONE" id="filterJournals"/>    <fieldset>
      <legend>Search</legend>
      <label for="search">Search</label>
      <div class="wrap">
        <input id="search" type="text" name="query" placeholder="Search">
        <input type="image" alt="SEARCH" src="/images/icon.search.gif">
      </div>
    </fieldset>
  </form>
    <a id="advSearch" href="/search/advanced?noSearchFlag=true&amp;query=&amp;articleURI=info%3Adoi%2F10.1371%2Fjournal.pone.0001437&filterJournals=PLoSONE">advanced search</a>
</div></div>

      </div>
      <!-- pagehdr-->
    </div>
    <!-- pagehdr-wrap -->

  <!--body and html tags gets closed in global_footer.ftl-->
<script type="text/javascript" src="/javascript/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<div id="pagebdy-wrap">
  <div id="pagebdy">

    <div id="article-block" class="cf">

<div class="article-meta cf">
  <ul id="almSignPost" style="display: none;"></ul>
  <div class="article-type">
    <span class="type oa">Open Access</span>
      <span class="type pr">Peer-Reviewed</span>
  </div>
</div>

<div class="header" id="hdr-article">

<div class="article-kicker">
      <span id="article-type-heading">
        Research Article
      </span>
</div>  <h1 property="dc:title" datatype="" rel="dc:type" href="http://purl.org/dc/dcmitype/Text">
    Distortions of Subjective Time Perception Within and Across Senses
  </h1>

  <ul class="authors">
      <li>


        <span rel="dc:creator" class="author">
          <span class="person" property="foaf:name" typeof="foaf:Person">
            Virginie van Wassenhove
              <span class="corresponding">mail</span>, 
          </span>
        </span>

          <div class="author_meta">
            <div class="author_inner">


              
              <p><span class="email">*</span>To whom correspondence should be addressed. E-mail: <a href="mailto:vvw@caltech.edu">vvw@caltech.edu</a></p>

                <p>Affiliation:
                  Division of Biology, California Institute of Technology, Pasadena, California, United States of America
                </p>


              <span class="close">X</span>

            </div>
          </div>
      </li>
      <li>


        <span rel="dc:creator" class="author">
          <span class="person" property="foaf:name" typeof="foaf:Person">
            Dean V. Buonomano, 
          </span>
        </span>

          <div class="author_meta">
            <div class="author_inner">


              
              

                <p>Affiliations:
                  Department of Psychology, University of California at Los Angeles, Los Angeles, California, United States of America, 
                  Department of Neurobiology, University of California at Los Angeles, Los Angeles, California, United States of America
                </p>


              <span class="close">X</span>

            </div>
          </div>
      </li>
      <li>


        <span rel="dc:creator" class="author">
          <span class="person" property="foaf:name" typeof="foaf:Person">
            Shinsuke Shimojo, 
          </span>
        </span>

          <div class="author_meta">
            <div class="author_inner">


              
              

                <p>Affiliation:
                  Division of Biology, California Institute of Technology, Pasadena, California, United States of America
                </p>


              <span class="close">X</span>

            </div>
          </div>
      </li>
      <li>


        <span rel="dc:creator" class="author">
          <span class="person" property="foaf:name" typeof="foaf:Person">
            Ladan Shams
          </span>
        </span>

          <div class="author_meta">
            <div class="author_inner">


              
              

                <p>Affiliation:
                  Department of Psychology, University of California at Los Angeles, Los Angeles, California, United States of America
                </p>


              <span class="close">X</span>

            </div>
          </div>
      </li>
  </ul>
  <ul class="date-doi-line">
    <li>Published: January 16, 2008</li>
    <li>DOI: 10.1371/journal.pone.0001437</li>
  </ul>


</div><!--end header-->
<div class="main cf" id="pjax-container">
  

<div class="nav items-5" id="nav-article">
  <ul>
  <li>
        <span class="active" name="article">Article</span>
  </li>
  <li>
      <a href="/article/authors/info%3Adoi%2F10.1371%2Fjournal.pone.0001437" name="authors">About the Authors</a>
  </li>
  <li>
      <a href="/article/metrics/info%3Adoi%2F10.1371%2Fjournal.pone.0001437" name="metrics">Metrics</a>
  </li>
  <li>
      <a href="/article/comments/info%3Adoi%2F10.1371%2Fjournal.pone.0001437" name="comments">Comments</a>
  </li>
  <li>
      <a href="/article/related/info%3Adoi%2F10.1371%2Fjournal.pone.0001437" name="related">Related Content</a>
  </li>
  </ul>
</div>

<script type="text/javascript">
  var selected_tab = "article";
</script>
  <div id="figure-thmbs" class="carousel cf">
    <div class="wrapper">
      <div class="slider">
              <div class="item">
                <a href="#pone-0001437-g001" data-doi="info:doi/10.1371/journal.pone.0001437" data-uri="info:doi/10.1371/journal.pone.0001437.g001" title="Figure 1">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.g001&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001437-g002" data-doi="info:doi/10.1371/journal.pone.0001437" data-uri="info:doi/10.1371/journal.pone.0001437.g002" title="Figure 2">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.g002&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001437-g003" data-doi="info:doi/10.1371/journal.pone.0001437" data-uri="info:doi/10.1371/journal.pone.0001437.g003" title="Figure 3">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.g003&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001437-g004" data-doi="info:doi/10.1371/journal.pone.0001437" data-uri="info:doi/10.1371/journal.pone.0001437.g004" title="Figure 4">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.g004&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001437-g005" data-doi="info:doi/10.1371/journal.pone.0001437" data-uri="info:doi/10.1371/journal.pone.0001437.g005" title="Figure 5">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.g005&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001437-g006" data-doi="info:doi/10.1371/journal.pone.0001437" data-uri="info:doi/10.1371/journal.pone.0001437.g006" title="Figure 6">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.g006&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
      </div>
    </div>
  </div>

  <div class="nav-col">
    <div class="nav" id="nav-article-page">
      <ul>
        <li class="nav-col-comments"><a href="/article/comments/info%3Adoi%2F10.1371%2Fjournal.pone.0001437">Reader Comments (9)</a></li>
          <li id="nav-figures"><a data-doi="info:doi/10.1371/journal.pone.0001437" >Figures</a></li>
      </ul>
    </div>
  </div>

  <div class="article">







<div class="abstract"><a id="abstract0" name="abstract0" toc="abstract0" title="Abstract"></a><h2>Abstract</h2>
<h3>Background</h3>
<a id="article1.front1.article-meta1.abstract1.sec1.p1" name="article1.front1.article-meta1.abstract1.sec1.p1"></a><p>The ability to estimate the passage of time is of fundamental importance for perceptual and cognitive processes. One experience of time is the perception of duration, which is not isomorphic to physical duration and can be distorted by a number of factors. Yet, the critical features generating these perceptual shifts in subjective duration are not understood.</p>


<h3>Methodology/Findings</h3>
<a id="article1.front1.article-meta1.abstract1.sec2.p1" name="article1.front1.article-meta1.abstract1.sec2.p1"></a><p>We used prospective duration judgments within and across sensory modalities to examine the effect of stimulus predictability and feature change on the perception of duration. First, we found robust distortions of perceived duration in auditory, visual and auditory-visual presentations despite the predictability of the feature changes in the stimuli. For example, a looming disc embedded in a series of steady discs led to time dilation, whereas a steady disc embedded in a series of looming discs led to time compression. Second, we addressed whether visual (auditory) inputs could alter the perception of duration of auditory (visual) inputs. When participants were presented with incongruent audio-visual stimuli, the perceived duration of auditory events could be shortened or lengthened by the presence of conflicting visual information; however, the perceived duration of visual events was seldom distorted by the presence of auditory information and was never perceived shorter than their actual durations.</p>


<h3>Conclusions/Significance</h3>
<a id="article1.front1.article-meta1.abstract1.sec3.p1" name="article1.front1.article-meta1.abstract1.sec3.p1"></a><p>These results support the existence of multisensory interactions in the perception of duration and, importantly, suggest that vision can modify auditory temporal perception in a pure timing task. Insofar as distortions in subjective duration can neither be accounted for by the unpredictability of an auditory, visual or auditory-visual event, we propose that it is the intrinsic features of the stimulus that critically affect subjective time distortions.</p>

</div>


<div class="articleinfo"><p><strong>Citation: </strong>van Wassenhove V, Buonomano DV, Shimojo S, Shams L (2008) Distortions of Subjective Time Perception Within and Across Senses. PLoS ONE 3(1):
          e1437.
            doi:10.1371/journal.pone.0001437</p><p><strong>Academic Editor: </strong>David Eagleman, Baylor College of Medicine, United States of America</p><p><strong>Received:</strong> October 3, 2007; <strong>Accepted:</strong> December 14, 2007; <strong>Published:</strong> January 16, 2008</p><p><strong>Copyright:</strong> © 2008 van Wassenhove et al. This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</p><p><strong>Funding: </strong>HFSP grant (RGP70/2003) to LS and SS. JST.ERATO Shimojo Implicit Brain Function Project to VvW</p><p><strong>Competing interests:</strong> The authors have declared that no competing interests exist.</p></div>





<div id="section1" class="section"><a id="s1" name="s1" toc="s1" title="Introduction"></a><h3>Introduction</h3><a id="article1.body1.sec1.p1" name="article1.body1.sec1.p1"></a><p>Subjective time is not isomorphic to physical time <a href="#pone.0001437-Efron1">[1]</a>: the subjective duration of an event can be systematically overestimated, a phenomenon referred to as “time dilation”, “time subjective expansion” <a href="#pone.0001437-Tse1">[2]</a> or “chronostasis” <a href="#pone.0001437-HodinottHill1">[3]</a>, <a href="#pone.0001437-Yarrow1">[4]</a>. Time dilation was recently proposed to rely on the predictability of the event to be judged: low probability events (i.e. high unpredictability) would be experienced as longer than high probability (i.e. high predictability) events of equal physical duration <a href="#pone.0001437-Tse1">[2]</a>. Distortions of subjective duration have also been reported in different contexts, namely, at the time of saccade <a href="#pone.0001437-Yarrow2">[5]</a>, <a href="#pone.0001437-Morrone1">[6]</a> or during voluntary action <a href="#pone.0001437-Park1">[7]</a>. An extensive literature shows that the duration of an event is not solely experienced on the basis of its temporal properties: attentional, arousal and emotional levels, expectancy and stimulus context can all affect the experience of time <a href="#pone.0001437-James1">[8]</a>, <a href="#pone.0001437-Fraisse1">[9]</a>, <a href="#pone.0001437-Zakay1">[10]</a>. Additionally, the time scale of the stimulus and the task used to measure participants' subjective duration have a bearing on the neural mechanisms involved in temporal processing <a href="#pone.0001437-Pppel1">[11]</a>, <a href="#pone.0001437-Lewis1">[12]</a>, <a href="#pone.0001437-Wittmann1">[13]</a>, <a href="#pone.0001437-Mauk1">[14]</a>. In the milliseconds to seconds range, time is perceived as a ‘subjective present’ (vs. ‘time estimation’) which inherently affects the perceptual structuring of the world <a href="#pone.0001437-Pppel1">[11]</a>, <a href="#pone.0001437-Wittmann1">[13]</a>, <a href="#pone.0001437-Pppel2">[15]</a> and thus provides crucial insights on perception. In a prospective (vs. retrospective) duration task, participants know prior to the experiment that they will report the duration of events, hence focusing the subject on the temporal properties of the stimuli <a href="#pone.0001437-Block1">[16]</a>. Here, we tested duration perception of <em>sub-second</em> range (~500 milliseconds) and highly ‘predictable’ auditory, visual, and auditory-visual events using prospective judgments.</p>
<a id="article1.body1.sec1.p2" name="article1.body1.sec1.p2"></a><p>Earlier studies have shown subjective time distortions in auditory <a href="#pone.0001437-HodinottHill1">[3]</a>, visual <a href="#pone.0001437-Tse1">[2]</a>, <a href="#pone.0001437-Yarrow2">[5]</a>, <a href="#pone.0001437-Morrone1">[6]</a>, <a href="#pone.0001437-Ross1">[17]</a>, <a href="#pone.0001437-Pariyadath1">[18]</a> and tactile <a href="#pone.0001437-Yarrow1">[4]</a>, <a href="#pone.0001437-Park1">[7]</a> sensory modalities but none has yet explored whether stimuli presented in one sensory modality could affect duration judgments in another sensory modality. Investigating cross-modal effects in time perception is crucial for determining whether time processes are centralized or distributed. The observation of time dilation effects in different sensory modalities has been taken as evidence for the existence of a common sensory-independent internal timer in subjective time perception <a href="#pone.0001437-Tse1">[2]</a>, <a href="#pone.0001437-HodinottHill1">[3]</a> but this is only a conjecture since similar results could be obtained if independent timers were to co-exist in each sensory modality. The dominant model of time measurement in the brain is the internal clock model. In its simplest form, an internal clock consists of a pacemaker which generates discrete events at a fixed frequency and an accumulator which counts these events; the resulting count can be compared with a duration stored in memory <a href="#pone.0001437-Wittmann1">[13]</a>, <a href="#pone.0001437-Mauk1">[14]</a>, <a href="#pone.0001437-Allan1">[19]</a>, <a href="#pone.0001437-Treisman1">[20]</a>. In an amodal (sensory-independent or ‘supramodal’) clock model, the experience of time is mediated by a single pacemaker receiving inputs from any sensory modality. In the modality-specific or ‘modal’ view, each sensory modality has its own pacemaker leading to a distributed processing of temporal information<a href="#pone.0001437-Mauk1">[14]</a>, <a href="#pone.0001437-Ivry1">[21]</a> (see <a href="#pone.0001437.s001">Figure S1</a> in Supplementary Material, for a schematic rendering of internal clocks). Studies comparing the perception of duration across sensory modalities have shown that the duration of an auditory interval is often judged as longer than the same interval presented in the visual sensory modality <a href="#pone.0001437-Penney1">[22]</a>, <a href="#pone.0001437-Goldstone1">[23]</a>, <a href="#pone.0001437-Wearden1">[24]</a>. These observations have lead to two specific (but non-exclusive) hypotheses with respect to clock models: (i) the latency of the on/off switch from the pacemaker to the accumulator may be more stable for the auditory than for the visual sensory modality and (ii) the rate of the pacemaker for the auditory inputs may run faster than for the visual ones <a href="#pone.0001437-Wearden1">[24]</a>, <a href="#pone.0001437-Penney2">[25]</a>, <a href="#pone.0001437-DroitVolet1">[26]</a>. However, these inter-sensory differences can also be accounted for by a distributed modal clock (e.g. modality-specific pacemakers and accumulators). The issue of a centralized vs. a distributed timing mechanism is complicated by discrepant findings: the improvements obtained by training participants on an auditory temporal discrimination task generalize to the tactile domain <a href="#pone.0001437-Nagarajan1">[27]</a>, to different frequencies <a href="#pone.0001437-Wright1">[28]</a>, <a href="#pone.0001437-Karmarkar1">[29]</a> and to different temporal tasks <a href="#pone.0001437-vanWassenhove1">[30]</a>. In vision, the perceptual improvements obtained after training on a visual temporal discrimination task transfer across hemispheres <a href="#pone.0001437-Westheimer1">[31]</a>. However, localized distortions of subjective time in vision have also been reported in adaptation experiments <a href="#pone.0001437-Johnston1">[32]</a>, <a href="#pone.0001437-Burr1">[33]</a>. Here, we thus examine the critical variables contributing to shifts in subjective time perception within and across the auditory and visual modalities and explore the notions of input predictability and intersensory interactions in the experience of duration.</p>
<a id="article1.body1.sec1.p3" name="article1.body1.sec1.p3"></a><p>Auditory (A), visual (V), congruent (‘multisensory’) and incongruent (‘intersensory’) auditory-visual (AV) durations were tested in three experiments (see <a href="#pone-0001437-g001">Figure 1</a>). The main paradigm consisted in presenting five consecutive stimuli within a single trial: the standard stimuli (stimuli 1, 2, 3 and 5 in the stream) were 500 ms whereas the fourth stimulus (the target) varied in duration only (control conditions) or in both duration and in feature (test conditions). Participants were instructed prior to the start of each experimental block which sensory modality they should evaluate; each block consisted of either a control or a test condition in the A, V, congruent AV or incongruent AV presentations. In Experiments 1 and 2, the standards were 500 ms steady visual discs and/or auditory pure tones. In Experiment 1 (hereafter referred to as ‘Loom’), the target was a visual looming disc and/or an auditory upward frequency-modulated (FM) sweep whereas in Experiment 2 (‘Recede’), the target was a visual receding disc and/or an auditory downward FM sweep. In Experiment 3 (‘Reverse’), the standards were visual looming discs and/or upward FM sweeps while the target was a steady signal (visual disc and/or auditory pure tone). In all three experiments, intersensory conditions were introduced to test the effect of incongruent AV presentations on duration judgments of a target modality (i.e. A or V). The term ‘intersensory’ will henceforth be used to designate the <em>incongruent</em> conditions. In the ‘auditory intersensory’ conditions, participants reported whether the auditory target was shorter or longer than all other auditory stimuli in the trial; conversely, in the ‘visual intersensory’ conditions, participants judged whether the visual target was shorter or longer than all other visual stimuli in the trial. In the intersensory conditions, the target (always 500 ms in duration) was paired with an oddball (varying in feature and duration) in the modality which was to be ignored. Importantly, the target in the attended sensory modality was identical in all respects to the standards in the same modality. We will first discuss the results of the unisensory (A, V) and congruent multisensory (AV) conditions within each experiment and will then turn onto the results for incongruent presentations (intersensory conditions).</p>
<div class="figure" id="pone-0001437-g001"><div class="img"><a name="pone-0001437-g001" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.g001&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001437" data-uri="info:doi/10.1371/journal.pone.0001437.g001"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.g001&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001437.g001/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001437.g001/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001437.g001/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001437.g001/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001437.g001.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001437.g001/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001437.g001/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001437.g001.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 1.  <span>Experimental design.</span></strong></p><a id="article1.body1.sec1.fig1.caption1.p1" name="article1.body1.sec1.fig1.caption1.p1"></a><p>All Experiments tested unimodal (auditory only, first column, or visual only, second column), multisensory (congruent auditory-visual, third column) and incongruent or intersensory auditory-visual conditions (auditory intersensory, fourth column and visual intersensory fifth column). In the control conditions, the target (4<sup>th</sup> stimulus in a stream of five stimuli) differed from the standards (stimulus 1, 2, 3 and 5; all 500 ms) in duration only. In the test conditions, the target differed from the standards in both feature and duration. In Experiment 1 (‘Loom’, first row) and Experiment 2 (‘Recede’, second row), the same control conditions were used, where standards were 500 ms discs or pure tones in visual and auditory displays, respectively. In the Loom tests, auditory standards were 500 ms pure tones, and auditory targets were upward going FM sweeps of varying duration; visual standards were 500 ms discs and visual targets were looming discs of different duration; auditory and visual conditions were combined in the multisensory condition. In the Recede tests, the target was a downward going FM sweep or a receding disc in the auditory and visual sensory modalities, respectively. In the control of Experiment 3 (‘Reverse’, third row), the auditory standards were upward FM sweeps and the visual standards were 500 ms looming discs. In the Reverse tests, the oddballs were a steady disc and a pure tone of variable duration in visual and auditory displays, respectively. The Loom, Recede and Reverse intersensory conditions consisted in presenting congruent auditory-visual standards but incongruent auditory-visual targets. An oddball was introduced in the sensory modality which was to be ignored. In the auditory intersensory conditions, participants evaluated the auditory target while neglecting visual inputs; conversely, in the visual intersensory conditions, participants evaluated the visual target while ignoring the auditory inputs. In the Loom auditory (first row, fourth column) and visual intersensory (first row, fifth column) conditions, the oddball was a looming disc and an upward FM sweep, respectively. In the Recede auditory (second row, fourth column) and visual intersensory (second row, fifth column) conditions, the oddball was a receding or a downward FM sweep, respectively. In the Reverse auditory (third row, fourth column) and visual intersensory (third row, fifth column) conditions, the oddball was a steady disc or a tone, respectively.</p>
<span>doi:10.1371/journal.pone.0001437.g001</span></div></div>

<div id="section2" class="section"><a id="s2" name="s2" toc="s2" title="Results"></a><h3>Results</h3>
<h4>Subjective time distortions in auditory, visual and congruent (multisensory) audiovisual displays</h4>
<a id="article1.body1.sec2.sec1.p1" name="article1.body1.sec2.sec1.p1"></a><p>First, we tested our experimental design in A, V and congruent AV conditions: on a given trial, the target always occurred in 4<sup>th</sup> position within a stream of four 500 ms standards. There was no element of surprise as to the (temporal or spatial) position of the oddball. Participants judged whether the target was “shorter” or “longer” than all other standards in the trial. In the Loom experiment, targets were looming visual signals and/or upward auditory FM sweeps; in the Recede experiment, targets were visual receding signals and/or downward auditory FM sweeps. In the control conditions, the target solely changed in duration whereas in the test conditions, the target changed in both feature and duration (see <a href="#pone-0001437-g001">Figure 1</a>, first and second row, respectively.)</p>
<a id="article1.body1.sec2.sec1.p2" name="article1.body1.sec2.sec1.p2"></a><p>In Loom, the points of subjective equality were derived from cumulative Gaussian fits of the individuals' percentage of longer responses for each condition (tests and controls in A, V and AV presentations). <a href="#pone.0001437.s002">Figure S2</a> provides an example of an individual's psychometric fits in A, V and AV test and control presentations. The point of subjective equality (PSE) was defined for each individual as the duration corresponding to 50% of “longer” responses. <a href="#pone-0001437-g002">Figure 2</a> provides the grand average of the individual PSE (left-hand side) together with the PSE differences between tests and controls obtained in each sensory modality and in each experiment (right hand-side). In Loom (<a href="#pone-0001437-g002">Figure 2</a>, first row), all three sensory modalities (A, V and AV) showed a significant decrease of PSE in the test conditions as compared to the control conditions. The decrease in PSE signifies that for an equivalent physical duration, a shorter looming (upward FM) signal was judged as longer than a steady disc (pure tone). A 3×2 repeated measures ANOVA with PSE as dependent variable and factors of modality (A, V and AV) and condition (test and control) showed a main effect of condition (F<sub>1, 24</sub> = 21.091, p≤0.0001). No effect of modality (F<sub>2, 48</sub> = 0.939, p = 0.393) or interaction of modality with condition (F<sub>2, 48</sub> = 1.752, p = 0.184) were obtained, suggesting that the decrease of PSE was comparable across uni- and multi-sensory presentations. The temporal dilation effects observed in the Loom experiment were associated with a large effect size as evaluated by Cohen (d) and Hedge's (ĝ) indices (see <a href="#s4">Methods</a> section): d = 0.77 and ĝ = 0.75 in the auditory conditions, d = 1.22 and ĝ = 1.18 in the visual conditions, and d = 0.62 and ĝ = 0.61 in the multisensory conditions.</p>
<div class="figure" id="pone-0001437-g002"><div class="img"><a name="pone-0001437-g002" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.g002&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001437" data-uri="info:doi/10.1371/journal.pone.0001437.g002"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.g002&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001437.g002/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001437.g002/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001437.g002/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001437.g002/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001437.g002.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001437.g002/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001437.g002/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001437.g002.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 2.  <span>Subjective duration distortions in auditory, visual and congruent auditory-visual presentations.</span></strong></p><a id="article1.body1.sec2.sec1.fig1.caption1.p1" name="article1.body1.sec2.sec1.fig1.caption1.p1"></a><p>The points of subjective equality (PSE) were computed from the individuals' psychometric curves obtained in the control and test conditions. On the left hand-side, we report the obtained PSE for each experiment and auditory (blue), visual (green) and auditory-visual (red) conditions. On the right-hand side, we report the difference between the PSE obtained in a given test condition (e.g. visual test) and the PSE obtained in the associated control condition (e.g. visual control). In the relative PSE graphs, a positive shift of PSE indicates ‘subjective time compression’, thereby a given stimulus in the test condition is perceived as shorter than would actually be perceived by the participant in the control condition; conversely, a negative shift in PSE indicates ‘subjective time dilation’. Error bars are standard-errors of the mean. In the Loom experiment (first row), subjective time expansion is systematically observed in auditory (blue bar), visual (green bar) and congruent auditory-visual (red bar) presentations. In the Recede experiment (second row), no significant shift of PSE was observed. In the Reverse experiment (third row), both visual (green) and congruent auditory-visual (red) presentations led to a significant compression of subjective duration. No such effect was observed in the auditory (blue bar) condition. These results highlight both similarities and asymmetries in the distortion of subjective durations across sensory modalities.</p>
<span>doi:10.1371/journal.pone.0001437.g002</span></div><a id="article1.body1.sec2.sec1.p3" name="article1.body1.sec2.sec1.p3"></a><p>This first set of results demonstrates that although participants could predict <em>when</em> and <em>which</em> oddball would occur in each experimental block and in each sensory modality of presentation, a significant subjective time dilation was observed in all conditions. The change in PSE could be due to (i) the predictability of feature changes in the target, (ii) the increased attention to the expected target, or (iii) the intrinsic properties of the stimuli. For instance, the increased perceived brightness (loudness) in the looming visual (auditory) target could relate to the experience of duration: intensity-duration dependency have seldom been studied but noted in both visual <a href="#pone.0001437-Eagleman1">[34]</a> and auditory contexts <a href="#pone.0001437-Olron1">[35]</a>. If such were the case, a stimulus with an identical rate of perceived brightness (loudness) <em>decrease</em> as that used in the looming signals of Experiment 1 should induce a comparable <em>increase</em> of PSE (i.e. a subjective compression of time in the same order of magnitude). This was tested in the Recede experiment, where oddballs were visual receding signals and/or downward auditory FM sweeps. An analysis of PSE similar to that conducted in the Loom experiment is reported in <a href="#pone-0001437-g002">Figure 2b</a>, where no change of PSE was observed. A 3×2 repeated measures ANOVA with PSE as dependent variable and with factors of modality (A, V and AV) and condition (test and control) confirm this observation: neither condition (F<sub>1, 14</sub> = 0.133, p = 0.126), nor modality (F<sub>2, 28</sub> = 2.234, p = 0.721) nor their interaction (F<sub>2, 28</sub> = 1.34, p = 0.278) showed a significant effect.</p>
<a id="article1.body1.sec2.sec1.p4" name="article1.body1.sec2.sec1.p4"></a><p>The results obtained in the Loom and the Recede experiments indicate that although looming and receding signals provide an identical temporal rate with inverse directionality (i.e. increase/decrease in perceived brightness/loudness), they do not yield similar perceptual effects. While the former elicited time dilation in all sensory modalities (A, V and AV), the latter did not induce robust changes of duration. Hence, changes in perceived brightness or loudness cannot solely account for the observed changes in PSE. In contrast, an increase in perceived brightness/loudness may also increase the salience of the stimuli: auditory and visual looming signals are ecologically relevant because they signal approaching objects (and imminent collision) across many species <a href="#pone.0001437-Schiff1">[36]</a>, <a href="#pone.0001437-Maier1">[37]</a>, <a href="#pone.0001437-Ball1">[38]</a>. Looming signals are salient and more attention-grabbing (exogenous attention) than other types of signals including the receding ones that were used here <a href="#pone.0001437-Franconeri1">[39]</a>, <a href="#pone.0001437-Franconeri2">[40]</a>. A decrease in perceived brightness/loudness may thus also decrease the salience of the stimulus, leading the following conflicting result: a change in perceived brightness/loudness may draw attention to the target, while the directionality of the change (here, decrease) may lead to a decrease in the salience of the target. The tension between increased salience due to changing stimuli and the decreased salience due to the directionality of the change may have lead to the null result observed here. We next address whether salient standards such as looming-stimuli would induce a distortion of perceived duration in a steady target. Specifically, we predicted that the PSE to a steady target should increase i.e. that the subjective duration of the steady target embedded in a looming stream would be shortened.</p>


<h4>Induced subjective time compression</h4>
<a id="article1.body1.sec2.sec2.p1" name="article1.body1.sec2.sec2.p1"></a><p>In the Reverse experiment, the standards were looming visual signals and/or upward auditory FM sweeps, whereas the target was a steady visual disc and/or an auditory pure tone (<a href="#pone-0001437-g001">Figure 1</a>, bottom row). As in Experiment 1 and 2, individuals' PSE were computed for each experimental condition. <a href="#pone-0001437-g002">Figure 2</a> (bottom row) reports the grand average absolute PSE (left-hand side) and differences in PSE (right-hand side) for each sensory modality. A 3×2 repeated measures ANOVA with PSE as dependent variable, and with factors of modality (A, V and AV) and condition (test and control) was performed. Main effects of modality (F<sub>2, 34</sub> = 29.697, p≤0.0001), condition (F<sub>1, 17</sub> = 13.241, p≤0.002) and their interaction were found to be significant (F<sub>2, 34</sub> = 7.149, p≤0.003). A paired t-test comparison of PSE between controls and tests showed that whereas a significant increase of PSE was observed in the visual (t<sub>1, 34</sub> = 2.032, p≤0.001) and auditory-visual (t<sub>1, 34</sub> = 2.032, p≤0.0001) conditions, no significant effect was observed in the auditory condition (t<sub>1, 34</sub> = 2.032, p = 0.47). Large effect sizes were observed in the auditory (d = −1.01 and ĝ = −1.35) and auditory-visual (d = −0.69 and ĝ = −0.93) conditions.</p>
<a id="article1.body1.sec2.sec2.p2" name="article1.body1.sec2.sec2.p2"></a><p>Therefore, looming standards lead to the <em>compression</em> of subjective duration of a steady visual and auditory-visual target but not of an auditory target. Under the hypothesis of the salience effect discussed above, the target in the Reverse condition could either be experienced as ‘less salient’ as compared to the looming standards, or ‘more salient’ because it differs from the sequence of standard stimuli. The compression of subjective duration observed in the visual and auditory-visual conditions is more consistent with a <em>decrease</em> in the salience of the visual target induced by an increase of salience in the standards (i.e. looming is more salient than a steady target overall). In the auditory domain however, both decrease and increase in salience may be relevant leading to a null effect.</p>


<h4>Intersensory effects in experiencing duration</h4>
<a id="article1.body1.sec2.sec3.p1" name="article1.body1.sec2.sec3.p1"></a><p>Thus far, we reported results in which the auditory and visual sensory modalities were tested separately or in congruent conditions i.e. when both modalities conveyed congruent temporal and feature information. Next, we examine the intersensory conditions, in which auditory and visual signals convey conflicting temporal and/or feature information. In these intersensory tasks, the standards (500 ms) and the targets were always co-occurring AV stimuli (<a href="#pone-0001437-g001">Figure 1</a>, fourth and fifth columns). In the Loom intersensory conditions (<a href="#pone-0001437-g001">Figure 1</a>, first row), the auditory (visual) target remained identical to the standard auditory (visual) stimuli (500 ms tone or steady disc) but was paired with a looming visual disc (upward auditory FM sweep) of variable duration. In the Recede experiment (<a href="#pone-0001437-g001">Figure 1</a>, second row), the auditory (visual) target was paired with a receding disc (downward FM sweep). In the Reverse experiment (<a href="#pone-0001437-g001">Figure 1</a>, third row), the auditory (visual) target was paired with a steady disc (tone) of variable duration. The results for all three experiments are now grouped as a function of the intersensory condition of interest, namely, the effect of audition on visual duration (visual intersensory tasks, ‘AVv’) and the effect of vision on auditory duration (auditory intersensory tasks, ‘AVa’).</p>
<h5>Visual intersensory conditions: auditory duration seldom captures visual duration.</h5><a id="article1.body1.sec2.sec3.sec1.p1" name="article1.body1.sec2.sec3.sec1.p1"></a><p>The PSE quantification obtained in the visual intersensory conditions are reported in <a href="#pone-0001437-g003">Figure 3</a>: the absolute PSE are reported in the second column and the relative PSE, in the fourth column. In the Loom experiment (<a href="#pone-0001437-g003">Figure 3</a>, first row), the PSE obtained in the visual intersensory condition (second and fourth column) did not significantly differ from the visual control (green) or the auditory test (blue) conditions. No significant difference was observed between the PSE obtained in the visual intersensory condition and the AV test (red) or control (orange) conditions. Thus, the looming auditory event did not induce temporal dilation of visual duration in this task, which is particularly surprising given the robustness of subjective duration dilation observed in the auditory alone condition. In the Recede experiment (<a href="#pone-0001437-g003">Figure 3</a>, second row), a similar profile is observed (second and fourth column): auditory information does not significantly shift the visual PSE when compared to the visual control condition (green) and the multisensory test and control conditions (red and orange, respectively). This result is consistent with the lack of time distortion observed in the A, V and congruent AV conditions. In the Reverse experiment (<a href="#pone-0001437-g003">Figure 3</a>, bottom row), the PSE obtained in the visual intersensory condition show a significant time dilation effect with respect to the visual control condition (green) (t<sub>1,20</sub> = 2.085, p≤0.01; effect sizes: d = −0.43 and ĝ = −1.15) and the multisensory test (red, t<sub>1,20</sub> = 2.085, p≤0.009; effect sizes: d = −0.43 and ĝ = −1.18.)</p>
<div class="figure" id="pone-0001437-g003"><div class="img"><a name="pone-0001437-g003" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.g003&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001437" data-uri="info:doi/10.1371/journal.pone.0001437.g003"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.g003&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001437.g003/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001437.g003/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001437.g003/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001437.g003/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001437.g003.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001437.g003/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001437.g003/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001437.g003.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 3.  <span>Subjective duration distortions in intersensory conditions (incongruent auditory-visual presentations).</span></strong></p><a id="article1.body1.sec2.sec3.sec1.fig1.caption1.p1" name="article1.body1.sec2.sec3.sec1.fig1.caption1.p1"></a><p>The PSE for the auditory (blue) intersensory conditions and the visual (green) intersensory conditions and their relevant control conditions (gray) are reported in the left panel as ‘absolute PSE’. The PSE differences between the intersensory conditions and their possible controls are reported in the right panels as ‘Relative PSE’. The corrected t-tests values are reported in the adjacent table for auditory and visual intersensory conditions in all three Experiments. The PSE obtained in a given intersensory (e.g. auditory intersensory) condition could be compared with (i) the auditory control (Ac), (ii) the visual test (V), (iii) the auditory-visual test (AV) or (iii) the auditory-visual control (AVc). A positive shift of PSE indicates ‘subjective time compression’ and a negative shift in PSE indicates ‘subjective time expansion’. Error bars are standard-errors of the mean. In Loom (first row), subjective time expansion is observed in the auditory intersensory condition when compared to the unisensory presentations (Ac, blue and V, green) and the congruent AV test (red); in the visual intersensory condition, no effect was observed suggesting that vision captures auditory duration but not the opposite. In Recede (second row), no significant intersensory effects were observed in either auditory or visual intersensory conditions. In Reverse (third row), the visual oddball captures auditory duration towards compression (blue bar) whereas the auditory oddball captures visual duration towards expansion (green bar). The auditory intersensory condition significantly differed from Ac, AV and AVc; the visual intersensory condition significantly differed from Vc and AV. These results provide evidence that visual information influences auditory temporal perception, but that the converse is surprisingly seldom observed.</p>
<span>doi:10.1371/journal.pone.0001437.g003</span></div><a id="article1.body1.sec2.sec3.sec1.p2" name="article1.body1.sec2.sec3.sec1.p2"></a><p>Altogether in the visual intersensory conditions, auditory information captures subjective visual duration only in the Reverse experiment. This result is intriguing considering (i) that no distortion in duration was observed in the Reverse auditory test for a steady target and (ii) that the direction of PSE shift would be expected to be towards duration compression. One possible explanation is that even though participants were instructed to ignore the sound, they could not ignore it. Judging visual duration while paying attention to the sound may have caused a <em>contrast effect</em> across sensory modalities resulting in the dilation of perceived visual duration in the Reverse condition. However, it is unclear why a contrast effect would selectively operate in the Reverse condition but not, for instance, in the intersensory Loom condition.</p>

<h5>Auditory intersensory conditions: visual capture of subjective auditory duration.</h5><a id="article1.body1.sec2.sec3.sec2.p1" name="article1.body1.sec2.sec3.sec2.p1"></a><p>In the Loom experiment (<a href="#pone-0001437-g003">Figure 3</a>, first row), a significant negative shift of PSE in the intersensory auditory condition was observed when compared to the auditory control (t<sub>1,11</sub> = 2.08, p≤0.0003; d = −0.58 and ĝ = −1.58), the multisensory test (t<sub>1,10</sub> = 2.1, p≤0.01; d = −0.4 and ĝ = −1.17 ) and the multisensory control (t<sub>1,11</sub> = 2.08, p≤0.001; d = −0.54 and ĝ = −1.48) conditions. Visual inputs capture auditory duration with time dilation. In the Recede experiment (<a href="#pone-0001437-g003">Figure 3b</a>, blue bar), no significant shift of auditory intersensory PSE was observed as compared to the control condition (t<sub>1,10</sub> = 2.1, p = 0.96). Here, a visual receding signal does <em>not</em> alter the auditory point of subjective equality. This result is again consistent with the lack of temporal distortion obtained in the V, A, and congruent AV conditions. In the Reverse experiment (<a href="#pone-0001437-g003">Figure 3c</a>, blue bar), a visual oddball affected subjective auditory duration with a significant positive change of PSE when compared to the auditory control (t<sub>1,12</sub> = 2.07, p≤0.0001; d = 0.63 and ĝ = 1.84), the multisensory test (t<sub>1,12</sub> = 2.18, p≤0.01; d = 0.57 and ĝ = 1.52) and the multisensory control (t<sub>1,18</sub> = 2.1, p≤0.001; d = 0.6 and ĝ = 1.62). In the Reverse Experiment, time compression is induced in the auditory modality via visual presentation but no time compression was observed for the auditory alone condition. Further discussion of this effect is provided in the next section.</p>



<h4>Auditory-visual integration and perceived duration</h4>
<a id="article1.body1.sec2.sec4.p1" name="article1.body1.sec2.sec4.p1"></a><p>The ‘modality appropriateness hypothesis’ <a href="#pone.0001437-Welch1">[41]</a> has long proposed that the more precise modality dominates the integration of a multisensory event: audition has often been referred to as the dominant channel in temporal tasks <a href="#pone.0001437-Gebhard1">[42]</a>, <a href="#pone.0001437-Shipley1">[43]</a>, <a href="#pone.0001437-Recanzone1">[44]</a> and visual timing has been suggested to be encoded in an auditory form <a href="#pone.0001437-Guttman1">[45]</a>. While providing a useful theoretical framework for multisensory integration, the modality appropriateness hypothesis does not provide a quantitative account of multisensory perceptual effects. More recently, Bayesian models have successfully accounted for multisensory integration in a variety of contexts <a href="#pone.0001437-Kording1">[46]</a>, <a href="#pone.0001437-Ernst1">[47]</a>, <a href="#pone.0001437-Ernst2">[48]</a>, <a href="#pone.0001437-Denve1">[49]</a>, <a href="#pone.0001437-Massaro1">[50]</a>. We here compare the predictions of a traditional model of multisensory integration <a href="#pone.0001437-Ernst1">[47]</a>, <a href="#pone.0001437-vanBeers1">[51]</a> with our data on the perception of multi- and inter-sensory AV durations. We refer to this model as “forced-fusion” as it assumes that the signals of the different sensory modalities are always completely fused into a single percept (see <a href="#pone.0001437-Kording1">[46]</a>, <a href="#pone.0001437-Shams1">[52]</a> for discussion). In order to compare the observed data with the predictions of the traditional forced-fusion model, we used a method similar to the one described by Alais and Burr <a href="#pone.0001437-Alais1">[53]</a>. In <a href="#pone-0001437-g004">Figure 4</a>, we report the predicted PSE in the multisensory (congruent) or intersensory (incongruent) AV conditions (black bars) based on the independent combination of the PSE obtained in each sensory modality (A and V alone) and in each condition (control or test), and the estimated weight of each sensory modality. The red bars denote the observed PSE in each experiment. The outcomes of two-tailed paired t-tests between the predicted and observed measures across participants are reported in the table of <a href="#pone-0001437-g004">Figure 4</a>. As can be seen, the forced-fusion model predicted the observed data well when auditory and visual stimuli were congruent i.e. in the multisensory conditions. However, this model failed half of the time in predicting the direction of PSE shift when auditory and visual durations were incongruent, in particular under the auditory intersensory conditions of the Loom (t<sub>1,16</sub> = 2.1, p≤0.008) and Reverse (t<sub>1,20</sub> = 2.08, p≤0.001) experiments. In the auditory alone condition of the Reverse experiment, no distortion of subjective duration was found, yet the presentation of incongruent visual information during the auditory presentation compressed the perception of auditory duration. This finding cannot be accounted for by a forced-fusion model. Additional comparisons between the model predictions and the observed variance of the multisensory and intersensory conditions are provided in <a href="#pone.0001437.s003">Figure S3</a>. Note that all observed variances are reported in <a href="#pone-0001437-g005">Figure 5</a> and <a href="#pone-0001437-g006">6</a>. In <a href="#pone.0001437.s003">Figure S3</a>, we report the comparisons between the observed and the predicted variances in multi- and inter-sensory conditions. While the model accounts well for the observed variance in the multisensory conditions, it largely underestimates the variance observed in the intersensory conditions - with the exception of the Reverse visual intersensory condition.</p>
<div class="figure" id="pone-0001437-g004"><div class="img"><a name="pone-0001437-g004" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.g004&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001437" data-uri="info:doi/10.1371/journal.pone.0001437.g004"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.g004&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001437.g004/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001437.g004/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001437.g004/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001437.g004/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001437.g004.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001437.g004/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001437.g004/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001437.g004.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 4.  <span>Forced-fusion model: comparison between predicted and observed PSE in congruent and incongruent auditory-visual presentations.</span></strong></p><a id="article1.body1.sec2.sec4.fig1.caption1.p1" name="article1.body1.sec2.sec4.fig1.caption1.p1"></a><p>In each graph, the black bars indicate the “estimated”, and the red bar, the “observed” PSE. The adjacent table reports the results of paired t-tests between predicted and observed PSE. In the congruent AV presentations (left column) and for all three experiments, the predictions of the forced-fusion Bayesian model did not significantly differ from the observed PSE. In the incongruent conditions (right column), the model fails to predict the perceptual outcomes observed in the auditory intersensory conditions of the Loom and the Reverse experiments. Additional comparisons between predicted and observed variances in these conditions are provided as Supplementary Material in <a href="#pone.0001437.s003">Figure S3</a>.</p>
<span>doi:10.1371/journal.pone.0001437.g004</span></div><div class="figure" id="pone-0001437-g005"><div class="img"><a name="pone-0001437-g005" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.g005&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001437" data-uri="info:doi/10.1371/journal.pone.0001437.g005"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.g005&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001437.g005/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001437.g005/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001437.g005/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001437.g005/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001437.g005.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001437.g005/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001437.g005/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001437.g005.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 5.  <span>Variance in uni- and multi-sensory observed data.</span></strong></p><a id="article1.body1.sec2.sec4.fig2.caption1.p1" name="article1.body1.sec2.sec4.fig2.caption1.p1"></a><p>We report the variance for the tests (gray) and controls (black) of the auditory, visual and auditory-visual conditions in the Loom (top row), Recede (middle row) and Reverse (bottom row) experiments. No significant differences of variance were observed between tests and controls within each modality of presentation. Bars indicate standard-errors of the mean.</p>
<span>doi:10.1371/journal.pone.0001437.g005</span></div><div class="figure" id="pone-0001437-g006"><div class="img"><a name="pone-0001437-g006" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.g006&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001437" data-uri="info:doi/10.1371/journal.pone.0001437.g006"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.g006&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001437.g006/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001437.g006/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001437.g006/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001437.g006/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001437.g006.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001437.g006/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001437.g006/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001437.g006.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 6.  <span>Variance in intersensory observed data.</span></strong></p><a id="article1.body1.sec2.sec4.fig3.caption1.p1" name="article1.body1.sec2.sec4.fig3.caption1.p1"></a><p>Variance for the auditory intersensory (blue, left column) and visual intersensory (green, right column) conditions are reported along with their respective control conditions (gray) in each experiment. The tables indicate the significant variance effects between the test and possible control conditions. A significant increase of variance was observed in the auditory intersensory conditions with respect to variance in auditory control, visual test, multisensory control and test conditions in all Experiments to the exception of the visual test in the Reverse condition. A significant increase of variance was observed in the visual intersensory conditions of the Loom and Recede experiments with respect to the auditory, multisensory test and control. In all experiments, no difference was observed between the visual intersensory and the visual control conditions and all possible control conditions in the Reverse experiment. Bars indicate standard-errors of the mean.</p>
<span>doi:10.1371/journal.pone.0001437.g006</span></div><a id="article1.body1.sec2.sec4.p2" name="article1.body1.sec2.sec4.p2"></a><p>In the visual intersensory condition, we observed no significant difference of PSE between the auditory control and the visual intersensory condition (leading to a significant dilation of duration). One possible explanation for this result is the observation that the absolute auditory control PSE in the Reverse conditions is significantly smaller than those observed in the visual control condition (t<sub>1,22</sub> = 2.07, p≤0.001) (see <a href="#pone-0001437-g002">Figure 2</a>, bottom row). This comparison is in line with prior observations suggesting that for the same physical duration, the auditory is judged as longer than the visual stimulus <a href="#pone.0001437-Wearden1">[24]</a>. In the intersensory presentation then, the auditory stimulus captures the duration of the visual stimuli. The result for this condition is consistent with (i) no variance change in visual intersensory condition (<a href="#pone-0001437-g005">Figure 5</a>) and (ii) the model prediction of the PSE change (<a href="#pone-0001437-g004">Figure 4</a>). In the auditory intersensory condition, a compression of duration was observed and as can be seen in <a href="#pone-0001437-g006">Figure 6</a>, an increase of variance was observed that did not significantly differ from that observed in the visual test condition. In this case, the forced-fusion model does not predict the change of PSE (<a href="#pone-0001437-g004">Figure 4</a>) nor the increase in variance (<a href="#pone.0001437.s003">Figure S3</a>). Both auditory and visual intersensory conditions of the Reverse experiment illustrate cases of intersensory captures in duration judgment. In the auditory intersensory case, the less variable sensory modality is not the most influential in the decision process, suggesting that some other factors may be at work. One possible explanation would be the existence of a multisensory contrast effect in which conflicting duration information presented in two sensory modalities is magnified when reporting the perceived duration of only one sensory modality. This hypothesis will require further testing as it is not entirely consistent with the results observed in the Loom condition. Altogether, these results show that at the time scale of a few hundreds of milliseconds, the temporal cues provided in the visual channel can compromise the temporal experience of an auditory event and that the auditory sensory modality may not always be the privileged channel in the experience of duration.</p>

</div>

<div id="section3" class="section"><a id="s3" name="s3" toc="s3" title="Discussion"></a><h3>Discussion</h3><a id="article1.body1.sec3.p1" name="article1.body1.sec3.p1"></a><p>Subjective time dilation was consistently found in auditory, visual and auditory-visual presentations for a visual stimulus increasing in size, and an auditory event increasing in frequency (Loom experiment). These results establish that the subjective dilation of perceived duration occurs even when the target is predicted and expected. Second, a decrease in visual size and auditory frequency (Recede experiment) did not lead to significant distortions of subjective time, suggesting that orienting attention to the duration of the odd stimulus is not necessary to produce a subjective expansion of time; rather, the very fact that subjective time dilation was selective to the looming signals suggest that the salience of these stimuli is a major feature in the subjective experience of time. In the Reverse experiment (looming standards, steady target), we observed a robust compression of subjective duration in visual and auditory-visual but not in auditory presentations; these results further highlight the role of <em>contextual salience</em> in the experience of time, at least in vision. Here, the degree to which a target is salient may be a combination of (i) the ecological value of a stimulus (e.g. looming equals ‘approaching object’) and (ii) the temporal context within which the stimulus is embedded. If oddball-ness was the sole factor in orienting attention to the target, a dilation of subjective duration should always be observed in our conditions because the target always differed from the standards in features and/or duration; this is not what we observed in the Recede and Reverse experiments, suggesting that it is the salience of the target that matters. With respect to multisensory integration in duration perception, our results show asymmetries within and across sensory modalities. Visual inputs robustly lengthened and shortened the experience of duration in audition (Loom and Reverse experiments, respectively) whereas auditory inputs seldom lengthened visual subjective duration (Reverse experiment). The influence of vision on the subjective duration of auditory events is not straightforwardly accounted by a ‘forced-fusion’ model of multisensory integration as will be discussed below.</p>
<a id="article1.body1.sec3.p2" name="article1.body1.sec3.p2"></a><p>In the current experiments, the target was always presented in 4<sup>th</sup> position and at the same location in the stream of standard events. In the test blocks, the probability of a feature change in the target was also constant across trials (i.e. equal to one), leaving the duration as the sole unpredictable variable. Nevertheless, our data show a robust dilation of subjective time which replicates prior studies that have used unpredictable targets <a href="#pone.0001437-Tse1">[2]</a>. In internal clock models, prospective duration tasks have been proposed to rely heavily on attentional resources <a href="#pone.0001437-Block1">[16]</a>: the participant's state of arousal affects the <em>rate</em> of the pacemaker(s) whereas attention affects the <em>latency</em> of the switch to the accumulator i.e. the onset of the time keeper <a href="#pone.0001437-Penney1">[22]</a>. Therefore, a shift of attention to a target stimulus could lead to an early opening of the switch, in turn leading to a lengthening of the experienced duration (see <a href="#pone.0001437.s001">Figure S1</a>). Other studies have suggested that the auditory switch may be more stable than the visual switch <a href="#pone.0001437-Wearden1">[24]</a>, which would lead to greater variability in visual time keeping than in auditory time keeping <a href="#pone.0001437-Nagarajan1">[27]</a>. Our analyses of variance (<a href="#pone-0001437-g004">Figure 4</a> and <a href="#pone-0001437-g005">5</a>) show a tendency for visual conditions to be of equal or more variability than the auditory conditions, supporting the notion that auditory and visual time keeping mechanisms are not entirely shared and ultimately, that sensory-specific properties are preserved in the extraction of temporal cues. Under the accumulator/switch framework, the distortions of time we observed could thus be interpreted as follows: dilation and compression of subjective duration entails a faster and slower rate of the pacemaker, and/or a shorter and longer latency of the switch, respectively. While reasonably fitting the looming (‘arousing’ stimulus) and the receding (‘non-arousing’) data, the problem emerges for the results obtained in the Reverse experiment and in particular, it is unclear why (i) a non-arousing steady stimulus would lead to compression in vision but not in audition, and (ii) why a shift of attention would occur much later in vision than in audition. Additionally, the observed variability in the auditory intersensory judgments is superior to that of the visual intersensory judgments (<a href="#pone-0001437-g006">Figure 6</a>). Under the accumulator/switch framework, one would needs to posit that visual (auditory) inputs can change the latency of the auditory (visual) switch or the rate of the auditory (visual) pacemaker to explain these changes in variability. Our data are thus difficult to interpret within this framework, and offer new challenges for the internal clock model.</p>
<a id="article1.body1.sec3.p3" name="article1.body1.sec3.p3"></a><p>Numerous stimulus attributes can clearly affect duration estimation <a href="#pone.0001437-Tse1">[2]</a>–<a href="#pone.0001437-Mauk1">[14]</a>. Here, our goal was to minimize the effect of attentional orienting by providing consistent trials within which one main factor would vary, namely, the properties of the target in feature or duration space. An attentional account for the dilation of subjective time was previously formulated by Tse and colleagues <a href="#pone.0001437-Tse1">[2]</a>. Here, we refine this suggestion by showing that the salience of a target with respect to a stream of standard events - independently of whether the target is expected or not - is a determining factor for subjective distortions of time perception. Here, it is argued that the unpredictability of a target is unnecessary for temporal distortions but that it is nevertheless likely to influence time perception. For instance, in our Receding experiment, we observed no temporal distortion in contrast to the temporal dilation reported by Tse and colleagues <a href="#pone.0001437-Tse1">[2]</a> for a similar stimulus configuration. Again, a major difference between the two experiments is that of the uncertainty of the target. In <a href="#pone.0001437-Tse1">[2]</a>, the receding stimulus is unpredictable and the dilation effect may be accounted for by its unpredictability; when this uncertainty is removed as in our Receding experiment, this stimulus does not induce time dilation. Additionally, when participants were asked to respond to all stimuli in the train (see Experiment 7 in <a href="#pone.0001437-Tse1">[2]</a>) the overall temporal dilation effect diminished suggesting a role for task-dependent attentional orientation in their experiments. One possibility is that uncertainty is a dominant factor relative to the salience of the stimulus in time dilation but when the unpredictability of the stimulus is removed, it is the sensory features that prevail, leading to different pattern of temporal distortion including time compression (see our Reverse Experiment). This interpretation converges with a recent study looking at the effect of stimulus predictability on duration judgments <a href="#pone.0001437-Pariyadath1">[18]</a>. An additional component is the potential contribution of emotional valence as looming stimuli are ‘threat’ signals (i.e. negative emotional valence) <a href="#pone.0001437-Schiff1">[36]</a>. Faces with a strong emotional valence have been shown to increase the perceived duration of the face presentation <a href="#pone.0001437-DroitVolet2">[54]</a> although no duration dilation was found when comparing an arousing stimulus to a neutral stimulus in an oddball paradigm <a href="#pone.0001437-Pariyadath1">[18]</a>. In one experiment, Tse et al. <a href="#pone.0001437-Tse1">[2]</a> used mannequin figures and showed an overall smaller temporal dilation for these stimuli. Among those stimuli that were less predictable, they showed larger temporal dilation effects, suggesting that there is an interaction between the ecological relevance (or the ‘semantics’ <a href="#pone.0001437-Tse1">[2]</a>) of the stimuli and their probability of occurrence.</p>
<a id="article1.body1.sec3.p4" name="article1.body1.sec3.p4"></a><p>Although our results do not directly address the neural mechanisms involved in subjective time perception, they are parsimonious with the notion that temporal processes below the second range are not centralized but are an inherent property of cortical networks <a href="#pone.0001437-Buonomano1">[55]</a>, <a href="#pone.0001437-Karmarkar2">[56]</a>. Traditional clock models do not differentiate (or seldom address the difference) between the supra- and sub-second range durations <a href="#pone.0001437-Mauk1">[14]</a> but the hypothesis that temporal cues can be extracted locally - i.e. early in the hierarchy of the analytical sensory pathways - is more consistent with a sub-second range temporal processing model <a href="#pone.0001437-Karmarkar2">[56]</a>. For short durations, recent findings indicate that the extraction of temporal cues such as visual temporal frequency is spatially confined <a href="#pone.0001437-Karmarkar1">[29]</a>, <a href="#pone.0001437-Johnston1">[32]</a>, <a href="#pone.0001437-Burr1">[33]</a>, <a href="#pone.0001437-Karmarkar2">[56]</a>, <a href="#pone.0001437-Kanai1">[57]</a>. Such results have led to the hypothesis that temporal processing could occur as early as V1, and that the neural mechanisms underlying time processing could be local <a href="#pone.0001437-Johnston1">[32]</a>, <a href="#pone.0001437-Burr1">[33]</a>, <a href="#pone.0001437-Kanai1">[57]</a>.</p>
<a id="article1.body1.sec3.p5" name="article1.body1.sec3.p5"></a><p>A recent study comparing auditory and visual filled duration judgments and using combined magneto- and electro-encephalographic recordings shows an intricate pattern of transient and sustained activity in both sensory and non-sensory specific cortical areas <a href="#pone.0001437-NDiaye1">[58]</a>. Of particular interest, the authors report sensory-specific sustained responses which share the same cortical sources as the early sensory-specific transient responses. The authors also report a contingent-negative variation (CNV) which was independent of sensory modality, whose sources originated in a fronto-parietal network and which was concurrent with the sensory-specific sustained responses. These results suggest parallel ongoing temporal processing in sensory-specific pathways together with a component associated with the retention of information and working memory <a href="#pone.0001437-Rosahl1">[59]</a>. Other EEG studies also point out to an early differentiation of sensory-specific components that are tied to the duration of the stimuli with respect to the standards <a href="#pone.0001437-Bendixen1">[60]</a>, further indicating local processing of temporal cues. Additionally, parietal areas (in particular, the right Inferior Parietal Lobule or IPL) have recently been argued to be part of a ‘when’ pathway <a href="#pone.0001437-Battelli1">[61]</a> and activation of the IPL has indeed been reported during attentional orientation to time <a href="#pone.0001437-Coull1">[62]</a>, <a href="#pone.0001437-Coull2">[63]</a> and multisensory temporal tasks <a href="#pone.0001437-Dhamala1">[64]</a>. Neurons in parietal areas show time-dependent firing properties <a href="#pone.0001437-Leon1">[65]</a> which converge with the notion that time may be encoded in a state-dependent network <a href="#pone.0001437-Karmarkar2">[56]</a>. The IPL has also been categorized as a ‘metamodal’ (or amodal) area <a href="#pone.0001437-PascualLeone1">[66]</a>, providing a potentially crucial cortical area for the interactions of auditory and visual durations observed here.</p>
<a id="article1.body1.sec3.p6" name="article1.body1.sec3.p6"></a><p>With respect to the novel multisensory and intersensory effects reported here, the “modality appropriateness hypothesis” <a href="#pone.0001437-Welch1">[41]</a> argues that the most precise modality contributes most to the formation of a multisensory percept. Specifically, the temporal and spatial dimension would be dominated by the auditory and the visual sensory modalities, respectively. However, the assignment of sensory dominance may not always follow this strict dichotomy. The underlying assumption of the “modality appropriateness hypothesis” is that auditory temporal resolution is more precise than that of the visual modality. This assumption is based on prior studies of auditory-visual synchrony <a href="#pone.0001437-Gebhard1">[42]</a>, <a href="#pone.0001437-Shipley1">[43]</a>, <a href="#pone.0001437-Recanzone1">[44]</a>, but temporal simultaneity judgments do not entail the involvement of the temporal processing system in which the analysis of the time that has elapsed is needed <a href="#pone.0001437-Wittmann1">[13]</a>, <a href="#pone.0001437-Ivry1">[21]</a>. Time perception encompasses many processing levels (from the sub-second to years) that engage different brain mechanisms <a href="#pone.0001437-Pppel1">[11]</a>, <a href="#pone.0001437-Lewis1">[12]</a>, <a href="#pone.0001437-Wittmann1">[13]</a>, <a href="#pone.0001437-Mauk1">[14]</a>, <a href="#pone.0001437-Pppel2">[15]</a>. In synchrony studies (a scale of a few to tens of milliseconds) the auditory modality is likely to be more reliable than vision, with temporal rates of integration as fine as a couple of milliseconds <a href="#pone.0001437-Plomp1">[67]</a>, <a href="#pone.0001437-Penner1">[68]</a>. However, dynamic visual stimuli bear better temporal resolution than static ones <a href="#pone.0001437-Westheimer1">[31]</a> suggesting that dynamic visual events may have a comparable temporal resolution to that of auditory stimuli (e.g. temporal frequency in the 4–8Hz range has been defined as the limiting temporal factor in vision <a href="#pone.0001437-Kanai1">[57]</a>). Our data show that audition may not always be the dominant channel for temporal information. The pattern of multisensory interactions found in this study appears inconsistent with the traditional forced-fusion model of multisensory integration: (i) the intersensory effects and (ii) the variance observed in both multi- and inter-sensory conditions are not well predicted by the model, suggesting that some stimuli properties need to be incorporated in the model (for instance, as priors). Future studies should investigate alternative models of multisensory perception <a href="#pone.0001437-Kording1">[46]</a>, <a href="#pone.0001437-Roach1">[69]</a>, <a href="#pone.0001437-Bresciani1">[70]</a> to examine whether models that do not <em>a priori</em> assume integration across sensory modalities can better account for multisensory interactions in time perception. Our results further suggest that duration judgments depend on the salience of the stimuli and not solely on the temporal cues afforded by each sensory modality. Previous studies have shown that contextual salience could alter visual perception when embedded in an auditory-visual context <a href="#pone.0001437-Watanabe1">[71]</a>. In the intersensory conditions, additional contextual cues may alter the duration of perception when combined across sensory modalities. In the Reverse auditory and visual intersensory conditions, opposite effects were found that could indicate a contrast mechanism in the estimation of duration between the two sensory modalities. In multisensory context then, a systematic mapping of unisensory <em>and</em> multisensory salience may help understand the specific contribution of each sensory modality to the representation of duration.</p>
<a id="article1.body1.sec3.p7" name="article1.body1.sec3.p7"></a><p>In summary, distortions in subjective temporal perception were found in auditory, visual and auditory-visual domains. The dilation and compression of subjective time were observed despite the predictability about <em>when</em> and <em>which</em> oddball would occur. The characteristics of distortion in subjective duration showed asymmetries across sensory modalities: vision captured audition in the experience of time while audition seldom influenced visual subjective duration. The pattern of results reported here is difficult to reconcile with our current understanding of duration perception and classic model of multisensory integration. Nevertheless, our results indicate that on a sub-second time scale, unpredictability is not the only factor that can produce shifts in subjective duration. We thus suggest that the contextual salience of the stimuli is a critical factor for the perception of duration at this time-scale, a feature that could be incorporated in models of multisensory and time perception.</p>
</div>

<div id="section4" class="section"><a id="s4" name="s4" toc="s4" title="Materials and Methods"></a><h3>Materials and Methods</h3>
<h4>Participants</h4>
<a id="article1.body1.sec4.sec1.p1" name="article1.body1.sec4.sec1.p1"></a><p>A total of fifty-nine participants (34 females, mean age 22.1 years) took part in the study. Twenty-five participants (16 females, mean age 20.6 years) took part in Experiment 1, fourteen of whom were also tested on the intersensory conditions of Experiment 1. Fifteen participants (7 females, mean age 26.4 years) completed Experiment 2, and eighteen participants (8 females, mean age 20.7 years) completed Experiment 3. All participants were naïve to the purpose of the study and participated in only one experiment. All experiments were run in accordance with the University of California Human subjects guidelines and the Declaration of Helsinki.</p>


<h4>Stimuli</h4>
<a id="article1.body1.sec4.sec2.p1" name="article1.body1.sec4.sec2.p1"></a><p>Visual stimuli consisted of a gray disk centered on the monitor screen and displayed on a black background. In the steady stimulus condition, the disk subtended two degrees of visual angle. The looming and the receding visual signals consisted of a centered gray disk changing in size from 2 to 5 degrees and from 5 to 2 degrees of visual angle, respectively. In the deviant stimuli, the change in size was constant regardless of the duration. The steady auditory stimuli consisted of a pure 1 kHz tone with 5 ms on/off linear ramp. The looming auditory signal consisted of an upward FM sweep centered at 1 kHz spanning a 500 Hz bandwidth (i.e. ranging from 0.75 to 1.25 kHz). The receding auditory signal consisted of a downward FM sweep centered at 1 kHz and ranging from 1.25 kHz to 0.75 kHz. Both looming and receding auditory signals were linearly ramped (on/off, 5 ms) and spanned the same initial and final frequency points regardless of signal duration. All stimuli were created using Matlab™ 7.1 (The Mathworks, Inc., Natick, MA) and presented in conjunction with the Psychophysics Toolbox extensions <a href="#pone.0001437-Brainard1">[72]</a>, <a href="#pone.0001437-Pelli1">[73]</a> on a Mac G4 (Experiments 1 and 2, ‘Loom’ and ‘Recede’) or a Mac G5 (Experiment 3, ‘Reverse’).</p>
<a id="article1.body1.sec4.sec2.p2" name="article1.body1.sec4.sec2.p2"></a><p>All auditory, visual or auditory-visual standard stimuli were 500 milliseconds in duration. All auditory (A), visual (V) or auditory-visual (AV) oddballs were +/− 24%, +/− 10% or +/− 4% of the standard duration (i.e. 380 ms, 450 ms, 480 ms , 520 ms, 580 ms or 620 ms.) The inter-stimulus intervals (ISI) were pseudo-randomly chosen from 750 ms to 950 ms in steps of 20 ms. The randomization of the ISI was used to prevent participants from using rhythmic cues in their duration judgments. The inter-trial intervals lasted one second following participants' response.</p>
<a id="article1.body1.sec4.sec2.p3" name="article1.body1.sec4.sec2.p3"></a><p>In all experiments, each trial consisted of a train of five stimuli. This paradigm was designed in order to avoid possible confounds of stimulus position. Precisely, it has been reported that the first event in a train of visual stimuli tends to be judged as longer than all other subsequent events of equal duration <a href="#pone.0001437-Rose1">[74]</a>. For this reason, multiple standards were used in order to provide sufficient exemplars of the standard durations. Additionally, the fourth stimulus was always the target: participants judged whether the target was “shorter” or “longer” than all other stimuli in the trial (i.e. the first, second, third and fifth stimuli.) In the <em>test</em> conditions, the target differed from the standard stimuli in feature (e.g. if the standards were steady sounds, the target was a looming sound) and in duration (the standards were always 500 ms while the deviants took any of the deviant duration values described above). In the <em>control</em> conditions, the target only differed from the standards in duration (e.g. if all standards were steady, the target was also steady but changed in duration). The results from the control conditions provided a psychometric curve for the changes in stimulus duration alone allowing for an estimation of the true point-of-subjective equality for a 500 ms duration stimulus (as opposed to veridical duration.)</p>
<a id="article1.body1.sec4.sec2.p4" name="article1.body1.sec4.sec2.p4"></a><p>In all experiments, eight conditions were tested as follows: auditory test and auditory control, visual test and visual control, auditory-visual test and auditory-visual control, intersensory auditory test (visual deviant), intersensory visual test (auditory deviant). In the auditory-visual tests and controls, both auditory and visual stimuli had the same durations. Hence, in these multisensory conditions, both sensory modalities were congruent with respect to their duration. In the intersensory conditions, the auditory and visual stimuli differed in duration. In the intersensory auditory test, the auditory target was always 500 ms while the visual target (which was to be ignored) took any of the target durations described previously. Conversely, in the visual intersensory conditions, the visual target was always 500 ms while the simultaneously occuring auditory events took any of the target durations described above. Hence, in the intersensory conditions, the auditory and visual durations were incongruent. The order of presentation for all these conditions was pseudo-randomized across participants.</p>
<a id="article1.body1.sec4.sec2.p5" name="article1.body1.sec4.sec2.p5"></a><p>Auditory-visual stimuli were aligned to the millisecond using the audio card and a photo-detector connected to an oscilloscope for auditory-visual output signals alignments. In the intersensory conditions, where auditory and visual were incongruent in durations, the stimuli were aligned to their mid-duration point. For instance, if a 620 ms duration stimulus was paired with a 500 ms duration stimulus, the onset and offset of the longest stimuli started and ended 60 ms before and after the 500 ms duration stimulus, respectively.</p>


<h4>Procedure</h4>
<a id="article1.body1.sec4.sec3.p1" name="article1.body1.sec4.sec3.p1"></a><p>All experiments took place in a dimly lighted room. Participants sat 57 cm away from the computer screen and stabilized their heads using a chin-rest. The auditory stimuli were delivered via loudspeakers placed on each side of the monitor screen and at the same height of the visual stimulus. The sound pressure level was set to 70 dB. The visual stimuli were delivered on 19” Cathode Ray Tube monitor with a refresh rate of 100 Hz. Prior to all experiments, participants were given a few practice trials on each experimental condition. In all experiments, an experimental block started with a statement specifying which sensory modality should be considered for the participant's duration judgment. During the experiment, participants were asked to provide their answers by button-press in a two-alternative forced choice paradigm. Response options were “shorter” or “longer”. In all experiments, each block consisted of seven repetitions of each duration test (six) leading to 56 trials per experimental condition. The entire experiment lasted ~1 hour for a total of 448 trials (56 trials×8 blocks). The experiment was self-paced and participants were given a break between each block.</p>


<h4>Data Analysis</h4>
<a id="article1.body1.sec4.sec4.p1" name="article1.body1.sec4.sec4.p1"></a><p>For each condition and each participant, data were averaged per trial type for each target duration leading to individual psychometric curves. Each individual curves was fitted to a normal cumulative distribution function using a non-linear least-square data fitting procedure (nlnfitDVB function) in Matlab™ (The Mathworks, Inc., Natick, MA.) An individual's point-of-subjective-equality (PSE) was determined at the 50% crossing point and the slope values estimated between the 25% and 75% crossing point. All subsequent statistical analyses including repeated measures ANOVA and paired-samples t-tests were performed using SPSS (SPSS, Inc, Chicago, IL.) Two indices were used for the estimation of the effect sizes. Cohen's d was computed as follows: <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.e001&amp;representation=PNG" class="inline-graphic"></span>, where <em>μ</em><sub>1</sub>and <em>μ</em><sub>2</sub> designate the means, and <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.e002&amp;representation=PNG" class="inline-graphic"></span> and <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.e003&amp;representation=PNG" class="inline-graphic"></span> designate the variance of the control and test groups, respectively. Hedges's ĝ indices were also determined in order to provide a more conservative estimate of size effect by incorporating the sample size. Hedges's ĝ indices were computed as follows: <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.e004&amp;representation=PNG" class="inline-graphic"></span>, where <em>μ</em><sub>1</sub> and <em>μ</em><sub>2</sub> designate the means, <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.e005&amp;representation=PNG" class="inline-graphic"></span> and <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.e006&amp;representation=PNG" class="inline-graphic"></span> the variance, and <em>n</em><sub>1</sub>and <em>n</em><sub>2</sub> the standard deviation sample size of the control and test data, respectively. N corresponds to the total number of samples.</p>


<h4>Bayesian Fits</h4>
<a id="article1.body1.sec4.sec5.p1" name="article1.body1.sec4.sec5.p1"></a><p>The variance of the psychometric fits used to evaluate participants' PSE in each experimental condition (test and control) was extracted to compute the sensory estimates. The auditory and visual weights were computed as follows for the control conditions: <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.e007&amp;representation=PNG" class="inline-graphic"></span> and <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.e008&amp;representation=PNG" class="inline-graphic"></span>, where <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.e009&amp;representation=PNG" class="inline-graphic"></span> and <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.e010&amp;representation=PNG" class="inline-graphic"></span> designate the variance of the visual and auditory condition, respectively. The predicted PSE were computed as the sum of the weighted unisensory PSE observed (obs) in each condition and each individual leading to the estimated (est) PSE as: <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001437.e011&amp;representation=PNG" class="inline-graphic"></span>. The observed and estimated PSE in AV conditions were then submitted to a paired t-test reported in <a href="#pone-0001437-g004">Figure 4</a>.</p>

</div>

<div id="section5" class="section"><a id="s5" name="s5" toc="s5" title="Supporting Information"></a><h3>Supporting Information</h3><div class="figshare_widget" doi="10.1371/journal.pone.0001437"></div><a name="pone.0001437.s001" id="pone.0001437.s001"></a><p class="siTitle"><strong><a href="/article/fetchSingleRepresentation.action?uri=info:doi/10.1371/journal.pone.0001437.s001">Figure S1. </a></strong></p><a id="article1.body1.sec5.supplementary-material1.caption1.p1" name="article1.body1.sec5.supplementary-material1.caption1.p1"></a><p class="preSiDOI">Schematic representation of auditory-visual interactions from the perspective of the ‘internal clock models’. In all the depicted internal clock models, the main components are: a pacemaker (‘tick-counter’), a switch modulated by attention, an accumulator which forwards the accumulated ticks in storage and in reference memory. The two memory components form the comparative stage between internalized duration template and test duration. The major differences between these models consist in the stage at which auditory and visual inputs converge. In the model depicted in panel a, the entire clock is ‘amodal’ in that the very first stage of time keeping (i.e. the pacemaker) do not distinguish between auditory or visual temporal cues. In the second model (panel b), the pacemaker is also shared between the two sensory modalities but the effects of attention remain separate permitting a semi-independent evaluation of the two sensory channels (note that attention can be switched between the two). In the ‘modal’ model (panel c), auditory and visual time-keeping remains independent (again, with the exception of the attentional switch) up to the amodal comparative stage.</p>
<p class="siDoi">doi:10.1371/journal.pone.0001437.s001</p><a id="article1.body1.sec5.supplementary-material1.caption1.p2" name="article1.body1.sec5.supplementary-material1.caption1.p2"></a><p class="postSiDOI">(0.21 MB TIF)</p>
<a name="pone.0001437.s002" id="pone.0001437.s002"></a><p class="siTitle"><strong><a href="/article/fetchSingleRepresentation.action?uri=info:doi/10.1371/journal.pone.0001437.s002">Figure S2. </a></strong></p><a id="article1.body1.sec5.supplementary-material2.caption1.p1" name="article1.body1.sec5.supplementary-material2.caption1.p1"></a><p class="preSiDOI">Samples of fitted psychometric curves. We provide examples of the fitted psychometric for three participants tested in the Loom (top row), Recede (middle row) and Reverse (bottom row) experiments for the auditory (blue, left column), visual (green, middle column) and multisensory (red, right column) conditions. The actual data are reported as filled disc for the Test conditions and as crosses for the Control conditions. The fits are continuous lines for the Test conditions and dotted lines for the Control conditions.</p>
<p class="siDoi">doi:10.1371/journal.pone.0001437.s002</p><a id="article1.body1.sec5.supplementary-material2.caption1.p2" name="article1.body1.sec5.supplementary-material2.caption1.p2"></a><p class="postSiDOI">(0.25 MB TIF)</p>
<a name="pone.0001437.s003" id="pone.0001437.s003"></a><p class="siTitle"><strong><a href="/article/fetchSingleRepresentation.action?uri=info:doi/10.1371/journal.pone.0001437.s003">Figure S3. </a></strong></p><a id="article1.body1.sec5.supplementary-material3.caption1.p1" name="article1.body1.sec5.supplementary-material3.caption1.p1"></a><p class="preSiDOI">Forced-fusion model: comparison between predicted and observed variances. In the multisensory conditions (left column), the forced-fusion predictions (black) of variance did not significantly differ from the observed variances (red) in the test (AV) and control (AVc) conditions to the exception of the AV control of the Loom experiment. Note however that the predicted variance tend to be smaller than the observed variance. To the opposite in the intersensory conditions (right column), all but one observed condition (red, Reverse visual intersensory) significantly differ from the predicted variances of the forced-fusion model (black). In particular, the observed variances are always higher than the predicted ones, suggesting the intervention of parameters not accounted for by this model. Bars indicate standard-errors of the mean.</p>
<p class="siDoi">doi:10.1371/journal.pone.0001437.s003</p><a id="article1.body1.sec5.supplementary-material3.caption1.p2" name="article1.body1.sec5.supplementary-material3.caption1.p2"></a><p class="postSiDOI">(0.16 MB TIF)</p>
</div>





<div><a id="ack" name="ack" toc="ack" title="Acknowledgments"></a><h3>Acknowledgments</h3>
<a id="article1.back1.ack1.p1" name="article1.back1.ack1.p1"></a><p>We would like to thank David Eagleman and Peter Tse for earlier discussion of the data, Ulrik Beierholm for his advice on Bayesian modeling, and Marc Wittmann and Bud Craig for their comments on earlier versions of this manuscript. We are also grateful for the very insightful and constructive comments received by two anonymous reviewers.</p>
</div><div class="contributions"><a id="authcontrib" name="authcontrib" toc="authcontrib" title="Author Contributions"></a><h3>Author Contributions</h3><p>Conceived and designed the experiments: Vv LS SS DB. Performed the experiments: Vv. Analyzed the data: Vv. Wrote the paper: Vv LS SS DB.</p></div><div><a id="references" name="references" toc="references" title="References"></a><h3>References</h3><ol class="references"><li><span class="label">1.
              </span><a name="pone.0001437-Efron1" id="pone.0001437-Efron1"></a>Efron R (1970) The minimum duration of a perception. Neuropsychologia  8: 57–63.  <ul class="find" data-citedArticleID="1041886" data-doi="10.1016/0028-3932(70)90025-4"><li><a href="http://dx.doi.org/10.1016/0028-3932(70)90025-4" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+minimum+duration+of+a+perception." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+minimum+duration+of+a+perception.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">2.
              </span><a name="pone.0001437-Tse1" id="pone.0001437-Tse1"></a>Tse PU, Intriligator J, Rivest J, Cavanagh P (2004) Attention and the subjective expansion of time. Perception and Psychophysics  66: 1171–1189.  <ul class="find" data-citedArticleID="1041976" data-doi="10.3758/bf03196844"><li><a href="http://dx.doi.org/10.3758/bf03196844" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Attention+and+the+subjective+expansion+of+time." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Attention+and+the+subjective+expansion+of+time.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">3.
              </span><a name="pone.0001437-HodinottHill1" id="pone.0001437-HodinottHill1"></a>Hodinott-Hill I, Thilo KV, Conwey A, Walsh V (2002) Auditory chronostasis: hanging on the telephone. Current Biology  12: 1779–1781.  <ul class="find" data-citedArticleID="1041904" data-doi="10.1016/s0960-9822(02)01219-8"><li><a href="http://dx.doi.org/10.1016/s0960-9822(02)01219-8" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Auditory+chronostasis%3A+hanging+on+the+telephone." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Auditory+chronostasis%3A+hanging+on+the+telephone.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">4.
              </span><a name="pone.0001437-Yarrow1" id="pone.0001437-Yarrow1"></a>Yarrow K, Rothwell JC (2003) Manual chronostasis: tactile perception precedes physical contact. Current Biology  13: 1134–1139.  <ul class="find" data-citedArticleID="1041990" data-doi="10.1016/s0960-9822(03)00413-5"><li><a href="http://dx.doi.org/10.1016/s0960-9822(03)00413-5" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Manual+chronostasis%3A+tactile+perception+precedes+physical+contact." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Manual+chronostasis%3A+tactile+perception+precedes+physical+contact.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">5.
              </span><a name="pone.0001437-Yarrow2" id="pone.0001437-Yarrow2"></a>Yarrow K, Haggard K, Heal R, Brown P, Rothwell JC (2001) Illusory perceptions of space and time preserve cross-saccadic perceptual continuity. Nature 302–305.  <ul class="find" data-citedArticleID="1041992" data-doi="10.1038/35104551"><li><a href="http://dx.doi.org/10.1038/35104551" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Illusory+perceptions+of+space+and+time+preserve+cross-saccadic+perceptual+continuity." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Illusory+perceptions+of+space+and+time+preserve+cross-saccadic+perceptual+continuity.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">6.
              </span><a name="pone.0001437-Morrone1" id="pone.0001437-Morrone1"></a>Morrone MC, Ross J, Burr D (2005) Saccadic eye movements cause compression of time as well as space. Nature Neuroscience  8: 950–954.  <ul class="find" data-citedArticleID="1041930" data-doi="10.1038/nn1488"><li><a href="http://dx.doi.org/10.1038/nn1488" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Saccadic+eye+movements+cause+compression+of+time+as+well+as+space." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Saccadic+eye+movements+cause+compression+of+time+as+well+as+space.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">7.
              </span><a name="pone.0001437-Park1" id="pone.0001437-Park1"></a>Park J, Schlag-Rey M, Schlag J (2003) Voluntary action expands perceived duration of its sensory consequences. Experimental Brain Research  149: 527–529.  <ul class="find" data-citedArticleID="1041940"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=Voluntary+action+expands+perceived+duration+of+its+sensory+consequences.&amp;auth=&amp;atitle=Voluntary+action+expands+perceived+duration+of+its+sensory+consequences." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Voluntary+action+expands+perceived+duration+of+its+sensory+consequences." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Voluntary+action+expands+perceived+duration+of+its+sensory+consequences.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">8.
              </span><a name="pone.0001437-James1" id="pone.0001437-James1"></a>James W (1890) The principles of psychology. New York: Henry Holt and Company.   <ul class="find-nolinks"></ul></li><li><span class="label">9.
              </span><a name="pone.0001437-Fraisse1" id="pone.0001437-Fraisse1"></a>Fraisse P (1957) Psychologie du temps. Paris: Presses Universitaires de France.   <ul class="find-nolinks"></ul></li><li><span class="label">10.
              </span><a name="pone.0001437-Zakay1" id="pone.0001437-Zakay1"></a>Zakay D, Block RA (1997) Temporal cognition. Current Directions in Psychological Science  6: 12–16.  <ul class="find" data-citedArticleID="1041994" data-doi="10.1111/1467-8721.ep11512604"><li><a href="http://dx.doi.org/10.1111/1467-8721.ep11512604" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Temporal+cognition." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Temporal+cognition.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">11.
              </span><a name="pone.0001437-Pppel1" id="pone.0001437-Pppel1"></a>Pöppel E (1997) A hierarchical model of temporal perception. Trends in Cognitive Sciences  1: 56–61.  <ul class="find" data-citedArticleID="1041954" data-doi="10.1016/s1364-6613(97)01008-5"><li><a href="http://dx.doi.org/10.1016/s1364-6613(97)01008-5" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=A+hierarchical+model+of+temporal+perception." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22A+hierarchical+model+of+temporal+perception.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">12.
              </span><a name="pone.0001437-Lewis1" id="pone.0001437-Lewis1"></a>Lewis PA, Miall RC (2003) Distinct systems for automatic and cognitively controlled time measurement: evidence for neuroimaging. Current Opinion in Neurobiology  13: 250–255.  <ul class="find" data-citedArticleID="1041922" data-doi="10.1016/s0959-4388(03)00036-9"><li><a href="http://dx.doi.org/10.1016/s0959-4388(03)00036-9" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Distinct+systems+for+automatic+and+cognitively+controlled+time+measurement%3A+evidence+for+neuroimaging." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Distinct+systems+for+automatic+and+cognitively+controlled+time+measurement%3A+evidence+for+neuroimaging.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">13.
              </span><a name="pone.0001437-Wittmann1" id="pone.0001437-Wittmann1"></a>Wittmann M (1999) Time perception and temporal processing levels of the brain. Chronobiology International  16: 17–32.  <ul class="find" data-citedArticleID="1041986" data-doi="10.3109/07420529908998709"><li><a href="http://dx.doi.org/10.3109/07420529908998709" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Time+perception+and+temporal+processing+levels+of+the+brain." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Time+perception+and+temporal+processing+levels+of+the+brain.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">14.
              </span><a name="pone.0001437-Mauk1" id="pone.0001437-Mauk1"></a>Mauk MD, Buonomano D (2004) The neural basis of temporal processing. Annual Reviews in Neurosciences  27: 307–340.  <ul class="find" data-citedArticleID="1041928" data-doi="10.1146/annurev.neuro.27.070203.144247"><li><a href="http://dx.doi.org/10.1146/annurev.neuro.27.070203.144247" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+neural+basis+of+temporal+processing." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+neural+basis+of+temporal+processing.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">15.
              </span><a name="pone.0001437-Pppel2" id="pone.0001437-Pppel2"></a>Pöppel E (1978)  Time Perception. In: Held R, Leibowitz H, Teuber H, editors. Perception. Berlin: Springer-Verlag. pp. 713–729.  <ul class="find-nolinks"></ul></li><li><span class="label">16.
              </span><a name="pone.0001437-Block1" id="pone.0001437-Block1"></a>Block RA, Zakay D (1997) Prospective and retrospective duration judgments: a meta-analytic review. Psychonomic Bulletin and Review  4: 184–197.  <ul class="find" data-citedArticleID="1041862" data-doi="10.3758/bf03209393"><li><a href="http://dx.doi.org/10.3758/bf03209393" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Prospective+and+retrospective+duration+judgments%3A+a+meta-analytic+review." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Prospective+and+retrospective+duration+judgments%3A+a+meta-analytic+review.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">17.
              </span><a name="pone.0001437-Ross1" id="pone.0001437-Ross1"></a>Ross J, Morrone MC, Goldberg ME, Burr DC (2001) Changes in visual perception at the time of saccades. Trends in Neurosciences  24: 113–121.  <ul class="find" data-citedArticleID="1041966" data-doi="10.1016/s0166-2236(00)01685-4"><li><a href="http://dx.doi.org/10.1016/s0166-2236(00)01685-4" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Changes+in+visual+perception+at+the+time+of+saccades." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Changes+in+visual+perception+at+the+time+of+saccades.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">18.
              </span><a name="pone.0001437-Pariyadath1" id="pone.0001437-Pariyadath1"></a>Pariyadath V, Eagleman D (2007) The effect of predictability on subjective duration PLoS ONE  2: e1264.  <ul class="find" data-citedArticleID="1041938" data-doi="10.1371/journal.pone.0001264"><li><a href="http://dx.doi.org/10.1371/journal.pone.0001264" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+effect+of+predictability+on+subjective+duration" target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+effect+of+predictability+on+subjective+duration%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">19.
              </span><a name="pone.0001437-Allan1" id="pone.0001437-Allan1"></a>Allan L (1979) The perception of time. Perception and Psychophysics  26: 340–354.  <ul class="find" data-citedArticleID="1041854" data-doi="10.3758/bf03204158"><li><a href="http://dx.doi.org/10.3758/bf03204158" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+perception+of+time." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+perception+of+time.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">20.
              </span><a name="pone.0001437-Treisman1" id="pone.0001437-Treisman1"></a>Treisman M (1963) Temporal discrimination and the indifference interval: implications for a model of the ‘internal clock’. Psychological Monographs  77: 1–31.  <ul class="find" data-citedArticleID="1041974" data-doi="10.1037/h0093864"><li><a href="http://dx.doi.org/10.1037/h0093864" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Temporal+discrimination+and+the+indifference+interval%3A+implications+for+a+model+of+the+%E2%80%98internal+clock%E2%80%99." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Temporal+discrimination+and+the+indifference+interval%3A+implications+for+a+model+of+the+%E2%80%98internal+clock%E2%80%99.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">21.
              </span><a name="pone.0001437-Ivry1" id="pone.0001437-Ivry1"></a>Ivry RB, Spencer RM (2004) The neural representation of time. Current Opinion in Neurobiology  14: 225–232.  <ul class="find" data-citedArticleID="1041906" data-doi="10.1016/j.conb.2004.03.013"><li><a href="http://dx.doi.org/10.1016/j.conb.2004.03.013" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+neural+representation+of+time." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+neural+representation+of+time.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">22.
              </span><a name="pone.0001437-Penney1" id="pone.0001437-Penney1"></a>Penney TB, Tourret S (2005) Les effets de la modalité sensorielle sur la perception du temps. Psychologie Française  50: 131–143.  <ul class="find" data-citedArticleID="1041948" data-doi="10.1016/j.psfr.2004.10.011"><li><a href="http://dx.doi.org/10.1016/j.psfr.2004.10.011" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Les+effets+de+la+modalit%C3%A9+sensorielle+sur+la+perception+du+temps." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Les+effets+de+la+modalit%C3%A9+sensorielle+sur+la+perception+du+temps.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">23.
              </span><a name="pone.0001437-Goldstone1" id="pone.0001437-Goldstone1"></a>Goldstone S, Goldfarb JL (1963) Judgment of filled and unfilled durations: intersensory factors. Perceptual and Motor Skills  17: 763–774.  <ul class="find" data-citedArticleID="1041900" data-doi="10.2466/pms.1963.17.3.763"><li><a href="http://dx.doi.org/10.2466/pms.1963.17.3.763" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Judgment+of+filled+and+unfilled+durations%3A+intersensory+factors." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Judgment+of+filled+and+unfilled+durations%3A+intersensory+factors.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">24.
              </span><a name="pone.0001437-Wearden1" id="pone.0001437-Wearden1"></a>Wearden JH, Edwards H, Fakhri M, Percival A (1998) Why “sounds are judged longer than lights”: application of a modal of the internal clock in humans. Quaterly Journal of Experimental Psychology  51B: 97–120.  <ul class="find" data-citedArticleID="1041980"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=Why+%3Fsounds+are+judged+longer+than+lights%3F%3A+application+of+a+modal+of+the+internal+clock+in+humans.&amp;auth=&amp;atitle=Why+%3Fsounds+are+judged+longer+than+lights%3F%3A+application+of+a+modal+of+the+internal+clock+in+humans." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Why+%E2%80%9Csounds+are+judged+longer+than+lights%E2%80%9D%3A+application+of+a+modal+of+the+internal+clock+in+humans." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Why+%E2%80%9Csounds+are+judged+longer+than+lights%E2%80%9D%3A+application+of+a+modal+of+the+internal+clock+in+humans.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">25.
              </span><a name="pone.0001437-Penney2" id="pone.0001437-Penney2"></a>Penney TB, Gibbon J, Meck WH (2000) Differential effects of auditory and visual signals on clock speed and temporal memory. Journal of Experimental Psychology: Human Perception and Performance  26: 1770–1787.  <ul class="find" data-citedArticleID="1041950" data-doi="10.1037/0096-1523.26.6.1770"><li><a href="http://dx.doi.org/10.1037/0096-1523.26.6.1770" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Differential+effects+of+auditory+and+visual+signals+on+clock+speed+and+temporal+memory." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Differential+effects+of+auditory+and+visual+signals+on+clock+speed+and+temporal+memory.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">26.
              </span><a name="pone.0001437-DroitVolet1" id="pone.0001437-DroitVolet1"></a>Droit-Volet S, Meck WH, Penney TB (2006) Sensory modality and time perception in children and adults. Behavioral Processes Epub.   <ul class="find" data-citedArticleID="1041880" data-doi="10.1016/j.beproc.2006.09.012"><li><a href="http://dx.doi.org/10.1016/j.beproc.2006.09.012" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Sensory+modality+and+time+perception+in+children+and+adults." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Sensory+modality+and+time+perception+in+children+and+adults.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">27.
              </span><a name="pone.0001437-Nagarajan1" id="pone.0001437-Nagarajan1"></a>Nagarajan SS, Blake DT, Wright BA, Byl N, Merzenich MM (1998) Practice-related improvements in somatosensory interval discrimination are temporally specific but generalize across location, hemisphere, and modality. Journal of Neuroscience  18: 1559–1570.  <ul class="find" data-citedArticleID="1041934"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=Practice-related+improvements+in+somatosensory+interval+discrimination+are+temporally+specific+but+generalize+across+location%2C+hemisphere%2C+and+modality.&amp;auth=&amp;atitle=Practice-related+improvements+in+somatosensory+interval+discrimination+are+temporally+specific+but+generalize+across+location%2C+hemisphere%2C+and+modality." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Practice-related+improvements+in+somatosensory+interval+discrimination+are+temporally+specific+but+generalize+across+location%2C+hemisphere%2C+and+modality." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Practice-related+improvements+in+somatosensory+interval+discrimination+are+temporally+specific+but+generalize+across+location%2C+hemisphere%2C+and+modality.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">28.
              </span><a name="pone.0001437-Wright1" id="pone.0001437-Wright1"></a>Wright BA, Buonomano DV, Mahncke HW, Merzenich MM (1997) Learning and generalization of auditory temporal-interval discrimination in humans. Journal of Neuroscience  17: 3956–3963.  <ul class="find" data-citedArticleID="1041988"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=Learning+and+generalization+of+auditory+temporal-interval+discrimination+in+humans.&amp;auth=&amp;atitle=Learning+and+generalization+of+auditory+temporal-interval+discrimination+in+humans." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Learning+and+generalization+of+auditory+temporal-interval+discrimination+in+humans." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Learning+and+generalization+of+auditory+temporal-interval+discrimination+in+humans.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">29.
              </span><a name="pone.0001437-Karmarkar1" id="pone.0001437-Karmarkar1"></a>Karmarkar UR, Buonomano DV (2003) Temporal specificity of perceptual learning in an auditory discrimination task. Learning and Memory  10: 141–147.  <ul class="find" data-citedArticleID="1041914" data-doi="10.1101/lm.55503"><li><a href="http://dx.doi.org/10.1101/lm.55503" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Temporal+specificity+of+perceptual+learning+in+an+auditory+discrimination+task." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Temporal+specificity+of+perceptual+learning+in+an+auditory+discrimination+task.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">30.
              </span><a name="pone.0001437-vanWassenhove1" id="pone.0001437-vanWassenhove1"></a>van Wassenhove V, Nagarajan SS (2007) Auditory cortical plasticity in learning to discriminate modulation rate. Journal of Neuroscience  27: 2663–2672.  <ul class="find" data-citedArticleID="1041998" data-doi="10.1523/jneurosci.4844-06.2007"><li><a href="http://dx.doi.org/10.1523/jneurosci.4844-06.2007" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Auditory+cortical+plasticity+in+learning+to+discriminate+modulation+rate." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Auditory+cortical+plasticity+in+learning+to+discriminate+modulation+rate.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">31.
              </span><a name="pone.0001437-Westheimer1" id="pone.0001437-Westheimer1"></a>Westheimer G (1999) Discrimination of short time intervals by the human observer Experimental Brain Research  129: 121–126.  <ul class="find" data-citedArticleID="1041984" data-doi="10.1007/s002210050942"><li><a href="http://dx.doi.org/10.1007/s002210050942" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Discrimination+of+short+time+intervals+by+the+human+observer" target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Discrimination+of+short+time+intervals+by+the+human+observer%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">32.
              </span><a name="pone.0001437-Johnston1" id="pone.0001437-Johnston1"></a>Johnston A, Arnold DH, Nishida S (2006) Spatially localized distortions of event time. Current Biology  16: 472–479.  <ul class="find" data-citedArticleID="1041910" data-doi="10.1016/j.cub.2006.01.032"><li><a href="http://dx.doi.org/10.1016/j.cub.2006.01.032" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Spatially+localized+distortions+of+event+time." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Spatially+localized+distortions+of+event+time.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">33.
              </span><a name="pone.0001437-Burr1" id="pone.0001437-Burr1"></a>Burr D, Tozzi AM, Concetta  (2007) Neural mechanisms for timing visual events are spatially selective in real-world coordinates. Nature Neuroscience 423–425.  <ul class="find" data-citedArticleID="1041870" data-doi="10.1038/nn1874"><li><a href="http://dx.doi.org/10.1038/nn1874" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Neural+mechanisms+for+timing+visual+events+are+spatially+selective+in+real-world+coordinates." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Neural+mechanisms+for+timing+visual+events+are+spatially+selective+in+real-world+coordinates.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">34.
              </span><a name="pone.0001437-Eagleman1" id="pone.0001437-Eagleman1"></a>Eagleman DM, Jacobson JE, Sejnowski TJ (2004) Perceived luminance depends on temporal context. Nature  428: 854–856.  <ul class="find" data-citedArticleID="1041884" data-doi="10.1038/nature02467"><li><a href="http://dx.doi.org/10.1038/nature02467" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Perceived+luminance+depends+on+temporal+context." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Perceived+luminance+depends+on+temporal+context.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">35.
              </span><a name="pone.0001437-Olron1" id="pone.0001437-Olron1"></a>Oléron G (1952) Influence de l'intensité d'un son sur l'estimation de sa durée apparente. L'année Psychologique  52: 383–392.  <ul class="find" data-citedArticleID="1041936"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=Influence+de+l%27intensit%E9+d%27un+son+sur+l%27estimation+de+sa+dur%E9e+apparente.&amp;auth=&amp;atitle=Influence+de+l%27intensit%E9+d%27un+son+sur+l%27estimation+de+sa+dur%E9e+apparente." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Influence+de+l%27intensit%C3%A9+d%27un+son+sur+l%27estimation+de+sa+dur%C3%A9e+apparente." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Influence+de+l%27intensit%C3%A9+d%27un+son+sur+l%27estimation+de+sa+dur%C3%A9e+apparente.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">36.
              </span><a name="pone.0001437-Schiff1" id="pone.0001437-Schiff1"></a>Schiff W, Caviness JA, Gibson JJ (1962) Persistent fear responses in Rhesus monkeys to the optical stimulus of “looming”. Science  136: 982–983.  <ul class="find" data-citedArticleID="1041968" data-doi="10.1126/science.136.3520.982"><li><a href="http://dx.doi.org/10.1126/science.136.3520.982" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Persistent+fear+responses+in+Rhesus+monkeys+to+the+optical+stimulus+of+%E2%80%9Clooming%E2%80%9D." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Persistent+fear+responses+in+Rhesus+monkeys+to+the+optical+stimulus+of+%E2%80%9Clooming%E2%80%9D.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">37.
              </span><a name="pone.0001437-Maier1" id="pone.0001437-Maier1"></a>Maier JX, Neuhoff JG, Logothetis NK, Ghazanfar AA (2004) Multisensory integration of looming signals by Rhesus monkeys. Neuron  43: 177–181.  <ul class="find" data-citedArticleID="1041924" data-doi="10.1016/j.neuron.2004.06.027"><li><a href="http://dx.doi.org/10.1016/j.neuron.2004.06.027" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Multisensory+integration+of+looming+signals+by+Rhesus+monkeys." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Multisensory+integration+of+looming+signals+by+Rhesus+monkeys.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">38.
              </span><a name="pone.0001437-Ball1" id="pone.0001437-Ball1"></a>Ball W, Tronick E (1971) Infant Responses to Impending Collision: Optical and Real. Science  171: 818.  <ul class="find" data-citedArticleID="1041856" data-doi="10.1126/science.171.3973.818"><li><a href="http://dx.doi.org/10.1126/science.171.3973.818" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Infant+Responses+to+Impending+Collision%3A+Optical+and+Real." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Infant+Responses+to+Impending+Collision%3A+Optical+and+Real.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">39.
              </span><a name="pone.0001437-Franconeri1" id="pone.0001437-Franconeri1"></a>Franconeri SL, Simons DJ (2003) Moving and looming stimuli capture attention. Perception &amp; Psychophysics  65: 999–1010.  <ul class="find" data-citedArticleID="1041894" data-doi="10.3758/bf03194829"><li><a href="http://dx.doi.org/10.3758/bf03194829" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Moving+and+looming+stimuli+capture+attention." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Moving+and+looming+stimuli+capture+attention.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">40.
              </span><a name="pone.0001437-Franconeri2" id="pone.0001437-Franconeri2"></a>Franconeri SL, Hollingworth A, Simons DJ (2005) Do new objects capture attention? Psychological Research  16:   <ul class="find" data-citedArticleID="1041896" data-doi="10.1111/j.0956-7976.2005.01528.x"><li><a href="http://dx.doi.org/10.1111/j.0956-7976.2005.01528.x" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Do+new+objects+capture+attention%3F" target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Do+new+objects+capture+attention%3F%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">41.
              </span><a name="pone.0001437-Welch1" id="pone.0001437-Welch1"></a>Welch R, Warren D (1980) Immediate perceptual response to intersensory discrepancy. Psychological Bulletin  88: 638–667.  <ul class="find" data-citedArticleID="1041982" data-doi="10.1037/0033-2909.88.3.638"><li><a href="http://dx.doi.org/10.1037/0033-2909.88.3.638" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Immediate+perceptual+response+to+intersensory+discrepancy." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Immediate+perceptual+response+to+intersensory+discrepancy.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">42.
              </span><a name="pone.0001437-Gebhard1" id="pone.0001437-Gebhard1"></a>Gebhard J, Mowbray G (1959) On discriminating the rate of visual flicker and auditory flutter. American Journal of Psychology  72: 521–528.  <ul class="find" data-citedArticleID="1041898" data-doi="10.2307/1419493"><li><a href="http://dx.doi.org/10.2307/1419493" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=On+discriminating+the+rate+of+visual+flicker+and+auditory+flutter." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22On+discriminating+the+rate+of+visual+flicker+and+auditory+flutter.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">43.
              </span><a name="pone.0001437-Shipley1" id="pone.0001437-Shipley1"></a>Shipley T (1964) Auditory flutter-driving of visual flicker. Science  145: 1328–1330.  <ul class="find" data-citedArticleID="1041972" data-doi="10.1126/science.145.3638.1328"><li><a href="http://dx.doi.org/10.1126/science.145.3638.1328" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Auditory+flutter-driving+of+visual+flicker." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Auditory+flutter-driving+of+visual+flicker.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">44.
              </span><a name="pone.0001437-Recanzone1" id="pone.0001437-Recanzone1"></a>Recanzone GH (2003) Auditory influences on visual temporal rate perception. Journal of Neurophysiology  89: 1078–1093.  <ul class="find" data-citedArticleID="1041958" data-doi="10.1152/jn.00706.2002"><li><a href="http://dx.doi.org/10.1152/jn.00706.2002" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Auditory+influences+on+visual+temporal+rate+perception." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Auditory+influences+on+visual+temporal+rate+perception.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">45.
              </span><a name="pone.0001437-Guttman1" id="pone.0001437-Guttman1"></a>Guttman SE, Gilroy LA, Blake R (2005) Hearing what the eyes see: auditory encoding of visual temporal sequences. Psychological Science  16: 228–235.  <ul class="find" data-citedArticleID="1041902" data-doi="10.1111/j.0956-7976.2005.00808.x"><li><a href="http://dx.doi.org/10.1111/j.0956-7976.2005.00808.x" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Hearing+what+the+eyes+see%3A+auditory+encoding+of+visual+temporal+sequences." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Hearing+what+the+eyes+see%3A+auditory+encoding+of+visual+temporal+sequences.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">46.
              </span><a name="pone.0001437-Kording1" id="pone.0001437-Kording1"></a>Kording KP, Beierholm U, Ma WJ, Quartz S, Tenenbaum JB, et al.  (2007) Causal inference in multisensory perception. Manuscript submitted for publication.  <ul class="find" data-citedArticleID="1041918" data-doi="10.1371/journal.pone.0000943"><li><a href="http://dx.doi.org/10.1371/journal.pone.0000943" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Causal+inference+in+multisensory+perception.+Manuscript+submitted+for+publication." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Causal+inference+in+multisensory+perception.+Manuscript+submitted+for+publication.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">47.
              </span><a name="pone.0001437-Ernst1" id="pone.0001437-Ernst1"></a>Ernst MO, Banks MS (2002) Humans integrate visual and haptic information in a statistically optimal fashion. Nature  415: 429–433.  <ul class="find" data-citedArticleID="1041888" data-doi="10.1038/415429a"><li><a href="http://dx.doi.org/10.1038/415429a" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Humans+integrate+visual+and+haptic+information+in+a+statistically+optimal+fashion." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Humans+integrate+visual+and+haptic+information+in+a+statistically+optimal+fashion.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">48.
              </span><a name="pone.0001437-Ernst2" id="pone.0001437-Ernst2"></a>Ernst MO, Bülthoff HH (2004) Meging the senses into a robust percept. Trends in Cognitive Sciences  8: 162–169.  <ul class="find" data-citedArticleID="1041890" data-doi="10.1016/j.tics.2004.02.002"><li><a href="http://dx.doi.org/10.1016/j.tics.2004.02.002" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Meging+the+senses+into+a+robust+percept." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Meging+the+senses+into+a+robust+percept.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">49.
              </span><a name="pone.0001437-Denve1" id="pone.0001437-Denve1"></a>Denève S, Pouget A (2004) Bayesian multisensory integration and cross-modal spatial links. Journal of Physiology Paris  98: 249–258.  <ul class="find" data-citedArticleID="1041876" data-doi="10.1016/j.jphysparis.2004.03.011"><li><a href="http://dx.doi.org/10.1016/j.jphysparis.2004.03.011" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Bayesian+multisensory+integration+and+cross-modal+spatial+links." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Bayesian+multisensory+integration+and+cross-modal+spatial+links.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">50.
              </span><a name="pone.0001437-Massaro1" id="pone.0001437-Massaro1"></a>Massaro DW (1998) Perceiving Talking Faces: From Speech Perception to a Behavioral Principle: Mit Pr.  <ul class="find" data-citedArticleID="1041926" data-doi="10.1006/jpho.2000.0108"><li><a href="http://dx.doi.org/10.1006/jpho.2000.0108" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Perceiving+Talking+Faces%3A+From+Speech+Perception+to+a+Behavioral+Principle%3A+Mit+Pr." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Perceiving+Talking+Faces%3A+From+Speech+Perception+to+a+Behavioral+Principle%3A+Mit+Pr.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">51.
              </span><a name="pone.0001437-vanBeers1" id="pone.0001437-vanBeers1"></a>van Beers R, Sittig A, Gon J (1999) Integration of proprioceptive and visual position-information: an experimentally supported model. Journal of Neurophysiology  81: 1355–1364.  <ul class="find" data-citedArticleID="1041996"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=Integration+of+proprioceptive+and+visual+position-information%3A+an+experimentally+supported+model.&amp;auth=&amp;atitle=Integration+of+proprioceptive+and+visual+position-information%3A+an+experimentally+supported+model." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Integration+of+proprioceptive+and+visual+position-information%3A+an+experimentally+supported+model." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Integration+of+proprioceptive+and+visual+position-information%3A+an+experimentally+supported+model.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">52.
              </span><a name="pone.0001437-Shams1" id="pone.0001437-Shams1"></a>Shams L, Beierholm U (2005) Sound-induced flash illusion as an optimal percept. Neuroreport  16: 1923–1927.  <ul class="find" data-citedArticleID="1041970" data-doi="10.1097/01.wnr.0000187634.68504.bb"><li><a href="http://dx.doi.org/10.1097/01.wnr.0000187634.68504.bb" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Sound-induced+flash+illusion+as+an+optimal+percept." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Sound-induced+flash+illusion+as+an+optimal+percept.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">53.
              </span><a name="pone.0001437-Alais1" id="pone.0001437-Alais1"></a>Alais D, Burr D (2004) The ventriloquist effect results from near-optimal bimodal integration. Current Biology  14: 257–262.  <ul class="find" data-citedArticleID="1041852" data-doi="10.1016/j.cub.2004.01.029"><li><a href="http://dx.doi.org/10.1016/j.cub.2004.01.029" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+ventriloquist+effect+results+from+near-optimal+bimodal+integration." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+ventriloquist+effect+results+from+near-optimal+bimodal+integration.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">54.
              </span><a name="pone.0001437-DroitVolet2" id="pone.0001437-DroitVolet2"></a>Droit-Volet S, Brunot S, Niendenthal PM (2004) Perception of the duration of emotional events. Cognition and Emotion  18: 849–858.  <ul class="find" data-citedArticleID="1041882" data-doi="10.1080/02699930341000194"><li><a href="http://dx.doi.org/10.1080/02699930341000194" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Perception+of+the+duration+of+emotional+events." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Perception+of+the+duration+of+emotional+events.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">55.
              </span><a name="pone.0001437-Buonomano1" id="pone.0001437-Buonomano1"></a>Buonomano D (2000) Decoding temporal information: a modal based on short-term synaptic plasticity. Journal of Neuroscience  20: 1129–1141.  <ul class="find" data-citedArticleID="1041868"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=Decoding+temporal+information%3A+a+modal+based+on+short-term+synaptic+plasticity.&amp;auth=&amp;atitle=Decoding+temporal+information%3A+a+modal+based+on+short-term+synaptic+plasticity." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Decoding+temporal+information%3A+a+modal+based+on+short-term+synaptic+plasticity." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Decoding+temporal+information%3A+a+modal+based+on+short-term+synaptic+plasticity.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">56.
              </span><a name="pone.0001437-Karmarkar2" id="pone.0001437-Karmarkar2"></a>Karmarkar UR, Buonomano DV (2007) Timing in the absence of clocks: encoding time in neural network states. Neuron  53: 427–238.  <ul class="find" data-citedArticleID="1041916" data-doi="10.1016/j.neuron.2007.01.006"><li><a href="http://dx.doi.org/10.1016/j.neuron.2007.01.006" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Timing+in+the+absence+of+clocks%3A+encoding+time+in+neural+network+states." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Timing+in+the+absence+of+clocks%3A+encoding+time+in+neural+network+states.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">57.
              </span><a name="pone.0001437-Kanai1" id="pone.0001437-Kanai1"></a>Kanai R, Paffen CLE, Hogendoorn H, Verstraten FA (2006) Time dilation in dynamic visual displays. Journal of Vision 1–10.  <ul class="find" data-citedArticleID="1041912" data-doi="10.1167/6.12.8"><li><a href="http://dx.doi.org/10.1167/6.12.8" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Time+dilation+in+dynamic+visual+displays." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Time+dilation+in+dynamic+visual+displays.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">58.
              </span><a name="pone.0001437-NDiaye1" id="pone.0001437-NDiaye1"></a>N'Diaye K, Ragot R, Garnero L, Pouthas V (2004) What is common to brain activity evoked by the perceptio of visual and auditory filled durations? A study with MEG and EEG co-recordings. Cognitive Brain Research  21: 250–268.  <ul class="find" data-citedArticleID="1041932" data-doi="10.1016/j.cogbrainres.2004.04.006"><li><a href="http://dx.doi.org/10.1016/j.cogbrainres.2004.04.006" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=What+is+common+to+brain+activity+evoked+by+the+perceptio+of+visual+and+auditory+filled+durations%3F+A+study+with+MEG+and+EEG+co-recordings." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22What+is+common+to+brain+activity+evoked+by+the+perceptio+of+visual+and+auditory+filled+durations%3F+A+study+with+MEG+and+EEG+co-recordings.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">59.
              </span><a name="pone.0001437-Rosahl1" id="pone.0001437-Rosahl1"></a>Rosahl SK, Knight RT (2002) Role of Prefrontal Cortex in Generation of the Contingent Negative Variation. Cerebral Cortex  5: 123–134.  <ul class="find" data-citedArticleID="1041962" data-doi="10.1093/cercor/5.2.123"><li><a href="http://dx.doi.org/10.1093/cercor/5.2.123" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Role+of+Prefrontal+Cortex+in+Generation+of+the+Contingent+Negative+Variation." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Role+of+Prefrontal+Cortex+in+Generation+of+the+Contingent+Negative+Variation.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">60.
              </span><a name="pone.0001437-Bendixen1" id="pone.0001437-Bendixen1"></a>Bendixen A, Grimm S, Schröger E (2005) Human auditory event-related potentials predict duration judgments. Neuroscience Letters  383: 284–288.  <ul class="find" data-citedArticleID="1041860" data-doi="10.1016/j.neulet.2005.04.034"><li><a href="http://dx.doi.org/10.1016/j.neulet.2005.04.034" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Human+auditory+event-related+potentials+predict+duration+judgments." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Human+auditory+event-related+potentials+predict+duration+judgments.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">61.
              </span><a name="pone.0001437-Battelli1" id="pone.0001437-Battelli1"></a>Battelli L, Pascual-Leone A, Cavanagh P (2007) The ‘when’ pathway of the right parietal lobe. Trends in Cognitive Sciences  11: 204–210.  <ul class="find" data-citedArticleID="1041858" data-doi="10.1016/j.tics.2007.03.001"><li><a href="http://dx.doi.org/10.1016/j.tics.2007.03.001" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+%E2%80%98when%E2%80%99+pathway+of+the+right+parietal+lobe." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+%E2%80%98when%E2%80%99+pathway+of+the+right+parietal+lobe.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">62.
              </span><a name="pone.0001437-Coull1" id="pone.0001437-Coull1"></a>Coull JT, Nobre AC (1998) Where and when to pay attention: the neural systems for directing attention to spatial locations and to time intervals as revealed by both PET and fMRI. Journal of Neuroscience  18: 7426–7435.  <ul class="find" data-citedArticleID="1041872"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=Where+and+when+to+pay+attention%3A+the+neural+systems+for+directing+attention+to+spatial+locations+and+to+time+intervals+as+revealed+by+both+PET+and+fMRI.&amp;auth=&amp;atitle=Where+and+when+to+pay+attention%3A+the+neural+systems+for+directing+attention+to+spatial+locations+and+to+time+intervals+as+revealed+by+both+PET+and+fMRI." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Where+and+when+to+pay+attention%3A+the+neural+systems+for+directing+attention+to+spatial+locations+and+to+time+intervals+as+revealed+by+both+PET+and+fMRI." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Where+and+when+to+pay+attention%3A+the+neural+systems+for+directing+attention+to+spatial+locations+and+to+time+intervals+as+revealed+by+both+PET+and+fMRI.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">63.
              </span><a name="pone.0001437-Coull2" id="pone.0001437-Coull2"></a>Coull JT, Vidal F, Nazarian B, Macar F (2004) Functional anatomy of the attentional modulation of time estimation. Science  303: 1506–1508.  <ul class="find" data-citedArticleID="1041874" data-doi="10.1126/science.1091573"><li><a href="http://dx.doi.org/10.1126/science.1091573" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Functional+anatomy+of+the+attentional+modulation+of+time+estimation." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Functional+anatomy+of+the+attentional+modulation+of+time+estimation.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">64.
              </span><a name="pone.0001437-Dhamala1" id="pone.0001437-Dhamala1"></a>Dhamala M, Assisi CG, Jirsa VK, Steinberg FL, Kelso JAS (2007) Multisensory intergation for timing engages different brain networks. NeuroImage  34: 764–773.  <ul class="find" data-citedArticleID="1041878" data-doi="10.1016/j.neuroimage.2006.07.044"><li><a href="http://dx.doi.org/10.1016/j.neuroimage.2006.07.044" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Multisensory+intergation+for+timing+engages+different+brain+networks." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Multisensory+intergation+for+timing+engages+different+brain+networks.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">65.
              </span><a name="pone.0001437-Leon1" id="pone.0001437-Leon1"></a>Leon MI, Shadlen MN (2002) Representation of time by neurons in the posterior parietal cortex of the Macaque. Neuron  38: 317–327.  <ul class="find" data-citedArticleID="1041920" data-doi="10.1016/s0896-6273(03)00185-5"><li><a href="http://dx.doi.org/10.1016/s0896-6273(03)00185-5" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Representation+of+time+by+neurons+in+the+posterior+parietal+cortex+of+the+Macaque." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Representation+of+time+by+neurons+in+the+posterior+parietal+cortex+of+the+Macaque.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">66.
              </span><a name="pone.0001437-PascualLeone1" id="pone.0001437-PascualLeone1"></a>Pascual-Leone A, Hamilton R (2001) The metamodal organization of the brain. Progress in Brain Research  134: 427–445.  <ul class="find" data-citedArticleID="1041942" data-doi="10.1016/s0079-6123(01)34028-1"><li><a href="http://dx.doi.org/10.1016/s0079-6123(01)34028-1" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+metamodal+organization+of+the+brain." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+metamodal+organization+of+the+brain.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">67.
              </span><a name="pone.0001437-Plomp1" id="pone.0001437-Plomp1"></a>Plomp R (1964) Rate of decay of auditory sensation. Journal of the Acoustical Society of America  36: 277–282.  <ul class="find" data-citedArticleID="1041952" data-doi="10.1121/1.1918946"><li><a href="http://dx.doi.org/10.1121/1.1918946" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Rate+of+decay+of+auditory+sensation." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Rate+of+decay+of+auditory+sensation.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">68.
              </span><a name="pone.0001437-Penner1" id="pone.0001437-Penner1"></a>Penner MJ (1977) Detection of temporal gaps in noise as a measure of the decay of auditory sensation. Journal of the Acoustical Society of America  61: 552–557.  <ul class="find" data-citedArticleID="1041946" data-doi="10.1121/1.381297"><li><a href="http://dx.doi.org/10.1121/1.381297" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Detection+of+temporal+gaps+in+noise+as+a+measure+of+the+decay+of+auditory+sensation." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Detection+of+temporal+gaps+in+noise+as+a+measure+of+the+decay+of+auditory+sensation.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">69.
              </span><a name="pone.0001437-Roach1" id="pone.0001437-Roach1"></a>Roach N, Heron J, McGraw P (2006) Resolving multisensory conflict: a strategy for balancing the costs and benefitrs of audio-visual integration. Proceedings of the Royal Society Biological Sciences  273: 2159–2168.  <ul class="find" data-citedArticleID="1041960" data-doi="10.1098/rspb.2006.3578"><li><a href="http://dx.doi.org/10.1098/rspb.2006.3578" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Resolving+multisensory+conflict%3A+a+strategy+for+balancing+the+costs+and+benefitrs+of+audio-visual+integration." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Resolving+multisensory+conflict%3A+a+strategy+for+balancing+the+costs+and+benefitrs+of+audio-visual+integration.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">70.
              </span><a name="pone.0001437-Bresciani1" id="pone.0001437-Bresciani1"></a>Bresciani J, Dammeier F, Ernst MO (2006) Vision and touch are automatically integrated for the perception of sequences of events. Journal of Vision  6: 554–564.  <ul class="find" data-citedArticleID="1041866" data-doi="10.1167/6.5.2"><li><a href="http://dx.doi.org/10.1167/6.5.2" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Vision+and+touch+are+automatically+integrated+for+the+perception+of+sequences+of+events." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Vision+and+touch+are+automatically+integrated+for+the+perception+of+sequences+of+events.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">71.
              </span><a name="pone.0001437-Watanabe1" id="pone.0001437-Watanabe1"></a>Watanabe K, Shimojo S (2001) When sound affects vision: effects of auditory grouping on visual motion perception. Journal of Psychological Science  12: 109–116.  <ul class="find" data-citedArticleID="1041978" data-doi="10.1111/1467-9280.00319"><li><a href="http://dx.doi.org/10.1111/1467-9280.00319" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=When+sound+affects+vision%3A+effects+of+auditory+grouping+on+visual+motion+perception." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22When+sound+affects+vision%3A+effects+of+auditory+grouping+on+visual+motion+perception.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">72.
              </span><a name="pone.0001437-Brainard1" id="pone.0001437-Brainard1"></a>Brainard D (1997) The Psychophysics Toolbox. Spatial Vision  10: 433–436.  <ul class="find" data-citedArticleID="1041864" data-doi="10.1163/156856897x00357"><li><a href="http://dx.doi.org/10.1163/156856897x00357" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+Psychophysics+Toolbox." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+Psychophysics+Toolbox.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">73.
              </span><a name="pone.0001437-Pelli1" id="pone.0001437-Pelli1"></a>Pelli D (1997) The VideoToolbox software for visual psychophysics: transforming numbers into movies. Spatial Vision  10: 437–442.  <ul class="find" data-citedArticleID="1041944" data-doi="10.1163/156856897x00366"><li><a href="http://dx.doi.org/10.1163/156856897x00366" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+VideoToolbox+software+for+visual+psychophysics%3A+transforming+numbers+into+movies." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+VideoToolbox+software+for+visual+psychophysics%3A+transforming+numbers+into+movies.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">74.
              </span><a name="pone.0001437-Rose1" id="pone.0001437-Rose1"></a>Rose D, Summers J (1995) Duration illusions in a train of visual stimuli. Perception  24: 1177–1187.  <ul class="find" data-citedArticleID="1041964" data-doi="10.1068/p241177"><li><a href="http://dx.doi.org/10.1068/p241177" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Duration+illusions+in+a+train+of+visual+stimuli." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Duration+illusions+in+a+train+of+visual+stimuli.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li></ol></div>

  </div>

      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.XML" value="135453"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.PDF" value="606943"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g001.PNG_L" value="596654"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g001.PNG_M" value="113887"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g001.PNG_S" value="14492"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g001.TIF" value="1388202"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g001.PNG_I" value="41444"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g002.PNG_L" value="107219"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g002.PNG_M" value="93365"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g002.PNG_S" value="14251"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g002.TIF" value="253148"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g002.PNG_I" value="33552"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g003.PNG_L" value="490290"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g003.PNG_M" value="101600"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g003.PNG_S" value="12283"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g003.TIF" value="1219026"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g003.PNG_I" value="34415"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g004.PNG_L" value="255809"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g004.PNG_M" value="100577"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g004.PNG_S" value="14005"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g004.TIF" value="681372"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g004.PNG_I" value="37353"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g005.PNG_L" value="142355"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g005.PNG_M" value="55474"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g005.PNG_S" value="14365"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g005.TIF" value="347914"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g005.PNG_I" value="58519"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g006.PNG_L" value="272041"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g006.PNG_M" value="82533"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g006.PNG_S" value="12484"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g006.TIF" value="801166"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.g006.PNG_I" value="29272"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.e001.PNG" value="8515"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.e001.TIF" value="24368"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.e002.PNG" value="5094"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.e002.TIF" value="21036"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.e003.PNG" value="5134"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.e003.TIF" value="21048"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.e004.PNG" value="13313"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.e004.TIF" value="29152"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.e005.PNG" value="5095"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.e005.TIF" value="21028"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.e006.PNG" value="5133"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.e006.TIF" value="21044"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.e007.PNG" value="7622"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.e007.TIF" value="23472"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.e008.PNG" value="7580"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.e008.TIF" value="23440"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.e009.PNG" value="5213"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.e009.TIF" value="21152"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.e010.PNG" value="5166"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.e010.TIF" value="21096"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.e011.PNG" value="9885"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.e011.TIF" value="25796"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.s001.TIF" value="214882"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.s002.TIF" value="245912"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001437.s003.TIF" value="155330"/>

</div>
<div class="sidebar">

  <div class="article-actions cf">
      <div class="download">
        <span class="btn"><a href="/article/fetchObject.action?uri=info%3Adoi%2F10.1371%2Fjournal.pone.0001437&amp;representation=PDF" title="Download" target="_blank">Download PDF</a></span>
      </div>
      <div class="btn-reveal dropdown">
        <div class="dropdown-icon">
          <span class="btn">&nbsp;</span>
        </div>

        <div class="content">
          <ul class="bullet">
            <li><a href="/article/citationList.action?articleURI=info%3Adoi%2F10.1371%2Fjournal.pone.0001437" title="Download citations">Citation</a></li>
            <li><a href="/article/fetchObjectAttachment.action?uri=info%3Adoi%2F10.1371%2Fjournal.pone.0001437&amp;representation=XML" title="Download article XML">XML</a></li>
          </ul>
        </div>
      </div> <!-- end btn-reveal dropdown-->


    <div class="btn-reveal flt-l">
        <span class="btn">Print</span>
        <div class="content">
            <ul class="bullet">
                <li id="print-article"><a href="#" onclick="if(typeof(_gaq) != 'undefined'){ _gaq.push(['_trackEvent','Article', 'Print', 'Click']); } window.print(); return false;" title="Print Article">Print article</a></li>
                <li>
                  <a href="https://www.odysseypress.com/onlinehost/reprint_order.php?type=A&page=0&journal=7&doi=10.1371/journal.pone.0001437&volume=&issue=&title=Distortions of Subjective Time Perception Within and Across Senses&author_name=Virginie%20van%20Wassenhove%2C%20Dean%20V.%20Buonomano%2C%20Shinsuke%20Shimojo%2C%20Ladan%20Shams&start_page=1&end_page=13" title="Odyssey Press">EzReprint</a>
                </li>
            </ul>
        </div>
    </div>

    <div class="btn-reveal flt-r">
        <span class="btn">Share</span>
        <div class="content">
            <ul class="social">
                <li><a href="http://www.reddit.com/submit?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001437" target="_blank" title="Submit to Reddit"><img src="/images/icon.reddit.16.png" width="16" height="16" alt="Reddit">Reddit</a></li>

                <li><a href="https://plus.google.com/share?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001437" target="_blank" title="Share on Google+"><img src="/images/icon.gplus.16.png" width="16" height="16" alt="Google+">Google+</a></li>

                <li><a href="http://www.stumbleupon.com/submit?url=http%3A%2F%2Fwww.plosone.org%2Farticle%2Finfo%253Adoi%252F10.1371%252Fjournal.pone.0001437" target="_blank" title="Add to StumbleUpon"><img src="/images/icon.stumble.16.png" width="16" height="16" alt="StumbleUpon">StumbleUpon</a></li>

                <li><a href="http://www.facebook.com/share.php?u=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001437&amp;t=Distortions%20of%20Subjective%20Time%20Perception%20Within%20and%20Across%20Senses" target="_blank" title="Share on Facebook"><img src="/images/icon.fb.16.png" width="16" height="16" alt="Facebook">Facebook</a></li>

                <li><a href="http://www.linkedin.com/shareArticle?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001437&title=Distortions%20of%20Subjective%20Time%20Perception%20Within%20and%20Across%20Senses&summary=Checkout%20this%20article%20I%20found%20at%20PLOS" target="_blank" title="Add to LinkedIn"><img src="/images/icon.linkedin.16.png" width="16" height="16" alt="Mendeley">LinkedIn</a></li>

                <li><a href="http://www.citeulike.org/posturl?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001437&amp;title=Distortions%20of%20Subjective%20Time%20Perception%20Within%20and%20Across%20Senses" target="_blank" title="Add to CiteULike"><img src="/images/icon.cul.16.png" width="16" height="16" alt="CiteULike">CiteULike</a></li>

                <li><a href="http://www.mendeley.com/import/?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001437" target="_blank" title="Add to Mendeley"><img src="/images/icon.mendeley.16.png" width="16" height="16" alt="Mendeley">Mendeley</a></li>

                <li><a href="https://www.pubchase.com/library?add_aid=10.1371%2Fjournal.pone.0001437&amp;source=plos" target="_blank" title="Add to PubChase"><img src="/images/icon.pc.16.png" width="16" height="16" alt="PubChase">PubChase</a></li>


                <script type="text/javascript">
                    // replace tweet with one that's pre-shortened to 140 chars
                    function truncateTweetText() {
                        var twtTitle = 'Distortions of Subjective Time Perception Within and Across Senses';
                        var twtUrl = 'http://dx.plos.org/10.1371/journal.pone.0001437';
                        // all URLs posted to twitter get auto-shortened to 20 chars.
                        var maxLength = 140 - (20 + 1);
                        // truncate the title to include space for twtTag and ellipsis (here, 10 = tag length + space + ellipsis)
                        if (twtTitle.length > maxLength) { twtTitle = twtTitle.substr(0, (maxLength - 10)) + '...'; }
                        // set the href to use the shortened tweet
                        $('#twitter-share-link').prop('href', 'http://twitter.com/intent/tweet?text=' + encodeURIComponent('#PLOSONE: ' + twtTitle + ' ' + twtUrl));
                    }
                </script>
                <li><a href="http://twitter.com/intent/tweet?text=#PLOSONE%3A%20Distortions%20of%20Subjective%20Time%20Perception%20Within%20and%20Across%20Senses http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001437" onclick="truncateTweetText();" target="_blank" title="Share on Twitter" id="twitter-share-link"><img src="/images/icon.twtr.16.png" width="16" height="16" alt="Twitter">Twitter</a></li>

                <li><a href="/article/email/info%3Adoi%2F10.1371%2Fjournal.pone.0001437" title="Email this article"><img src="/images/icon.email.16.png" width="16" height="16" alt="Email">Email</a></li>
            </ul>
        </div>
    </div><!--end btn-reveal flt-r-->
</div><!-- end article-actions-->

<!-- begin Crossmark -->

<a id="open-crossmark" href="#" style="margin-top: -28px; display:block"><img style="border: 0; display: none;
 padding: 10px 0 18px 0;"  id="crossmark-icon" src="/images/logo-crossmark-bw.png" /></a>
<div id="crossmark-dialog" style="display: none;" title="">
    <!-- the external CrossMark data is loaded inside this iframe -->
    <iframe id="crossmark-dialog-frame" frameborder="0"></iframe>
</div>

<!-- end crossmark -->


<div class="block" id="subject-area-sidebar-block">
    <div class="header">
        <h3>Subject Areas</h3><div title="More information" id="subject-area-sidebar-block-help-icon"><img align="right"
                                                                                                           alt="info" src="/images/button_info.png"/><div id="subject-area-sidebar-block-help"><img align="right"
                                                                                                                                                                                                    src="/images/button_info.png"/><p>
        <b>We want your feedback.</b> Do these subject areas make sense for this article? If not, click the flag
        next to the incorrect subject area and we will review it. Thanks for your help!
    </p></div></div>
    </div>


    <ul id="subject-area-sidebar-list">






















          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Attention%22" title="Search for articles in the subject area:'Attention'"><div class="flagText">Attention</div></a>
              <div data-categoryid="33353" data-articleid="25702"
                   data-categoryname="Attention"
                   class="flagImage" title="Flag 'Attention' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Pacemakers%22" title="Search for articles in the subject area:'Pacemakers'"><div class="flagText">Pacemakers</div></a>
              <div data-categoryid="35443" data-articleid="25702"
                   data-categoryname="Pacemakers"
                   class="flagImage" title="Flag 'Pacemakers' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Perception%22" title="Search for articles in the subject area:'Perception'"><div class="flagText">Perception</div></a>
              <div data-categoryid="21209" data-articleid="25702"
                   data-categoryname="Perception"
                   class="flagImage" title="Flag 'Perception' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Psychometrics%22" title="Search for articles in the subject area:'Psychometrics'"><div class="flagText">Psychometrics</div></a>
              <div data-categoryid="20089" data-articleid="25702"
                   data-categoryname="Psychometrics"
                   class="flagImage" title="Flag 'Psychometrics' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Sensory+cues%22" title="Search for articles in the subject area:'Sensory cues'"><div class="flagText">Sensory cues</div></a>
              <div data-categoryid="46249" data-articleid="25702"
                   data-categoryname="Sensory cues"
                   class="flagImage" title="Flag 'Sensory cues' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Sensory+perception%22" title="Search for articles in the subject area:'Sensory perception'"><div class="flagText">Sensory perception</div></a>
              <div data-categoryid="46099" data-articleid="25702"
                   data-categoryname="Sensory perception"
                   class="flagImage" title="Flag 'Sensory perception' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Vision%22" title="Search for articles in the subject area:'Vision'"><div class="flagText">Vision</div></a>
              <div data-categoryid="32965" data-articleid="25702"
                   data-categoryname="Vision"
                   class="flagImage" title="Flag 'Vision' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Visual+signals%22" title="Search for articles in the subject area:'Visual signals'"><div class="flagText">Visual signals</div></a>
              <div data-categoryid="35641" data-articleid="25702"
                   data-categoryname="Visual signals"
                   class="flagImage" title="Flag 'Visual signals' as inappropriate"></div>
          </li>
    </ul>
</div>

<div class="ad">
    <div class="title">Advertisement</div>






  <iframe id='a0852f54' name='a0852f54'
    src='http://ads.plos.org/www/delivery/afr.php?zoneid=381&amp;cb=6147'
    frameborder='0' scrolling='no' width='160' height='600'>
    <a href='http://ads.plos.org/www/delivery/ck.php?n=a0852f54&amp;cb=4055'
      target='_top'><img src='http://ads.plos.org/www/delivery/avw.php?zoneid=381&amp;cb=47&amp;n=a0852f54'
      border='0' alt=''/>
    </a>
  </iframe>



</div>

<div id="twitter-alm-timeline" class="twitter-alm-timeline"></div>

<div class="block sidebar-comments">
    <div class="header">
        <h3>Comments</h3>
    </div>
      <p><a href="/annotation/listThread.action?root=22055">acknowledgments</a><br>Posted by virginievw</p>
      <p><a href="/annotation/listThread.action?root=4215">t,p values corrections</a><br>Posted by virginievw</p>
      <p><a href="/annotation/listThread.action?root=11719">t, p value corrections</a><br>Posted by virginievw</p>
</div>

</div><!-- sidebar -->
    </div>
  </div>
</div>
<script src="http://wl.figshare.com/static/p_widget.js" type="text/javascript"></script><div id="pageftr">
  <div class="ftr-cols cf">
    <div class="col col-1">
      <img src="/images/logo-plos-footer.png" alt="PLOS Logo" class="logo" />
      <p><a href="/static/releaseNotes">Ambra 2.9.16</a> Managed Colocation provided <br />by <a href="http://www.isc.org/">Internet Systems Consortium</a>.<p>
      <div class="nav nav-aux">
        <a href="/static/privacy">Privacy Policy</a> |
        <a href="/static/terms">Terms of Use</a> |
        <a href="http://www.plos.org/advertise/">Advertise</a> |
        <a href="http://www.plos.org/about/media-inquiries/">Media Inquiries</a>
      </div>
    </div>
    <div class="col col-2">
      <p><a href="http://www.plos.org/publications/journals/">Publications</a></p>
      <div class="nav">
        <ul>
          <li><a href="http://www.plosbiology.org">PLOS Biology</a></li>
          <li><a href="http://www.plosmedicine.org">PLOS Medicine</a></li>
          <li><a href="http://www.ploscompbiol.org">PLOS Computational Biology</a></li>
          <li><a href="http://currents.plos.org">PLOS Currents</a></li>
          <li><a href="http://www.plosgenetics.org">PLOS Genetics</a></li>
          <li><a href="http://www.plospathogens.org">PLOS Pathogens</a></li>
          <li><a href="http://www.plosone.org">PLOS ONE</a></li>
          <li><a href="http://www.plosntds.org">PLOS Neglected Tropical Diseases</a></li>
        </ul>
      </div>
    </div>
    <div class="col col-3">
      <div class="nav">
        <p><a href="http://www.plos.org">plos.org</a></p>
        <p><a href="http://blogs.plos.org">Blogs</a></p>
        <p><a href="http://www.ploscollections.org">Collections</a></p>
        <p><a href="/feedback/new">Send us feedback</a></p>

        <p>California (US) corporation #C2354500, based in San Francisco</p>
      </div>
    </div>
  </div>
</div><!-- pageftr -->

</div><!-- end page-wrap, this div is in header.ftl -->
<script type="text/javascript" src="/javascript/jquery-1.8.1-min.js?v=Tm7VCOzZz3lE03ghpkS6SWkHbyI"></script>
<script type="text/javascript" src="/javascript/ga-min.js?v=lNQ4gt8QcPDatjsdOFl_FGpPhLY"></script>
<script type="text/javascript" src="/javascript/jquery.hoverIntent-min.js?v=mRiGNYY9cIXxVb8u0K_MdW7hHnc"></script>
<script type="text/javascript" src="/javascript/jquery.placeholder-min.js?v=21Pn56Ur9h1N4K4VZDa0nqI3Pxo"></script>
<script type="text/javascript" src="/javascript/jquery.jsonp-2.4.0-min.js?v=lqTpzoHfSq3I5Ygo01qq5WankEo"></script>
<script type="text/javascript" src="/javascript/jquery-ui-1.9.2.custom-min.js?v=raSSlfNO0YsV5uUpAKmTB9n5VTc"></script>
<script type="text/javascript" src="/javascript/jquery.tooltip-min.js?v=cw+6Smh+mdryIA25xvqIvHMrnZM"></script>
<script type="text/javascript" src="/javascript/jquery.uniform-min.js?v=kYUAnX6W2W_2fK3RIuQ2m_YFG9U"></script>
<script type="text/javascript" src="/javascript/jquery.pjax-min.js?v=939kLBjL5_YKbx71T1RHjYaD4l8"></script>
<script type="text/javascript" src="/javascript/imagesloaded-min.js?v=XeuAp8Gc3mvQUo+wZCSF8ttPwvw"></script>
<script type="text/javascript" src="/javascript/figviewer-min.js?v=yPUa0sUQ_iHkI+IRv2i9bjyZJFo"></script>
<script type="text/javascript" src="/javascript/global-min.js?v=0Q3PwjeaWtXYDnqIsQvnL_ou0qs"></script>
<script type="text/javascript" src="/javascript/jquery.touchswipe-min.js?v=huaek_e6HqTduvCNAN91dJolTyw"></script>
<script type="text/javascript" src="/javascript/jquery.base64-min.js?v=VwV1zeVqKZj5FCAdlK0q5NRxbBg"></script>
<script type="text/javascript" src="/javascript/alm-min.js?v=Y5gm6B0b4Kx2YHNObNrgEeBgXlY"></script>
<script type="text/javascript" src="/javascript/taxonomy-browser-min.js?v=vBVMuDMYkGJCXIUxLe35GoyiJNw"></script>
<script type="text/javascript" src="/javascript/jquery.filterize-min.js?v=j0ZKVnHyk2nhFy8eIuNJkp7xaM0"></script>
<script type="text/javascript" src="/javascript/plosone-min.js?v=TK4H4arL_XBSwwJq+K1N3kqYfAI"></script>
<script type="text/javascript" src="/javascript/twitter-min.js?v=xKgcxLsQFXy+at1ao1NVke8nFlM"></script>
<script type="text/javascript" src="/javascript/crossmark.1.4-min.js?v=3FO4k0SjwTaGNnKGNSqthar1080"></script>
<script type="text/javascript">
  var _sf_async_config={uid:16579,domain:"plosone.org"};
  (function(){
    function loadChartbeat() {
      window._sf_endpt=(new Date()).getTime();
      var e = document.createElement('script');
      e.setAttribute('language', 'javascript');
      e.setAttribute('type', 'text/javascript');
      e.setAttribute('src',
          (("https:" == document.location.protocol) ? "https://a248.e.akamai.net/chartbeat.download.akamai.com/102508/" : "http://static.chartbeat.com/") +
              "js/chartbeat.js");
      document.body.appendChild(e);
    }
    var oldonload = window.onload;
    window.onload = (typeof window.onload != 'function') ?
        loadChartbeat : function() { oldonload(); loadChartbeat(); };
  })();
</script>
<!-- <script type="application/javascript" src="http://crossmark.crossref.org/javascripts/v1.3/crossmark.min.js"></script> -->

</body>
</html>
