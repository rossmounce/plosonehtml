

 



<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"
      xmlns:foaf="http://xmlns.com/foaf/0.1/"
      xmlns:dc="http://purl.org/dc/terms/"
      xmlns:doi="http://dx.doi.org/"
      xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
      xmlns:xsd="http://www.w3.org/2001/XMLSchema-datatypes#"
      lang="en" xml:lang="en"
      itemscope itemtype="http://schema.org/Article"
      class="no-js">
<head prefix="og: http://ogp.me/ns#">
  <title>PLOS ONE: Haptic Guidance Improves the Visuo-Manual Tracking of Trajectories</title>


<link rel="stylesheet" type="text/css"  href="/css/global-min.css?v=izteQ6tu7kgsJZW_xmrYizvKiHM" />


    <!--[if lte IE 7]>
<link rel="stylesheet" type="text/css"  href="/css/lte_ie7-min.css?v=3bykQUyQmReeuobVyPozcJ9LxRc" />
    <![endif]-->


<link rel="stylesheet" type="text/css"  href="/css/jquery-ui-min.css?v=eXDHTEJM0lIAmDe5k0I0Ad4nxNo" />


<link rel="stylesheet" type="text/css"  href="/css/journal.css?v=T7ZVxJfgk9jNxLAJ2qHz1vZpgYU" />


<link rel="stylesheet" type="text/css" media="print" href="/css/print-min.css?v=T5lb0B3q6EXBsuDluc5V5w+AkRc" />


  <link rel="stylesheet" href="http://f.fontdeck.com/s/css/js/www.plosone.org/24557.css" type="text/css"/>

  <!--chartbeat -->
  <script type="text/javascript">var _sf_startpt = (new Date()).getTime()</script>
  <script>document.documentElement.className += ' js';</script>

  <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <meta http-equiv="X-UA-Compatible" content="IE=EmulateIE7; IE=EmulateIE9"/>
  <meta name="description" content="PLOS ONE: an inclusive, peer-reviewed, open-access resource from the PUBLIC LIBRARY OF SCIENCE. Reports of well-performed scientific studies from all disciplines freely available to the whole world."/>
  <meta name="keywords" content="PLOS, Public Library of Science, Open Access, Open-Access, Science, Medicine, Biology, Research, Peer-review, Inclusive, Interdisciplinary, Ante-disciplinary, Physics, Chemistry, Engineering"/>
  <meta name="almHost" content="http://alm.plos.org/api/v3/articles"/>
  <meta name="searchHost" content="http://api.plos.org/search" />
  <meta name="termsHost" content="http://api.plos.org/terms" />
  <meta name="solrApiKey" content="plos"/>
  <meta name="almAPIKey" content="3pezRBRXdyzYW6ztfwft" />
  <meta name="currentJournal" content="PLoSONE" />
  <meta name="almRequestBatchSize" content="" />

  <meta name="citation_publisher" content="Public Library of Science"/>
  <meta name="citation_doi" content="10.1371/journal.pone.0001775"/>
  <meta name="dc.identifier" content="10.1371/journal.pone.0001775" />

    <meta name="citation_title" content="Haptic Guidance Improves the Visuo-Manual Tracking of Trajectories"/>
    <meta itemprop="name" content="Haptic Guidance Improves the Visuo-Manual Tracking of Trajectories"/>

      <meta name="citation_author" content="Jérémy Bluteau"/>
            <meta name="citation_author_institution" content="Laboratoire d'Informatique de Grenoble (LIG), Institut National de la Recherche en Informatique et Automatique (INRIA) Grenoble-Rhône-Alpes, Grenoble, France"/>
            <meta name="citation_author_institution" content="Laboratoire des Techniques de l'Ingénierie Médicale et de la Complexité-Informatique, Mathématiques et Applications de Grenoble (TIMC-IMAG), Centre National de la Recherche Scientifique (CNRS), Université Joseph Fourier (Grenoble 1), Grenoble, France"/>
            <meta name="citation_author_institution" content="Centre National de la Recherche Scientifique (CNRS) and Université Pierre Mendès France (Grenoble 2), Grenoble, France"/>
      <meta name="citation_author" content="Sabine Coquillart"/>
            <meta name="citation_author_institution" content="Laboratoire d'Informatique de Grenoble (LIG), Institut National de la Recherche en Informatique et Automatique (INRIA) Grenoble-Rhône-Alpes, Grenoble, France"/>
      <meta name="citation_author" content="Yohan Payan"/>
            <meta name="citation_author_institution" content="Laboratoire des Techniques de l'Ingénierie Médicale et de la Complexité-Informatique, Mathématiques et Applications de Grenoble (TIMC-IMAG), Centre National de la Recherche Scientifique (CNRS), Université Joseph Fourier (Grenoble 1), Grenoble, France"/>
      <meta name="citation_author" content="Edouard Gentaz"/>
            <meta name="citation_author_institution" content="Centre National de la Recherche Scientifique (CNRS) and Université Pierre Mendès France (Grenoble 2), Grenoble, France"/>

    <meta name="citation_date" content="2008/3/12"/>

  <meta name="citation_pdf_url" content="http://dx.plos.org/10.1371/journal.pone.0001775.pdf" />

      <meta name="citation_journal_title" content="PLOS ONE" />
    <meta name="citation_firstpage" content="e1775"/>
    <meta name="citation_issue" content="3"/>
    <meta name="citation_volume" content="3"/>
    <meta name="citation_issn" content="1932-6203"/>

    <meta name="citation_journal_abbrev" content="PLoS ONE" />

      <meta name="citation_reference" content="citation_author=RA Schmidt; citation_number=1; citation_date=1987; citation_publisher=Human Kinetics; " />
      <meta name="citation_reference" content="citation_title=Haptic guidance: experimental evaluation of a haptic training method for a perceptual motor skill.; citation_author=D Feygin; citation_author=M Keehner; citation_author=R Tendick; citation_journal_title=In proceedings of 10th Haptic Interfaces for Virtual Environment and Teleoperator Systems,; citation_number=2; citation_pages=40-47; citation_date=2002; " />
      <meta name="citation_reference" content="citation_title=Learning to perform a new movement with robotic assistance: comparison of haptic guidance and visual demonstration.; citation_author=J Liu; citation_author=S Cramer; citation_author=D Reinkensmeyer; citation_journal_title=J Neuroengineering Rehabil,; citation_volume=3(1743-0003 (Electronic)); citation_number=3; citation_pages=20; citation_date=2006; " />
      <meta name="citation_reference" content="citation_title=A robotic teacher of chinese handwriting.; citation_author=CL Teo; citation_author=E Burdet; citation_author=HP Lim; citation_journal_title=In proceedings of 10th Haptic Interfaces for Virtual Environment and Teleoperator Systems,; citation_number=4; citation_pages=335-341; citation_date=2002; " />
      <meta name="citation_reference" content="citation_title=A Visuo-haptic device - Telemaque - increases kindergarten children's handwriting acquisition.; citation_author=R Palluel-Germain; citation_author=F Bara; citation_author=A Hillairet de Boisferon; citation_author=B Hennion; citation_author=P Gouagout; citation_author=E Gentaz; citation_journal_title=In proceedings of IEEE World Haptics 2007,; citation_number=5; citation_pages=72-77; citation_date=2007; " />
      <meta name="citation_reference" content="citation_title=Teaching to write japanese characters using a haptic interface.; citation_author=J Solis; citation_author=CA Avizzano; citation_author=M Bergamasco; citation_journal_title=In proceedings of 10th Haptic Interfaces for Virtual Environment and Teleoperator Systems,; citation_number=6; citation_pages=255-262; citation_date=2002; " />
      <meta name="citation_reference" content="citation_title=Virtual lesson and its application to virtual calligraphy system.; citation_author=K Henmi; citation_author=T Yoshikawa; citation_journal_title=In proceedings of Robotics and Automation,; citation_volume=2; citation_number=7; citation_pages=1275-1280; citation_date=1998; " />
      <meta name="citation_reference" content="citation_title=The virtual teacher.; citation_author=PTCPB Gillespie; citation_author=S O'Modhrain; citation_author=D Zaretsky; citation_journal_title=In ASME International Mechanical Engineering Conference and Exposition,; citation_volume=64; citation_number=8; citation_pages=171-174; citation_date=1998; " />
      <meta name="citation_reference" content="citation_title=A developmental study of the relationship between geometry and kinematics in drawing movements.; citation_author=P Viviani; citation_author=R Schneider; citation_journal_title=Journal of Experimental Psychology: Human Perception and Performance,; citation_volume=17(1); citation_number=9; citation_pages=198-218; citation_date=1991; " />
      <meta name="citation_reference" content="citation_title=Trajectory determines movement kinematics.; citation_author=P Viviani; citation_author=C Terzuolo; citation_journal_title=Neuroscience,; citation_volume=7(2); citation_number=10; citation_pages=431-437; citation_date=1982; " />
      <meta name="citation_reference" content="citation_title=The law relating the kinematic and figural aspects of drawing movements.; citation_author=F Lacquaniti; citation_author=C Terzuolo; citation_author=P Viviani; citation_journal_title=Acta Psychologica,; citation_volume=54(1-3); citation_number=11; citation_pages=115-130; citation_date=1983; " />
      <meta name="citation_reference" content="citation_title=Motor skill training assistance using haptic attributes.; citation_author=G Srimathveeravalli; citation_author=K Thenkurussi; citation_journal_title=In proceedings of Haptic Interfaces for Virtual Environment and Teleoperator Systems,WHC,; citation_number=12; citation_pages=452-457; citation_date=2005; " />
      <meta name="citation_reference" content="citation_title=Haptic feedback enhances force skill learning.; citation_author=D Morris; citation_author=H Tan; citation_author=F Barbagli; citation_author=T Chang; citation_author=K Salisbury; citation_journal_title=In proceedings of EuroHaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems,; citation_number=13; citation_pages=21-26; citation_date=2007; " />
      <meta name="citation_reference" content="citation_title=What you can see is what you can feel-development of a visual/haptic interface to virtual environment.; citation_author=Y Yokokohji; citation_author=RL Hollis; citation_author=T Kanade; citation_journal_title=In proceedings of Virtual Reality Annual International Symposium,; citation_volume=265; citation_number=14; citation_pages=46-53; citation_date=1996; " />
      <meta name="citation_reference" content="citation_title=The CHAI Libraries.; citation_author=F Conti; citation_journal_title=In Eurohaptics '03; citation_number=15; citation_date=2003; " />
      <meta name="citation_reference" content="citation_title=Dynamic Time Warping: An intuitive way of handwriting recognition?; citation_author=R Niels; citation_number=16; citation_date=2004; citation_publisher=Radboud University Nijmegen, Faculty of Social Sciences, Department of Artificial Intelligence/Cognitive Science; " />
      <meta name="citation_reference" content="citation_title=Independent learning of internal models for kinematic and kynematic control of reaching.; citation_author=JW Krakauer; citation_author=M Ghilardi; citation_author=C Ghez; citation_journal_title=Nature Neuroscience,; citation_volume=2; citation_number=17; citation_pages=1026-1031; citation_date=1999; " />
      <meta name="citation_reference" content="citation_title=Internal models for motor control and trajectory planning.; citation_author=M Kawato; citation_journal_title=Current Opinion in Neurobiology,; citation_volume=9; citation_number=18; citation_pages=718-727; citation_date=1999; " />
      <meta name="citation_reference" content="citation_title=Is movement variability important for sports biomechanists?; citation_author=R Bartlett; citation_author=J Wheat; citation_author=M Robins; citation_journal_title=Sports Biomecanics,; citation_volume=6; citation_number=19; citation_pages=224-243; citation_date=2007; " />

  <link rel="canonical" href="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0001775" />

    <meta name="twitter:card" content="summary"/>
    <meta name="twitter:site" content="@plosone"/>
    <meta name="twitter:title" content="Haptic Guidance Improves the Visuo-Manual Tracking of Trajectories"/>
    <meta name="twitter:description" content="BackgroundLearning to perform new movements is usually achieved by following visual demonstrations. Haptic guidance by a force feedback device is a recent and original technology which provides additional proprioceptive cues during visuo-motor learning tasks. The effects of two types of haptic guidances-control in position (HGP) or in force (HGF)&ndash;on visuo-manual tracking (&ldquo;following&rdquo;) of trajectories are still under debate.Methodology/Principals FindingsThree training techniques of haptic guidance (HGP, HGF or control condition, NHG, without haptic guidance) were evaluated in two experiments. Movements produced by adults were assessed in terms of shapes (dynamic time warping) and kinematics criteria (number of velocity peaks and mean velocity) before and after the training sessions. Trajectories consisted of two Arabic and two Japanese-inspired letters in Experiment 1 and ellipses in Experiment 2. We observed that the use of HGF globally improves the fluency of the visuo-manual tracking of trajectories while no significant improvement was found for HGP or NHG.Conclusion/SignificanceThese results show that the addition of haptic information, probably encoded in force coordinates, play a crucial role on the visuo-manual tracking of new trajectories."/>
      <meta name="twitter:image" content="http://dx.plos.org/10.1371/journal.pone.0001775.g004"/>

  <meta property="og:title" content="Haptic Guidance Improves the Visuo-Manual Tracking of Trajectories" />
  <meta property="og:type" content="article" />
  <meta property="og:url" content="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0001775" />

 <!--end articleInfoX-->

  <link rel="pingback" href="http://www.plosone.org/pingback" />


  <link rel="shortcut icon" href="/images/favicon.ico" type="image/x-icon"/>
  <link rel="home" title="home" href="/"/>
  <link rel="alternate" type="application/rss+xml"
        title="PLOS ONE: New Articles"
        href="http://www.plosone.org/article/feed"/>
</head>
<body>

  <div id="page-wrap">
    <div id="topbanner" class="cf">

<!-- Div for the ad at the top of journal home page-->
<div class="center">
  <div class="title">Advertisement</div>
  <iframe id='a3ac9da4' name='a3ac9da4'
    src='http://ads.plos.org/www/delivery/afr.php?zoneid=345&amp;cb=7193'
    frameborder='0' scrolling='no' width='730' height='90'>
    <a href='http://ads.plos.org/www/delivery/ck.php?n=a3ac9da4&amp;cb=5542'
      target='_top'><img src='http://ads.plos.org/www/delivery/avw.php?zoneid=345&amp;cb=721&amp;n=a3ac9da4'
      border='0' alt=''/>
    </a>
  </iframe>
</div>    </div>

    <div id="pagehdr-wrap">
      <div id="pagehdr">
        <div id="user" class="nav">
          <ul>
            <li><a href="http://www.plos.org">plos.org</a></li>
            <li><a href="https://register.plos.org/ambra-registration/register.action">create account</a></li>
            <li class="btn-style"><a
              href="/user/secure/secureRedirect.action?goTo=%2Farticle%2FfetchArticle.action%3FarticleURI%3Dinfo%253Adoi%252F10.1371%252Fjournal.pone.0001775">sign in</a>
            </li>
          </ul>
        </div>
        <div class="logo">
          <a href="/"><img src="/images/logo.png" alt="PLOS ONE"></a>
        </div>

<div id="nav-main" class="nav">
  <ul>
        <li id="mn-01"><a href="/taxonomy" class="areas-link">Subject Areas</a></li>
    <li id="mn-02"><a href="javascript:void(0);">For Authors</a>
      <div class="submenu" style="width: 540px; margin-left: -300px;">
        <div class="block">
          <div class="submit-script">
            <h3>Submit your Manuscript</h3>
            <ul>
              <li>Fair, rigorous peer review</li>
              <li>Broad scope and wide reach</li>
            </ul>
            <a href="/static/submissionInstructions" class="btn">get started</a>
          </div>
        </div>
        <div class="menu">
          <ul>
            <li><a href="/static/publish">Why Publish with PLOS ONE</a></li>
            <li><a href="/static/publication">Publication Criteria</a></li>
            <li><a href="/static/editorial">Editorial Policies</a></li>
            <li><a href="/static/guidelines">Preparing A Manuscript</a></li>
            <li><a href="/static/figureGuidelines">Figure and Table Guidelines</a></li>
          <li><a href="/static/supportingInformation">Supporting Information Guidelines</a></li>
            <li><a href="/static/submissionInstructions">Submitting a Manuscript</a></li>
          </ul>
        </div>
      </div>
    </li>

    <li id="mn-03"><a href="javascript:void(0);">About Us</a>
      <div class="submenu" style="width:248px; margin-left:-30px;">
        <div class="menu">
          <ul>
            <li><a href="/static/information">Journal Information</a></li>
            <li><a href="/static/edboard">Editorial Board</a></li>
            <li><a href="/static/reviewerGuidelines">Reviewer Guidelines</a></li>
            <li><a href="/static/almInfo">Article-Level Metrics</a></li>
            <li><a href="/static/license">Open-Access License</a></li>
            <li><a href="/static/downloads">Media Downloads</a></li>
            <li><a href="/static/commentGuidelines">Guidelines for Comments</a></li>
            <li><a href="/static/corrections">Corrections</a></li>
            <li><a href="/static/help">Help Using this Site</a></li>
            <li><a href="/static/contact">Contact Us</a></li>
          </ul>
        </div>
      </div>
    </li>
  </ul>
<div id="db">
  <form name="searchForm" action="/search/simple?noSearchFlag=true&amp;query=&amp;articleURI=info%3Adoi%2F10.1371%2Fjournal.pone.0001775" method="get" >
<input type="hidden" name="from" value="globalSimpleSearch" id="from"/><input type="hidden" name="filterJournals" value="PLoSONE" id="filterJournals"/>    <fieldset>
      <legend>Search</legend>
      <label for="search">Search</label>
      <div class="wrap">
        <input id="search" type="text" name="query" placeholder="Search">
        <input type="image" alt="SEARCH" src="/images/icon.search.gif">
      </div>
    </fieldset>
  </form>
    <a id="advSearch" href="/search/advanced?noSearchFlag=true&amp;query=&amp;articleURI=info%3Adoi%2F10.1371%2Fjournal.pone.0001775&filterJournals=PLoSONE">advanced search</a>
</div></div>

      </div>
      <!-- pagehdr-->
    </div>
    <!-- pagehdr-wrap -->

  <!--body and html tags gets closed in global_footer.ftl-->
<script type="text/javascript" src="/javascript/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<div id="pagebdy-wrap">
  <div id="pagebdy">

    <div id="article-block" class="cf">

<div class="article-meta cf">
  <ul id="almSignPost" style="display: none;"></ul>
  <div class="article-type">
    <span class="type oa">Open Access</span>
      <span class="type pr">Peer-Reviewed</span>
  </div>
</div>

<div class="header" id="hdr-article">

<div class="article-kicker">
      <span id="article-type-heading">
        Research Article
      </span>
</div>  <h1 property="dc:title" datatype="" rel="dc:type" href="http://purl.org/dc/dcmitype/Text">
    Haptic Guidance Improves the Visuo-Manual Tracking of Trajectories
  </h1>

  <ul class="authors">
      <li>


        <span rel="dc:creator" class="author">
          <span class="person" property="foaf:name" typeof="foaf:Person">
            Jérémy Bluteau, 
          </span>
        </span>

          <div class="author_meta">
            <div class="author_inner">


              
              

                <p>Affiliations:
                  Laboratoire d'Informatique de Grenoble (LIG), Institut National de la Recherche en Informatique et Automatique (INRIA) Grenoble-Rhône-Alpes, Grenoble, France, 
                  Laboratoire des Techniques de l'Ingénierie Médicale et de la Complexité-Informatique, Mathématiques et Applications de Grenoble (TIMC-IMAG), Centre National de la Recherche Scientifique (CNRS), Université Joseph Fourier (Grenoble 1), Grenoble, France, 
                  Centre National de la Recherche Scientifique (CNRS) and Université Pierre Mendès France (Grenoble 2), Grenoble, France
                </p>


              <span class="close">X</span>

            </div>
          </div>
      </li>
      <li>


        <span rel="dc:creator" class="author">
          <span class="person" property="foaf:name" typeof="foaf:Person">
            Sabine Coquillart, 
          </span>
        </span>

          <div class="author_meta">
            <div class="author_inner">


              
              

                <p>Affiliation:
                  Laboratoire d'Informatique de Grenoble (LIG), Institut National de la Recherche en Informatique et Automatique (INRIA) Grenoble-Rhône-Alpes, Grenoble, France
                </p>


              <span class="close">X</span>

            </div>
          </div>
      </li>
      <li>


        <span rel="dc:creator" class="author">
          <span class="person" property="foaf:name" typeof="foaf:Person">
            Yohan Payan, 
          </span>
        </span>

          <div class="author_meta">
            <div class="author_inner">


              
              

                <p>Affiliation:
                  Laboratoire des Techniques de l'Ingénierie Médicale et de la Complexité-Informatique, Mathématiques et Applications de Grenoble (TIMC-IMAG), Centre National de la Recherche Scientifique (CNRS), Université Joseph Fourier (Grenoble 1), Grenoble, France
                </p>


              <span class="close">X</span>

            </div>
          </div>
      </li>
      <li>


        <span rel="dc:creator" class="author">
          <span class="person" property="foaf:name" typeof="foaf:Person">
            Edouard Gentaz
              <span class="corresponding">mail</span>
          </span>
        </span>

          <div class="author_meta">
            <div class="author_inner">


              
              <p><span class="email">* E-mail:</span> <a href="mailto:edouard.gentaz@upmf-grenoble.fr">edouard.gentaz@upmf-grenoble.fr</a></p>

                <p>Affiliation:
                  Centre National de la Recherche Scientifique (CNRS) and Université Pierre Mendès France (Grenoble 2), Grenoble, France
                </p>


              <span class="close">X</span>

            </div>
          </div>
      </li>
  </ul>
  <ul class="date-doi-line">
    <li>Published: March 12, 2008</li>
    <li>DOI: 10.1371/journal.pone.0001775</li>
  </ul>


</div><!--end header-->
<div class="main cf" id="pjax-container">
  

<div class="nav items-5" id="nav-article">
  <ul>
  <li>
        <span class="active" name="article">Article</span>
  </li>
  <li>
      <a href="/article/authors/info%3Adoi%2F10.1371%2Fjournal.pone.0001775" name="authors">About the Authors</a>
  </li>
  <li>
      <a href="/article/metrics/info%3Adoi%2F10.1371%2Fjournal.pone.0001775" name="metrics">Metrics</a>
  </li>
  <li>
      <a href="/article/comments/info%3Adoi%2F10.1371%2Fjournal.pone.0001775" name="comments">Comments</a>
  </li>
  <li>
      <a href="/article/related/info%3Adoi%2F10.1371%2Fjournal.pone.0001775" name="related">Related Content</a>
  </li>
  </ul>
</div>

<script type="text/javascript">
  var selected_tab = "article";
</script>
  <div id="figure-thmbs" class="carousel cf">
    <div class="wrapper">
      <div class="slider">
              <div class="item">
                <a href="#pone-0001775-g001" data-doi="info:doi/10.1371/journal.pone.0001775" data-uri="info:doi/10.1371/journal.pone.0001775.g001" title="Figure 1">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001775.g001&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001775-g002" data-doi="info:doi/10.1371/journal.pone.0001775" data-uri="info:doi/10.1371/journal.pone.0001775.g002" title="Figure 2">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001775.g002&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001775-g003" data-doi="info:doi/10.1371/journal.pone.0001775" data-uri="info:doi/10.1371/journal.pone.0001775.g003" title="Figure 3">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001775.g003&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001775-g004" data-doi="info:doi/10.1371/journal.pone.0001775" data-uri="info:doi/10.1371/journal.pone.0001775.g004" title="Figure 4">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001775.g004&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001775-t001" data-doi="info:doi/10.1371/journal.pone.0001775" data-uri="info:doi/10.1371/journal.pone.0001775.t001" title="Table 1">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001775.t001&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001775-t002" data-doi="info:doi/10.1371/journal.pone.0001775" data-uri="info:doi/10.1371/journal.pone.0001775.t002" title="Table 2">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001775.t002&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
      </div>
    </div>
  </div>

  <div class="nav-col">
    <div class="nav" id="nav-article-page">
      <ul>
        <li class="nav-col-comments"><a href="/article/comments/info%3Adoi%2F10.1371%2Fjournal.pone.0001775">Reader Comments (1)</a></li>
          <li id="nav-figures"><a data-doi="info:doi/10.1371/journal.pone.0001775" >Figures</a></li>
      </ul>
    </div>
  </div>

  <div class="article">







<div class="abstract"><a id="abstract0" name="abstract0" toc="abstract0" title="Abstract"></a><h2>Abstract</h2>
<h3>Background</h3>
<a id="article1.front1.article-meta1.abstract1.sec1.p1" name="article1.front1.article-meta1.abstract1.sec1.p1"></a><p>Learning to perform new movements is usually achieved by following visual demonstrations. Haptic guidance by a force feedback device is a recent and original technology which provides additional proprioceptive cues during visuo-motor learning tasks. The effects of two types of haptic guidances-control in position (HGP) or in force (HGF)–on visuo-manual tracking (“following”) of trajectories are still under debate.</p>


<h3>Methodology/Principals Findings</h3>
<a id="article1.front1.article-meta1.abstract1.sec2.p1" name="article1.front1.article-meta1.abstract1.sec2.p1"></a><p>Three training techniques of haptic guidance (HGP, HGF or control condition, NHG, without haptic guidance) were evaluated in two experiments. Movements produced by adults were assessed in terms of shapes (dynamic time warping) and kinematics criteria (number of velocity peaks and mean velocity) before and after the training sessions. Trajectories consisted of two Arabic and two Japanese-inspired letters in Experiment 1 and ellipses in Experiment 2. We observed that the use of HGF globally improves the fluency of the visuo-manual tracking of trajectories while no significant improvement was found for HGP or NHG.</p>


<h3>Conclusion/Significance</h3>
<a id="article1.front1.article-meta1.abstract1.sec3.p1" name="article1.front1.article-meta1.abstract1.sec3.p1"></a><p>These results show that the addition of haptic information, probably encoded in force coordinates, play a crucial role on the visuo-manual tracking of new trajectories.</p>

</div>


<div class="articleinfo"><p><strong>Citation: </strong>Bluteau J, Coquillart S, Payan Y, Gentaz E (2008) Haptic Guidance Improves the Visuo-Manual Tracking of Trajectories. PLoS ONE 3(3):
          e1775.
            doi:10.1371/journal.pone.0001775</p><p><strong>Academic Editor: </strong>Chris Miall, University of Birmingham, United Kingdom</p><p><strong>Received:</strong> December 22, 2007; <strong>Accepted:</strong> January 28, 2008; <strong>Published:</strong> March 12, 2008</p><p><strong>Copyright:</strong> © 2008 Bluteau et al. This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</p><p><strong>Funding: </strong>We thank “Region Rhone-Alpes”, especially the Cluster ISLE-II and the PPF “Interactions Multimodales” for the partial funding of this research.</p><p><strong>Competing interests:</strong> The authors have declared that no competing interests exist.</p></div>





<div id="section1" class="section"><a id="s1" name="s1" toc="s1" title="Introduction"></a><h3>Introduction</h3><a id="article1.body1.sec1.p1" name="article1.body1.sec1.p1"></a><p>Learning to perform new movements is usually achieved by following visual demonstrations <a href="#pone.0001775-Schmidt1">[1]</a>. Haptic guidance by a force feedback device is a recent and original technology that provides additional proprioceptive cues during visuo-motor learning tasks. Virtual simulators, in which haptic and visual cues are provided, seem to be an efficient way to teach complex movements <a href="#pone.0001775-Feygin1">[2]</a>–<a href="#pone.0001775-PalluelGermain1">[5]</a>. Two well-known robotic haptic guidances have been currently implemented: The first one uses spatial coordinates (HGP)-position information- of the trajectory to learn, whereas the second one (HGF) uses forces generated by a teacher to control the student's task (<a href="#pone-0001775-g001">Figure 1</a>).</p>
<div class="figure" id="pone-0001775-g001"><div class="img"><a name="pone-0001775-g001" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001775.g001&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001775" data-uri="info:doi/10.1371/journal.pone.0001775.g001"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001775.g001&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001775.g001/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001775.g001/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001775.g001/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001775.g001/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001775.g001.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001775.g001/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001775.g001/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001775.g001.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 1. </strong></p><a id="article1.body1.sec1.fig1.caption1.p1" name="article1.body1.sec1.fig1.caption1.p1"></a><p>Schematic view of haptic guidances: (a) Haptic guidance in position (HGP); the force felt by the user at time <em>t</em> is proportional to displacement between the current user position and the theoretical position on the model trajectory; (b) Haptic guidance in force (HGF); the force felt by the user at time <em>t</em> is the same as the force existing for the theoretical trajectory at the same time.</p>
<span>doi:10.1371/journal.pone.0001775.g001</span></div><a id="article1.body1.sec1.p2" name="article1.body1.sec1.p2"></a><p>Haptic guidance in position (HGP) mostly uses a proportional derivative controller <em>i.e.</em> following point-per-point the visual representation of the target trajectory. Based on this technology, Solis <em>et al.</em> <a href="#pone.0001775-Solis1">[6]</a> had developed a Japanese calligraphy system using reactive robot technology. Unfortunately, this study mainly focused on the technical aspects. In the same vein, Henmi <em>et al.</em> <a href="#pone.0001775-Henmi1">[7]</a> also designed a Japanese calligraphy system using a “record and playback” strategy: The authors recorded positions and forces applied by a human teacher and displayed them to the students. However, in these two studies, no behavioral data was reported. Gillespie <em>et al.</em> <a href="#pone.0001775-Gillespie1">[8]</a> developed a virtual teacher based on a proportional derivative position controller to help students to properly move a simulated crane. This pilot study with 24 participants showed that their implementation of the virtual teacher concept did not significantly improve the learning of oscillating curves. More recently, Palluel-Germain <em>et al.</em> <a href="#pone.0001775-PalluelGermain1">[5]</a>, in a pilot study, analyzed the effects of using HPG to train the fluency of writing cursive letters in kindergarten children. Fluency of handwriting (analyzed by kinematics parameters such as average velocity, number of velocity peaks, and number of breaks during the production) was tested before and after the training sessions (either visuo-haptic or control). Letters were computer generated to control the dynamics by changing the distance between successive points of a discrete trajectory. Results showed that the fluency of handwriting for all letters was higher after the visuo-haptic training session than after the control training session: The movements of the hand were faster, exhibited less velocity peaks and the children lifted the pen less frequently during handwriting. Finally, other studies in adults <a href="#pone.0001775-Feygin1">[2]</a>, <a href="#pone.0001775-Teo1">[4]</a> confirmed the positive effect of visuo-haptic training sessions using proportional derivative position controller but most of them mainly describe the technical aspects. In these studies, the analysis of kinematics criteria remained rather unexplored.</p>
<a id="article1.body1.sec1.p3" name="article1.body1.sec1.p3"></a><p>Haptic guidance in force (HGF) is an alternative control method, which is congruent with two well-known psychophysical principles <a href="#pone.0001775-Viviani1">[9]</a>, <a href="#pone.0001775-Viviani2">[10]</a>, <a href="#pone.0001775-Lacquaniti1">[11]</a>: The homothety principle which states that the trajectory keeps its shape characteristics whatever its size, and the isochrony principle which states that the velocity for tracing increases as function of its size. Hemni <em>et al.</em> <a href="#pone.0001775-Henmi1">[7]</a> compared the effects of HGF and HGP on a handwriting task in addition to visual cues. Preliminary results showed both techniques to be equally effective. Srimathveeravalli <em>et al.</em> <a href="#pone.0001775-Srimathveeravalli1">[12]</a> introduced a new paradigm providing the closest possible replication of an expert's skill. The authors proposed that if the nature of forces generated by the teacher and by the student were the same, then their trajectories would be similar. Force profiles of the teacher were then used to guide the motion of the student. Demonstration of its efficiency was shown by comparing this method with other classical haptic training methods in terms of shape matching with an unfamiliar Tamil (Indian) letter. Results confirmed the authors' hypothesis and showed that a “record-and-playback” training method with force information was more efficient than training method with only position control. Unfortunately, this study mainly focused on a shape matching score and did not examine kinematics criteria. Recently, Morris et al <a href="#pone.0001775-Morris1">[13]</a> explored the use of haptic feedback for teaching a sequence of forces. Results showed that adults are able to learn sensory-motor skills via visuo-haptic training. This result would allow us to better understand the positive effects of HGF during training session of handwriting observed by Srimathveeravalli <a href="#pone.0001775-Srimathveeravalli1">[12]</a>.</p>
<a id="article1.body1.sec1.p4" name="article1.body1.sec1.p4"></a><p>In the present study, we have investigated with adults whether the two types of haptic guidance-control in position (HGP) or in force (HGF)–based on psychophysics laws of movement production, would improve visuo-manual tracking of Arabic and Japanese-inspired letters (Experiment 1) and untrained ellipses (Experiment 2). The effects of HGP on kinematics would then be tested, in extension of Palluel-Germain <em>et al.</em> <a href="#pone.0001775-PalluelGermain1">[5]</a> study. Moreover, the effects of HGF on kinematics criteria (fluidity) were considered as a complement of Srimathveeravalli <a href="#pone.0001775-Srimathveeravalli1">[12]</a> study. In both experiments three training sessions were conducted, which differed according to the haptic guidance used: HGP, HGF or no haptic guidance (NHG). We proposed that the addition of haptic cues to training session would improve the performance of subjects. Movements were evaluated in terms of shapes (dynamic time warping) and kinematics criteria (number of velocity peaks and mean velocity). Progress was assessed from the difference of performances before (pre-test) and after (post-test) the training session. We hypothesized that haptic guidance of both types would improve the performance of the subjects in comparison to the control training session. In Experiment 1, Twenty-three adults were asked to learn to track visuo-manually two unfamiliar Arabic and two unfamiliar Japanese-inspired letters.</p>
<a id="article1.body1.sec1.p5" name="article1.body1.sec1.p5"></a><p>In Experiment 2, we explored whether training on one set of trajectories with the two haptic guidances-HGP or HGF–improve the visuo-manual tracking of another set of similar trajectories in terms of shape and kinematics aspects. We have proposed shape variability of stimuli to improve the training sessions. Generation of a range of trajectories required a highly defined base trajectory. The ellipse, a “two-parameter” trajectory (well-known in psychophysics studies) was chosen. Twenty-four adults were asked to track three visually presented ellipses. Psychophysics studies showed that there is an unambiguous relationship between letter production and movement kinematics. The shape of the trajectory determines the movement kinematics (so called “the two-thirds power law”) <a href="#pone.0001775-Viviani1">[9]</a>, <a href="#pone.0001775-Viviani2">[10]</a>, <a href="#pone.0001775-Lacquaniti1">[11]</a>. The trajectory and dynamics of the drawing movement are mutually constrained by this law. Viviani <em>et al.</em> <a href="#pone.0001775-Viviani1">[9]</a> found that this law can be taken as an explanation of steady-state adult performances of handwriting skills. The “two-third” law was used to generate trajectories for this Experiment in order to prevent any dependence of the teacher's specific way of tracing a trajectory. We introduced shape variability in the trained trajectories. They were similar to the pre and post test trajectories but never the same. Because this variability of required movements with haptic guidances generated a variability in the sensorial feedbacks (visual and proprioceptive), we hypothesized an increase of performances to track new (but closed) movements.</p>
</div>

<div id="section2" class="section"><a id="s2" name="s2" toc="s2" title="Methods"></a><h3>Methods</h3>
<h4>Experiment 1: Japanese and Arabic letters</h4>
<h5>Participants.</h5><a id="article1.body1.sec2.sec1.sec1.p1" name="article1.body1.sec2.sec1.sec1.p1"></a><p>Participants were 23 right-handed Caucasian adults, with no significant language, motor or neurological dysfunction. They were students from University of Grenoble and their age ranged from 18 to 26 years. The present study was conducted in accordance with the Declaration of Helsinki. It was conducted with the understanding and the written consent of each participant which was obtained and was approved by the local ethic committee.</p>

<h5>Experimental Setup.</h5><a id="article1.body1.sec2.sec1.sec2.p1" name="article1.body1.sec2.sec1.sec2.p1"></a><p>The present experimental setup was similar to the “WYSIWYF” interface proposed by Yokokohji <em>et al.</em> <a href="#pone.0001775-Yokokohji1">[14]</a>. We used a PHANToM™ Omni device (Sensable Technology). The modified PHANToM's stylus (<a href="#pone-0001775-g002">Figure 2.a</a>) served as a pen and a simple flat screen, mounted under the force feedback device, served as a paper. <a href="#pone-0001775-g002">Figure 2.c</a> shows a user writing with the virtual interface. The Chai3D Framework <a href="#pone.0001775-Conti1">[15]</a> was used to develop the application (<a href="#pone-0001775-g002">Figure 2.b</a>), on a classical personal computer (Pentium IV, 3.2 Ghz, 2Go Ram, NVIDIA Quadro Fx). Efforts have been made in the design of the physical setup to put the user in a situation, as close as possible to the usual handwriting task. The maximal depth from the virtual drawing and the real PHANToM's stylus is 0.5 mm (height of the protective glass on the screen). Calibration between the force feedback device and the screen was done by triangulation at the beginning of each experiment. This resulted in co-location of the stylus and the virtual trace which provided a natural feeling of handwriting.</p>
<div class="figure" id="pone-0001775-g002"><div class="img"><a name="pone-0001775-g002" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001775.g002&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001775" data-uri="info:doi/10.1371/journal.pone.0001775.g002"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001775.g002&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001775.g002/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001775.g002/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001775.g002/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001775.g002/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001775.g002.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001775.g002/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001775.g002/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001775.g002.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 2. </strong></p><a id="article1.body1.sec2.sec1.sec2.fig1.caption1.p1" name="article1.body1.sec2.sec1.sec2.fig1.caption1.p1"></a><p>System overview: (a) The modified stylus pen; (b) The graphic User Interface displayed to the subject; (c) A subject undergoing training on the WYSIWYF interface.</p>
<span>doi:10.1371/journal.pone.0001775.g002</span></div>
<h5>Tested and Trained trajectories: Arabic and Japanese-like letters.</h5><a id="article1.body1.sec2.sec1.sec3.p1" name="article1.body1.sec2.sec1.sec3.p1"></a><p>Trajectories were chosen to be “biologically and culturally possible” but also unfamiliar for participants (criterion used to select the participants). We explored two Arabic letters (<a href="#pone-0001775-g003">fig. 3.a and 3.b</a>) and two Japanese-inspired letters (<a href="#pone-0001775-g003">fig. 3.c and 3.d</a>). These trajectories were generated from several expert productions. Moreover, they were chosen to provide different difficulty levels defined by the number of “brutal change” of direction (&gt;45°) in the shape (letter 1: one 90° change; letter 2: one 180° change; letter 3: three changes; letter 4: four changes). It should be noted that theses changes of direction in shape imply large changes in the kinematics. The Japanese letters were modified in order to avoid lift up from the stylus by orthographically projecting the aerial path in the 2-dimensional reference of the letter.</p>
<div class="figure" id="pone-0001775-g003"><div class="img"><a name="pone-0001775-g003" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001775.g003&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001775" data-uri="info:doi/10.1371/journal.pone.0001775.g003"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001775.g003&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001775.g003/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001775.g003/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001775.g003/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001775.g003/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001775.g003.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001775.g003/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001775.g003/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001775.g003.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 3.  <span>Letters proposed in experiment 1: Letters 1 and 2 are Arabic and letters 3 and 4 are “Japanese-like” letters.</span></strong></p><span>doi:10.1371/journal.pone.0001775.g003</span></div>
<h5>Pre-test and post tests.</h5><a id="article1.body1.sec2.sec1.sec4.p1" name="article1.body1.sec2.sec1.sec4.p1"></a><p>Participants were assessed before and after the training sessions in order to measure the visuo-manual tracking of letters. Participants were asked to trace with their right hand visually presented letters with the stylus as accurately and as promptly as possible. No feedback was given by the experimenter. Each participant executed five trials for each letter in pseudo random order (two identical consecutive letters never occurred). In total, there were therefore 20 trials in the pre and post-tests.</p>

<h5>Movement analysis.</h5><a id="article1.body1.sec2.sec1.sec5.p1" name="article1.body1.sec2.sec1.sec5.p1"></a><p>Three main criteria were used to evaluate the movement: Number of velocity peaks, mean velocity and shape matching score. The positions and time stamps of each trial were recorded and pre-processed to compute these measures. The PHANToM device allowed us to record the position of the tool tip at about 1 KHz, which resulted in over sampling. To avoid long computation time and due to the frequency range of information, data could be reasonably sampled at 200Hz. This is equivalent to applying a low-pass filter to avoid high frequency noise due to hardware imprecision in time sampling.</p>

<h4>1. Number of Velocity Peaks</h4>
<a id="article1.body1.sec2.sec1.sec5.sec1.p1" name="article1.body1.sec2.sec1.sec5.sec1.p1"></a><p>The number of velocity peaks is a criterion to estimate the fluidity of the movement. A small number of velocity peaks, with no regression of the shape quality (shape matching criterion) indicates a “good” fluidity. To compute these peaks, the velocity was low-pass filtered using a 6-order Butterworth filter (cut-off frequency = 50Hz). Attention was paid to avoid distortions. Then, we computed the acceleration from these filtered data and counted the sign inversions for the acceleration. This value gave us the number of velocity peaks.</p>


<h4>2. Mean Velocity</h4>
<a id="article1.body1.sec2.sec1.sec5.sec2.p1" name="article1.body1.sec2.sec1.sec5.sec2.p1"></a><p>The mean velocity also is a criterion to estimate the fluidity of the movement. A high mean velocity, with no regression of the shape quality (shape matching criterion), indicates a good fluidity of handwriting production.</p>


<h4>3. Shape matching</h4>
<a id="article1.body1.sec2.sec1.sec5.sec3.p1" name="article1.body1.sec2.sec1.sec5.sec3.p1"></a><p>Dynamic time warping (DTW) algorithm <a href="#pone.0001775-Morris1">[13]</a>, <a href="#pone.0001775-Niels1">[16]</a> computes a cost corresponding to a match between a reference trajectory and a subject recall trajectory. DTW constructs a global cost matrix by aligning the two temporal series. Then, a minimal path through the matrix is determined and the final value of this minimal path provides a representative cost for the warping of the two trajectories, <em>i.e.</em> the similarity between the two shapes. This algorithm was implemented for each axis (X and Y of the unit table) separately. The cost function in this case was the Euclidean distance between two points. This criterion gives a score of shape matching: A low score means a good match in shape.</p>


<h5>Training Sessions.</h5><a id="article1.body1.sec2.sec1.sec6.p1" name="article1.body1.sec2.sec1.sec6.p1"></a><p>Each subjects participated in three training sessions (Haptic guidance in position-HGP, haptic guidance in force–HGF, and no haptic guidance–NHG). The order was given by a Latin-square plan. Participants were asked to move a stylus with their right hand to follow a visually presented trajectory. There were 20 test trials (5 trials×4 letters) in each training session.</p>

<h4>1. Haptic Guidance in Position (HGP)</h4>
<a id="article1.body1.sec2.sec1.sec6.sec1.p1" name="article1.body1.sec2.sec1.sec6.sec1.p1"></a><p>Position Proportional-Derivative control is well known in automatism. It consists in minimising the trajectory error during the training. This type of control can be thought of as a spring, attached to the trajectory points, pulling the stylus' tip to the next point (<a href="#pone-0001775-g001">Figure 1.a</a>). The proportional and derivative gains were derived from <a href="#pone.0001775-Srimathveeravalli1">[12]</a> and experimentally tuned (with pilot studies) to 0.4 N/mm and 0.2 Ns/mm.</p>


<h4>2. Haptic Guidance in Force (HGF)</h4>
<a id="article1.body1.sec2.sec1.sec6.sec2.p1" name="article1.body1.sec2.sec1.sec6.sec2.p1"></a><p>According to the hypothesis proposed by Srimathveeravalli <em>et al.</em> <a href="#pone.0001775-Srimathveeravalli1">[12]</a>, similar force profiles lead to similar trajectories (<a href="#pone-0001775-g001">Figure 1.b</a>). The handwriting task has been modelled as a force needed to move a mass on a surface with a constant friction value. To compute the forces from computer generated trajectories, a simple lumped model, described in previous studies <a href="#pone.0001775-Srimathveeravalli1">[12]</a>, was used. This model is described in Equation (1).<a name="" id=""></a><span class="equation"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001775.e001&amp;representation=PNG" class="inline-graphic"></span><br>where <em>F</em> is the force, <em>m</em> is the mass of the system (hand+stylus), <em>a</em> is the acceleration, <em>c</em> is the damping coefficient and <em>k</em> is the spring constant. According to this simple model, we were able to compute the force profile for the previously generated trajectories. The mass, the damping coefficient and the spring constant used for the method were theoretically estimated and were set equal to 0.1 Kg, 0.5 Ns/mm and 0.1 Ns/mm respectively. This force profile was then used as a reference for a proportional derivative control with visual tracking. Even if visual matching errors could occur during the movement, the haptic sensations felt by the user would be similar to what the expert felt during his interaction with the model. The proportional and derivative gains used were theoretically estimated and were set to 0.5N/mm and 0.1Ns/mm respectively.</p>


<h4>3. Control session without haptic guidance (NHG)</h4>
<a id="article1.body1.sec2.sec1.sec6.sec3.p1" name="article1.body1.sec2.sec1.sec6.sec3.p1"></a><p>To replicate learning through observation and manual repetition, no haptic assistance was provided to the participants during the training session. This task was similar to pre and post tests in which no haptic guidance was added.</p>




<h4>Experiment 2: Untrained ellipses</h4>
<h5>Participants.</h5><a id="article1.body1.sec2.sec2.sec1.p1" name="article1.body1.sec2.sec2.sec1.p1"></a><p>Participants were 24 right-handed adults, with no significant language, motor or neurological dysfunction. They were students from University in Grenoble and their age ranged from 18 to 28 years. The present study was conducted in accordance with the Declaration of Helsinki. It was conducted with the understanding and the written consent of each participant which was obtained and was approved by the local ethic committee.</p>

<h5>Experimental Setup.</h5><a id="article1.body1.sec2.sec2.sec2.p1" name="article1.body1.sec2.sec2.sec2.p1"></a><p>The experimental setup was the same as in Experiment 1.</p>

<h5>Pre-test and post tests.</h5><a id="article1.body1.sec2.sec2.sec3.p1" name="article1.body1.sec2.sec2.sec3.p1"></a><p>Participants were assessed before and after the training sessions in order to measure the visuo-manual tracking of letters. Participants were asked to trace with their right hand visually presented ellipses with the stylus as accurately and as promptly as possible. No feedback was given by the experimenter. Each participant followed 18 ellipses presented in pseudo random order. In total, there were therefore 18 trials in the pre test and 18 trials in the post-test.</p>

<h5>Characteristics of test Trajectories.</h5><a id="article1.body1.sec2.sec2.sec4.p1" name="article1.body1.sec2.sec2.sec4.p1"></a><p>In the pre and post tests, three target trajectories were derived from a base ellipse. Contrary to the Record-and-playback strategy <a href="#pone.0001775-Srimathveeravalli1">[12]</a>, where the base trajectories were recorded from a teacher, we have designed elliptical paths by controlling each parameter (size, velocity profile, number of points...). The shape of each ellipse varied from 6 to 2 cm in width and in height. The generation of these trajectories was made by a Scilab™ (<a href="http://www.scilab.org">www.scilab.org</a>) routine. Stimuli used for this experiment were composed of 1000 points (X,Y). Their velocity profiles followed the two-third power law <a href="#pone.0001775-Viviani2">[10]</a>, <a href="#pone.0001775-Lacquaniti1">[11]</a>, (<em>i.e.</em>, velocity V is proportional to the radius of curvature r of the trajectory: v = k * r<sup>−1/3</sup>; equivalent to angular velocity A is proportional to the curvature c of the trajectory: A = k * c<sup>2/3</sup>). Our generated trajectories were in adequacy with a trained-level movement skill. The untrained tested trajectories are shown (red curves) in <a href="#pone-0001775-g004">Figure 4</a>.</p>
<div class="figure" id="pone-0001775-g004"><div class="img"><a name="pone-0001775-g004" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001775.g004&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001775" data-uri="info:doi/10.1371/journal.pone.0001775.g004"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001775.g004&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001775.g004/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001775.g004/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001775.g004/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001775.g004/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001775.g004.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001775.g004/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001775.g004/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001775.g004.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 4.  <span>All ellipses used in experiment 2: In red, the three references trajectories used before and after each training session; In green and blue, the trajectories used during the training sessions, equidistant in the choice of their diagonals (eccentricity).</span></strong></p><span>doi:10.1371/journal.pone.0001775.g004</span></div>
<h5>Movement analysis.</h5><a id="article1.body1.sec2.sec2.sec5.p1" name="article1.body1.sec2.sec2.sec5.p1"></a><p>Three main criteria (number of velocity peaks, mean velocity and Shape matching) used to analyse the movements were the same as in Experiment 1.</p>

<h5>Training Sessions.</h5><a id="article1.body1.sec2.sec2.sec6.p1" name="article1.body1.sec2.sec2.sec6.p1"></a><p>Three training sessions-HGP, HGF and NHG-were proposed to each participants (the order was given by a Latin-square plan). There were 24 test trials in each training session. The trajectories used during the pre and post test were never encountered during the training sessions. This was done to provide variability during the training session. Ellipses used in training were generated using the same procedure as trajectories used in tests (cf. § Characteristics of Test Trajectories). Eighteen ellipses have been chosen around the three tested ones (see <a href="#pone-0001775-g004">Figure 4</a>). They appeared randomly during the training session. In total, each participant performed 72 trials. The three haptic guidance modes and parameters were similar to those found in Experiment 1 except for HGP, where the proportional and derivative gains were experimentally tuned to 0.6 N/mm and 0.2 Ns/mm for smoother sensations.</p>


</div>

<div id="section3" class="section"><a id="s3" name="s3" toc="s3" title="Results"></a><h3>Results</h3>
<h4>Experiment 1: Japanese and Arabic letters</h4>
<a id="article1.body1.sec3.sec1.p1" name="article1.body1.sec3.sec1.p1"></a><p>Preliminary analysis of variance (ANOVA) showed that the order of training sessions had no effect and did not interact with any other factors (all p&gt;.25). Then, for each criterion, ANOVA was performed with test (pre and post tests), and letter (L1: Arabic Letter 1, L2: Arabic Letter 2, L3: Japanese-inspired Letter 3 or L4: Japanese-inspired Letter 4) as within factors and training mode (HGF, HGP or NHG) as independent factors. Summary of raw data can be found in <a href="#pone-0001775-t001">Table 1</a>.</p>
<div class="figure" id="pone-0001775-t001"><div class="img"><a name="pone-0001775-t001" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001775.t001&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001775" data-uri="info:doi/10.1371/journal.pone.0001775.t001"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001775.t001&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001775.t001/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001775.t001/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001775.t001/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001775.t001/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001775.t001.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001775.t001/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001775.t001/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001775.t001.TIF"></span>)
                </a></li></ul></div><p><strong>Table 1.  <span>Summary of raw data of Experiment 1 (mean±SE).</span></strong></p><span>doi:10.1371/journal.pone.0001775.t001</span></div><h5>1. Number of velocity peaks.</h5><a id="article1.body1.sec3.sec1.sec1.p1" name="article1.body1.sec3.sec1.sec1.p1"></a><p>The main effect of letters was significant (F(3,66) = 11.20; p&lt;.05). Pre-planned contrasts showed (all p&lt;.05) that the number of velocity peaks increased with the type of letters: Letter 1 (m = 8.77), Letter 2 (m = 9.27), Letter 3 (m = 11.03) and Letter 4 (m = 10.02). This factor did not interact with training mode. The interaction between training session and period factors was significant (F(2,44) = 5,01; p&lt;.05). Post-hoc analyses (Tukey test; p&lt;.5) revealed a significant decrease of the number of velocity peaks for only HGF mode. However, no significant difference was observed for both HGP and NHG modes. Finally, the interaction between training mode and letter factors was not significant (F(6,102) = 1,15; p&gt;.25).</p>
<a id="article1.body1.sec3.sec1.sec1.p2" name="article1.body1.sec3.sec1.sec1.p2"></a><p>We have performed additional analysis in order to asses the effects of training mode on each test of letter type:</p>


<ul class="bulletlist">

<li>Arabic Letter 1 and Japanese-inspired Letter 3: No significant interaction between training mode and test;</li>

<li>Arabic Letter 2: The interaction between training mode and test was significant (F(2,44) = 6.14; p&lt;.05). Post-hoc analyses (Tukey test; p&lt;.05) revealed a significant decrease for HGF (Pre-test: m = 9.42; post-test m = 7.06) mode and no significant difference for NHG and HGP modes;</li>

<li>Japanese-inspired Letter 4: The interaction between training mode and test was significant (F(2,44) = 3.79; p&lt;.05). Post-hoc analyses (Tukey test; p&lt;.05) revealed a significant decrease for HGF (Pre-test: m = 11.12; post-test m = 8.86) mode (p&lt;.05) and no significant differences for NHG and HGP modes.</li>

</ul>
<h5>2. Mean velocity.</h5><a id="article1.body1.sec3.sec1.sec2.p1" name="article1.body1.sec3.sec1.sec2.p1"></a><p>The main effect of letters was significant (F(2,66) = 13.577; p&lt;.05). This factor did not interact with training mode. The interaction between training mode and test was significant (F(2,44) = 11.09; p&lt;.05). Post-hoc analyses (Tukey; p&lt;.05) revealed a significant increase of the mean velocity for only HGF mode. By contrast, no significant difference was observed for both HGP and NHG mode.</p>
<a id="article1.body1.sec3.sec1.sec2.p2" name="article1.body1.sec3.sec1.sec2.p2"></a><p>We have performed additional analysis in order to asses the effects of training mode on each test of letter type:</p>


<ul class="bulletlist">

<li>Arabic Letter 1: The interaction between training mode and test was significant (F(2,44) = 8.734;p&lt;.05). Post-hoc analyses (Tukey; p&lt;.05) revealed a significant decrease for HGF mode;</li>

<li>Arabic Letter 2: The interaction between training session and period factors was significant (F(2,44) = 13.135;p&lt;.05) Post-hoc analyses (Tukey test; p&lt;.05) revealed a significant increase for HGF;</li>

<li>Japanese-inspired Letter 3: The interaction between training mode and test was significant (F(2,44) = 11.559;p&lt;.05). Post-hoc analyses (Tukey test; p&lt;.05) revealed a significant increase for HGF mode and no significant differences for NHG and HGP modes;</li>

<li>Japanese-inspired Letter 4: The interaction between training mode and test was significant (F(2,44) = 7.744;p&lt;.05). Post-hoc analyses (Tukey test; p&lt;.05) revealed a significant increase for HGF mode and no significant differences for NHG and HGP modes.</li>

</ul>
<h5>3. Shape Matching Score.</h5><a id="article1.body1.sec3.sec1.sec3.p1" name="article1.body1.sec3.sec1.sec3.p1"></a><p>The main effect of letters was significant (F(3,66) = 277.01; p&lt;.05). This factor did not interact with training mode factor. The interaction between training mode and test was not significant (F(1,22) = 0.61; p&gt;.25). Complementary analyses per letters were then performed to precise the specific effect of training mode on each letter after training sessions and no significant effect was observed (all p&gt;.25).</p>
<a id="article1.body1.sec3.sec1.sec3.p2" name="article1.body1.sec3.sec1.sec3.p2"></a><p>In summary, the main results of this experiment revealed a significant reduction of the number of velocity peaks (for two among the four letters) and a significant increase on mean velocity through all the tested letters with HGF training. The results are concordant with our hypotheses, even though this type of haptic guidance appeared to be sensitive to the trajectories tested. Contrary to our hypotheses, no major effect on the number of velocity peaks and the mean velocity was found for HGP. It appears that HGP has no significantly beneficial effect on the fluidity of movements (even if trends of improvement were observed). No effect of NHG training was found on all criteria. Finally, none of the training modes effected shape matching criterion. Differences between our and previous results from literature could be explained by the different types of trajectories used. Moreover, it is possible that same trajectories for the training and the test could have weakened the power of the results. To test this hypothesis, we have investigated this relation in a more detailed experiment with specifically chosen trajectories. Moreover, we added variability in trajectories by changing the experimental protocol (tested and trained trajectories were not the same).</p>



<h4>Experiment 2: Untrained ellipses</h4>
<a id="article1.body1.sec3.sec2.p1" name="article1.body1.sec3.sec2.p1"></a><p>Preliminary analysis of variance (ANOVA) showed that the order of training sessions had no effect and did not interact with any other factors (all p&gt;.25). Then, for each criterion, ANOVA was performed with test (pre and post tests), and ellipse (E1, E2 or E3) as within factors and training mode (HGF, HGP or NHG) as independent factors. Summary of raw data can be found in <a href="#pone-0001775-t002">Table 2</a>.</p>
<div class="figure" id="pone-0001775-t002"><div class="img"><a name="pone-0001775-t002" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001775.t002&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001775" data-uri="info:doi/10.1371/journal.pone.0001775.t002"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001775.t002&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001775.t002/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001775.t002/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001775.t002/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001775.t002/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001775.t002.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001775.t002/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001775.t002/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001775.t002.TIF"></span>)
                </a></li></ul></div><p><strong>Table 2.  <span>Summary of raw data of Experiment 2 (mean±SE).</span></strong></p><span>doi:10.1371/journal.pone.0001775.t002</span></div><h5>1. Number of velocity peaks.</h5><a id="article1.body1.sec3.sec2.sec1.p1" name="article1.body1.sec3.sec2.sec1.p1"></a><p>The main effect of tested ellipses was significant (F(2,46) = 16.342; p&lt;.05). Pre-planned contrasts showed that the number of velocity peaks was lower for the circle (E2: m = 9.3) than the horizontal (E1: m = 13.2) and vertical (E2: m = 14.1) ellipses (F(1,23) = 19.67; p&lt;.01) This factor did not interact with training mode factor. The interaction between training mode and test was significant (F(2,46) = 8.86; p&lt;.05). Post-hoc analyses (Tukey test; p&lt;.05) revealed a significant decrease of the number of velocity peaks for both HGP and HGF mode. By contrast, no significant difference was observed for NHG mode.</p>

<h5>2. Mean velocity.</h5><a id="article1.body1.sec3.sec2.sec2.p1" name="article1.body1.sec3.sec2.sec2.p1"></a><p>The main effect of tested ellipses was significant (F(2,46) = 19.321; p&lt;.05). Pre-planned contrasts showed that the mean velocity was lower for the circle (E2: m = 4.70 cm/s) than the horizontal (E1: m = 5.86 cm/s) and vertical (E2: m = 5.77 cm/s) ellipses (F(1,23) = 30.53; p&lt;.05) This factor did not interact with training session factor. The interaction between training mode and test was significant (F(2,46) = 13.22; p&lt;.05). Post-hoc analyses (Tukey test; p&lt;.05) revealed a significant increase of mean velocity for only HGF mode. However, no significant difference was observed for both HGP mode and NHG mode.</p>

<h5>3. Shape Matching Score.</h5><a id="article1.body1.sec3.sec2.sec3.p1" name="article1.body1.sec3.sec2.sec3.p1"></a><p>The main effect of tested ellipses was significant (F(2,46) = 12.482; p&lt;.01). Pre-planned contrasts showed that the mean DTW shape matching score was lower for horizontal ellipse (E1: m = 20.13) and the circle (E2: m = 20.18) than vertical (E2: m = 27.53) ellipses (p&lt;.05). This factor did not interact with training mode. The interaction between training mode and test was not significant (<em>F</em>(2,46) = 0.45; p&gt;.25).</p>


</div>

<div id="section4" class="section"><a id="s4" name="s4" toc="s4" title="Discussion"></a><h3>Discussion</h3><a id="article1.body1.sec4.p1" name="article1.body1.sec4.p1"></a><p>The present study examined whether two well-known types of haptic guidance-HGP or HGF-improve the visuo-manual tracking of trajectories. The number of velocity peaks and mean velocity were the two criteria used to estimate the fluidity of movements. The results of Experiment 1, in which trained and tested movements were identical, showed that HGF mode reduced the number of velocity peaks for only two among four letters and increased mean velocity. These results were consistent with our hypotheses and within previous literature <a href="#pone.0001775-Srimathveeravalli1">[12]</a>, <a href="#pone.0001775-Morris1">[13]</a>. The other two modes, HGP and NHG, had no significant effect on these two performances criteria. Detailed analysis revealed similar effects of training modes, independent of the type of the letter: HGF improved performances whereas HGP and NHG showed no significant improvement. The lack of effect of HGP was not consistent with our hypotheses and results observed by Feygin <em>et al.</em> <a href="#pone.0001775-Feygin1">[2]</a> or Teo <em>et al.</em> <a href="#pone.0001775-Teo1">[4]</a>. The efficiency of haptic guidances with different difficulty levels of trajectories could be discussed in relation to the choice of parameters (proportional and derivative gains) because their respective influence is not clearly established.</p>
<a id="article1.body1.sec4.p2" name="article1.body1.sec4.p2"></a><p>In the second experiment, results showed that both HGF and HGP reduced the number of peaks during visuo-manual tracking of the test ellipses. These results were in concordance with our hypotheses and extended the results of Palluel-Germain <em>et al.</em> <a href="#pone.0001775-PalluelGermain1">[5]</a> with children. In the control group (NHG), it seems that visual feedback alone was not enough to improve the performance. However, only HGF mode increased the mean velocity on test ellipses in contrast to NHG and HGP modes. This showed that HGF better improved the fluidity of movements than HGP. Contrary to our results, Palluel-Germain <em>et al.</em> <a href="#pone.0001775-PalluelGermain1">[5]</a> observed that HGP increased mean velocity with children. This suggests that HGP may be less suitable for adults since adults would have better knowledge of the shape they had to draw and better kinesthetic control of their upper limbs. The global superiority of HGF over HGP suggested that learned information for this specific motor activity could be stored as internal inverse model and encoded in force coordinates as suggested by Krakauer <a href="#pone.0001775-Krakauer1">[17]</a>. This suggests taking into account the type of feedback information included in these internal models because the effects of visual, position or force information were non equivalent. Thus, kinematics information could be encoded in reference to force coordinates rather than spatial Cartesian coordinates. We could also discuss these results with respect to different internal representation stages of motor knowledge, which evolve from children to adults (creation of internal representation-internal inverse models <a href="#pone.0001775-Kawato1">[18]</a> or generalized motor plan- or adjustment of this knowledge). Moreover, our results could be explained by the generalization of shapes during training session that helped to integrate these trajectories. By providing several training trajectories, adjustment of internal representations could be more involved and thereby improved. This proposes that a motor learning task (as drawing) would be improved by variability of required movements as evidenced in sports <a href="#pone.0001775-Bartlett1">[19]</a>. Further questions remain unanswered: As human handwriting production is variable by nature, would a handwriting training with variability in letters be efficient? In which way can we introduce variability in letters? Could variability within the letters be a set of several letters produced by experts? Further theoretical definition of variability needs to be investigated.</p>
<a id="article1.body1.sec4.p3" name="article1.body1.sec4.p3"></a><p>Finally, Dynamic Time Warping (DTW) score gives a score (level) of shape matching between two trajectories: Expected and recorded trajectories. This criterion was used in previous studies <a href="#pone.0001775-Srimathveeravalli1">[12]</a> to assess the effect of haptic training on the shape of a trajectory. In both experiments, no effect of training modes on the shape matching criterion was found. These former results did not confirm the effect on shape matching observed by Srimathveeravalli et al <a href="#pone.0001775-Srimathveeravalli1">[12]</a>. The lack of improvement could be explained by a “ceiling effect” on the shape matching criterion, due to expert ability of adults and by different experimental designs (the authors <a href="#pone.0001775-Srimathveeravalli1">[12]</a> hide the model trajectory during recall phase, thereby suppressing any visual help).</p>
<a id="article1.body1.sec4.p4" name="article1.body1.sec4.p4"></a><p>In conclusion, we found a positive global effect of the HGF mode on the fluidity of movements in the two experiments. The superiority of this type of haptic guidance suggests that position information is mainly given by visual modality (no improvement of shape by adding haptic guidance) and kinematics information is given by haptic modality, probably encoded in force coordinates. Moreover, this study explored the use of variability in learning sessions: knowledge extracted from a set of trajectories (elliptical paths) during the training period of haptic guidance can be applied to unfamiliar trajectories of the same type, suggesting a generalization process.</p>
</div>





<div><a id="ack" name="ack" toc="ack" title="Acknowledgments"></a><h3>Acknowledgments</h3>
<a id="article1.back1.ack1.p1" name="article1.back1.ack1.p1"></a><p>We thank the student of psychology of University Pierre Mendès France who participated in the experimental study. We also thank Sophie Zijp-Rouzier and Nicolas Tarrin for their fruitful collaboration. Finally, we sincerely thank Jean-françois Cuniberto for his useful help building the physical setup and Richard Palluel-Germain, David Meary, Sylvette Maniguet and Inna Tsirlin for their help.</p>
</div><div class="contributions"><a id="authcontrib" name="authcontrib" toc="authcontrib" title="Author Contributions"></a><h3>Author Contributions</h3><p>Conceived and designed the experiments: EG JB. Performed the experiments: JB. Analyzed the data: JB. Contributed reagents/materials/analysis tools: JB. Wrote the paper: EG JB SC YP.</p></div><div><a id="references" name="references" toc="references" title="References"></a><h3>References</h3><ol class="references"><li><span class="label">1.
              </span><a name="pone.0001775-Schmidt1" id="pone.0001775-Schmidt1"></a>Schmidt RA (1987) Motor control and learning: A behavioural emphasis, Second ed. Champaign, IL: Human Kinetics.   <ul class="find-nolinks"></ul></li><li><span class="label">2.
              </span><a name="pone.0001775-Feygin1" id="pone.0001775-Feygin1"></a>Feygin D, Keehner M, Tendick R (2002) Haptic guidance: experimental evaluation of a haptic training method for a perceptual motor skill. In proceedings of 10th Haptic Interfaces for Virtual Environment and Teleoperator Systems, 40–47.  <ul class="find" data-citedArticleID="1072478" data-doi="10.1109/haptic.2002.998939"><li><a href="http://dx.doi.org/10.1109/haptic.2002.998939" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Haptic+guidance%3A+experimental+evaluation+of+a+haptic+training+method+for+a+perceptual+motor+skill." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Haptic+guidance%3A+experimental+evaluation+of+a+haptic+training+method+for+a+perceptual+motor+skill.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">3.
              </span><a name="pone.0001775-Liu1" id="pone.0001775-Liu1"></a>Liu J, Cramer S, Reinkensmeyer D (2006) Learning to perform a new movement with robotic assistance: comparison of haptic guidance and visual demonstration. J Neuroengineering Rehabil,  3(1743-0003 (Electronic)): 20.  <ul class="find" data-citedArticleID="1072490"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=Learning+to+perform+a+new+movement+with+robotic+assistance%3A+comparison+of+haptic+guidance+and+visual+demonstration.&amp;auth=&amp;atitle=Learning+to+perform+a+new+movement+with+robotic+assistance%3A+comparison+of+haptic+guidance+and+visual+demonstration." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Learning+to+perform+a+new+movement+with+robotic+assistance%3A+comparison+of+haptic+guidance+and+visual+demonstration." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Learning+to+perform+a+new+movement+with+robotic+assistance%3A+comparison+of+haptic+guidance+and+visual+demonstration.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">4.
              </span><a name="pone.0001775-Teo1" id="pone.0001775-Teo1"></a>Teo CL, Burdet E, Lim HP (2002) A robotic teacher of chinese handwriting. In proceedings of 10<sup>th</sup> Haptic Interfaces for Virtual Environment and Teleoperator Systems, 335–341.  <ul class="find" data-citedArticleID="1072504" data-doi="10.1109/haptic.2002.998977"><li><a href="http://dx.doi.org/10.1109/haptic.2002.998977" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=A+robotic+teacher+of+chinese+handwriting." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22A+robotic+teacher+of+chinese+handwriting.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">5.
              </span><a name="pone.0001775-PalluelGermain1" id="pone.0001775-PalluelGermain1"></a>Palluel-Germain R, Bara F, Hillairet de Boisferon A, Hennion B, Gouagout P, Gentaz E (2007) A Visuo-haptic device - Telemaque - increases kindergarten children's handwriting acquisition. In proceedings of IEEE World Haptics 2007, 72–77.  <ul class="find" data-citedArticleID="1072496" data-doi="10.1109/whc.2007.13"><li><a href="http://dx.doi.org/10.1109/whc.2007.13" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=A+Visuo-haptic+device+-+Telemaque+-+increases+kindergarten+children%27s+handwriting+acquisition." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22A+Visuo-haptic+device+-+Telemaque+-+increases+kindergarten+children%27s+handwriting+acquisition.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">6.
              </span><a name="pone.0001775-Solis1" id="pone.0001775-Solis1"></a>Solis J, Avizzano CA, Bergamasco M (2002) Teaching to write japanese characters using a haptic interface. In proceedings of 10th Haptic Interfaces for Virtual Environment and Teleoperator Systems, 255–262.  <ul class="find" data-citedArticleID="1072500" data-doi="10.1109/haptic.2002.998966"><li><a href="http://dx.doi.org/10.1109/haptic.2002.998966" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Teaching+to+write+japanese+characters+using+a+haptic+interface." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Teaching+to+write+japanese+characters+using+a+haptic+interface.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">7.
              </span><a name="pone.0001775-Henmi1" id="pone.0001775-Henmi1"></a>Henmi K, Yoshikawa T (1998) Virtual lesson and its application to virtual calligraphy system. In proceedings of Robotics and Automation,  2: 1275–1280.  <ul class="find" data-citedArticleID="1072482" data-doi="10.1109/robot.1998.677278"><li><a href="http://dx.doi.org/10.1109/robot.1998.677278" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Virtual+lesson+and+its+application+to+virtual+calligraphy+system." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Virtual+lesson+and+its+application+to+virtual+calligraphy+system.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">8.
              </span><a name="pone.0001775-Gillespie1" id="pone.0001775-Gillespie1"></a>Gillespie PTCPB, O'Modhrain S, Zaretsky D (1998) The virtual teacher. In ASME International Mechanical Engineering Conference and Exposition,  64: 171–174.  <ul class="find" data-citedArticleID="1072480"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=The+virtual+teacher.&amp;auth=&amp;atitle=The+virtual+teacher." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+virtual+teacher." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+virtual+teacher.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">9.
              </span><a name="pone.0001775-Viviani1" id="pone.0001775-Viviani1"></a>Viviani P, Schneider R (1991) A developmental study of the relationship between geometry and kinematics in drawing movements. Journal of Experimental Psychology: Human Perception and Performance,  17(1): 198–218.  <ul class="find" data-citedArticleID="1072506" data-doi="10.1037/0096-1523.17.1.198"><li><a href="http://dx.doi.org/10.1037/0096-1523.17.1.198" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=A+developmental+study+of+the+relationship+between+geometry+and+kinematics+in+drawing+movements." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22A+developmental+study+of+the+relationship+between+geometry+and+kinematics+in+drawing+movements.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">10.
              </span><a name="pone.0001775-Viviani2" id="pone.0001775-Viviani2"></a>Viviani P, Terzuolo C (1982) Trajectory determines movement kinematics. Neuroscience,  7(2): 431–437.  <ul class="find" data-citedArticleID="1072508" data-doi="10.1016/0306-4522(82)90277-9"><li><a href="http://dx.doi.org/10.1016/0306-4522(82)90277-9" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Trajectory+determines+movement+kinematics." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Trajectory+determines+movement+kinematics.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">11.
              </span><a name="pone.0001775-Lacquaniti1" id="pone.0001775-Lacquaniti1"></a>Lacquaniti F, Terzuolo C, Viviani P (1983) The law relating the kinematic and figural aspects of drawing movements. Acta Psychologica,  54(1-3): 115–130.  <ul class="find" data-citedArticleID="1072488" data-doi="10.1016/0001-6918(83)90027-6"><li><a href="http://dx.doi.org/10.1016/0001-6918(83)90027-6" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+law+relating+the+kinematic+and+figural+aspects+of+drawing+movements." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+law+relating+the+kinematic+and+figural+aspects+of+drawing+movements.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">12.
              </span><a name="pone.0001775-Srimathveeravalli1" id="pone.0001775-Srimathveeravalli1"></a>Srimathveeravalli G, Thenkurussi K (2005) Motor skill training assistance using haptic attributes. In proceedings of Haptic Interfaces for Virtual Environment and Teleoperator Systems,WHC, 452–457.  <ul class="find" data-citedArticleID="1072502" data-doi="10.1109/whc.2005.96"><li><a href="http://dx.doi.org/10.1109/whc.2005.96" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Motor+skill+training+assistance+using+haptic+attributes." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Motor+skill+training+assistance+using+haptic+attributes.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">13.
              </span><a name="pone.0001775-Morris1" id="pone.0001775-Morris1"></a>Morris D, Tan H, Barbagli F, Chang T, Salisbury K (2007) Haptic feedback enhances force skill learning. In proceedings of EuroHaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, 21–26.  <ul class="find" data-citedArticleID="1072492" data-doi="10.1109/whc.2007.65"><li><a href="http://dx.doi.org/10.1109/whc.2007.65" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Haptic+feedback+enhances+force+skill+learning." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Haptic+feedback+enhances+force+skill+learning.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">14.
              </span><a name="pone.0001775-Yokokohji1" id="pone.0001775-Yokokohji1"></a>Yokokohji Y, Hollis RL, Kanade T (1996) What you can see is what you can feel-development of a visual/haptic interface to virtual environment. In proceedings of Virtual Reality Annual International Symposium,  265: 46–53.  <ul class="find" data-citedArticleID="1072510" data-doi="10.1109/vrais.1996.490509"><li><a href="http://dx.doi.org/10.1109/vrais.1996.490509" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=What+you+can+see+is+what+you+can+feel-development+of+a+visual%2Fhaptic+interface+to+virtual+environment." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22What+you+can+see+is+what+you+can+feel-development+of+a+visual%2Fhaptic+interface+to+virtual+environment.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">15.
              </span><a name="pone.0001775-Conti1" id="pone.0001775-Conti1"></a>Conti F (2003) The CHAI Libraries. In Eurohaptics '03.   <ul class="find" data-citedArticleID="1072476"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=The+CHAI+Libraries.&amp;auth=&amp;atitle=The+CHAI+Libraries." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+CHAI+Libraries." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+CHAI+Libraries.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">16.
              </span><a name="pone.0001775-Niels1" id="pone.0001775-Niels1"></a>Niels R (2004) Dynamic Time Warping: An intuitive way of handwriting recognition? Radboud University Nijmegen, Faculty of Social Sciences, Department of Artificial Intelligence/Cognitive Science.   Master's thesis.  <ul class="find-nolinks"></ul></li><li><span class="label">17.
              </span><a name="pone.0001775-Krakauer1" id="pone.0001775-Krakauer1"></a>Krakauer JW, Ghilardi M, Ghez C (1999) Independent learning of internal models for kinematic and kynematic control of reaching. Nature Neuroscience,  2: 1026–1031.  <ul class="find" data-citedArticleID="1072486" data-doi="10.1038/14826"><li><a href="http://dx.doi.org/10.1038/14826" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Independent+learning+of+internal+models+for+kinematic+and+kynematic+control+of+reaching." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Independent+learning+of+internal+models+for+kinematic+and+kynematic+control+of+reaching.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">18.
              </span><a name="pone.0001775-Kawato1" id="pone.0001775-Kawato1"></a>Kawato M (1999) Internal models for motor control and trajectory planning. Current Opinion in Neurobiology,  9: 718–727.  <ul class="find" data-citedArticleID="1072484" data-doi="10.1016/s0959-4388(99)00028-8"><li><a href="http://dx.doi.org/10.1016/s0959-4388(99)00028-8" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Internal+models+for+motor+control+and+trajectory+planning." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Internal+models+for+motor+control+and+trajectory+planning.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">19.
              </span><a name="pone.0001775-Bartlett1" id="pone.0001775-Bartlett1"></a>Bartlett R, Wheat J, Robins M (2007) Is movement variability important for sports biomechanists? Sports Biomecanics,  6: 224–243.  <ul class="find" data-citedArticleID="1072474" data-doi="10.1080/14763140701322994"><li><a href="http://dx.doi.org/10.1080/14763140701322994" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Is+movement+variability+important+for+sports+biomechanists%3F" target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Is+movement+variability+important+for+sports+biomechanists%3F%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li></ol></div>

  </div>

      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.XML" value="66687"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.PDF" value="257507"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.g001.PNG_L" value="250504"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.g001.PNG_M" value="92252"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.g001.PNG_S" value="8694"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.g001.TIF" value="362196"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.g001.PNG_I" value="33499"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.g002.PNG_L" value="2611194"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.g002.PNG_M" value="396489"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.g002.PNG_S" value="18763"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.g002.TIF" value="3320226"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.g002.PNG_I" value="206624"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.g003.PNG_L" value="546151"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.g003.PNG_M" value="69347"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.g003.PNG_S" value="6960"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.g003.TIF" value="1291122"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.g003.PNG_I" value="25541"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.e001.PNG" value="7213"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.e001.TIF" value="23092"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.g004.PNG_L" value="364235"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.g004.PNG_M" value="125641"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.g004.PNG_S" value="9287"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.g004.TIF" value="571218"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.g004.PNG_I" value="42359"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.t001.PNG_L" value="72270"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.t001.PNG_M" value="47805"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.t001.PNG_S" value="9037"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.t001.TIF" value="333312"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.t001.PNG_I" value="14580"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.t002.PNG_L" value="75013"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.t002.PNG_M" value="47660"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.t002.PNG_S" value="9140"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.t002.TIF" value="350784"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001775.t002.PNG_I" value="14496"/>

</div>
<div class="sidebar">

  <div class="article-actions cf">
      <div class="download">
        <span class="btn"><a href="/article/fetchObject.action?uri=info%3Adoi%2F10.1371%2Fjournal.pone.0001775&amp;representation=PDF" title="Download" target="_blank">Download PDF</a></span>
      </div>
      <div class="btn-reveal dropdown">
        <div class="dropdown-icon">
          <span class="btn">&nbsp;</span>
        </div>

        <div class="content">
          <ul class="bullet">
            <li><a href="/article/citationList.action?articleURI=info%3Adoi%2F10.1371%2Fjournal.pone.0001775" title="Download citations">Citation</a></li>
            <li><a href="/article/fetchObjectAttachment.action?uri=info%3Adoi%2F10.1371%2Fjournal.pone.0001775&amp;representation=XML" title="Download article XML">XML</a></li>
          </ul>
        </div>
      </div> <!-- end btn-reveal dropdown-->


    <div class="btn-reveal flt-l">
        <span class="btn">Print</span>
        <div class="content">
            <ul class="bullet">
                <li id="print-article"><a href="#" onclick="if(typeof(_gaq) != 'undefined'){ _gaq.push(['_trackEvent','Article', 'Print', 'Click']); } window.print(); return false;" title="Print Article">Print article</a></li>
                <li>
                  <a href="https://www.odysseypress.com/onlinehost/reprint_order.php?type=A&page=0&journal=7&doi=10.1371/journal.pone.0001775&volume=&issue=&title=Haptic Guidance Improves the Visuo-Manual Tracking of Trajectories&author_name=J%C3%A9r%C3%A9my%20Bluteau%2C%20Sabine%20Coquillart%2C%20Yohan%20Payan%2C%20Edouard%20Gentaz&start_page=1&end_page=7" title="Odyssey Press">EzReprint</a>
                </li>
            </ul>
        </div>
    </div>

    <div class="btn-reveal flt-r">
        <span class="btn">Share</span>
        <div class="content">
            <ul class="social">
                <li><a href="http://www.reddit.com/submit?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001775" target="_blank" title="Submit to Reddit"><img src="/images/icon.reddit.16.png" width="16" height="16" alt="Reddit">Reddit</a></li>

                <li><a href="https://plus.google.com/share?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001775" target="_blank" title="Share on Google+"><img src="/images/icon.gplus.16.png" width="16" height="16" alt="Google+">Google+</a></li>

                <li><a href="http://www.stumbleupon.com/submit?url=http%3A%2F%2Fwww.plosone.org%2Farticle%2Finfo%253Adoi%252F10.1371%252Fjournal.pone.0001775" target="_blank" title="Add to StumbleUpon"><img src="/images/icon.stumble.16.png" width="16" height="16" alt="StumbleUpon">StumbleUpon</a></li>

                <li><a href="http://www.facebook.com/share.php?u=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001775&amp;t=Haptic%20Guidance%20Improves%20the%20Visuo-Manual%20Tracking%20of%20Trajectories" target="_blank" title="Share on Facebook"><img src="/images/icon.fb.16.png" width="16" height="16" alt="Facebook">Facebook</a></li>

                <li><a href="http://www.linkedin.com/shareArticle?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001775&title=Haptic%20Guidance%20Improves%20the%20Visuo-Manual%20Tracking%20of%20Trajectories&summary=Checkout%20this%20article%20I%20found%20at%20PLOS" target="_blank" title="Add to LinkedIn"><img src="/images/icon.linkedin.16.png" width="16" height="16" alt="Mendeley">LinkedIn</a></li>

                <li><a href="http://www.citeulike.org/posturl?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001775&amp;title=Haptic%20Guidance%20Improves%20the%20Visuo-Manual%20Tracking%20of%20Trajectories" target="_blank" title="Add to CiteULike"><img src="/images/icon.cul.16.png" width="16" height="16" alt="CiteULike">CiteULike</a></li>

                <li><a href="http://www.mendeley.com/import/?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001775" target="_blank" title="Add to Mendeley"><img src="/images/icon.mendeley.16.png" width="16" height="16" alt="Mendeley">Mendeley</a></li>

                <li><a href="https://www.pubchase.com/library?add_aid=10.1371%2Fjournal.pone.0001775&amp;source=plos" target="_blank" title="Add to PubChase"><img src="/images/icon.pc.16.png" width="16" height="16" alt="PubChase">PubChase</a></li>


                <script type="text/javascript">
                    // replace tweet with one that's pre-shortened to 140 chars
                    function truncateTweetText() {
                        var twtTitle = 'Haptic Guidance Improves the Visuo-Manual Tracking of Trajectories';
                        var twtUrl = 'http://dx.plos.org/10.1371/journal.pone.0001775';
                        // all URLs posted to twitter get auto-shortened to 20 chars.
                        var maxLength = 140 - (20 + 1);
                        // truncate the title to include space for twtTag and ellipsis (here, 10 = tag length + space + ellipsis)
                        if (twtTitle.length > maxLength) { twtTitle = twtTitle.substr(0, (maxLength - 10)) + '...'; }
                        // set the href to use the shortened tweet
                        $('#twitter-share-link').prop('href', 'http://twitter.com/intent/tweet?text=' + encodeURIComponent('#PLOSONE: ' + twtTitle + ' ' + twtUrl));
                    }
                </script>
                <li><a href="http://twitter.com/intent/tweet?text=#PLOSONE%3A%20Haptic%20Guidance%20Improves%20the%20Visuo-Manual%20Tracking%20of%20Trajectories http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001775" onclick="truncateTweetText();" target="_blank" title="Share on Twitter" id="twitter-share-link"><img src="/images/icon.twtr.16.png" width="16" height="16" alt="Twitter">Twitter</a></li>

                <li><a href="/article/email/info%3Adoi%2F10.1371%2Fjournal.pone.0001775" title="Email this article"><img src="/images/icon.email.16.png" width="16" height="16" alt="Email">Email</a></li>
            </ul>
        </div>
    </div><!--end btn-reveal flt-r-->
</div><!-- end article-actions-->

<!-- begin Crossmark -->

<a id="open-crossmark" href="#" style="margin-top: -28px; display:block"><img style="border: 0; display: none;
 padding: 10px 0 18px 0;"  id="crossmark-icon" src="/images/logo-crossmark-bw.png" /></a>
<div id="crossmark-dialog" style="display: none;" title="">
    <!-- the external CrossMark data is loaded inside this iframe -->
    <iframe id="crossmark-dialog-frame" frameborder="0"></iframe>
</div>

<!-- end crossmark -->


<div class="block" id="subject-area-sidebar-block">
    <div class="header">
        <h3>Subject Areas</h3><div title="More information" id="subject-area-sidebar-block-help-icon"><img align="right"
                                                                                                           alt="info" src="/images/button_info.png"/><div id="subject-area-sidebar-block-help"><img align="right"
                                                                                                                                                                                                    src="/images/button_info.png"/><p>
        <b>We want your feedback.</b> Do these subject areas make sense for this article? If not, click the flag
        next to the incorrect subject area and we will review it. Thanks for your help!
    </p></div></div>
    </div>


    <ul id="subject-area-sidebar-list">
















          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Analysis+of+variance%22" title="Search for articles in the subject area:'Analysis of variance'"><div class="flagText">Analysis of variance</div></a>
              <div data-categoryid="42193" data-articleid="26374"
                   data-categoryname="Analysis of variance"
                   class="flagImage" title="Flag 'Analysis of variance' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Children%22" title="Search for articles in the subject area:'Children'"><div class="flagText">Children</div></a>
              <div data-categoryid="40327" data-articleid="26374"
                   data-categoryname="Children"
                   class="flagImage" title="Flag 'Children' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Ellipses%22" title="Search for articles in the subject area:'Ellipses'"><div class="flagText">Ellipses</div></a>
              <div data-categoryid="32735" data-articleid="26374"
                   data-categoryname="Ellipses"
                   class="flagImage" title="Flag 'Ellipses' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Human+learning%22" title="Search for articles in the subject area:'Human learning'"><div class="flagText">Human learning</div></a>
              <div data-categoryid="34727" data-articleid="26374"
                   data-categoryname="Human learning"
                   class="flagImage" title="Flag 'Human learning' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Kinematics%22" title="Search for articles in the subject area:'Kinematics'"><div class="flagText">Kinematics</div></a>
              <div data-categoryid="20035" data-articleid="26374"
                   data-categoryname="Kinematics"
                   class="flagImage" title="Flag 'Kinematics' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Learning%22" title="Search for articles in the subject area:'Learning'"><div class="flagText">Learning</div></a>
              <div data-categoryid="20059" data-articleid="26374"
                   data-categoryname="Learning"
                   class="flagImage" title="Flag 'Learning' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Teachers%22" title="Search for articles in the subject area:'Teachers'"><div class="flagText">Teachers</div></a>
              <div data-categoryid="46211" data-articleid="26374"
                   data-categoryname="Teachers"
                   class="flagImage" title="Flag 'Teachers' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Velocity%22" title="Search for articles in the subject area:'Velocity'"><div class="flagText">Velocity</div></a>
              <div data-categoryid="19713" data-articleid="26374"
                   data-categoryname="Velocity"
                   class="flagImage" title="Flag 'Velocity' as inappropriate"></div>
          </li>
    </ul>
</div>

<div class="ad">
    <div class="title">Advertisement</div>






  <iframe id='a0852f54' name='a0852f54'
    src='http://ads.plos.org/www/delivery/afr.php?zoneid=381&amp;cb=290'
    frameborder='0' scrolling='no' width='160' height='600'>
    <a href='http://ads.plos.org/www/delivery/ck.php?n=a0852f54&amp;cb=208'
      target='_top'><img src='http://ads.plos.org/www/delivery/avw.php?zoneid=381&amp;cb=9417&amp;n=a0852f54'
      border='0' alt=''/>
    </a>
  </iframe>



</div>

<div id="twitter-alm-timeline" class="twitter-alm-timeline"></div>

<div class="block sidebar-comments">
    <div class="header">
        <h3>Comments</h3>
    </div>
      <p><a href="/annotation/listThread.action?root=8909">Referee comments: Referee 1 (Carl P.T. Jackson)</a><br>Posted by PLoS_ONE_Group</p>
</div>

</div><!-- sidebar -->
    </div>
  </div>
</div>
<script src="http://wl.figshare.com/static/p_widget.js" type="text/javascript"></script><div id="pageftr">
  <div class="ftr-cols cf">
    <div class="col col-1">
      <img src="/images/logo-plos-footer.png" alt="PLOS Logo" class="logo" />
      <p><a href="/static/releaseNotes">Ambra 2.9.16</a> Managed Colocation provided <br />by <a href="http://www.isc.org/">Internet Systems Consortium</a>.<p>
      <div class="nav nav-aux">
        <a href="/static/privacy">Privacy Policy</a> |
        <a href="/static/terms">Terms of Use</a> |
        <a href="http://www.plos.org/advertise/">Advertise</a> |
        <a href="http://www.plos.org/about/media-inquiries/">Media Inquiries</a>
      </div>
    </div>
    <div class="col col-2">
      <p><a href="http://www.plos.org/publications/journals/">Publications</a></p>
      <div class="nav">
        <ul>
          <li><a href="http://www.plosbiology.org">PLOS Biology</a></li>
          <li><a href="http://www.plosmedicine.org">PLOS Medicine</a></li>
          <li><a href="http://www.ploscompbiol.org">PLOS Computational Biology</a></li>
          <li><a href="http://currents.plos.org">PLOS Currents</a></li>
          <li><a href="http://www.plosgenetics.org">PLOS Genetics</a></li>
          <li><a href="http://www.plospathogens.org">PLOS Pathogens</a></li>
          <li><a href="http://www.plosone.org">PLOS ONE</a></li>
          <li><a href="http://www.plosntds.org">PLOS Neglected Tropical Diseases</a></li>
        </ul>
      </div>
    </div>
    <div class="col col-3">
      <div class="nav">
        <p><a href="http://www.plos.org">plos.org</a></p>
        <p><a href="http://blogs.plos.org">Blogs</a></p>
        <p><a href="http://www.ploscollections.org">Collections</a></p>
        <p><a href="/feedback/new">Send us feedback</a></p>

        <p>California (US) corporation #C2354500, based in San Francisco</p>
      </div>
    </div>
  </div>
</div><!-- pageftr -->

</div><!-- end page-wrap, this div is in header.ftl -->
<script type="text/javascript" src="/javascript/jquery-1.8.1-min.js?v=Tm7VCOzZz3lE03ghpkS6SWkHbyI"></script>
<script type="text/javascript" src="/javascript/ga-min.js?v=lNQ4gt8QcPDatjsdOFl_FGpPhLY"></script>
<script type="text/javascript" src="/javascript/jquery.hoverIntent-min.js?v=mRiGNYY9cIXxVb8u0K_MdW7hHnc"></script>
<script type="text/javascript" src="/javascript/jquery.placeholder-min.js?v=21Pn56Ur9h1N4K4VZDa0nqI3Pxo"></script>
<script type="text/javascript" src="/javascript/jquery.jsonp-2.4.0-min.js?v=lqTpzoHfSq3I5Ygo01qq5WankEo"></script>
<script type="text/javascript" src="/javascript/jquery-ui-1.9.2.custom-min.js?v=raSSlfNO0YsV5uUpAKmTB9n5VTc"></script>
<script type="text/javascript" src="/javascript/jquery.tooltip-min.js?v=cw+6Smh+mdryIA25xvqIvHMrnZM"></script>
<script type="text/javascript" src="/javascript/jquery.uniform-min.js?v=kYUAnX6W2W_2fK3RIuQ2m_YFG9U"></script>
<script type="text/javascript" src="/javascript/jquery.pjax-min.js?v=939kLBjL5_YKbx71T1RHjYaD4l8"></script>
<script type="text/javascript" src="/javascript/imagesloaded-min.js?v=XeuAp8Gc3mvQUo+wZCSF8ttPwvw"></script>
<script type="text/javascript" src="/javascript/figviewer-min.js?v=yPUa0sUQ_iHkI+IRv2i9bjyZJFo"></script>
<script type="text/javascript" src="/javascript/global-min.js?v=0Q3PwjeaWtXYDnqIsQvnL_ou0qs"></script>
<script type="text/javascript" src="/javascript/jquery.touchswipe-min.js?v=huaek_e6HqTduvCNAN91dJolTyw"></script>
<script type="text/javascript" src="/javascript/jquery.base64-min.js?v=VwV1zeVqKZj5FCAdlK0q5NRxbBg"></script>
<script type="text/javascript" src="/javascript/alm-min.js?v=Y5gm6B0b4Kx2YHNObNrgEeBgXlY"></script>
<script type="text/javascript" src="/javascript/taxonomy-browser-min.js?v=vBVMuDMYkGJCXIUxLe35GoyiJNw"></script>
<script type="text/javascript" src="/javascript/jquery.filterize-min.js?v=j0ZKVnHyk2nhFy8eIuNJkp7xaM0"></script>
<script type="text/javascript" src="/javascript/plosone-min.js?v=TK4H4arL_XBSwwJq+K1N3kqYfAI"></script>
<script type="text/javascript" src="/javascript/twitter-min.js?v=xKgcxLsQFXy+at1ao1NVke8nFlM"></script>
<script type="text/javascript" src="/javascript/crossmark.1.4-min.js?v=3FO4k0SjwTaGNnKGNSqthar1080"></script>
<script type="text/javascript">
  var _sf_async_config={uid:16579,domain:"plosone.org"};
  (function(){
    function loadChartbeat() {
      window._sf_endpt=(new Date()).getTime();
      var e = document.createElement('script');
      e.setAttribute('language', 'javascript');
      e.setAttribute('type', 'text/javascript');
      e.setAttribute('src',
          (("https:" == document.location.protocol) ? "https://a248.e.akamai.net/chartbeat.download.akamai.com/102508/" : "http://static.chartbeat.com/") +
              "js/chartbeat.js");
      document.body.appendChild(e);
    }
    var oldonload = window.onload;
    window.onload = (typeof window.onload != 'function') ?
        loadChartbeat : function() { oldonload(); loadChartbeat(); };
  })();
</script>
<!-- <script type="application/javascript" src="http://crossmark.crossref.org/javascripts/v1.3/crossmark.min.js"></script> -->

</body>
</html>
