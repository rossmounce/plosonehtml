

 



<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"
      xmlns:foaf="http://xmlns.com/foaf/0.1/"
      xmlns:dc="http://purl.org/dc/terms/"
      xmlns:doi="http://dx.doi.org/"
      xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
      xmlns:xsd="http://www.w3.org/2001/XMLSchema-datatypes#"
      lang="en" xml:lang="en"
      itemscope itemtype="http://schema.org/Article"
      class="no-js">
<head prefix="og: http://ogp.me/ns#">
  <title>PLOS ONE: The Grasping Side of Odours</title>


<link rel="stylesheet" type="text/css"  href="/css/global-min.css?v=izteQ6tu7kgsJZW_xmrYizvKiHM" />


    <!--[if lte IE 7]>
<link rel="stylesheet" type="text/css"  href="/css/lte_ie7-min.css?v=3bykQUyQmReeuobVyPozcJ9LxRc" />
    <![endif]-->


<link rel="stylesheet" type="text/css"  href="/css/jquery-ui-min.css?v=eXDHTEJM0lIAmDe5k0I0Ad4nxNo" />


<link rel="stylesheet" type="text/css"  href="/css/journal.css?v=T7ZVxJfgk9jNxLAJ2qHz1vZpgYU" />


<link rel="stylesheet" type="text/css" media="print" href="/css/print-min.css?v=T5lb0B3q6EXBsuDluc5V5w+AkRc" />


  <link rel="stylesheet" href="http://f.fontdeck.com/s/css/js/www.plosone.org/24557.css" type="text/css"/>

  <!--chartbeat -->
  <script type="text/javascript">var _sf_startpt = (new Date()).getTime()</script>
  <script>document.documentElement.className += ' js';</script>

  <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <meta http-equiv="X-UA-Compatible" content="IE=EmulateIE7; IE=EmulateIE9"/>
  <meta name="description" content="PLOS ONE: an inclusive, peer-reviewed, open-access resource from the PUBLIC LIBRARY OF SCIENCE. Reports of well-performed scientific studies from all disciplines freely available to the whole world."/>
  <meta name="keywords" content="PLOS, Public Library of Science, Open Access, Open-Access, Science, Medicine, Biology, Research, Peer-review, Inclusive, Interdisciplinary, Ante-disciplinary, Physics, Chemistry, Engineering"/>
  <meta name="almHost" content="http://alm.plos.org/api/v3/articles"/>
  <meta name="searchHost" content="http://api.plos.org/search" />
  <meta name="termsHost" content="http://api.plos.org/terms" />
  <meta name="solrApiKey" content="plos"/>
  <meta name="almAPIKey" content="3pezRBRXdyzYW6ztfwft" />
  <meta name="currentJournal" content="PLoSONE" />
  <meta name="almRequestBatchSize" content="" />

  <meta name="citation_publisher" content="Public Library of Science"/>
  <meta name="citation_doi" content="10.1371/journal.pone.0001795"/>
  <meta name="dc.identifier" content="10.1371/journal.pone.0001795" />

    <meta name="citation_title" content="The Grasping Side of Odours"/>
    <meta itemprop="name" content="The Grasping Side of Odours"/>

      <meta name="citation_author" content="Federico Tubaldi"/>
            <meta name="citation_author_institution" content="Department of General Psychology, University of Padua, Padua, Italy"/>
      <meta name="citation_author" content="Caterina Ansuini"/>
            <meta name="citation_author_institution" content="Department of General Psychology, University of Padua, Padua, Italy"/>
      <meta name="citation_author" content="Roberto Tirindelli"/>
            <meta name="citation_author_institution" content="Department of Neuroscience, University of Parma, Parma, Italy"/>
      <meta name="citation_author" content="Umberto Castiello"/>
            <meta name="citation_author_institution" content="Department of General Psychology, University of Padua, Padua, Italy"/>
            <meta name="citation_author_institution" content="Department of Psychology, Royal Holloway, University of London, Egham, United Kingdom"/>

    <meta name="citation_date" content="2008/3/19"/>

  <meta name="citation_pdf_url" content="http://dx.plos.org/10.1371/journal.pone.0001795.pdf" />

      <meta name="citation_journal_title" content="PLOS ONE" />
    <meta name="citation_firstpage" content="e1795"/>
    <meta name="citation_issue" content="3"/>
    <meta name="citation_volume" content="3"/>
    <meta name="citation_issn" content="1932-6203"/>

    <meta name="citation_journal_abbrev" content="PLoS ONE" />

      <meta name="citation_reference" content="citation_title=Multisensory integration-neural and behavioral solutions for dealing with stimuli from different sensory modalities.; citation_author=BE Stein; citation_author=MA Meredith; citation_journal_title=Ann NY Acad Sci; citation_volume=608; citation_number=1; citation_pages=51-70; citation_date=1990; " />
      <meta name="citation_reference" content="citation_title=Audiotactile interactions in roughness perception.; citation_author=S Guest; citation_author=C Catmur; citation_author=D Lloyd; citation_author=C Spence; citation_journal_title=Exp Brain Res; citation_volume=146; citation_number=2; citation_pages=161-171; citation_date=2002; " />
      <meta name="citation_reference" content="citation_title=A computational perspective on the neural basis of multisensory spatial representation.; citation_author=A Pouget; citation_author=S Deneve; citation_author=JR Duhmael; citation_journal_title=Nat Rev Neurosci; citation_volume=3; citation_number=3; citation_pages=741-747; citation_date=2002; " />
      <meta name="citation_reference" content="citation_title=Crossmodal integration for perception and action.; citation_author=C Lalanne; citation_author=J Lorenceau; citation_journal_title=J Physiol Paris; citation_volume=98; citation_number=4; citation_pages=265-279; citation_date=2004; " />
      <meta name="citation_reference" content="citation_title=Prediction of external events with our motor system: towards a new framework.; citation_author=RJ Schubotz; citation_journal_title=Trends Cogni Sci; citation_volume=11; citation_number=5; citation_pages=211-218; citation_date=2007; " />
      <meta name="citation_reference" content="citation_title=The grasping hand.; citation_author=CL MacKenzie; citation_author=T Iberall; citation_number=6; citation_pages=78; citation_date=1994; citation_publisher=Elsevier-North Holland; " />
      <meta name="citation_reference" content="citation_title=Hand and Brain: Neurophysiology and Psychology of Hand Movements.; citation_author=AM Wing; citation_author=P Haggard; citation_author=JR Flanagan; citation_number=7; citation_pages=29; citation_date=1996; citation_publisher=Academic Press; " />
      <meta name="citation_reference" content="citation_title=The neuroscience of grasping.; citation_author=U Castiello; citation_journal_title=Nat Rev Neurosci; citation_volume=6; citation_number=8; citation_pages=726-736; citation_date=2005; " />
      <meta name="citation_reference" content="citation_title=The intelligent hand.; citation_author=RL Klatzky; citation_author=SJ Lederman; citation_number=9; citation_pages=121-151; citation_date=1987; citation_publisher=Academic Press; " />
      <meta name="citation_reference" content="citation_title=Roles of glabrous skin receptors and sensorimotor memory in automatic control of precision grip when lifting rougher or more slippery objects.; citation_author=RS Johansson; citation_author=G Westling; citation_journal_title=Exp Brain Res; citation_volume=56; citation_number=10; citation_pages=550-564; citation_date=1984; " />
      <meta name="citation_reference" content="citation_title=Control of grip force when tilting objects: effect of curvature of grasped surfaces and applied tangential torque.; citation_author=AW Goodwin; citation_author=P Jenmalm; citation_author=RS Johansson; citation_journal_title=J Neurosci; citation_volume=18; citation_number=11; citation_pages=10724-10734; citation_date=1998; " />
      <meta name="citation_reference" content="citation_title=Visual and tactile information about object-curvature control fingertip forces and grasp kinematics in human dexterous manipulation.; citation_author=P Jenmalm; citation_author=S Dahlstedt; citation_author=RS Johansson; citation_journal_title=J Neurophysiol; citation_volume=84; citation_number=12; citation_pages=2984-2997; citation_date=2000; " />
      <meta name="citation_reference" content="citation_title=There's more to touch than meets the eye: the salience of object attributes for haptics with and without vision.; citation_author=RL Klatsky; citation_author=SJ Lederman; citation_author=C Reed; citation_journal_title=J Exp Psychol Gen; citation_volume=116; citation_number=13; citation_pages=356-369; citation_date=1987; " />
      <meta name="citation_reference" content="citation_title=Perception of material from contact sounds.; citation_author=RL Klatzky; citation_author=DK Pai; citation_author=EP Krotkov; citation_journal_title=Presence: Teleoperators & Virtual Environments; citation_volume=9; citation_number=14; citation_pages=399-410; citation_date=2000; " />
      <meta name="citation_reference" content="citation_title=Role of uncertainty in sensorimotor control.; citation_author=RJ Van Beers; citation_author=P Baraduc; citation_author=DM Wolpert; citation_journal_title=Philos T Roy Soc B; citation_volume=357; citation_number=15; citation_pages=1137-1145; citation_date=2002; " />
      <meta name="citation_reference" content="citation_title=A crossmodal interference effect in grasping objects.; citation_author=S Patchay; citation_author=U Castiello; citation_author=P Haggard; citation_journal_title=Psychol Bull Rev; citation_volume=10; citation_number=16; citation_pages=924-931; citation_date=2003; " />
      <meta name="citation_reference" content="citation_title=Cross-modal links in action: evidence for an object-centred reference frame for control of grasping.; citation_author=S Patchay; citation_author=P Haggard; citation_author=U Castiello; citation_journal_title=Exp Brain Res; citation_volume=23; citation_number=17; citation_pages=1-11; citation_date=2006; " />
      <meta name="citation_reference" content="citation_title=Grasping at thin air: multimodal contact cues for reaching and grasping.; citation_author=MA Zahariev; citation_author=CL MacKenzie; citation_journal_title=Exp Brain Res; citation_volume=180; citation_number=18; citation_pages=69-84; citation_date=2007; " />
      <meta name="citation_reference" content="citation_title=Multisensory integration during grasping movements.; citation_author=U Castiello; citation_author=F Tubaldi; citation_author=C Ansuini; citation_author=B Giordano; citation_author=M Grassi; citation_journal_title=Journal of Psychophysiol. In press.; citation_number=19; " />
      <meta name="citation_reference" content="citation_title=Optimal response of eye and hand motor systems in pointing at a visual target, II: static and dynamic visual cues in the control of hand movement.; citation_author=C Prablanc; citation_author=JF Echallier; citation_author=M Jeannerod; citation_author=E Komilis; citation_journal_title=Biol Cybernetics; citation_volume=35; citation_number=20; citation_pages=183-187; citation_date=1979; " />
      <meta name="citation_reference" content="citation_title=The effect of auditory cues on the haptic perception of stiffness in virtual environments.; citation_author=DW DiFranco; citation_author=GL Beauregard; citation_author=MA Srinivasan; citation_journal_title=Proceedings of the ASME Dynamic Systems and Control Division, DSC; citation_volume=61; citation_number=21; citation_pages=17-22; citation_date=1997; " />
      <meta name="citation_reference" content="citation_title=Where is my arm? The relative role of vision and proprioceptioon in the neuronal representation.; citation_author=M Graziano; citation_journal_title=Proc Natl Acad Sci USA; citation_volume=96; citation_number=22; citation_pages=10418-10421; citation_date=1999; " />
      <meta name="citation_reference" content="citation_title=Integrating multimodal information about surface texture via a probe: relative contributions of haptic and touch-produced sounds.; citation_author=SJ Lederman; citation_author=RL Klatzky; citation_author=T Morgan; citation_author=C Hamilton; citation_journal_title=Proceedings of the 10th annual Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, IEEE 2002,; citation_number=23; citation_pages=97-104; citation_date=2002; " />
      <meta name="citation_reference" content="citation_title=Relative performance using haptic and/or touchproduced auditory cues in a remote absolute texture identification task.; citation_author=SJ Lederman; citation_author=AM Martin; citation_author=C Tong; citation_author=RL Klatzky; citation_journal_title=Proceedings of the 11th annual Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, IEEE 2003,; citation_number=24; citation_pages=151-158; citation_date=2003; " />
      <meta name="citation_reference" content="citation_title=Cross-modal interactions between olfaction and vision when grasping.; citation_author=U Castiello; citation_author=GM Zucco; citation_author=V Parma; citation_author=C Ansuini; citation_author=R Tirindelli; citation_journal_title=Chem Senses; citation_volume=31; citation_number=25; citation_pages=665-71; citation_date=2006; " />
      <meta name="citation_reference" content="citation_title=Patterns of hand motion during grasping and the influence of sensory guidance.; citation_author=M Santello; citation_author=M Flanders; citation_author=JF Soechting; citation_journal_title=J Neurosci; citation_volume=22; citation_number=26; citation_pages=1426-1435; citation_date=2002; " />
      <meta name="citation_reference" content="citation_title=The role of vision on hand preshaping during reach to grasp.; citation_author=SA Winges; citation_author=DJ Weber; citation_author=M Santello; citation_journal_title=Exp Brain Res; citation_volume=152; citation_number=27; citation_pages=489-98; citation_date=2003; " />
      <meta name="citation_reference" content="citation_title=The distribution of muscular weakness in upper motor neuron lesions affecting the arm.; citation_author=JG Colebatch; citation_author=SC Gandevia; citation_journal_title=Brain; citation_volume=112; citation_number=28; citation_pages=749-763; citation_date=1989; " />
      <meta name="citation_reference" content="citation_title=Reach to grasp: the natural response to perturbation of object size.; citation_author=U Castiello; citation_author=KM Bennett; citation_author=GE Stelmach; citation_journal_title=Exp Brain Res; citation_volume=94; citation_number=29; citation_pages=163-178; citation_date=1993; " />
      <meta name="citation_reference" content="citation_title=Reprogramming of grip aperture in a double-step virtual grasping paradigm.; citation_author=O Bock; citation_author=S Jungling; citation_journal_title=Exp Brain Res; citation_volume=125; citation_number=30; citation_pages=61-66; citation_date=1999; " />
      <meta name="citation_reference" content="citation_title=Action-based mechanisms of attention.; citation_author=SP Tipper; citation_author=LA Howard; citation_author=G Houghton; citation_journal_title=Philos Trans R Soc Lond B Biol Sci; citation_volume=353; citation_number=31; citation_pages=1385-1393; citation_date=1998; " />
      <meta name="citation_reference" content="citation_title=Mechanism of selection for the control of hand action.; citation_author=U Castiello; citation_journal_title=Trends Cogn Sci; citation_volume=3; citation_number=32; citation_pages=264-271; citation_date=1999; " />
      <meta name="citation_reference" content="citation_title=Gustatory, olfactory, and visual convergence within the primate orbitofrontal cortex.; citation_author=ET Rolls; citation_author=L Baylis; citation_journal_title=J Neurosci; citation_volume=14; citation_number=33; citation_pages=5437-5452; citation_date=1994; " />
      <meta name="citation_reference" content="citation_title=Neural mechanisms mediating attention and orientation to multisensory cues.; citation_author=BE Stein; citation_author=MT Wallace; citation_author=MA Meredith; citation_number=34; citation_pages=683-701; citation_date=1995; citation_publisher=Bradford Books, MIT Press; " />
      <meta name="citation_reference" content="citation_title=Auditory-visual integration during multimodal object recognition in humans: a behavioral and electrophysiological study.; citation_author=MH Giard; citation_author=F Peronnet; citation_journal_title=J Cognitive Neurosci; citation_volume=11; citation_number=35; citation_pages=473-490; citation_date=1999; " />
      <meta name="citation_reference" content="citation_title=Crossmodal processing in the human brain: insights from functional neuroimaging studies.; citation_author=GA Calvert; citation_journal_title=Cereb Cortex; citation_volume=11; citation_number=36; citation_pages=1110-1123; citation_date=2001; " />
      <meta name="citation_reference" content="citation_title=The nose smells what the eye sees: crossmodal visual facilitation of human olfactory perception.; citation_author=JA Gottfried; citation_author=RJ Dolan; citation_journal_title=Neuron; citation_volume=39; citation_number=37; citation_pages=375-386; citation_date=2003; " />
      <meta name="citation_reference" content="citation_title=Color of scents: chromatic stimuli modulate odor responses in the human brain.; citation_author=RA Österbauer; citation_author=PM Matthews; citation_author=M Jenkinson; citation_author=CF Beckmann; citation_author=PC Hansen; citation_journal_title=J Neurophysiol; citation_volume=93; citation_number=38; citation_pages=3434-3441; citation_date=2005; " />
      <meta name="citation_reference" content="citation_title=Do the eyes see what the nose knows? An investigation of the effects of olfactory priming on visual event related potentials.; citation_author=J Grigor; citation_journal_title=Chem Senses; citation_volume=20; citation_number=39; citation_pages=163; citation_date=1995; " />
      <meta name="citation_reference" content="citation_title=The effect of odour priming on long latency visual evoked potentials of matching and mismatching objects.; citation_author=J Grigor; citation_author=S Van Toller; citation_author=J Behan; citation_author=A Richardson; citation_journal_title=Chem Senses; citation_volume=24; citation_number=40; citation_pages=137-144; citation_date=1999; " />
      <meta name="citation_reference" content="citation_title=Visual event related potentials modulated by contextually relevant and irrelevant olfactory primes.; citation_author=M Sarfarazi; citation_author=B Cave; citation_author=A Richardson; citation_author=J Behan; citation_author=EM Sedgwick; citation_journal_title=Chem Senses; citation_volume=24; citation_number=41; citation_pages=145-154; citation_date=1999; " />
      <meta name="citation_reference" content="citation_title=The anatomical connections of the macaque monkey orbitofrontal cortex. A review.; citation_author=C Cavada; citation_author=T Compañy; citation_author=J Tejedor; citation_author=RJ Cruz-Rizzolo; citation_author=F Reinoso-Suárez; citation_journal_title=Cereb Cortex; citation_volume=10; citation_number=42; citation_pages=220-242; citation_date=2000; " />
      <meta name="citation_reference" content="citation_title=Frontal Granular cortex input to the cingulate (M3), supplementary (M2) and primary (M1) motor cortices in the rhesus monkey.; citation_author=RJ Morecraft; citation_author=GW Van Hoesen; citation_journal_title=J Comp Neurol.; citation_volume=337; citation_number=43; citation_pages=669-689; citation_date=1993; " />
      <meta name="citation_reference" content="citation_title=Comparing natural and constrained movements: new insights into the visuomotor control of grasping.; citation_author=C Begliomini; citation_author=A Caria; citation_author=W Grodd; citation_author=U Castiello; citation_journal_title=PLoS ONE; citation_volume=10; citation_number=44; citation_pages=1-10; citation_date=2007; " />
      <meta name="citation_reference" content="citation_title=Prefrontal connections of medial motor areas in the rhesus monkey.; citation_author=JF Bates; citation_author=PS Goldman-Rakic; citation_journal_title=J Comp Neurol; citation_volume=336; citation_number=45; citation_pages=211-228; citation_date=1993; " />
      <meta name="citation_reference" content="citation_title=Distinct olfactory cross-modal effects on the human motor system.; citation_author=S Rossi; citation_author=A De Capua; citation_author=P Pasqualetti; citation_author=M Ulivelli; citation_author=L Fadiga; citation_journal_title=PloS ONE. In press; citation_number=46; " />
      <meta name="citation_reference" content="citation_title=Schemas for the temporal control of behavior.; citation_author=MA Arbib; citation_journal_title=Hum Neurobiol; citation_volume=4; citation_number=47; citation_pages=63-72; citation_date=1985; " />
      <meta name="citation_reference" content="citation_title=Modeling parietal-premotor interactions in primate control of grasping.; citation_author=AH Fagg; citation_author=MA Arbib; citation_journal_title=Neural Networks; citation_volume=11; citation_number=48; citation_pages=1277-1303; citation_date=1998; " />
      <meta name="citation_reference" content="citation_title=Peripherally obtained electrophysiological responses to olfactory stimulation in man: electro-olfactograms exhibit a smaller degree of desensitization compared with subjective intensity estimates.; citation_author=T Hummel; citation_author=M Knecht; citation_author=G Kobal; citation_journal_title=Brain Res; citation_volume=717; citation_number=49; citation_pages=160-164; citation_date=1996; " />
      <meta name="citation_reference" content="citation_title=Grasping a fruit: selection for action.; citation_author=U Castiello; citation_journal_title=J Exp Psychol Hum Percept Perform; citation_volume=22; citation_number=50; citation_pages=582-603; citation_date=1996; " />
      <meta name="citation_reference" content="citation_title=Repeated-measures contrasts for “multiple-pattern” hypotheses.; citation_author=RM Furr; citation_author=R Roshental; citation_journal_title=Psychol Methods; citation_volume=8; citation_number=51; citation_pages=275-293; citation_date=2003; " />
      <meta name="citation_reference" content="citation_title=Alternate methods for analyzing data from experiments.; citation_author=B Thompson; citation_journal_title=J Exp Educ; citation_volume=54; citation_number=52; citation_pages=50-55; citation_date=1985; " />
      <meta name="citation_reference" content="citation_title=Orientation of the opposition axis in mentally simulated grasping.; citation_author=V Frak; citation_author=Y Paulignan; citation_author=M Jeannerod; citation_journal_title=Exp Brain Res; citation_volume=136; citation_number=53; citation_pages=120-127; citation_date=2001; " />
      <meta name="citation_reference" content="citation_title=Control of hand shaping in response to object shape perturbation.; citation_author=C Ansuini; citation_author=M Santello; citation_author=F Tubaldi; citation_author=S Massaccesi; citation_author=U Castiello; citation_journal_title=Exp Brain Res; citation_volume=180; citation_number=54; citation_pages=85-96; citation_date=2007; " />
      <meta name="citation_reference" content="citation_title=Controlling the false discovery rate: A practical and powerful approach to multiple testing.; citation_author=Y Benjamini; citation_author=Y Hochberg; citation_journal_title=J Royal Stat Soc Ser B; citation_volume=57; citation_number=55; citation_pages=289-300; citation_date=1995; " />

  <link rel="canonical" href="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0001795" />

    <meta name="twitter:card" content="summary"/>
    <meta name="twitter:site" content="@plosone"/>
    <meta name="twitter:title" content="The Grasping Side of Odours"/>
    <meta name="twitter:description" content="BackgroundResearch on multisensory integration during natural tasks such as reach-to-grasp is still in its infancy. Crossmodal links between vision, proprioception and audition have been identified, but how olfaction contributes to plan and control reach-to-grasp movements has not been decisively shown. We used kinematics to explicitly test the influence of olfactory stimuli on reach-to-grasp movements.Methodology/Principal FindingsSubjects were requested to reach towards and grasp a small or a large visual target (i.e., precision grip, involving the opposition of index finger and thumb for a small size target and a power grip, involving the flexion of all digits around the object for a large target) in the absence or in the presence of an odour evoking either a small or a large object that if grasped would require a precision grip and a whole hand grasp, respectively. When the type of grasp evoked by the odour did not coincide with that for the visual target, interference effects were evident on the kinematics of hand shaping and the level of synergies amongst fingers decreased. When the visual target and the object evoked by the odour required the same type of grasp, facilitation emerged and the intrinsic relations amongst individual fingers were maintained.Conclusions/SignificanceThis study demonstrates that olfactory information contains highly detailed information able to elicit the planning for a reach-to-grasp movement suited to interact with the evoked object. The findings offer a substantial contribution to the current debate about the multisensory nature of the sensorimotor transformations underlying grasping."/>
      <meta name="twitter:image" content="http://dx.plos.org/10.1371/journal.pone.0001795.g009"/>

  <meta property="og:title" content="The Grasping Side of Odours" />
  <meta property="og:type" content="article" />
  <meta property="og:url" content="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0001795" />

 <!--end articleInfoX-->

  <link rel="pingback" href="http://www.plosone.org/pingback" />


  <link rel="shortcut icon" href="/images/favicon.ico" type="image/x-icon"/>
  <link rel="home" title="home" href="/"/>
  <link rel="alternate" type="application/rss+xml"
        title="PLOS ONE: New Articles"
        href="http://www.plosone.org/article/feed"/>
</head>
<body>

  <div id="page-wrap">
    <div id="topbanner" class="cf">

<!-- Div for the ad at the top of journal home page-->
<div class="center">
  <div class="title">Advertisement</div>
  <iframe id='a3ac9da4' name='a3ac9da4'
    src='http://ads.plos.org/www/delivery/afr.php?zoneid=345&amp;cb=9473'
    frameborder='0' scrolling='no' width='730' height='90'>
    <a href='http://ads.plos.org/www/delivery/ck.php?n=a3ac9da4&amp;cb=3454'
      target='_top'><img src='http://ads.plos.org/www/delivery/avw.php?zoneid=345&amp;cb=6415&amp;n=a3ac9da4'
      border='0' alt=''/>
    </a>
  </iframe>
</div>    </div>

    <div id="pagehdr-wrap">
      <div id="pagehdr">
        <div id="user" class="nav">
          <ul>
            <li><a href="http://www.plos.org">plos.org</a></li>
            <li><a href="https://register.plos.org/ambra-registration/register.action">create account</a></li>
            <li class="btn-style"><a
              href="/user/secure/secureRedirect.action?goTo=%2Farticle%2FfetchArticle.action%3FarticleURI%3Dinfo%253Adoi%252F10.1371%252Fjournal.pone.0001795">sign in</a>
            </li>
          </ul>
        </div>
        <div class="logo">
          <a href="/"><img src="/images/logo.png" alt="PLOS ONE"></a>
        </div>

<div id="nav-main" class="nav">
  <ul>
        <li id="mn-01"><a href="/taxonomy" class="areas-link">Subject Areas</a></li>
    <li id="mn-02"><a href="javascript:void(0);">For Authors</a>
      <div class="submenu" style="width: 540px; margin-left: -300px;">
        <div class="block">
          <div class="submit-script">
            <h3>Submit your Manuscript</h3>
            <ul>
              <li>Fair, rigorous peer review</li>
              <li>Broad scope and wide reach</li>
            </ul>
            <a href="/static/submissionInstructions" class="btn">get started</a>
          </div>
        </div>
        <div class="menu">
          <ul>
            <li><a href="/static/publish">Why Publish with PLOS ONE</a></li>
            <li><a href="/static/publication">Publication Criteria</a></li>
            <li><a href="/static/editorial">Editorial Policies</a></li>
            <li><a href="/static/guidelines">Preparing A Manuscript</a></li>
            <li><a href="/static/figureGuidelines">Figure and Table Guidelines</a></li>
          <li><a href="/static/supportingInformation">Supporting Information Guidelines</a></li>
            <li><a href="/static/submissionInstructions">Submitting a Manuscript</a></li>
          </ul>
        </div>
      </div>
    </li>

    <li id="mn-03"><a href="javascript:void(0);">About Us</a>
      <div class="submenu" style="width:248px; margin-left:-30px;">
        <div class="menu">
          <ul>
            <li><a href="/static/information">Journal Information</a></li>
            <li><a href="/static/edboard">Editorial Board</a></li>
            <li><a href="/static/reviewerGuidelines">Reviewer Guidelines</a></li>
            <li><a href="/static/almInfo">Article-Level Metrics</a></li>
            <li><a href="/static/license">Open-Access License</a></li>
            <li><a href="/static/downloads">Media Downloads</a></li>
            <li><a href="/static/commentGuidelines">Guidelines for Comments</a></li>
            <li><a href="/static/corrections">Corrections</a></li>
            <li><a href="/static/help">Help Using this Site</a></li>
            <li><a href="/static/contact">Contact Us</a></li>
          </ul>
        </div>
      </div>
    </li>
  </ul>
<div id="db">
  <form name="searchForm" action="/search/simple?noSearchFlag=true&amp;query=&amp;articleURI=info%3Adoi%2F10.1371%2Fjournal.pone.0001795" method="get" >
<input type="hidden" name="from" value="globalSimpleSearch" id="from"/><input type="hidden" name="filterJournals" value="PLoSONE" id="filterJournals"/>    <fieldset>
      <legend>Search</legend>
      <label for="search">Search</label>
      <div class="wrap">
        <input id="search" type="text" name="query" placeholder="Search">
        <input type="image" alt="SEARCH" src="/images/icon.search.gif">
      </div>
    </fieldset>
  </form>
    <a id="advSearch" href="/search/advanced?noSearchFlag=true&amp;query=&amp;articleURI=info%3Adoi%2F10.1371%2Fjournal.pone.0001795&filterJournals=PLoSONE">advanced search</a>
</div></div>

      </div>
      <!-- pagehdr-->
    </div>
    <!-- pagehdr-wrap -->

  <!--body and html tags gets closed in global_footer.ftl-->
<script type="text/javascript" src="/javascript/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<div id="pagebdy-wrap">
  <div id="pagebdy">

    <div id="article-block" class="cf">

<div class="article-meta cf">
  <ul id="almSignPost" style="display: none;"></ul>
  <div class="article-type">
    <span class="type oa">Open Access</span>
      <span class="type pr">Peer-Reviewed</span>
  </div>
</div>

<div class="header" id="hdr-article">

<div class="article-kicker">
      <span id="article-type-heading">
        Research Article
      </span>
</div>  <h1 property="dc:title" datatype="" rel="dc:type" href="http://purl.org/dc/dcmitype/Text">
    The Grasping Side of Odours
  </h1>

  <ul class="authors">
      <li>


        <span rel="dc:creator" class="author">
          <span class="person" property="foaf:name" typeof="foaf:Person">
            Federico Tubaldi, 
          </span>
        </span>

          <div class="author_meta">
            <div class="author_inner">


              
              

                <p>Affiliation:
                  Department of General Psychology, University of Padua, Padua, Italy
                </p>


              <span class="close">X</span>

            </div>
          </div>
      </li>
      <li>


        <span rel="dc:creator" class="author">
          <span class="person" property="foaf:name" typeof="foaf:Person">
            Caterina Ansuini, 
          </span>
        </span>

          <div class="author_meta">
            <div class="author_inner">


              
              

                <p>Affiliation:
                  Department of General Psychology, University of Padua, Padua, Italy
                </p>


              <span class="close">X</span>

            </div>
          </div>
      </li>
      <li>


        <span rel="dc:creator" class="author">
          <span class="person" property="foaf:name" typeof="foaf:Person">
            Roberto Tirindelli, 
          </span>
        </span>

          <div class="author_meta">
            <div class="author_inner">


              
              

                <p>Affiliation:
                  Department of Neuroscience, University of Parma, Parma, Italy
                </p>


              <span class="close">X</span>

            </div>
          </div>
      </li>
      <li>


        <span rel="dc:creator" class="author">
          <span class="person" property="foaf:name" typeof="foaf:Person">
            Umberto Castiello
              <span class="corresponding">mail</span>
          </span>
        </span>

          <div class="author_meta">
            <div class="author_inner">


              
              <p><span class="email">* E-mail:</span> <a href="mailto:umberto.castiello@unipd.it">umberto.castiello@unipd.it</a></p>

                <p>Affiliations:
                  Department of General Psychology, University of Padua, Padua, Italy, 
                  Department of Psychology, Royal Holloway, University of London, Egham, United Kingdom
                </p>


              <span class="close">X</span>

            </div>
          </div>
      </li>
  </ul>
  <ul class="date-doi-line">
    <li>Published: March 19, 2008</li>
    <li>DOI: 10.1371/journal.pone.0001795</li>
  </ul>


</div><!--end header-->
<div class="main cf" id="pjax-container">
  

<div class="nav items-5" id="nav-article">
  <ul>
  <li>
        <span class="active" name="article">Article</span>
  </li>
  <li>
      <a href="/article/authors/info%3Adoi%2F10.1371%2Fjournal.pone.0001795" name="authors">About the Authors</a>
  </li>
  <li>
      <a href="/article/metrics/info%3Adoi%2F10.1371%2Fjournal.pone.0001795" name="metrics">Metrics</a>
  </li>
  <li>
      <a href="/article/comments/info%3Adoi%2F10.1371%2Fjournal.pone.0001795" name="comments">Comments</a>
  </li>
  <li>
      <a href="/article/related/info%3Adoi%2F10.1371%2Fjournal.pone.0001795" name="related">Related Content</a>
  </li>
  </ul>
</div>

<script type="text/javascript">
  var selected_tab = "article";
</script>
  <div id="figure-thmbs" class="carousel cf">
    <div class="wrapper">
      <div class="slider">
              <div class="item">
                <a href="#pone-0001795-g001" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.g001" title="Figure 1">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g001&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001795-g002" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.g002" title="Figure 2">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g002&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001795-g003" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.g003" title="Figure 3">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g003&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001795-g004" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.g004" title="Figure 4">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g004&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001795-g005" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.g005" title="Figure 5">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g005&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001795-t001" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.t001" title="Table 1">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.t001&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001795-g006" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.g006" title="Figure 6">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g006&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001795-g007" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.g007" title="Figure 7">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g007&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001795-t002" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.t002" title="Table 2">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.t002&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001795-g008" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.g008" title="Figure 8">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g008&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001795-g009" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.g009" title="Figure 9">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g009&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001795-t003" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.t003" title="Table 3">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.t003&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001795-t004" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.t004" title="Table 4">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.t004&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
      </div>
    </div>
  </div>

  <div class="nav-col">
    <div class="nav" id="nav-article-page">
      <ul>
        <li class="nav-col-comments"><a href="/article/comments/info%3Adoi%2F10.1371%2Fjournal.pone.0001795">Reader Comments (2)</a></li>
          <li id="nav-figures"><a data-doi="info:doi/10.1371/journal.pone.0001795" >Figures</a></li>
      </ul>
    </div>
  </div>

  <div class="article">







<div class="abstract"><a id="abstract0" name="abstract0" toc="abstract0" title="Abstract"></a><h2>Abstract</h2>
<h3>Background</h3>
<a id="article1.front1.article-meta1.abstract1.sec1.p1" name="article1.front1.article-meta1.abstract1.sec1.p1"></a><p>Research on multisensory integration during natural tasks such as reach-to-grasp is still in its infancy. Crossmodal links between vision, proprioception and audition have been identified, but how olfaction contributes to plan and control reach-to-grasp movements has not been decisively shown. We used kinematics to explicitly test the influence of olfactory stimuli on reach-to-grasp movements.</p>


<h3>Methodology/Principal Findings</h3>
<a id="article1.front1.article-meta1.abstract1.sec2.p1" name="article1.front1.article-meta1.abstract1.sec2.p1"></a><p>Subjects were requested to reach towards and grasp a small or a large visual target (i.e., precision grip, involving the opposition of index finger and thumb for a small size target and a power grip, involving the flexion of all digits around the object for a large target) in the absence or in the presence of an odour evoking either a small or a large object that if grasped would require a precision grip and a whole hand grasp, respectively. When the type of grasp evoked by the odour did not coincide with that for the visual target, interference effects were evident on the kinematics of hand shaping and the level of synergies amongst fingers decreased. When the visual target and the object evoked by the odour required the same type of grasp, facilitation emerged and the intrinsic relations amongst individual fingers were maintained.</p>


<h3>Conclusions/Significance</h3>
<a id="article1.front1.article-meta1.abstract1.sec3.p1" name="article1.front1.article-meta1.abstract1.sec3.p1"></a><p>This study demonstrates that olfactory information contains highly detailed information able to elicit the planning for a reach-to-grasp movement suited to interact with the evoked object. The findings offer a substantial contribution to the current debate about the multisensory nature of the sensorimotor transformations underlying grasping.</p>

</div>


<div class="articleinfo"><p><strong>Citation: </strong>Tubaldi F, Ansuini C, Tirindelli R, Castiello U (2008) The Grasping Side of Odours. PLoS ONE 3(3):
          e1795.
            doi:10.1371/journal.pone.0001795</p><p><strong>Editor: </strong>Eric Warrant, Lund University, Sweden</p><p><strong>Received:</strong> December 10, 2007; <strong>Accepted:</strong> February 12, 2008; <strong>Published:</strong> March 19, 2008</p><p><strong>Copyright:</strong> © 2008 Tubaldi et al. This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</p><p><strong>Funding: </strong>This work was supported by a project grant from the University of Padova to UC.</p><p><strong>Competing interests:</strong> The authors have declared that no competing interests exist.</p></div>





<div id="section1" class="section"><a id="s1" name="s1" toc="s1" title="Introduction"></a><h3>Introduction</h3><a id="article1.body1.sec1.p1" name="article1.body1.sec1.p1"></a><p>Reach and grasp movements are amongst the most common actions we perform in our everyday lives. To perform this kind of action, different sensory modalities are used in concert to perceive and interact with multimodally specified objects and events <a href="#pone.0001795-Stein1">[1]</a>–<a href="#pone.0001795-Schubotz1">[5]</a>.</p>
<a id="article1.body1.sec1.p2" name="article1.body1.sec1.p2"></a><p>The visual system provides information about object location, size, shape, and orientation, and also about the movement of one's hand towards the object <a href="#pone.0001795-MacKenzie1">[6]</a>–<a href="#pone.0001795-Castiello1">[8]</a>. The haptic system provides information about object weight and texture <a href="#pone.0001795-Klatzky1">[9]</a>, confirms target acquisition, modulates grip force for stable grasp <a href="#pone.0001795-Johansson1">[10]</a>–<a href="#pone.0001795-Jenmalm1">[12]</a>, and contributes to detect potential collisions with other objects in the environment. Action-generated sounds and noises are very common in a natural environment and touch related sounds can also provide information about the structure of surfaces <a href="#pone.0001795-Klatsky1">[13]</a>, <a href="#pone.0001795-Klatzky2">[14]</a>.</p>
<a id="article1.body1.sec1.p3" name="article1.body1.sec1.p3"></a><p>Although the above evidence suggests that the motor system takes into account streams of information encoded in different modalities, it is customary to study sensory systems in isolation. However, most real-life situations require that these sensory systems provide us with integrated cues about object properties and recent antecedents seem to suggest that such integration is particularly relevant when reaching to grasp an object <a href="#pone.0001795-VanBeers1">[15]</a>–<a href="#pone.0001795-Castiello2">[19]</a>. For instance, when estimating where a hand is in space, visual and proprioceptive information are available. These two sources of information are integrated in a way that minimizes the uncertainty in the estimate, which in turn is used to plan a goal-directed movement <a href="#pone.0001795-VanBeers1">[15]</a>–<a href="#pone.0001795-Patchay2">[17]</a>, <a href="#pone.0001795-Prablanc1">[20]</a>, <a href="#pone.0001795-DiFranco1">[21]</a>. Adding sound contact cues on motor performance when reaching to grasp an object facilitates and fine-tunes action performance <a href="#pone.0001795-Zahariev1">[18]</a>, <a href="#pone.0001795-Castiello2">[19]</a>, <a href="#pone.0001795-DiFranco1">[21]</a>–<a href="#pone.0001795-Lederman2">[24]</a>.</p>
<a id="article1.body1.sec1.p4" name="article1.body1.sec1.p4"></a><p>An aspect which has been largely neglected in terms of the multisensory processes underlying reach to-grasp movements concerns chemosensory information. One study in our laboratory considered reach-to-grasp movements performed in the presence of an olfactory task-irrelevant stimulus. The olfactory stimulus could evoke an object of a smaller or larger dimension than the target object. In these circumstances, the maximum distance between the index finger and thumb (i.e., maximum hand aperture) was affected. If the olfactory stimulus evoked an object smaller than the target, then maximum hand aperture was smaller than when no-odour was delivered. If the olfactory stimulus evoked an object larger than the target, then maximum hand aperture was larger than when grasping occurred in the absence of olfactory information <a href="#pone.0001795-Castiello3">[25]</a>.</p>
<a id="article1.body1.sec1.p5" name="article1.body1.sec1.p5"></a><p>Although suggestive of the potential influence olfactory information may have on reach-to-grasp movements, the dependent measure used in this preliminary observation (i.e., maximum hand aperture) did not allow for a precise examination of three critical aspects. First, it does not permit a full understanding of how detailed the motor commands embedded within the ‘grasp’ plan elicited by the object's olfactory representation are. In this respect, recording detailed kinematics at the level of individual digits may shed more light on this aspect. If the motion of individual fingers is modulated by the olfactory information, then the ‘grasp’ plan elicited by the olfactory representation may consider the structure of the object associated with the odour. Second, maximum hand aperture is a measure which does not allow to ascertain how olfactory interference fully manifests within a complex sensory-motor system such as that sub-serving visual grasping. An index quantifying the intrinsic relations amongst fingers, such as the pattern of hand motion covariation (i.e., the extent to which the motion of digits' single joints is coordinated into synergies <a href="#pone.0001795-Santello1">[26]</a>, <a href="#pone.0001795-Winges1">[27]</a>), may be needed. If an odour affects the pattern of hand motion covariation, then olfactory-induced destabilization of motion synergies amongst fingers would be a potent index of interference. Conversely, if an odour leaves unchanged the pattern of hand motion covariation, then no inferences about olfactory type of interference could be drawn. Finally, maximum hand aperture is a time-locked kinematic parameter (i.e., occurs at 50–60% of reaching duration when grasping under natural conditions) which does not allow to determine with a high temporal resolution when the olfactory and the visual information integrate en-route for action control. In this respect, by looking at the entire time course of action would allow to determine when the olfactory and the visual information do integrate.</p>
<a id="article1.body1.sec1.p6" name="article1.body1.sec1.p6"></a><p>With this in mind, we set out to investigate detailed hand kinematics along the entire time course of a reach-to-grasp movement towards visual targets of different size eliciting different types of grasp (<a href="#pone-0001795-g001">Fig. 1A</a>) in the absence or in the presence of preceding olfactory information. Specifically, we recorded angular excursion at the metacarpal phalangeal (<em>mcp</em>) and proximal interphalangeal (<em>pip</em>) joints for all five digits, and abduction angles between digits by means of a CyberGlove (<a href="#pone-0001795-g001">Fig. 1B</a>). For the odourless conditions, subjects reached towards and grasped either a small or a large visual target in the absence of preceding olfactory information by using a precision grip and a power grip, respectively. These conditions were termed respectively ‘OS’ and ‘OL’ (<a href="#pone-0001795-g002">Fig. 2</a>). For the congruent conditions, before movement initiation an odour evoking an object that if grasped would require the same type of grasp as the visual target was delivered. These conditions were named ‘SS’ and ‘LL’, respectively (<a href="#pone-0001795-g002">Fig. 2</a>). For the incongruent conditions, before movement initiation an odour evoking an object that if grasped would require a different type of grasp as the visual target was delivered. For the ‘SL’ condition, an odour associated with an object requiring a precise grasp was presented with a visual target requiring a whole hand grasp (<a href="#pone-0001795-g002">Fig. 2</a>). For the ‘LS’ condition, an odour associated with an object requiring a whole hand grasp was presented with a target requiring a precision grip (<a href="#pone-0001795-g002">Fig. 2</a>).</p>
<div class="figure" id="pone-0001795-g001"><div class="img"><a name="pone-0001795-g001" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g001&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.g001"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g001&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g001/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g001/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g001/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g001/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001795.g001.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g001/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g001/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001795.g001.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 1.  <span>The visual targets and the experimental set up.</span></strong></p><a id="article1.body1.sec1.fig1.caption1.p1" name="article1.body1.sec1.fig1.caption1.p1"></a><p>(A) The visual targets defined as ‘large’ were an apple and an orange, whereas those defined as ‘small’ were an almond and a strawberry. (B) Legends indicate the parts composing the experimental set up.</p>
<span>doi:10.1371/journal.pone.0001795.g001</span></div><div class="figure" id="pone-0001795-g002"><div class="img"><a name="pone-0001795-g002" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g002&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.g002"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g002&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g002/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g002/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g002/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g002/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001795.g002.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g002/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g002/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001795.g002.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 2.  <span>Odour-target combination for each experimental condition.</span></strong></p><a id="article1.body1.sec1.fig2.caption1.p1" name="article1.body1.sec1.fig2.caption1.p1"></a><p>From left to right columns report the number of trials for each odour/target combination, the type of odour, the type of target, and the experimental conditions.</p>
<span>doi:10.1371/journal.pone.0001795.g002</span></div><a id="article1.body1.sec1.p7" name="article1.body1.sec1.p7"></a><p>Capitalizing on the effects of olfactory information on reach-to-grasp movements previously reported <a href="#pone.0001795-Castiello3">[25]</a> we hypothesized that an odour delivered before movement initiation might be able to trigger a motor plan reflecting the size of the object associated with the odour (i.e., power grip for a large sized stimulus vs. precision grip for a small sized stimulus). Therefore, we expect that the size information carried by the odour would affect kinematics differently depending on the congruency between the motor plan elicited by the ‘size’ of the delivered odour and that elicited by the size of the visual target. Specifically we foresee that for the incongruent conditions the motor plan dictated by the visual target should interfere with the motor plan elicited by the olfactory stimulus. For instance, if the delivery of a ‘large’ odour is followed by the presentation of a small visual target, then angular values at both fingers' joints and abductions would be greater than when no olfactory information is given. Conversely, we expected that when an odour associated with a small object is delivered and the target is large, angular values would be smaller than when no-odour is administered. For the congruent conditions, in which both the olfactory and visual information elicit a similar motor plan, the pattern of fingers' joints and abductions should be more pronounced than when no olfactory information is provided. Finally, in order to specifically test the extent of the influence olfactory information may have on the unfolding of the reach-to-grasp movements we also evaluated hand motion covariation patterns. The comparison of hand motion covariation for the congruent and the incongruent conditions with the no-odour conditions should give a measure of how the olfactory stimulus influences the degree of coordination amongst digits.</p>
<a id="article1.body1.sec1.p8" name="article1.body1.sec1.p8"></a><p>To sum up, the aim of the present study was to address three critical and interrelated questions: (i) whether central mechanisms for the visual guidance of grasping are sensitive to olfactory information; (ii) whether the integration of an olfactory stimulus eliciting a hand conformation similar to that elicited by the visual target facilitates the production of a hand posture tailored for the visual target; and (iii) whether delivering an olfactory stimulus - eliciting a hand conformation different from that called by the visual target - reveals interference mechanisms which are played out on the functional organization of individual finger joints.</p>
</div>

<div id="section2" class="section"><a id="s2" name="s2" toc="s2" title="Results"></a><h3>Results</h3>
<h4>The Effect of Size on Hand Shaping</h4>
<a id="article1.body1.sec2.sec1.p1" name="article1.body1.sec2.sec1.p1"></a><p>Here we present the effects of target size on hand shaping as derived from the conditions in which the visual targets are presented in the absence of preceding olfactory information. This is an important aspect of the present study because in order to ascertain the effects of olfactory information in terms of ‘size’ on hand shaping it is necessary to demonstrate that the size of the visual target does affect hand shaping. In this respect, significantly different kinematic patterns of hand shaping for the small and the large targets were found. As shown in <a href="#pone-0001795-g003">Fig. 3</a> the <em>mcp</em> joint for the thumb was more extended for the large than for the small target from 40% to the end of the movement. The <em>mcp</em> joint for the index and the middle fingers was significantly more extended for the large than for the small target throughout the entire movement. For the ring and little fingers no significant differences with respect to target size were found from 70 and from 40% up to the end of movement duration, respectively (<a href="#pone-0001795-g003">Fig. 3</a>). A similar pattern was also evident for the <em>pip</em> joints of all fingers (except for the thumb), but differences related to target size became evident at a later time than for the <em>mcp</em> joints. The <em>pip</em> joint of the thumb was more flexed for the large than for the small target during the last epoch (90–100%). The thumb-index abduction angle was greater for the large than for the small target from 30 up to 100% of movement duration (<a href="#pone-0001795-g004">Fig. 4</a>). Similar size effects were also evident for the middle-ring and the ring-little abduction angles from 10 to 40% of movement duration (<a href="#pone-0001795-g004">Fig. 4</a>). In summary, the fingers were more extended when preparing to grasp a larger than a smaller target whereas the thumb was more flexed for the large than for the small target. This signifies that the size of the visual target was taken into account when planning the motion of all digits.</p>
<div class="figure" id="pone-0001795-g003"><div class="img"><a name="pone-0001795-g003" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g003&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.g003"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g003&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g003/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g003/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g003/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g003/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001795.g003.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g003/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g003/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001795.g003.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 3.  <span>Time course of fingers motion during reaching in the absence of olfactory stimuli.</span></strong></p><a id="article1.body1.sec2.sec1.fig1.caption1.p1" name="article1.body1.sec2.sec1.fig1.caption1.p1"></a><p>Each trace corresponds to the average angular excursion for the <em>mcp</em> (left panels) and <em>pip</em> (right panels) joints of the thumb, index, middle, ring, and little fingers for the ‘OL’ (black squares) and the ‘OS’ (white circles) conditions. Bars represent mean standard error. Positive values correspond to finger flexion, whereas negative values correspond to finger extension. Asterisks indicate significant results (<em>p</em>&lt;.05) for the comparisons between the ‘OL’ and the ‘OS’ conditions at different epochs of normalized movement time. OL = Odourless air-Large target; OS = Odourless air-Small target.</p>
<span>doi:10.1371/journal.pone.0001795.g003</span></div><div class="figure" id="pone-0001795-g004"><div class="img"><a name="pone-0001795-g004" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g004&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.g004"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g004&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g004/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g004/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g004/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g004/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001795.g004.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g004/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g004/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001795.g004.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 4.  <span>Time course of abduction angle between fingers during reaching in the absence of olfactory stimuli.</span></strong></p><a id="article1.body1.sec2.sec1.fig2.caption1.p1" name="article1.body1.sec2.sec1.fig2.caption1.p1"></a><p>Each trace corresponds to the average abduction angle for the ‘OL’ (black squares) and the ‘OS’ (white circles) conditions. Bars represent mean standard error. Increase in negative values correspond to bigger abduction (i.e., increase of digits' angular distance). Asterisks indicate significant results (<em>p&lt;</em>.05) for the comparisons between the ‘OL’ and the ‘OS’ conditions at different epochs of normalized movement time. OL = Odourless air-Large target; OS = Odourless air-Small target.</p>
<span>doi:10.1371/journal.pone.0001795.g004</span></div>

<h4>The Effect of Odours on Hand Shaping</h4>
<a id="article1.body1.sec2.sec2.p1" name="article1.body1.sec2.sec2.p1"></a><p>Here we describe the specific effects of odour ‘size’ on hand shaping. Specifically in the following sections we report on the effects of odour ‘size’ on the digits' angular excursion and abduction angles.</p>
<h5>Grasping a large target.</h5><a id="article1.body1.sec2.sec2.sec1.p1" name="article1.body1.sec2.sec2.sec1.p1"></a><p>For the congruent ‘LL’ condition, the <em>pip</em> joint of the index, middle and ring fingers was more extended than for the ‘OL’ condition (<a href="#pone-0001795-g005">Fig. 5</a>). This effect was particularly evident at the very beginning of movement duration (i.e., at 10–20% for both the index and the ring finger, and at 20% for the middle finger) (<a href="#pone-0001795-t001">Table 1</a>). A similar effect was exhibited by the <em>mcp</em> joint of the thumb which was more extended for the ‘LL’ than for the ‘OL’ condition at 20% of movement duration (<a href="#pone-0001795-g005">Fig. 5</a> and <a href="#pone-0001795-t001">Table 1</a>). For these joints, after 20% of movement duration, no differences when comparing ‘LL’ and the ‘OL’ conditions were evident.</p>
<div class="figure" id="pone-0001795-g005"><div class="img"><a name="pone-0001795-g005" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g005&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.g005"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g005&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g005/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g005/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g005/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g005/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001795.g005.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g005/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g005/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001795.g005.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 5.  <span>Time course of finger motion during reaching for the large target either in the absence or in the presence of an odour evoking a large object.</span></strong></p><a id="article1.body1.sec2.sec2.sec1.fig1.caption1.p1" name="article1.body1.sec2.sec2.sec1.fig1.caption1.p1"></a><p>Each trace corresponds to the average angular excursion of a representative subject (Subject 15) for the <em>mcp</em> joint of the thumb and the <em>pip</em> joint of the index, middle, and ring fingers when performing the ‘OL’ (black squares) and the ‘LL’ (blue squares) conditions. Positive values correspond to finger flexion whereas negative values correspond to finger extension. OL = Odourless air-Large target; LL = ‘Large’ odour-Large target.</p>
<span>doi:10.1371/journal.pone.0001795.g005</span></div><div class="figure" id="pone-0001795-t001"><div class="img"><a name="pone-0001795-t001" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.t001&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.t001"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.t001&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.t001/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.t001/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.t001/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.t001/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001795.t001.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.t001/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.t001/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001795.t001.TIF"></span>)
                </a></li></ul></div><p><strong>Table 1.  <span>Average angular excursions at different epochs of normalized movement time.</span></strong></p><span>doi:10.1371/journal.pone.0001795.t001</span></div><a id="article1.body1.sec2.sec2.sec1.p2" name="article1.body1.sec2.sec2.sec1.p2"></a><p>For the incongruent ‘SL’ condition, the <em>mcp</em> joint of the index, middle, and ring fingers was more flexed than for the ‘OL’ condition (<a href="#pone-0001795-g006">Fig. 6</a>). In particular, the <em>mcp</em> joint of index, middle, and ring fingers showed an over-flexion at about half of movement duration (<a href="#pone-0001795-t001">Table 1</a>). However, a delayed odour ‘size’ effect was evident for the <em>mcp</em> joint of the index finger (<a href="#pone-0001795-t001">Table 1</a>). A similar pattern was also found for the <em>pip</em> joints of both the thumb and the index finger showing a greater flexion in the ‘SL’ than in the ‘OL’ condition at 50% and 40% of movement duration, respectively (<a href="#pone-0001795-g006">Fig. 6</a> and <a href="#pone-0001795-t001">Table 1</a>). The middle-ring and the ring-little abduction angles were smaller for the ‘SL’ than for the ‘OL’ condition. This effect was evident within the second half of movement duration (<a href="#pone-0001795-g007">Fig. 7</a> and <a href="#pone-0001795-t002">Table 2</a>).</p>
<div class="figure" id="pone-0001795-g006"><div class="img"><a name="pone-0001795-g006" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g006&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.g006"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g006&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g006/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g006/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g006/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g006/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001795.g006.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g006/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g006/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001795.g006.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 6.  <span>Time course of finger motion during reaching for the large target either in the absence or in the presence of an odour evoking a small object.</span></strong></p><a id="article1.body1.sec2.sec2.sec1.fig2.caption1.p1" name="article1.body1.sec2.sec2.sec1.fig2.caption1.p1"></a><p>Each trace denotes the average angular excursion of a representative subject (subject 15) for the <em>mcp</em> joint of index, middle and ring fingers (upper panels), and the <em>pip</em> joint of the thumb and index finger (lower panels) when performing the ‘OL’ (black squares) and the ‘SL’ (red squares) conditions. Positive values correspond to finger flexion whereas negative values correspond to finger extension. OL = Odourless air-Large target; SL = ‘Small’ odour-Large target.</p>
<span>doi:10.1371/journal.pone.0001795.g006</span></div><div class="figure" id="pone-0001795-g007"><div class="img"><a name="pone-0001795-g007" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g007&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.g007"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g007&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g007/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g007/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g007/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g007/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001795.g007.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g007/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g007/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001795.g007.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 7.  <span>Time course of abduction angle between fingers during reaching for the large target either in the absence or in the presence of an odour evoking a small object.</span></strong></p><a id="article1.body1.sec2.sec2.sec1.fig3.caption1.p1" name="article1.body1.sec2.sec2.sec1.fig3.caption1.p1"></a><p>Each trace denotes average abduction angle of a representative subject (Subject 10) for the middle-ring and the ring-little fingers when performing the ‘OL’ (black squares) and the ‘SL’ (red squares) conditions. Increase in negative values correspond to bigger abduction (i.e., increase of digits' angular distance). OL = Odourless air-Large target; SL = ‘Small’ odour-Large target.</p>
<span>doi:10.1371/journal.pone.0001795.g007</span></div><div class="figure" id="pone-0001795-t002"><div class="img"><a name="pone-0001795-t002" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.t002&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.t002"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.t002&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.t002/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.t002/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.t002/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.t002/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001795.t002.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.t002/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.t002/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001795.t002.TIF"></span>)
                </a></li></ul></div><p><strong>Table 2.  <span>Average fingers' abduction angles at different epochs of the normalized movement time.</span></strong></p><span>doi:10.1371/journal.pone.0001795.t002</span></div><a id="article1.body1.sec2.sec2.sec1.p3" name="article1.body1.sec2.sec2.sec1.p3"></a><p>These results indicate that the presence of a ‘large’ odour magnified the ‘extension’ pattern which was found when a large target was grasped in the absence of olfactory information. Such magnification was particularly evident during the first part of movement duration. Conversely, the presence of a ‘small’ odour determined a ‘flexion’ pattern which was not evident when the large target was grasped in the absence of olfactory information (showing a similarity, in terms of flexion, with the pattern elicited by the small target when grasped in the absence of olfactory information). The effect due to the presence of the ‘small’ odour persisted up to the end of the movement duration.</p>

<h5>Grasping a small target.</h5><a id="article1.body1.sec2.sec2.sec2.p1" name="article1.body1.sec2.sec2.sec2.p1"></a><p>For the congruent ‘SS’ condition, the <em>mcp</em> joints of both the index and the little finger were more flexed than for the ‘OS’ condition. Specifically, the <em>mcp</em> joints for both the index and the little finger showed such over-flexion at 40%, and from 20 up to 60% of movement duration, respectively (<a href="#pone-0001795-g008">Fig. 8</a> and <a href="#pone-0001795-t003">Table 3</a>). For the incongruent ‘LS’ condition, angular excursion of the <em>mcp</em> joint for both the thumb and the ring finger significantly differed from angular excursions obtained for the ‘OS’ condition. In particular, at 20% of movement duration, the <em>mcp</em> joint of the ring finger was more extended in the ‘LS’ than ‘OS’ condition (<a href="#pone-0001795-g009">Fig. 9</a> and <a href="#pone-0001795-t003">Table 3</a>). In contrast, from 10% up to the end of movement duration, the <em>mcp</em> joint of the thumb was more flexed for the ‘LS’ than for the ‘OS’ condition (<a href="#pone-0001795-g009">Fig. 9</a> and <a href="#pone-0001795-t003">Table 3</a>).</p>
<div class="figure" id="pone-0001795-g008"><div class="img"><a name="pone-0001795-g008" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g008&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.g008"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g008&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g008/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g008/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g008/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g008/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001795.g008.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g008/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g008/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001795.g008.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 8.  <span>Time course of finger motion during reaching for the small target either in the absence or in the presence of an odour evoking a small object.</span></strong></p><a id="article1.body1.sec2.sec2.sec2.fig1.caption1.p1" name="article1.body1.sec2.sec2.sec2.fig1.caption1.p1"></a><p>Each trace denotes average angular excursion of a representative subject (Subject 2) for the <em>mcp</em> joint of the index and the little fingers when performing the ‘OS’ (black circles) and the ‘SS’ (purple circles) conditions. Positive values correspond to finger flexion whereas negative values correspond to finger extension. OS = Odourless air-Small target; SS = ‘Small’ odour-Small target.</p>
<span>doi:10.1371/journal.pone.0001795.g008</span></div><div class="figure" id="pone-0001795-g009"><div class="img"><a name="pone-0001795-g009" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g009&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.g009"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.g009&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g009/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g009/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g009/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g009/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001795.g009.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.g009/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.g009/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001795.g009.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 9.  <span>Time course of finger motion during reaching for the small target either in the absence or in the presence of an odour evoking a large object.</span></strong></p><a id="article1.body1.sec2.sec2.sec2.fig2.caption1.p1" name="article1.body1.sec2.sec2.sec2.fig2.caption1.p1"></a><p>Each trace depicts average angular excursion of a representative subject (Subject 2) for the <em>mcp</em> joint of the thumb and the ring finger when performing the ‘OS’ (black circles) and the ‘LS’ (green circles) conditions. Positive values correspond to finger flexion whereas negative values correspond to finger extension. OS = Odourless air-Small target; LS = ‘Large’ odour-Small target.</p>
<span>doi:10.1371/journal.pone.0001795.g009</span></div><div class="figure" id="pone-0001795-t003"><div class="img"><a name="pone-0001795-t003" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.t003&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.t003"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.t003&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.t003/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.t003/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.t003/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.t003/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001795.t003.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.t003/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.t003/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001795.t003.TIF"></span>)
                </a></li></ul></div><p><strong>Table 3.  <span>Average angular excursions at different epochs of normalized movement time.</span></strong></p><span>doi:10.1371/journal.pone.0001795.t003</span></div><a id="article1.body1.sec2.sec2.sec2.p2" name="article1.body1.sec2.sec2.sec2.p2"></a><p>To sum up, the presence of a ‘small’ odour enhanced the pattern of hand flexion which was found when the small target was grasped in the absence of olfactory information. Such intensification was particularly evident during the first part of movement duration. Conversely, the presence of a ‘large’ odour determined both a greater ring finger extension and a greater thumb flexion with respect to when the small target was grasped in the absence of olfactory information (showing similarity with the pattern elicited by the large target when grasped in the absence of olfactory information). The effect due to the presence of the ‘large’ odour persisted throughout the entire movement duration.</p>



<h4>Hand Motion Covariation</h4>
<a id="article1.body1.sec2.sec3.p1" name="article1.body1.sec2.sec3.p1"></a><p>This section reports on the results concerned with the pattern of hand motion covariation as obtained by the absolute value of the slopes of the regression lines fitting angular values between articulations' pairs (see ‘Data analysis’ section). The relationship between the size of the odour-evoked stimulus and the size of the visual target did affect the absolute value of the slopes during reaching (F<sub>(6.36,572.25)</sub> = 4.02, <em>p</em>&lt;.001). Post-hoc analyses revealed that the slope absolute values decreased at specific epochs during reaching only when the odour was associated with an object having a different size than the visual target (<a href="#pone-0001795-t004">Table 4</a>). Further, the temporal window of the reduction in covariation was wider when the stimulus associated with the odour was small rather than large (<a href="#pone-0001795-t004">Table 4</a>). Therefore, the pattern of hand motion covariation was weakened when the ‘size’ of the odour did not match the size of the target. Importantly the delivery of an odour evoking a stimulus of a similar size to the target did not alter the motion covariation characterizing the hand when no odour was delivered.</p>
<div class="figure" id="pone-0001795-t004"><div class="img"><a name="pone-0001795-t004" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.t004&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001795" data-uri="info:doi/10.1371/journal.pone.0001795.t004"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001795.t004&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.t004/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.t004/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.t004/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.t004/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001795.t004.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001795.t004/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001795.t004/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001795.t004.TIF"></span>)
                </a></li></ul></div><p><strong>Table 4.  <span>Average absolute value of the slopes of the regression lines fitting angular values for each articulations' pair at different epochs of normalized movement time.</span></strong></p><span>doi:10.1371/journal.pone.0001795.t004</span></div>
</div>

<div id="section3" class="section"><a id="s3" name="s3" toc="s3" title="Discussion"></a><h3>Discussion</h3><a id="article1.body1.sec3.p1" name="article1.body1.sec3.p1"></a><p>The present study has investigated the effects of odour stimuli on the kinematics of hand shaping at the level of individual digits' motion. The results indicate that the kinematic patterning of a reach-to-grasp movement was influenced by the ‘size’ of an odour. Crucially, the motor plan evoked by the odour is surprisingly fine-grained and when elicited can modulate both the pattern of angular excursion at the level of individual fingers' joints and the degree of synergic movement amongst digits.</p>

<h4>When the Size of the Visual Target and the ‘Size’ of the Olfactory Stimulus do not Match Interference Emerges</h4>
<a id="article1.body1.sec3.sec1.p1" name="article1.body1.sec3.sec1.p1"></a><p>As reported here, reach-to-grasp movements can be planned on the basis of olfactory information. The motor plan elicited by the olfactory stimulus is not totally overridden by the motor plan triggered, at a later time, by the visual target. That is, some aspects of the motor plan elicited by a ‘size’ incongruent olfactory stimulus persist in the motor plan executed for grasping the visual target. This effect was evident when comparing the incongruent odour (‘LS’ and ‘SL’) with the respective odourless (‘OS’ and ‘OL’) conditions.</p>
<a id="article1.body1.sec3.sec1.p2" name="article1.body1.sec3.sec1.p2"></a><p>When the odour was ‘large’ and the visual target was small, only one finger joint (i.e., the <em>mcp</em> joint of the ring finger) was affected by the olfactory stimulus. In contrast, the influence of the ‘small’ odour on the kinematics of a reach-to-grasp movement towards a large target was much more evident and a greater number of joints were mobilized. This seems to suggest that planning for a reach-to-grasp movement on the basis of a ‘small’ odour when the target is large poses more constraints than when the odour is ‘large’ and the movement is directed towards a small target. Our proposal is that the motor plan elicited by the odour has to be modified according to the visual target. However such reorganization could be more easily managed without compromising object grasp when the odour is ‘large’ and the visual target is small than vice versa.</p>
<a id="article1.body1.sec3.sec1.p3" name="article1.body1.sec3.sec1.p3"></a><p>In terms of complexity, several factors could contribute to the difference in kinematic response between the two types of incongruent conditions. For instance, biomechanically there may be more advantage for closure (as happens for the present ‘LS’ condition) than for opening (as happens for the present ‘SL’ condition). Colebatch and Gandevia <a href="#pone.0001795-Colebatch1">[28]</a> found, for example, that thumb and finger flexors were 2.8–3.5 times stronger than extensors. For a task focused upon a grasping action, the biomechanical setting for the flexors would be more favoured. This view seems to be supported by the results obtained in previous studies looking at the reprogramming of grip aperture following a perturbation of object size <a href="#pone.0001795-Castiello4">[29]</a>, <a href="#pone.0001795-Bock1">[30]</a>. These findings indicate that the passage from a large to a small object was easier than the passage from a small to a large object.</p>
<a id="article1.body1.sec3.sec1.p4" name="article1.body1.sec3.sec1.p4"></a><p>Of note is the finding that when the odour is ‘large’ and the target is small, the thumb is over-flexed with respect to the condition in which the small visual stimulus is presented without preceding olfactory information. A possible explanation for such an effect considers how the thumb behaves for movements performed in the absence of olfactory information (i.e., no-odour conditions). In such circumstances, the thumb is usually more flexed at the end of the movement for the large than for the small target. Therefore, the finding that a ‘large’ odour determines an over-flexion of this digit strengthens the hypothesis that a motor plan suited for grasping a larger target is evoked by the odour.</p>
<a id="article1.body1.sec3.sec1.p5" name="article1.body1.sec3.sec1.p5"></a><p>The delivery of ‘incongruent’ odours also had an effect on the extent of synergic movements within the hand. This is signified by the loosening of synergies amongst fingers observed for the incongruent odour conditions with respect to the level of synergies observed for the no-odour conditions. A possible interpretation for these findings relies on the requirement to integrate the motor plan established for the visual target into the motor plan elicited by the preceding ‘odour’ stimulus. This integration process is gradual and it spreads throughout the entire movement duration. In other words, the ‘olfactory’ motor plan is not immediately excluded as the visual target appears (as it can be noticed on the fingers' angular excursion profiles), but penetrates the ‘visual’ motor plan. Such intrusion results in an on-line adjustment which renders the system more unstable and therefore determines a decrease in the level of covariation amongst digits. In line with the hypothesis that dealing with the intrusion of a ‘large’ odour is easier than dealing with the intrusion of a ‘small’ odour, the temporal window in which the decrease in the level of covariation was found it was greater when the olfactory stimulus was ‘small’ and the visual target was ‘large’ than when the olfactory stimulus was ‘large’ and the visual target was ‘small’.</p>
<a id="article1.body1.sec3.sec1.p6" name="article1.body1.sec3.sec1.p6"></a><p>It is now necessary to comment on how we view the processing of olfactory stimuli in terms of action control. Our preferred ideas are that during initial perceptual analysis, a limited number of objects potentially relevant for action are processed in parallel. This initial perceptual processing flows continuously into areas of the brain that represent and subsequently initiate action. Such perceptual inputs are capable of automatically activating their associated responses without subjects' intentions to act <a href="#pone.0001795-Tipper1">[31]</a>, <a href="#pone.0001795-Castiello5">[32]</a>. Due to this highly efficient and automatic conversion of perceptual inputs into the actions, different sensory inputs can evoke actions in parallel. As soon as the target is identified, an appropriate reach-to-grasp motor plan is initialized which then competes with the motor plan triggered by the odour; this conflict is played out in the kinematics of hand shaping. Thus, according to this model, the difference between the grasp plans activated by the visual target and by the olfactory stimulus is essential for hand shaping interference effects to be observed.</p>


<h4>When the Size of the Visual Target and the ‘Size’ of the Olfactory Stimulus Match Facilitation Emerges</h4>
<a id="article1.body1.sec3.sec2.p1" name="article1.body1.sec3.sec2.p1"></a><p>When a preceding odour elicits a motor plan which is congruent with the motor plan subsequently established for the visual target, the kinematic patterning is magnified. Therefore, the grasp plan triggered by the olfactory stimulus primed the grasp plan established for the visual target. This effect was evident at the very beginning of the movement, fading away during the second phase of the movement. Remember that for both the incongruent conditions the conflict between the ‘olfactory’ and the ‘visual’ grasp plans lasted for the entire movement duration. Importantly, and again in contrast with what reported for the incongruent conditions, an odour of a similar ‘size’ than the visual target, does not alter hand synergies with respect to when no-odour is presented. This indicates that when the ‘size’ of the odour and the size of the visual target match, the integration of the two modalities reinforces the grasp plan, the established synergic pattern is more ‘protected’ and it does not change. Having two sources carrying similar information leads to a more stable and coherent action.</p>
<a id="article1.body1.sec3.sec2.p2" name="article1.body1.sec3.sec2.p2"></a><p>Research on multisensory processing brings evidence of enhancements of multimodal neurons' firings, perceptual processes, or reaction times, in response to stimuli with similar characteristics represented in different modalities <a href="#pone.0001795-Stein1">[1]</a>, <a href="#pone.0001795-Rolls1">[33]</a>–<a href="#pone.0001795-Calvert1">[36]</a>. More recently, similar enhancements have also been found for prehensile tasks <a href="#pone.0001795-Patchay1">[16]</a>–<a href="#pone.0001795-Zahariev1">[18]</a>. For instance, reach-to-grasp movements were faster if two cues related to the same target object pertained to different sensory modalities, i.e., visual and auditory than when only one cue is presented <a href="#pone.0001795-Zahariev1">[18]</a>. The present results crucially extend this literature by demonstrating that similar facilitation effect can also be revealed for multisensory integrations involving olfaction.</p>
<a id="article1.body1.sec3.sec2.p3" name="article1.body1.sec3.sec2.p3"></a><p>It is tempting to speculate about the possible neural mechanisms underlying the reported facilitation effects. Evidence from neuroimaging <a href="#pone.0001795-Gottfried1">[37]</a>, <a href="#pone.0001795-sterbauer1">[38]</a> and neurophysiological studies <a href="#pone.0001795-Grigor1">[39]</a>–<a href="#pone.0001795-Sarfarazi1">[41]</a> may help in this exercise. For example, by manipulating the degree of semantic correspondence between odour-picture pairs, Gottfried and Dolan <a href="#pone.0001795-Gottfried1">[37]</a> revealed facilitation for semantically congruent versus incongruent situation. This advantage was associated with enhanced neural activity within the orbitofrontal cortex (OFC). Similarly, Österbauer and collaborators <a href="#pone.0001795-sterbauer1">[38]</a> found increased activity within the OFC when the perceived congruence between visual and olfactory stimuli became progressively higher. Thus, it might be reasonable to assume that the facilitation effects found in the present study are mediated by visual-olfactory representations encoded at the level of multisensory integration sites within the OFC. But, how do these visual-olfactory representations manage to modulate motor output? Comparative literature may provide some evidence for neural networks which connect the OFC with motor regions <a href="#pone.0001795-Cavada1">[42]</a>. Of particular interest for our study is the presence of direct connections between OFC and motor areas involved in arm-hand movement control such as the motor cingulated area 24c/M3, the supplementary motor area F3/M2, the pre-supplementary motor area F6 and the ventral premotor area F5. Furthermore, also the primary motor cortex (M1) receives inputs from frontal granular area 12 <a href="#pone.0001795-Morecraft1">[43]</a>. On the basis of the well-known homology between cerebral regions underling reach-to-grasp movement in monkeys and humans <a href="#pone.0001795-Castiello1">[8]</a>, <a href="#pone.0001795-Begliomini1">[44]</a>, we suggest that the cortico-cortical connections between OFC and motor areas influencing motor output in non human primates <a href="#pone.0001795-Bates1">[45]</a> may also exist in humans and account for the influence of multisensory information on motor behaviour and more specifically on prehensile actions <a href="#pone.0001795-Rossi1">[46]</a>. In this respect, the present findings provide some support to theoretical models specifically designed to infer about the neural mechanisms underlying reach-to-grasp movements <a href="#pone.0001795-Arbib1">[47]</a>, <a href="#pone.0001795-Fagg1">[48]</a>. These models posit that robust ‘multisensory’ perception might act to increase the level of activation of perceptual schemas, which in turn might increase the ‘readiness‘ of brain areas devoted to the control of prehensile actions. In this view, we demonstrate that also olfactory information, as with any sensory modality, might have the potential to enhance activity within the neural networks subtending a complex system such as the hand.</p>


<h4>Conclusions</h4>
<a id="article1.body1.sec3.sec3.p1" name="article1.body1.sec3.sec3.p1"></a><p>A tenet from previous research on reach-to-grasp movements is the notion of visuo-motor transformation. That is, the conversion of the geometric features characterizing the to-be-grasped object into an appropriate motor prototype. The evidence for the existence of such process comes from the demonstration that structural properties (e.g., size, shape, and texture) of visually encoded objects reflect on hand posture at the level of individual finger movements when grasping.</p>
<a id="article1.body1.sec3.sec3.p2" name="article1.body1.sec3.sec3.p2"></a><p>Here we extend this notion revealing that the size of the object evoked by the odour has the potential to modulate hand shaping. Importantly, the fact that ‘size’ olfactory information modulates the hand at the level of individual digits (and not only the thumb-index distance as previously reported) leads to two important considerations in terms of sensorimotor transformation. First, from a perceptual perspective, the representation evoked by the odour seems to contain highly detailed information about the object (i.e., volumetric features rather than a linear dimension such as the thumb-index distance). If olfaction had provided a blurred and holistic object's representation (i.e., a low spatial-resolution of the object's image), then the odour would have not affected the hand in its entirety. Second, from a motor perspective, the olfactory representation seems to be mapped into the action vocabulary with a certain degree of reliability. The elicited motor plan embodies specific and selective commands for handling the ‘smelled’ object, and it is fully manageable by the motor system. Therefore, it is not an incomplete primal sketch which only provides a preliminary descriptive in the terms of motor execution.</p>
<a id="article1.body1.sec3.sec3.p3" name="article1.body1.sec3.sec3.p3"></a><p>Another aspect of the present results is how hand kinematics modulates depending on the similarity between the ‘visual’ and ‘olfactory’ motor blueprints. Current literature on multisensory integration reports facilitation effects when two sensory modalities provide congruent information about an object and interference effects when different sensory modalities provide discordant information. In this respect, we crucially extend this literature by having identified a chemosensory-visual binding for the control of action. We found facilitation effects when olfactory/visual information elicited a congruent motor planning and interference when olfactory/visual information triggered different motor plans.</p>
<a id="article1.body1.sec3.sec3.p4" name="article1.body1.sec3.sec3.p4"></a><p>The present findings open to a number of unsolved questions. For instance, how do multisensory integration neural loci, such as the orbitofrontal cortex, modulate their activity when information for action planning is provided through different modalities? And, how do multisensory integration sites ‘talk’ with the neural circuits underlying grasping as to modulate motor output? Further research using functional imaging and neurophysiological techniques may have the potential to uncover the neural underpinnings for the effects reported here.</p>

</div>

<div id="section4" class="section"><a id="s4" name="s4" toc="s4" title="Materials and Methods"></a><h3>Materials and Methods</h3>
<h4>Subjects</h4>
<a id="article1.body1.sec4.sec1.p1" name="article1.body1.sec4.sec1.p1"></a><p>Twenty-six right handed subjects (21 females and 5 males, mean age 22±3.5 years) took part in the experiment. All participants reported normal olfaction, no history of olfactory dysfunction, and normal or corrected-to-normal vision in a confidential report. All subjects were naïve as to the purpose of the experiment and gave their informed written consent to participate in the study. The experimental session lasted approximately 30 min. The experimental procedures were approved by the Institutional Review Board at the University of Padua and were in accordance with the declaration of Helsinki.</p>


<h4>Stimuli and apparatus</h4>
<a id="article1.body1.sec4.sec2.p1" name="article1.body1.sec4.sec2.p1"></a><p>The visual stimuli (i.e., targets) consisted of four plastic objects grouped on the basis of their natural size: large (apple, orange) and small (almond, strawberry) (<a href="#pone-0001795-g001">Fig. 1A</a>). Plastic objects were used in order to maintain consistent visual attributes and sizes similar throughout the period of experimentation. The odour stimuli corresponded to the target stimuli described above. Odour solutions of strawberry, almond, orange, and apple were obtained mixing 6000 µl of prophylenic glycol and 180 µl (3%), 60 µl (1%), 420 µl (7%), and 45 µl (0.75%) of the specific odorant compound, respectively. A custom-built computer-controlled olfactometer (Department of Experimental Psychology, University of Oxford) was used to deliver the odour stimuli or odourless air. Each odour generator consisted of a glass boat containing one of the four odour stimuli. A fifth glass boat containing prophylenic glycol was used for the delivery of odourless air. The air passed over the odour solutions and the prophylenic glycol at a flow rate of 8 l/min and it was delivered to subjects via Teflon tubing to a facial mask (<a href="#pone-0001795-g001">Fig. 1B</a>). Data from a pilot study showed that the objects associated with the administered odour stimuli were all correctly identified by the subjects. Further, the odour stimuli were judged to have equal intensity, hedonic tone and familiarity and to be iso-intense during all the experimental session. At the beginning of each trial, subjects placed their right hand on a starting platform within which a pressure sensitive switch was embedded (i.e., starting switch). The platform was designed with slight convexities dictating a natural flexed posture of the fingers (<a href="#pone-0001795-g001">Fig. 1B</a>). The target object was placed on a second pressure sensitive switch (i.e., the ending switch) embedded within the working surface (<a href="#pone-0001795-g001">Fig. 1B</a>).Vision was controlled using spectacles fitted with liquid crystal lenses (Translucent Technologies Inc., Toronto, Ontario, Canada) that rendered the target visually accessible by changing from opaque to clear (<a href="#pone-0001795-g001">Fig. 1B</a>). The release of the starting switch corresponded to the onset of the reaching movement towards the target and determined visual availability of the target object (i.e., opening of the spectacles). Movement offset was taken at the time in which the ending switch was released when the object was lifted. Reaching duration was calculated as the time interval between the release of the starting and ending switches.</p>


<h4>Procedures</h4>
<a id="article1.body1.sec4.sec3.p1" name="article1.body1.sec4.sec3.p1"></a><p>Participants began each trial with the elbow and the wrist resting on a flat surface, the forearm horizontal, the arm oriented in the parasagittal plane passing through the shoulder, and the right hand in a pronated position with the palm toward the working surface on the starting switch. The target was aligned with the subject's body midline and located at 33-cm-distance from the hand starting position to the left of the subject's right shoulder (<a href="#pone-0001795-g001">Fig. 1B</a>). The sequence of events for each trial was as follows: 1) vision was occluded before the target was positioned on the working surface; 2) an auditory tone (850 ms duration, 65 dB sound pressure, and 800 Hz frequency) indicated odour delivery; 3) after 3 s, a similar tone indicated the offset of odour delivery; 4) following a 500 ms interval the tone was presented again; 5) upon hearing the tone, participants were instructed to reach towards, grasp and lift the target object. Sufficient time (10 s) was allowed between trials to recover from any odour adaptation <a href="#pone.0001795-Hummel1">[49]</a>. The adopted sequence of events was chosen because previous literature has revealed that effects of task irrelevant information on reach-to-grasp kinematics are maximized when the task irrelevant stimulus/cue (presented in the same or a different sensory modality than the target) is presented slightly before the to-be-grasped target <a href="#pone.0001795-Patchay1">[16]</a>, <a href="#pone.0001795-Tipper1">[31]</a>, <a href="#pone.0001795-Castiello6">[50]</a>. We instructed the subjects to reach at a natural speed and not to grasp the object by the stem. The experimenter visually monitored each trial to ensure subject's compliance to these requirements. Subjects naturally grasp the small objects between the thumb and either (or both) the index and the middle fingers and the large objects opposing the thumb with all the other fingers.</p>
<a id="article1.body1.sec4.sec3.p2" name="article1.body1.sec4.sec3.p2"></a><p>This experimental task was performed under six different experimental conditions:</p>
<a id="article1.body1.sec4.sec3.p3" name="article1.body1.sec4.sec3.p3"></a><p>(1) ‘OL’ condition: odourless air was delivered before the reach-to-grasp movement towards a large target was initiated;</p>
<a id="article1.body1.sec4.sec3.p4" name="article1.body1.sec4.sec3.p4"></a><p>(2) ‘OS’ condition: odourless air was delivered before the reach-to-grasp movement towards a small target was initiated;</p>
<a id="article1.body1.sec4.sec3.p5" name="article1.body1.sec4.sec3.p5"></a><p>(3) ‘LL’ condition: an odour associated with an object of a large size was presented before the reach-to-grasp movement towards a large target was initiated;</p>
<a id="article1.body1.sec4.sec3.p6" name="article1.body1.sec4.sec3.p6"></a><p>(4) ‘SS’ condition: an odour associated with an object of a small size was presented before the reach-to-grasp movement towards a small target was initiated;</p>
<a id="article1.body1.sec4.sec3.p7" name="article1.body1.sec4.sec3.p7"></a><p>(5) ‘SL’ condition: an odour associated with an object of a small size was presented before the reach-to-grasp movement towards a large target was initiated;</p>
<a id="article1.body1.sec4.sec3.p8" name="article1.body1.sec4.sec3.p8"></a><p>(6) ‘LS’ condition: an odour associated with an object of a large size was presented before the reach-to-grasp movement towards a small target was initiated.</p>
<a id="article1.body1.sec4.sec3.p9" name="article1.body1.sec4.sec3.p9"></a><p>Odour-target combinations for each experimental condition are represented in <a href="#pone-0001795-g002">Fig. 2</a>. Participants performed a total of 48 trials (8 for each experimental condition) which were presented in randomized order within one block.</p>


<h4>Recording techniques</h4>
<a id="article1.body1.sec4.sec4.p1" name="article1.body1.sec4.sec4.p1"></a><p>Hand posture was measured by resistive sensors embedded in a glove (CyberGlove, Virtual Technologies, Palo Alto, CA, USA), worn on the subject's right hand (<a href="#pone-0001795-g001">Fig. 1B</a>). The sensors' linearity was 0.62% of maximum nonlinearity over the full range of hand motion. The sensors' resolution was 0.5°, which remains constant over the entire range of joint motion. The output of the transducers was sampled at 12-ms interval. Angular excursion was measured at metacarpal phalangeal (<em>mcp</em>) and proximal interphalangeal (<em>pip</em>) joints of the thumb, index, middle, ring, and little finger. Abduction angles between the thumb-index, index-middle, middle-ring, and ring-little fingers were measured. Before the experimental block started, baseline hand posture for each subject was recorded. Subjects were requested to place their right hand flat on the table with the fingers straightened, close to each other and to hold that position until baseline fingers' angular excursion and abduction angles were recorded. Angular excursion and abduction angles were defined 0° when the fingers were maintained straight and together in the plane of the palm (‘reference hand posture’). Fingers' flexion was assigned positive values whereas fingers' extension was given negative values with respect to the baseline. Abduction angles were reported on a continuum of negative values with respect to the baseline. A decrease in such values indicated relatively greater abduction.</p>


<h4>Data Analysis</h4>
<a id="article1.body1.sec4.sec5.p1" name="article1.body1.sec4.sec5.p1"></a><p>Data from each trial were time normalized to compare hand posture across experimental conditions at different epochs during reaching. Specifically, the pattern for both fingers' angular excursion and abduction angles was calculated from 10 to 100% of reaching duration, at 10% intervals. The results predicted by our hypotheses (see ‘Introduction’ section) were assessed at each epoch of the normalized movement time by means of planned orthogonal contrasts <a href="#pone.0001795-Furr1">[51]</a> implemented with R-2.5.1 software package (<a href="http://cran.r-project.org">http://cran.r-project.org</a>). Since contrasts are coding vectors that mathematically express predicted results <a href="#pone.0001795-Thompson1">[52]</a>, we created vectors to assess the target size effect (i.e., 1 and −1 for ‘OL’ and ‘OS’ condition, respectively, 0 for the remaining conditions), the effect of odours having a similar ‘size’ as the visual target (i.e., 1 and −1 for ‘LL’ and ‘OL’ condition, respectively, 0 for remaining conditions; −1 and 1 for ‘SS’ and ‘OS’ condition, respectively, 0 for remaining conditions), and the effect of odours having a different ‘size’ than the visual target (i.e., −1 and 1 for ‘SL’ and ‘OL’ condition, respectively, 0 for remaining conditions; 1 and −1 for ‘LS’ and ‘OS’ condition, respectively, 0 for remaining conditions). We used one-tail <em>t-test</em> for all fingers' joints and abduction angles since a specific direction of the ‘size’ effect for both the target and the object evoked by the odour was predicted. A two-tails <em>t-test</em> was used for the thumb's joints given that on the basis of recent experimental evidence no specific predictions could be made <a href="#pone.0001795-Frak1">[53]</a>, <a href="#pone.0001795-Ansuini1">[54]</a>. This is because it has been demonstrated that the thumb's angular excursion is not specifically modulated to object's structural properties (e.g., shape), but it reflects a role in action guidance. The <em>t-</em>values corresponding to each contrast were considered statistically significant if less than .05 (α-level).</p>
<a id="article1.body1.sec4.sec5.p2" name="article1.body1.sec4.sec5.p2"></a><p>The effects of the relationship between the ‘odour’ size and the visual target size on the degree of motion covariation within the hand during reaching for the target were assessed as follows. First, we computed the slope of the regression line between angular excursion of ‘joint-joint’, ‘joint-abduction’, and ‘abduction-abduction’ pairs (45, 40, and 6 pairs, respectively, for a total of 91 pairs) for each of the six experimental conditions (i.e., ‘OL’, ‘OS’, ‘LL’, ‘SS’, ‘SL’, ‘SS’) and for each epoch of the normalized movement time. For this analysis, each subject was taken as a statistical unit. Then, in order to obtain a quantitative index of the degree of hand motion covariation, we calculated absolute values of the obtained slopes. Finally, an analysis of variance (ANOVA) was performed on these values with odour ‘size’ (large, small, and no-odour), target size (large, small), and time (from 10 to 100%, by step of 10%) as within subject factors. For this analysis, each of the 91 pairs was considered as a statistical unit. Before running the ANOVA, we checked for all the main assumptions behind this statistical model (i.e., normality and sphericity). Kolmogorov-Smirnov test revealed that the normality assumption was satisfied (α-level: .05). Whereas, Mauchly test showed that the sphericity assumption was violated (α-level: .05), hence, Greenhouse-Geisser correction was applied to the degrees of freedom of <em>F</em>-statistics.</p>
<a id="article1.body1.sec4.sec5.p3" name="article1.body1.sec4.sec5.p3"></a><p>Results from the ANOVA performed on the slope absolute values were explored through post-hoc multiple comparisons. Specifically, paired sample <em>t-tests</em> were used to compare ‘OL’ vs. ‘OS’ condition, ‘LL’ vs. ‘OL’ condition, ‘SL’ vs. ‘OL’ condition, ‘SS’ vs. ‘OS’ condition, and ‘LS’ vs. ‘OS’ condition at each epoch. For these <em>t-tests</em>, the increase of the type I error (α-level: .01) was controlled by applying False Discovery Rate (<em>FDR</em>) correction <a href="#pone.0001795-Benjamini1">[55]</a>.</p>

</div>





<div><a id="ack" name="ack" toc="ack" title="Acknowledgments"></a><h3>Acknowledgments</h3>
<a id="article1.back1.ack1.p1" name="article1.back1.ack1.p1"></a><p>We thank Heidi Chapman for comments on a previous version of this manuscript. Stefano Massaccesi and Gianmarco Altoè are thanked for technical and statistical support, respectively.</p>
</div><div class="contributions"><a id="authcontrib" name="authcontrib" toc="authcontrib" title="Author Contributions"></a><h3>Author Contributions</h3><p>Conceived and designed the experiments: UC FT. Performed the experiments: FT. Analyzed the data: FT CA. Contributed reagents/materials/analysis tools: RT. Wrote the paper: UC FT CA.</p></div><div><a id="references" name="references" toc="references" title="References"></a><h3>References</h3><ol class="references"><li><span class="label">1.
              </span><a name="pone.0001795-Stein1" id="pone.0001795-Stein1"></a>Stein BE, Meredith MA (1990) Multisensory integration-neural and behavioral solutions for dealing with stimuli from different sensory modalities. Ann NY Acad Sci  608: 51–70.  <ul class="find" data-citedArticleID="1074552" data-doi="10.1111/j.1749-6632.1990.tb48891.x"><li><a href="http://dx.doi.org/10.1111/j.1749-6632.1990.tb48891.x" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Multisensory+integration-neural+and+behavioral+solutions+for+dealing+with+stimuli+from+different+sensory+modalities." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Multisensory+integration-neural+and+behavioral+solutions+for+dealing+with+stimuli+from+different+sensory+modalities.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">2.
              </span><a name="pone.0001795-Guest1" id="pone.0001795-Guest1"></a>Guest S, Catmur C, Lloyd D, Spence C (2002) Audiotactile interactions in roughness perception. Exp Brain Res  146: 161–171.  <ul class="find" data-citedArticleID="1074510" data-doi="10.1007/s00221-002-1164-z"><li><a href="http://dx.doi.org/10.1007/s00221-002-1164-z" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Audiotactile+interactions+in+roughness+perception." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Audiotactile+interactions+in+roughness+perception.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">3.
              </span><a name="pone.0001795-Pouget1" id="pone.0001795-Pouget1"></a>Pouget A, Deneve S, Duhmael JR (2002) A computational perspective on the neural basis of multisensory spatial representation. Nat Rev Neurosci  3: 741–747.  <ul class="find" data-citedArticleID="1074538" data-doi="10.1038/nrn914"><li><a href="http://dx.doi.org/10.1038/nrn914" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=A+computational+perspective+on+the+neural+basis+of+multisensory+spatial+representation." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22A+computational+perspective+on+the+neural+basis+of+multisensory+spatial+representation.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">4.
              </span><a name="pone.0001795-Lalanne1" id="pone.0001795-Lalanne1"></a>Lalanne C, Lorenceau J (2004) Crossmodal integration for perception and action. J Physiol Paris  98: 265–279.  <ul class="find" data-citedArticleID="1074524" data-doi="10.1016/j.jphysparis.2004.06.001"><li><a href="http://dx.doi.org/10.1016/j.jphysparis.2004.06.001" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Crossmodal+integration+for+perception+and+action." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Crossmodal+integration+for+perception+and+action.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">5.
              </span><a name="pone.0001795-Schubotz1" id="pone.0001795-Schubotz1"></a>Schubotz RJ (2007) Prediction of external events with our motor system: towards a new framework. Trends Cogni Sci  11: 211–218.  <ul class="find" data-citedArticleID="1074550" data-doi="10.1016/j.tics.2007.02.006"><li><a href="http://dx.doi.org/10.1016/j.tics.2007.02.006" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Prediction+of+external+events+with+our+motor+system%3A+towards+a+new+framework." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Prediction+of+external+events+with+our+motor+system%3A+towards+a+new+framework.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">6.
              </span><a name="pone.0001795-MacKenzie1" id="pone.0001795-MacKenzie1"></a>MacKenzie CL, Iberall T (1994) The grasping hand. Amsterdam: Elsevier-North Holland.   <ul class="find-nolinks"></ul></li><li><span class="label">7.
              </span><a name="pone.0001795-Wing1" id="pone.0001795-Wing1"></a>Wing AM, Haggard P, Flanagan JR (1996) Hand and Brain: Neurophysiology and Psychology of Hand Movements. San Diego: Academic Press.   <ul class="find-nolinks"></ul></li><li><span class="label">8.
              </span><a name="pone.0001795-Castiello1" id="pone.0001795-Castiello1"></a>Castiello U (2005) The neuroscience of grasping. Nat Rev Neurosci  6: 726–736.  <ul class="find" data-citedArticleID="1074474" data-doi="10.1038/nrn1744"><li><a href="http://dx.doi.org/10.1038/nrn1744" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+neuroscience+of+grasping." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+neuroscience+of+grasping.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">9.
              </span><a name="pone.0001795-Klatzky1" id="pone.0001795-Klatzky1"></a>Klatzky RL, Lederman SJ (1987)  The intelligent hand. In: Bower GH, editor. The psychology of learning and motivation. San Diego: Academic Press. pp. 121–151.  <ul class="find-nolinks"></ul></li><li><span class="label">10.
              </span><a name="pone.0001795-Johansson1" id="pone.0001795-Johansson1"></a>Johansson RS, Westling G (1984) Roles of glabrous skin receptors and sensorimotor memory in automatic control of precision grip when lifting rougher or more slippery objects. Exp Brain Res  56: 550–564.  <ul class="find" data-citedArticleID="1074516" data-doi="10.1007/bf00237997"><li><a href="http://dx.doi.org/10.1007/bf00237997" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Roles+of+glabrous+skin+receptors+and+sensorimotor+memory+in+automatic+control+of+precision+grip+when+lifting+rougher+or+more+slippery+objects." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Roles+of+glabrous+skin+receptors+and+sensorimotor+memory+in+automatic+control+of+precision+grip+when+lifting+rougher+or+more+slippery+objects.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">11.
              </span><a name="pone.0001795-Goodwin1" id="pone.0001795-Goodwin1"></a>Goodwin AW, Jenmalm P, Johansson RS (1998) Control of grip force when tilting objects: effect of curvature of grasped surfaces and applied tangential torque. J Neurosci  18: 10724–10734.  <ul class="find" data-citedArticleID="1074500"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=Control+of+grip+force+when+tilting+objects%3A+effect+of+curvature+of+grasped+surfaces+and+applied+tangential+torque.&amp;auth=&amp;atitle=Control+of+grip+force+when+tilting+objects%3A+effect+of+curvature+of+grasped+surfaces+and+applied+tangential+torque." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Control+of+grip+force+when+tilting+objects%3A+effect+of+curvature+of+grasped+surfaces+and+applied+tangential+torque." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Control+of+grip+force+when+tilting+objects%3A+effect+of+curvature+of+grasped+surfaces+and+applied+tangential+torque.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">12.
              </span><a name="pone.0001795-Jenmalm1" id="pone.0001795-Jenmalm1"></a>Jenmalm P, Dahlstedt S, Johansson RS (2000) Visual and tactile information about object-curvature control fingertip forces and grasp kinematics in human dexterous manipulation. J Neurophysiol  84: 2984–2997.  <ul class="find" data-citedArticleID="1074514"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=Visual+and+tactile+information+about+object-curvature+control+fingertip+forces+and+grasp+kinematics+in+human+dexterous+manipulation.&amp;auth=&amp;atitle=Visual+and+tactile+information+about+object-curvature+control+fingertip+forces+and+grasp+kinematics+in+human+dexterous+manipulation." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Visual+and+tactile+information+about+object-curvature+control+fingertip+forces+and+grasp+kinematics+in+human+dexterous+manipulation." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Visual+and+tactile+information+about+object-curvature+control+fingertip+forces+and+grasp+kinematics+in+human+dexterous+manipulation.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">13.
              </span><a name="pone.0001795-Klatsky1" id="pone.0001795-Klatsky1"></a>Klatsky RL, Lederman SJ, Reed C (1987) There's more to touch than meets the eye: the salience of object attributes for haptics with and without vision. J Exp Psychol Gen  116: 356–369.  <ul class="find" data-citedArticleID="1074518"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=There%27s+more+to+touch+than+meets+the+eye%3A+the+salience+of+object+attributes+for+haptics+with+and+without+vision.&amp;auth=&amp;atitle=There%27s+more+to+touch+than+meets+the+eye%3A+the+salience+of+object+attributes+for+haptics+with+and+without+vision." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=There%27s+more+to+touch+than+meets+the+eye%3A+the+salience+of+object+attributes+for+haptics+with+and+without+vision." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22There%27s+more+to+touch+than+meets+the+eye%3A+the+salience+of+object+attributes+for+haptics+with+and+without+vision.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">14.
              </span><a name="pone.0001795-Klatzky2" id="pone.0001795-Klatzky2"></a>Klatzky RL, Pai DK, Krotkov EP (2000) Perception of material from contact sounds. Presence: Teleoperators &amp; Virtual Environments  9: 399–410.  <ul class="find" data-citedArticleID="1074522" data-doi="10.1162/105474600566907"><li><a href="http://dx.doi.org/10.1162/105474600566907" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Perception+of+material+from+contact+sounds." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Perception+of+material+from+contact+sounds.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">15.
              </span><a name="pone.0001795-VanBeers1" id="pone.0001795-VanBeers1"></a>Van Beers RJ, Baraduc P, Wolpert DM (2002) Role of uncertainty in sensorimotor control. Philos T Roy Soc B  357: 1137–1145.  <ul class="find" data-citedArticleID="1074560" data-doi="10.1098/rstb.2002.1101"><li><a href="http://dx.doi.org/10.1098/rstb.2002.1101" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Role+of+uncertainty+in+sensorimotor+control." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Role+of+uncertainty+in+sensorimotor+control.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">16.
              </span><a name="pone.0001795-Patchay1" id="pone.0001795-Patchay1"></a>Patchay S, Castiello U, Haggard P (2003) A crossmodal interference effect in grasping objects. Psychol Bull Rev  10: 924–931.  <ul class="find" data-citedArticleID="1074534" data-doi="10.3758/bf03196553"><li><a href="http://dx.doi.org/10.3758/bf03196553" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=A+crossmodal+interference+effect+in+grasping+objects." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22A+crossmodal+interference+effect+in+grasping+objects.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">17.
              </span><a name="pone.0001795-Patchay2" id="pone.0001795-Patchay2"></a>Patchay S, Haggard P, Castiello U (2006) Cross-modal links in action: evidence for an object-centred reference frame for control of grasping. Exp Brain Res  23: 1–11.  <ul class="find" data-citedArticleID="1074536" data-doi="10.1007/s00221-005-0240-6"><li><a href="http://dx.doi.org/10.1007/s00221-005-0240-6" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Cross-modal+links+in+action%3A+evidence+for+an+object-centred+reference+frame+for+control+of+grasping." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Cross-modal+links+in+action%3A+evidence+for+an+object-centred+reference+frame+for+control+of+grasping.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">18.
              </span><a name="pone.0001795-Zahariev1" id="pone.0001795-Zahariev1"></a>Zahariev MA, MacKenzie CL (2007) Grasping at thin air: multimodal contact cues for reaching and grasping. Exp Brain Res  180: 69–84.  <ul class="find" data-citedArticleID="1074566" data-doi="10.1007/s00221-006-0845-4"><li><a href="http://dx.doi.org/10.1007/s00221-006-0845-4" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Grasping+at+thin+air%3A+multimodal+contact+cues+for+reaching+and+grasping." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Grasping+at+thin+air%3A+multimodal+contact+cues+for+reaching+and+grasping.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">19.
              </span><a name="pone.0001795-Castiello2" id="pone.0001795-Castiello2"></a>Castiello U, Tubaldi F, Ansuini C, Giordano B, Grassi MMultisensory integration during grasping movements. Journal of Psychophysiol. In press..   <ul class="find" data-citedArticleID="1074476"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=Multisensory+integration+during+grasping+movements.&amp;auth=&amp;atitle=Multisensory+integration+during+grasping+movements." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Multisensory+integration+during+grasping+movements." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Multisensory+integration+during+grasping+movements.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">20.
              </span><a name="pone.0001795-Prablanc1" id="pone.0001795-Prablanc1"></a>Prablanc C, Echallier JF, Jeannerod M, Komilis E (1979) Optimal response of eye and hand motor systems in pointing at a visual target, II: static and dynamic visual cues in the control of hand movement. Biol Cybernetics  35: 183–187.  <ul class="find" data-citedArticleID="1074540" data-doi="10.1007/bf00337063"><li><a href="http://dx.doi.org/10.1007/bf00337063" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Optimal+response+of+eye+and+hand+motor+systems+in+pointing+at+a+visual+target%2C+II%3A+static+and+dynamic+visual+cues+in+the+control+of+hand+movement." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Optimal+response+of+eye+and+hand+motor+systems+in+pointing+at+a+visual+target%2C+II%3A+static+and+dynamic+visual+cues+in+the+control+of+hand+movement.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">21.
              </span><a name="pone.0001795-DiFranco1" id="pone.0001795-DiFranco1"></a>DiFranco DW, Beauregard GL, Srinivasan MA (1997) The effect of auditory cues on the haptic perception of stiffness in virtual environments. Proceedings of the ASME Dynamic Systems and Control Division, DSC  61: 17–22.  <ul class="find" data-citedArticleID="1074490"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=The+effect+of+auditory+cues+on+the+haptic+perception+of+stiffness+in+virtual+environments.&amp;auth=&amp;atitle=The+effect+of+auditory+cues+on+the+haptic+perception+of+stiffness+in+virtual+environments." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+effect+of+auditory+cues+on+the+haptic+perception+of+stiffness+in+virtual+environments." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+effect+of+auditory+cues+on+the+haptic+perception+of+stiffness+in+virtual+environments.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">22.
              </span><a name="pone.0001795-Graziano1" id="pone.0001795-Graziano1"></a>Graziano M (1999) Where is my arm? The relative role of vision and proprioceptioon in the neuronal representation. Proc Natl Acad Sci USA  96: 10418–10421.  <ul class="find" data-citedArticleID="1074504"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=Where+is+my+arm%3F+The+relative+role+of+vision+and+proprioceptioon+in+the+neuronal+representation.&amp;auth=&amp;atitle=Where+is+my+arm%3F+The+relative+role+of+vision+and+proprioceptioon+in+the+neuronal+representation." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Where+is+my+arm%3F+The+relative+role+of+vision+and+proprioceptioon+in+the+neuronal+representation." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Where+is+my+arm%3F+The+relative+role+of+vision+and+proprioceptioon+in+the+neuronal+representation.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">23.
              </span><a name="pone.0001795-Lederman1" id="pone.0001795-Lederman1"></a>Lederman SJ, Klatzky RL, Morgan T, Hamilton C (2002) Integrating multimodal information about surface texture via a probe: relative contributions of haptic and touch-produced sounds. Proceedings of the 10<sup>th</sup> annual Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, IEEE 2002, 97–104.  <ul class="find" data-citedArticleID="1074526" data-doi="10.1109/haptic.2002.998946"><li><a href="http://dx.doi.org/10.1109/haptic.2002.998946" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Integrating+multimodal+information+about+surface+texture+via+a+probe%3A+relative+contributions+of+haptic+and+touch-produced+sounds." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Integrating+multimodal+information+about+surface+texture+via+a+probe%3A+relative+contributions+of+haptic+and+touch-produced+sounds.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">24.
              </span><a name="pone.0001795-Lederman2" id="pone.0001795-Lederman2"></a>Lederman SJ, Martin AM, Tong C, Klatzky RL (2003) Relative performance using haptic and/or touchproduced auditory cues in a remote absolute texture identification task. Proceedings of the 11<sup>th</sup> annual Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, IEEE 2003, 151–158.  <ul class="find" data-citedArticleID="1074528" data-doi="10.1109/haptic.2003.1191261"><li><a href="http://dx.doi.org/10.1109/haptic.2003.1191261" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Relative+performance+using+haptic+and%2For+touchproduced+auditory+cues+in+a+remote+absolute+texture+identification+task." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Relative+performance+using+haptic+and%2For+touchproduced+auditory+cues+in+a+remote+absolute+texture+identification+task.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">25.
              </span><a name="pone.0001795-Castiello3" id="pone.0001795-Castiello3"></a>Castiello U, Zucco GM, Parma V, Ansuini C, Tirindelli R (2006) Cross-modal interactions between olfaction and vision when grasping. Chem Senses  31: 665–71.  <ul class="find" data-citedArticleID="1074478" data-doi="10.1093/chemse/bjl007"><li><a href="http://dx.doi.org/10.1093/chemse/bjl007" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Cross-modal+interactions+between+olfaction+and+vision+when+grasping." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Cross-modal+interactions+between+olfaction+and+vision+when+grasping.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">26.
              </span><a name="pone.0001795-Santello1" id="pone.0001795-Santello1"></a>Santello M, Flanders M, Soechting JF (2002) Patterns of hand motion during grasping and the influence of sensory guidance. J Neurosci  22: 1426–1435.  <ul class="find" data-citedArticleID="1074546"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=Patterns+of+hand+motion+during+grasping+and+the+influence+of+sensory+guidance.&amp;auth=&amp;atitle=Patterns+of+hand+motion+during+grasping+and+the+influence+of+sensory+guidance." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Patterns+of+hand+motion+during+grasping+and+the+influence+of+sensory+guidance." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Patterns+of+hand+motion+during+grasping+and+the+influence+of+sensory+guidance.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">27.
              </span><a name="pone.0001795-Winges1" id="pone.0001795-Winges1"></a>Winges SA, Weber DJ, Santello M (2003) The role of vision on hand preshaping during reach to grasp. Exp Brain Res  152: 489–98.  <ul class="find" data-citedArticleID="1074564" data-doi="10.1007/s00221-003-1571-9"><li><a href="http://dx.doi.org/10.1007/s00221-003-1571-9" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+role+of+vision+on+hand+preshaping+during+reach+to+grasp." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+role+of+vision+on+hand+preshaping+during+reach+to+grasp.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">28.
              </span><a name="pone.0001795-Colebatch1" id="pone.0001795-Colebatch1"></a>Colebatch JG, Gandevia SC (1989) The distribution of muscular weakness in upper motor neuron lesions affecting the arm. Brain  112: 749–763.  <ul class="find" data-citedArticleID="1074488" data-doi="10.1093/brain/112.3.749"><li><a href="http://dx.doi.org/10.1093/brain/112.3.749" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+distribution+of+muscular+weakness+in+upper+motor+neuron+lesions+affecting+the+arm." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+distribution+of+muscular+weakness+in+upper+motor+neuron+lesions+affecting+the+arm.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">29.
              </span><a name="pone.0001795-Castiello4" id="pone.0001795-Castiello4"></a>Castiello U, Bennett KM, Stelmach GE (1993) Reach to grasp: the natural response to perturbation of object size. Exp Brain Res  94: 163–178.  <ul class="find" data-citedArticleID="1074480" data-doi="10.1007/bf00230479"><li><a href="http://dx.doi.org/10.1007/bf00230479" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Reach+to+grasp%3A+the+natural+response+to+perturbation+of+object+size." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Reach+to+grasp%3A+the+natural+response+to+perturbation+of+object+size.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">30.
              </span><a name="pone.0001795-Bock1" id="pone.0001795-Bock1"></a>Bock O, Jungling S (1999) Reprogramming of grip aperture in a double-step virtual grasping paradigm. Exp Brain Res  125: 61–66.  <ul class="find" data-citedArticleID="1074470" data-doi="10.1007/s002210050658"><li><a href="http://dx.doi.org/10.1007/s002210050658" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Reprogramming+of+grip+aperture+in+a+double-step+virtual+grasping+paradigm." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Reprogramming+of+grip+aperture+in+a+double-step+virtual+grasping+paradigm.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">31.
              </span><a name="pone.0001795-Tipper1" id="pone.0001795-Tipper1"></a>Tipper SP, Howard LA, Houghton G (1998) Action-based mechanisms of attention. Philos Trans R Soc Lond B Biol Sci  353: 1385–1393.  <ul class="find" data-citedArticleID="1074558" data-doi="10.1098/rstb.1998.0292"><li><a href="http://dx.doi.org/10.1098/rstb.1998.0292" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Action-based+mechanisms+of+attention." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Action-based+mechanisms+of+attention.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">32.
              </span><a name="pone.0001795-Castiello5" id="pone.0001795-Castiello5"></a>Castiello U (1999) Mechanism of selection for the control of hand action. Trends Cogn Sci  3: 264–271.  <ul class="find" data-citedArticleID="1074482" data-doi="10.1016/s1364-6613(99)01346-7"><li><a href="http://dx.doi.org/10.1016/s1364-6613(99)01346-7" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Mechanism+of+selection+for+the+control+of+hand+action." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Mechanism+of+selection+for+the+control+of+hand+action.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">33.
              </span><a name="pone.0001795-Rolls1" id="pone.0001795-Rolls1"></a>Rolls ET, Baylis L (1994) Gustatory, olfactory, and visual convergence within the primate orbitofrontal cortex. J Neurosci  14: 5437–5452.  <ul class="find" data-citedArticleID="1074542"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=Gustatory%2C+olfactory%2C+and+visual+convergence+within+the+primate+orbitofrontal+cortex.&amp;auth=&amp;atitle=Gustatory%2C+olfactory%2C+and+visual+convergence+within+the+primate+orbitofrontal+cortex." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Gustatory%2C+olfactory%2C+and+visual+convergence+within+the+primate+orbitofrontal+cortex." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Gustatory%2C+olfactory%2C+and+visual+convergence+within+the+primate+orbitofrontal+cortex.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">34.
              </span><a name="pone.0001795-Stein2" id="pone.0001795-Stein2"></a>Stein BE, Wallace MT, Meredith MA (1995)  Neural mechanisms mediating attention and orientation to multisensory cues. In: Gazzaniga MS, editor. The Cognitive Neurosciences. London: Bradford Books, MIT Press. pp. 683–701.  <ul class="find-nolinks"></ul></li><li><span class="label">35.
              </span><a name="pone.0001795-Giard1" id="pone.0001795-Giard1"></a>Giard MH, Peronnet F (1999) Auditory-visual integration during multimodal object recognition in humans: a behavioral and electrophysiological study. J Cognitive Neurosci  11: 473–490.  <ul class="find" data-citedArticleID="1074498" data-doi="10.1162/089892999563544"><li><a href="http://dx.doi.org/10.1162/089892999563544" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Auditory-visual+integration+during+multimodal+object+recognition+in+humans%3A+a+behavioral+and+electrophysiological+study." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Auditory-visual+integration+during+multimodal+object+recognition+in+humans%3A+a+behavioral+and+electrophysiological+study.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">36.
              </span><a name="pone.0001795-Calvert1" id="pone.0001795-Calvert1"></a>Calvert GA (2001) Crossmodal processing in the human brain: insights from functional neuroimaging studies. Cereb Cortex  11: 1110–1123.  <ul class="find" data-citedArticleID="1074472" data-doi="10.1093/cercor/11.12.1110"><li><a href="http://dx.doi.org/10.1093/cercor/11.12.1110" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Crossmodal+processing+in+the+human+brain%3A+insights+from+functional+neuroimaging+studies." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Crossmodal+processing+in+the+human+brain%3A+insights+from+functional+neuroimaging+studies.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">37.
              </span><a name="pone.0001795-Gottfried1" id="pone.0001795-Gottfried1"></a>Gottfried JA, Dolan RJ (2003) The nose smells what the eye sees: crossmodal visual facilitation of human olfactory perception. Neuron  39: 375–386.  <ul class="find" data-citedArticleID="1074502" data-doi="10.1016/s0896-6273(03)00392-1"><li><a href="http://dx.doi.org/10.1016/s0896-6273(03)00392-1" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+nose+smells+what+the+eye+sees%3A+crossmodal+visual+facilitation+of+human+olfactory+perception." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+nose+smells+what+the+eye+sees%3A+crossmodal+visual+facilitation+of+human+olfactory+perception.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">38.
              </span><a name="pone.0001795-sterbauer1" id="pone.0001795-sterbauer1"></a>Österbauer RA, Matthews PM, Jenkinson M, Beckmann CF, Hansen PC, et al.  (2005) Color of scents: chromatic stimuli modulate odor responses in the human brain. J Neurophysiol  93: 3434–3441.  <ul class="find" data-citedArticleID="1074568" data-doi="10.1152/jn.00555.2004"><li><a href="http://dx.doi.org/10.1152/jn.00555.2004" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Color+of+scents%3A+chromatic+stimuli+modulate+odor+responses+in+the+human+brain." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Color+of+scents%3A+chromatic+stimuli+modulate+odor+responses+in+the+human+brain.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">39.
              </span><a name="pone.0001795-Grigor1" id="pone.0001795-Grigor1"></a>Grigor J (1995) Do the eyes see what the nose knows? An investigation of the effects of olfactory priming on visual event related potentials. Chem Senses  20: 163.  <ul class="find" data-citedArticleID="1074506"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=Do+the+eyes+see+what+the+nose+knows%3F+An+investigation+of+the+effects+of+olfactory+priming+on+visual+event+related+potentials.&amp;auth=&amp;atitle=Do+the+eyes+see+what+the+nose+knows%3F+An+investigation+of+the+effects+of+olfactory+priming+on+visual+event+related+potentials." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Do+the+eyes+see+what+the+nose+knows%3F+An+investigation+of+the+effects+of+olfactory+priming+on+visual+event+related+potentials." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Do+the+eyes+see+what+the+nose+knows%3F+An+investigation+of+the+effects+of+olfactory+priming+on+visual+event+related+potentials.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">40.
              </span><a name="pone.0001795-Grigor2" id="pone.0001795-Grigor2"></a>Grigor J, Van Toller S, Behan J, Richardson A (1999) The effect of odour priming on long latency visual evoked potentials of matching and mismatching objects. Chem Senses  24: 137–144.  <ul class="find" data-citedArticleID="1074508" data-doi="10.1093/chemse/24.2.137"><li><a href="http://dx.doi.org/10.1093/chemse/24.2.137" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+effect+of+odour+priming+on+long+latency+visual+evoked+potentials+of+matching+and+mismatching+objects." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+effect+of+odour+priming+on+long+latency+visual+evoked+potentials+of+matching+and+mismatching+objects.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">41.
              </span><a name="pone.0001795-Sarfarazi1" id="pone.0001795-Sarfarazi1"></a>Sarfarazi M, Cave B, Richardson A, Behan J, Sedgwick EM (1999) Visual event related potentials modulated by contextually relevant and irrelevant olfactory primes. Chem Senses  24: 145–154.  <ul class="find" data-citedArticleID="1074548" data-doi="10.1093/chemse/24.2.145"><li><a href="http://dx.doi.org/10.1093/chemse/24.2.145" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Visual+event+related+potentials+modulated+by+contextually+relevant+and+irrelevant+olfactory+primes." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Visual+event+related+potentials+modulated+by+contextually+relevant+and+irrelevant+olfactory+primes.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">42.
              </span><a name="pone.0001795-Cavada1" id="pone.0001795-Cavada1"></a>Cavada C, Compañy T, Tejedor J, Cruz-Rizzolo RJ, Reinoso-Suárez F (2000) The anatomical connections of the macaque monkey orbitofrontal cortex. A review. Cereb Cortex  10: 220–242.  <ul class="find" data-citedArticleID="1074486" data-doi="10.1093/cercor/10.3.220"><li><a href="http://dx.doi.org/10.1093/cercor/10.3.220" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+anatomical+connections+of+the+macaque+monkey+orbitofrontal+cortex.+A+review." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+anatomical+connections+of+the+macaque+monkey+orbitofrontal+cortex.+A+review.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">43.
              </span><a name="pone.0001795-Morecraft1" id="pone.0001795-Morecraft1"></a>Morecraft RJ, Van Hoesen GW (1993) Frontal Granular cortex input to the cingulate (M3), supplementary (M2) and primary (M1) motor cortices in the rhesus monkey. J Comp Neurol.  337: 669–689.  <ul class="find" data-citedArticleID="1074532" data-doi="10.1002/cne.903370411"><li><a href="http://dx.doi.org/10.1002/cne.903370411" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Frontal+Granular+cortex+input+to+the+cingulate+%28M3%29%2C+supplementary+%28M2%29+and+primary+%28M1%29+motor+cortices+in+the+rhesus+monkey." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Frontal+Granular+cortex+input+to+the+cingulate+%28M3%29%2C+supplementary+%28M2%29+and+primary+%28M1%29+motor+cortices+in+the+rhesus+monkey.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">44.
              </span><a name="pone.0001795-Begliomini1" id="pone.0001795-Begliomini1"></a>Begliomini C, Caria A, Grodd W, Castiello U (2007) Comparing natural and constrained movements: new insights into the visuomotor control of grasping. PLoS ONE  10: 1–10.  <ul class="find" data-citedArticleID="1074466" data-doi="10.1371/journal.pone.0001108"><li><a href="http://dx.doi.org/10.1371/journal.pone.0001108" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Comparing+natural+and+constrained+movements%3A+new+insights+into+the+visuomotor+control+of+grasping." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Comparing+natural+and+constrained+movements%3A+new+insights+into+the+visuomotor+control+of+grasping.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">45.
              </span><a name="pone.0001795-Bates1" id="pone.0001795-Bates1"></a>Bates JF, Goldman-Rakic PS (1993) Prefrontal connections of medial motor areas in the rhesus monkey. J Comp Neurol  336: 211–228.  <ul class="find" data-citedArticleID="1074464" data-doi="10.1002/cne.903360205"><li><a href="http://dx.doi.org/10.1002/cne.903360205" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Prefrontal+connections+of+medial+motor+areas+in+the+rhesus+monkey." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Prefrontal+connections+of+medial+motor+areas+in+the+rhesus+monkey.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">46.
              </span><a name="pone.0001795-Rossi1" id="pone.0001795-Rossi1"></a>Rossi S, De Capua A, Pasqualetti P, Ulivelli M, Fadiga L, et al. Distinct olfactory cross-modal effects on the human motor system. PloS ONE. In press.   <ul class="find" data-citedArticleID="1074544" data-doi="10.1371/journal.pone.0001702"><li><a href="http://dx.doi.org/10.1371/journal.pone.0001702" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Distinct+olfactory+cross-modal+effects+on+the+human+motor+system." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Distinct+olfactory+cross-modal+effects+on+the+human+motor+system.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">47.
              </span><a name="pone.0001795-Arbib1" id="pone.0001795-Arbib1"></a>Arbib MA (1985) Schemas for the temporal control of behavior. Hum Neurobiol  4: 63–72.  <ul class="find" data-citedArticleID="1074462"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=Schemas+for+the+temporal+control+of+behavior.&amp;auth=&amp;atitle=Schemas+for+the+temporal+control+of+behavior." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Schemas+for+the+temporal+control+of+behavior." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Schemas+for+the+temporal+control+of+behavior.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">48.
              </span><a name="pone.0001795-Fagg1" id="pone.0001795-Fagg1"></a>Fagg AH, Arbib MA (1998) Modeling parietal-premotor interactions in primate control of grasping. Neural Networks  11: 1277–1303.  <ul class="find" data-citedArticleID="1074492" data-doi="10.1016/s0893-6080(98)00047-1"><li><a href="http://dx.doi.org/10.1016/s0893-6080(98)00047-1" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Modeling+parietal-premotor+interactions+in+primate+control+of+grasping." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Modeling+parietal-premotor+interactions+in+primate+control+of+grasping.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">49.
              </span><a name="pone.0001795-Hummel1" id="pone.0001795-Hummel1"></a>Hummel T, Knecht M, Kobal G (1996) Peripherally obtained electrophysiological responses to olfactory stimulation in man: electro-olfactograms exhibit a smaller degree of desensitization compared with subjective intensity estimates. Brain Res  717: 160–164.  <ul class="find" data-citedArticleID="1074512" data-doi="10.1016/0006-8993(96)00094-7"><li><a href="http://dx.doi.org/10.1016/0006-8993(96)00094-7" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Peripherally+obtained+electrophysiological+responses+to+olfactory+stimulation+in+man%3A+electro-olfactograms+exhibit+a+smaller+degree+of+desensitization+compared+with+subjective+intensity+estimates." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Peripherally+obtained+electrophysiological+responses+to+olfactory+stimulation+in+man%3A+electro-olfactograms+exhibit+a+smaller+degree+of+desensitization+compared+with+subjective+intensity+estimates.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">50.
              </span><a name="pone.0001795-Castiello6" id="pone.0001795-Castiello6"></a>Castiello U (1996) Grasping a fruit: selection for action. J Exp Psychol Hum Percept Perform  22: 582–603.  <ul class="find" data-citedArticleID="1074484" data-doi="10.1037/0096-1523.22.3.582"><li><a href="http://dx.doi.org/10.1037/0096-1523.22.3.582" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Grasping+a+fruit%3A+selection+for+action." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Grasping+a+fruit%3A+selection+for+action.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">51.
              </span><a name="pone.0001795-Furr1" id="pone.0001795-Furr1"></a>Furr RM, Roshental R (2003) Repeated-measures contrasts for “multiple-pattern” hypotheses. Psychol Methods  8: 275–293.  <ul class="find" data-citedArticleID="1074496" data-doi="10.1037/1082-989x.8.3.275"><li><a href="http://dx.doi.org/10.1037/1082-989x.8.3.275" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Repeated-measures+contrasts+for+%E2%80%9Cmultiple-pattern%E2%80%9D+hypotheses." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Repeated-measures+contrasts+for+%E2%80%9Cmultiple-pattern%E2%80%9D+hypotheses.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">52.
              </span><a name="pone.0001795-Thompson1" id="pone.0001795-Thompson1"></a>Thompson B (1985) Alternate methods for analyzing data from experiments. J Exp Educ  54: 50–55.  <ul class="find" data-citedArticleID="1074556" data-doi="10.1080/00220973.1985.10806398"><li><a href="http://dx.doi.org/10.1080/00220973.1985.10806398" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Alternate+methods+for+analyzing+data+from+experiments." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Alternate+methods+for+analyzing+data+from+experiments.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">53.
              </span><a name="pone.0001795-Frak1" id="pone.0001795-Frak1"></a>Frak V, Paulignan Y, Jeannerod M (2001) Orientation of the opposition axis in mentally simulated grasping. Exp Brain Res  136: 120–127.  <ul class="find" data-citedArticleID="1074494" data-doi="10.1007/s002210000583"><li><a href="http://dx.doi.org/10.1007/s002210000583" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Orientation+of+the+opposition+axis+in+mentally+simulated+grasping." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Orientation+of+the+opposition+axis+in+mentally+simulated+grasping.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">54.
              </span><a name="pone.0001795-Ansuini1" id="pone.0001795-Ansuini1"></a>Ansuini C, Santello M, Tubaldi F, Massaccesi S, Castiello U (2007) Control of hand shaping in response to object shape perturbation. Exp Brain Res  180: 85–96.  <ul class="find" data-citedArticleID="1074460" data-doi="10.1007/s00221-006-0840-9"><li><a href="http://dx.doi.org/10.1007/s00221-006-0840-9" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Control+of+hand+shaping+in+response+to+object+shape+perturbation." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Control+of+hand+shaping+in+response+to+object+shape+perturbation.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">55.
              </span><a name="pone.0001795-Benjamini1" id="pone.0001795-Benjamini1"></a>Benjamini Y, Hochberg Y (1995) Controlling the false discovery rate: A practical and powerful approach to multiple testing. J Royal Stat Soc Ser B  57: 289–300.  <ul class="find" data-citedArticleID="1074468"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=Controlling+the+false+discovery+rate%3A+A+practical+and+powerful+approach+to+multiple+testing.&amp;auth=&amp;atitle=Controlling+the+false+discovery+rate%3A+A+practical+and+powerful+approach+to+multiple+testing." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Controlling+the+false+discovery+rate%3A+A+practical+and+powerful+approach+to+multiple+testing." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Controlling+the+false+discovery+rate%3A+A+practical+and+powerful+approach+to+multiple+testing.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li></ol></div>

  </div>

      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.XML" value="126231"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.PDF" value="631205"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g001.PNG_L" value="3022365"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g001.PNG_M" value="327929"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g001.PNG_S" value="20084"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g001.TIF" value="4530436"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g001.PNG_I" value="183602"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g002.PNG_L" value="3295219"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g002.PNG_M" value="150896"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g002.PNG_S" value="20074"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g002.TIF" value="7771744"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g002.PNG_I" value="113294"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g003.PNG_L" value="1006033"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g003.PNG_M" value="50795"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g003.PNG_S" value="9835"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g003.TIF" value="1577550"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g003.PNG_I" value="36487"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g004.PNG_L" value="501237"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g004.PNG_M" value="34456"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g004.PNG_S" value="9776"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g004.TIF" value="760090"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g004.PNG_I" value="53155"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g005.PNG_L" value="654772"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g005.PNG_M" value="55175"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g005.PNG_S" value="16821"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g005.TIF" value="1495394"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g005.PNG_I" value="93897"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.t001.PNG_L" value="155426"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.t001.PNG_M" value="132027"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.t001.PNG_S" value="19074"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.t001.TIF" value="824056"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.t001.PNG_I" value="93539"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g006.PNG_L" value="757590"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g006.PNG_M" value="54696"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g006.PNG_S" value="19003"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g006.TIF" value="1574960"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g006.PNG_I" value="115614"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g007.PNG_L" value="417468"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g007.PNG_M" value="76909"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g007.PNG_S" value="14501"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g007.TIF" value="835828"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g007.PNG_I" value="48314"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.t002.PNG_L" value="75287"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.t002.PNG_M" value="44536"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.t002.PNG_S" value="9054"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.t002.TIF" value="397600"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.t002.PNG_I" value="13811"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g008.PNG_L" value="422648"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g008.PNG_M" value="76847"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g008.PNG_S" value="14263"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g008.TIF" value="841388"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g008.PNG_I" value="47998"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g009.PNG_L" value="385113"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g009.PNG_M" value="68543"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g009.PNG_S" value="13550"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g009.TIF" value="864460"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.g009.PNG_I" value="46425"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.t003.PNG_L" value="123812"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.t003.PNG_M" value="76815"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.t003.PNG_S" value="11615"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.t003.TIF" value="684678"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.t003.PNG_I" value="24616"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.t004.PNG_L" value="77620"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.t004.PNG_M" value="113387"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.t004.PNG_S" value="15946"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.t004.TIF" value="402172"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001795.t004.PNG_I" value="39099"/>

</div>
<div class="sidebar">

  <div class="article-actions cf">
      <div class="download">
        <span class="btn"><a href="/article/fetchObject.action?uri=info%3Adoi%2F10.1371%2Fjournal.pone.0001795&amp;representation=PDF" title="Download" target="_blank">Download PDF</a></span>
      </div>
      <div class="btn-reveal dropdown">
        <div class="dropdown-icon">
          <span class="btn">&nbsp;</span>
        </div>

        <div class="content">
          <ul class="bullet">
            <li><a href="/article/citationList.action?articleURI=info%3Adoi%2F10.1371%2Fjournal.pone.0001795" title="Download citations">Citation</a></li>
            <li><a href="/article/fetchObjectAttachment.action?uri=info%3Adoi%2F10.1371%2Fjournal.pone.0001795&amp;representation=XML" title="Download article XML">XML</a></li>
          </ul>
        </div>
      </div> <!-- end btn-reveal dropdown-->


    <div class="btn-reveal flt-l">
        <span class="btn">Print</span>
        <div class="content">
            <ul class="bullet">
                <li id="print-article"><a href="#" onclick="if(typeof(_gaq) != 'undefined'){ _gaq.push(['_trackEvent','Article', 'Print', 'Click']); } window.print(); return false;" title="Print Article">Print article</a></li>
                <li>
                  <a href="https://www.odysseypress.com/onlinehost/reprint_order.php?type=A&page=0&journal=7&doi=10.1371/journal.pone.0001795&volume=&issue=&title=The Grasping Side of Odours&author_name=Federico%20Tubaldi%2C%20Caterina%20Ansuini%2C%20Roberto%20Tirindelli%2C%20Umberto%20Castiello&start_page=1&end_page=13" title="Odyssey Press">EzReprint</a>
                </li>
            </ul>
        </div>
    </div>

    <div class="btn-reveal flt-r">
        <span class="btn">Share</span>
        <div class="content">
            <ul class="social">
                <li><a href="http://www.reddit.com/submit?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001795" target="_blank" title="Submit to Reddit"><img src="/images/icon.reddit.16.png" width="16" height="16" alt="Reddit">Reddit</a></li>

                <li><a href="https://plus.google.com/share?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001795" target="_blank" title="Share on Google+"><img src="/images/icon.gplus.16.png" width="16" height="16" alt="Google+">Google+</a></li>

                <li><a href="http://www.stumbleupon.com/submit?url=http%3A%2F%2Fwww.plosone.org%2Farticle%2Finfo%253Adoi%252F10.1371%252Fjournal.pone.0001795" target="_blank" title="Add to StumbleUpon"><img src="/images/icon.stumble.16.png" width="16" height="16" alt="StumbleUpon">StumbleUpon</a></li>

                <li><a href="http://www.facebook.com/share.php?u=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001795&amp;t=The%20Grasping%20Side%20of%20Odours" target="_blank" title="Share on Facebook"><img src="/images/icon.fb.16.png" width="16" height="16" alt="Facebook">Facebook</a></li>

                <li><a href="http://www.linkedin.com/shareArticle?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001795&title=The%20Grasping%20Side%20of%20Odours&summary=Checkout%20this%20article%20I%20found%20at%20PLOS" target="_blank" title="Add to LinkedIn"><img src="/images/icon.linkedin.16.png" width="16" height="16" alt="Mendeley">LinkedIn</a></li>

                <li><a href="http://www.citeulike.org/posturl?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001795&amp;title=The%20Grasping%20Side%20of%20Odours" target="_blank" title="Add to CiteULike"><img src="/images/icon.cul.16.png" width="16" height="16" alt="CiteULike">CiteULike</a></li>

                <li><a href="http://www.mendeley.com/import/?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001795" target="_blank" title="Add to Mendeley"><img src="/images/icon.mendeley.16.png" width="16" height="16" alt="Mendeley">Mendeley</a></li>

                <li><a href="https://www.pubchase.com/library?add_aid=10.1371%2Fjournal.pone.0001795&amp;source=plos" target="_blank" title="Add to PubChase"><img src="/images/icon.pc.16.png" width="16" height="16" alt="PubChase">PubChase</a></li>


                <script type="text/javascript">
                    // replace tweet with one that's pre-shortened to 140 chars
                    function truncateTweetText() {
                        var twtTitle = 'The Grasping Side of Odours';
                        var twtUrl = 'http://dx.plos.org/10.1371/journal.pone.0001795';
                        // all URLs posted to twitter get auto-shortened to 20 chars.
                        var maxLength = 140 - (20 + 1);
                        // truncate the title to include space for twtTag and ellipsis (here, 10 = tag length + space + ellipsis)
                        if (twtTitle.length > maxLength) { twtTitle = twtTitle.substr(0, (maxLength - 10)) + '...'; }
                        // set the href to use the shortened tweet
                        $('#twitter-share-link').prop('href', 'http://twitter.com/intent/tweet?text=' + encodeURIComponent('#PLOSONE: ' + twtTitle + ' ' + twtUrl));
                    }
                </script>
                <li><a href="http://twitter.com/intent/tweet?text=#PLOSONE%3A%20The%20Grasping%20Side%20of%20Odours http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001795" onclick="truncateTweetText();" target="_blank" title="Share on Twitter" id="twitter-share-link"><img src="/images/icon.twtr.16.png" width="16" height="16" alt="Twitter">Twitter</a></li>

                <li><a href="/article/email/info%3Adoi%2F10.1371%2Fjournal.pone.0001795" title="Email this article"><img src="/images/icon.email.16.png" width="16" height="16" alt="Email">Email</a></li>
            </ul>
        </div>
    </div><!--end btn-reveal flt-r-->
</div><!-- end article-actions-->

<!-- begin Crossmark -->

<a id="open-crossmark" href="#" style="margin-top: -28px; display:block"><img style="border: 0; display: none;
 padding: 10px 0 18px 0;"  id="crossmark-icon" src="/images/logo-crossmark-bw.png" /></a>
<div id="crossmark-dialog" style="display: none;" title="">
    <!-- the external CrossMark data is loaded inside this iframe -->
    <iframe id="crossmark-dialog-frame" frameborder="0"></iframe>
</div>

<!-- end crossmark -->


<div class="block" id="subject-area-sidebar-block">
    <div class="header">
        <h3>Subject Areas</h3><div title="More information" id="subject-area-sidebar-block-help-icon"><img align="right"
                                                                                                           alt="info" src="/images/button_info.png"/><div id="subject-area-sidebar-block-help"><img align="right"
                                                                                                                                                                                                    src="/images/button_info.png"/><p>
        <b>We want your feedback.</b> Do these subject areas make sense for this article? If not, click the flag
        next to the incorrect subject area and we will review it. Thanks for your help!
    </p></div></div>
    </div>


    <ul id="subject-area-sidebar-list">

















          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Analysis+of+variance%22" title="Search for articles in the subject area:'Analysis of variance'"><div class="flagText">Analysis of variance</div></a>
              <div data-categoryid="42193" data-articleid="26414"
                   data-categoryname="Analysis of variance"
                   class="flagImage" title="Flag 'Analysis of variance' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Fingers%22" title="Search for articles in the subject area:'Fingers'"><div class="flagText">Fingers</div></a>
              <div data-categoryid="48433" data-articleid="26414"
                   data-categoryname="Fingers"
                   class="flagImage" title="Flag 'Fingers' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Hands%22" title="Search for articles in the subject area:'Hands'"><div class="flagText">Hands</div></a>
              <div data-categoryid="48175" data-articleid="26414"
                   data-categoryname="Hands"
                   class="flagImage" title="Flag 'Hands' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Kinematics%22" title="Search for articles in the subject area:'Kinematics'"><div class="flagText">Kinematics</div></a>
              <div data-categoryid="20035" data-articleid="26414"
                   data-categoryname="Kinematics"
                   class="flagImage" title="Flag 'Kinematics' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Olfactory+organs%22" title="Search for articles in the subject area:'Olfactory organs'"><div class="flagText">Olfactory organs</div></a>
              <div data-categoryid="49655" data-articleid="26414"
                   data-categoryname="Olfactory organs"
                   class="flagImage" title="Flag 'Olfactory organs' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Smell%22" title="Search for articles in the subject area:'Smell'"><div class="flagText">Smell</div></a>
              <div data-categoryid="18091" data-articleid="26414"
                   data-categoryname="Smell"
                   class="flagImage" title="Flag 'Smell' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Thumbs%22" title="Search for articles in the subject area:'Thumbs'"><div class="flagText">Thumbs</div></a>
              <div data-categoryid="48443" data-articleid="26414"
                   data-categoryname="Thumbs"
                   class="flagImage" title="Flag 'Thumbs' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Vision%22" title="Search for articles in the subject area:'Vision'"><div class="flagText">Vision</div></a>
              <div data-categoryid="32965" data-articleid="26414"
                   data-categoryname="Vision"
                   class="flagImage" title="Flag 'Vision' as inappropriate"></div>
          </li>
    </ul>
</div>

<div class="ad">
    <div class="title">Advertisement</div>






  <iframe id='a0852f54' name='a0852f54'
    src='http://ads.plos.org/www/delivery/afr.php?zoneid=381&amp;cb=884'
    frameborder='0' scrolling='no' width='160' height='600'>
    <a href='http://ads.plos.org/www/delivery/ck.php?n=a0852f54&amp;cb=1336'
      target='_top'><img src='http://ads.plos.org/www/delivery/avw.php?zoneid=381&amp;cb=7321&amp;n=a0852f54'
      border='0' alt=''/>
    </a>
  </iframe>



</div>

<div id="twitter-alm-timeline" class="twitter-alm-timeline"></div>

<div class="block sidebar-comments">
    <div class="header">
        <h3>Comments</h3>
    </div>
      <p><a href="/annotation/listThread.action?root=7593">Referee comments: Referee 2</a><br>Posted by PLoS_ONE_Group</p>
      <p><a href="/annotation/listThread.action?root=12701">Referee comments: Referee 1 (Linus Andersson)</a><br>Posted by PLoS_ONE_Group</p>
</div>

</div><!-- sidebar -->
    </div>
  </div>
</div>
<script src="http://wl.figshare.com/static/p_widget.js" type="text/javascript"></script><div id="pageftr">
  <div class="ftr-cols cf">
    <div class="col col-1">
      <img src="/images/logo-plos-footer.png" alt="PLOS Logo" class="logo" />
      <p><a href="/static/releaseNotes">Ambra 2.9.16</a> Managed Colocation provided <br />by <a href="http://www.isc.org/">Internet Systems Consortium</a>.<p>
      <div class="nav nav-aux">
        <a href="/static/privacy">Privacy Policy</a> |
        <a href="/static/terms">Terms of Use</a> |
        <a href="http://www.plos.org/advertise/">Advertise</a> |
        <a href="http://www.plos.org/about/media-inquiries/">Media Inquiries</a>
      </div>
    </div>
    <div class="col col-2">
      <p><a href="http://www.plos.org/publications/journals/">Publications</a></p>
      <div class="nav">
        <ul>
          <li><a href="http://www.plosbiology.org">PLOS Biology</a></li>
          <li><a href="http://www.plosmedicine.org">PLOS Medicine</a></li>
          <li><a href="http://www.ploscompbiol.org">PLOS Computational Biology</a></li>
          <li><a href="http://currents.plos.org">PLOS Currents</a></li>
          <li><a href="http://www.plosgenetics.org">PLOS Genetics</a></li>
          <li><a href="http://www.plospathogens.org">PLOS Pathogens</a></li>
          <li><a href="http://www.plosone.org">PLOS ONE</a></li>
          <li><a href="http://www.plosntds.org">PLOS Neglected Tropical Diseases</a></li>
        </ul>
      </div>
    </div>
    <div class="col col-3">
      <div class="nav">
        <p><a href="http://www.plos.org">plos.org</a></p>
        <p><a href="http://blogs.plos.org">Blogs</a></p>
        <p><a href="http://www.ploscollections.org">Collections</a></p>
        <p><a href="/feedback/new">Send us feedback</a></p>

        <p>California (US) corporation #C2354500, based in San Francisco</p>
      </div>
    </div>
  </div>
</div><!-- pageftr -->

</div><!-- end page-wrap, this div is in header.ftl -->
<script type="text/javascript" src="/javascript/jquery-1.8.1-min.js?v=Tm7VCOzZz3lE03ghpkS6SWkHbyI"></script>
<script type="text/javascript" src="/javascript/ga-min.js?v=lNQ4gt8QcPDatjsdOFl_FGpPhLY"></script>
<script type="text/javascript" src="/javascript/jquery.hoverIntent-min.js?v=mRiGNYY9cIXxVb8u0K_MdW7hHnc"></script>
<script type="text/javascript" src="/javascript/jquery.placeholder-min.js?v=21Pn56Ur9h1N4K4VZDa0nqI3Pxo"></script>
<script type="text/javascript" src="/javascript/jquery.jsonp-2.4.0-min.js?v=lqTpzoHfSq3I5Ygo01qq5WankEo"></script>
<script type="text/javascript" src="/javascript/jquery-ui-1.9.2.custom-min.js?v=raSSlfNO0YsV5uUpAKmTB9n5VTc"></script>
<script type="text/javascript" src="/javascript/jquery.tooltip-min.js?v=cw+6Smh+mdryIA25xvqIvHMrnZM"></script>
<script type="text/javascript" src="/javascript/jquery.uniform-min.js?v=kYUAnX6W2W_2fK3RIuQ2m_YFG9U"></script>
<script type="text/javascript" src="/javascript/jquery.pjax-min.js?v=939kLBjL5_YKbx71T1RHjYaD4l8"></script>
<script type="text/javascript" src="/javascript/imagesloaded-min.js?v=XeuAp8Gc3mvQUo+wZCSF8ttPwvw"></script>
<script type="text/javascript" src="/javascript/figviewer-min.js?v=yPUa0sUQ_iHkI+IRv2i9bjyZJFo"></script>
<script type="text/javascript" src="/javascript/global-min.js?v=0Q3PwjeaWtXYDnqIsQvnL_ou0qs"></script>
<script type="text/javascript" src="/javascript/jquery.touchswipe-min.js?v=huaek_e6HqTduvCNAN91dJolTyw"></script>
<script type="text/javascript" src="/javascript/jquery.base64-min.js?v=VwV1zeVqKZj5FCAdlK0q5NRxbBg"></script>
<script type="text/javascript" src="/javascript/alm-min.js?v=Y5gm6B0b4Kx2YHNObNrgEeBgXlY"></script>
<script type="text/javascript" src="/javascript/taxonomy-browser-min.js?v=vBVMuDMYkGJCXIUxLe35GoyiJNw"></script>
<script type="text/javascript" src="/javascript/jquery.filterize-min.js?v=j0ZKVnHyk2nhFy8eIuNJkp7xaM0"></script>
<script type="text/javascript" src="/javascript/plosone-min.js?v=TK4H4arL_XBSwwJq+K1N3kqYfAI"></script>
<script type="text/javascript" src="/javascript/twitter-min.js?v=xKgcxLsQFXy+at1ao1NVke8nFlM"></script>
<script type="text/javascript" src="/javascript/crossmark.1.4-min.js?v=3FO4k0SjwTaGNnKGNSqthar1080"></script>
<script type="text/javascript">
  var _sf_async_config={uid:16579,domain:"plosone.org"};
  (function(){
    function loadChartbeat() {
      window._sf_endpt=(new Date()).getTime();
      var e = document.createElement('script');
      e.setAttribute('language', 'javascript');
      e.setAttribute('type', 'text/javascript');
      e.setAttribute('src',
          (("https:" == document.location.protocol) ? "https://a248.e.akamai.net/chartbeat.download.akamai.com/102508/" : "http://static.chartbeat.com/") +
              "js/chartbeat.js");
      document.body.appendChild(e);
    }
    var oldonload = window.onload;
    window.onload = (typeof window.onload != 'function') ?
        loadChartbeat : function() { oldonload(); loadChartbeat(); };
  })();
</script>
<!-- <script type="application/javascript" src="http://crossmark.crossref.org/javascripts/v1.3/crossmark.min.js"></script> -->

</body>
</html>
