

 



<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"
      xmlns:foaf="http://xmlns.com/foaf/0.1/"
      xmlns:dc="http://purl.org/dc/terms/"
      xmlns:doi="http://dx.doi.org/"
      xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
      xmlns:xsd="http://www.w3.org/2001/XMLSchema-datatypes#"
      lang="en" xml:lang="en"
      itemscope itemtype="http://schema.org/Article"
      class="no-js">
<head prefix="og: http://ogp.me/ns#">
  <title>PLOS ONE: Learning and Innovative Elements of Strategy Adoption Rules Expand Cooperative Network Topologies</title>


<link rel="stylesheet" type="text/css"  href="/css/global-min.css?v=izteQ6tu7kgsJZW_xmrYizvKiHM" />


    <!--[if lte IE 7]>
<link rel="stylesheet" type="text/css"  href="/css/lte_ie7-min.css?v=3bykQUyQmReeuobVyPozcJ9LxRc" />
    <![endif]-->


<link rel="stylesheet" type="text/css"  href="/css/jquery-ui-min.css?v=eXDHTEJM0lIAmDe5k0I0Ad4nxNo" />


<link rel="stylesheet" type="text/css"  href="/css/journal.css?v=T7ZVxJfgk9jNxLAJ2qHz1vZpgYU" />


<link rel="stylesheet" type="text/css" media="print" href="/css/print-min.css?v=T5lb0B3q6EXBsuDluc5V5w+AkRc" />


  <link rel="stylesheet" href="http://f.fontdeck.com/s/css/js/www.plosone.org/24557.css" type="text/css"/>

  <!--chartbeat -->
  <script type="text/javascript">var _sf_startpt = (new Date()).getTime()</script>
  <script>document.documentElement.className += ' js';</script>

  <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <meta http-equiv="X-UA-Compatible" content="IE=EmulateIE7; IE=EmulateIE9"/>
  <meta name="description" content="PLOS ONE: an inclusive, peer-reviewed, open-access resource from the PUBLIC LIBRARY OF SCIENCE. Reports of well-performed scientific studies from all disciplines freely available to the whole world."/>
  <meta name="keywords" content="PLOS, Public Library of Science, Open Access, Open-Access, Science, Medicine, Biology, Research, Peer-review, Inclusive, Interdisciplinary, Ante-disciplinary, Physics, Chemistry, Engineering"/>
  <meta name="almHost" content="http://alm.plos.org/api/v3/articles"/>
  <meta name="searchHost" content="http://api.plos.org/search" />
  <meta name="termsHost" content="http://api.plos.org/terms" />
  <meta name="solrApiKey" content="plos"/>
  <meta name="almAPIKey" content="3pezRBRXdyzYW6ztfwft" />
  <meta name="currentJournal" content="PLoSONE" />
  <meta name="almRequestBatchSize" content="" />

  <meta name="citation_publisher" content="Public Library of Science"/>
  <meta name="citation_doi" content="10.1371/journal.pone.0001917"/>
  <meta name="dc.identifier" content="10.1371/journal.pone.0001917" />

    <meta name="citation_title" content="Learning and Innovative Elements of Strategy Adoption Rules Expand Cooperative Network Topologies"/>
    <meta itemprop="name" content="Learning and Innovative Elements of Strategy Adoption Rules Expand Cooperative Network Topologies"/>

      <meta name="citation_author" content="Shijun Wang"/>
            <meta name="citation_author_institution" content="Department of Automation, Tsinghua University, Beijing, China"/>
      <meta name="citation_author" content="Máté S. Szalay"/>
            <meta name="citation_author_institution" content="Department of Medical Chemistry, Semmelweis University, Budapest, Hungary"/>
      <meta name="citation_author" content="Changshui Zhang"/>
            <meta name="citation_author_institution" content="Department of Automation, Tsinghua University, Beijing, China"/>
      <meta name="citation_author" content="Peter Csermely"/>
            <meta name="citation_author_institution" content="Department of Medical Chemistry, Semmelweis University, Budapest, Hungary"/>

    <meta name="citation_date" content="2008/4/9"/>

  <meta name="citation_pdf_url" content="http://dx.plos.org/10.1371/journal.pone.0001917.pdf" />

      <meta name="citation_journal_title" content="PLOS ONE" />
    <meta name="citation_firstpage" content="e1917"/>
    <meta name="citation_issue" content="4"/>
    <meta name="citation_volume" content="3"/>
    <meta name="citation_issn" content="1932-6203"/>

    <meta name="citation_journal_abbrev" content="PLoS ONE" />

      <meta name="citation_reference" content="citation_title=The evolution of cooperation.; citation_author=R Axelrod; citation_author=WD Hamilton; citation_journal_title=Science; citation_volume=211; citation_number=1; citation_pages=1390-1396; citation_date=1981; " />
      <meta name="citation_reference" content="citation_title=Five rules for the evolution of cooperation.; citation_author=MA Nowak; citation_journal_title=Science; citation_volume=314; citation_number=2; citation_pages=1560-1563; citation_date=2006; " />
      <meta name="citation_reference" content="citation_title=Evolutionary games on graphs.; citation_author=G Szabó; citation_author=G Fáth; citation_journal_title=Physics Reports; citation_volume=446; citation_number=3; citation_pages=97-216; citation_date=2006; " />
      <meta name="citation_reference" content="citation_title=The group covariance effect and fitness trade-offs during evolutionary transitions in individuality.; citation_author=RE Michod; citation_journal_title=Proc. Natl Acad. Sci. USA; citation_volume=103; citation_number=4; citation_pages=9113-9117; citation_date=2006; " />
      <meta name="citation_reference" content="citation_title=Cooperation prevails when individuals adjust their social ties.; citation_author=FC Santos; citation_author=JM Pacheco; citation_author=T Lenaerts; citation_journal_title=PLOS Comput. Biol.; citation_volume=2; citation_number=5; citation_pages=e140; citation_date=2006; " />
      <meta name="citation_reference" content="citation_title=Variation in behaviour promotes cooperation in the Prisoner's Dilemma game.; citation_author=JM McNamara; citation_author=Z Barta; citation_author=AI Houston; citation_journal_title=Nature; citation_volume=428; citation_number=6; citation_pages=745-748; citation_date=2004; " />
      <meta name="citation_reference" content="citation_title=Evolution of cooperation and communication skills as a consequence of environment fluctuations.; citation_author=A Feigel; citation_number=7; citation_date=2006; " />
      <meta name="citation_reference" content="citation_title=Evolutionary Prisoner's Dilemma game on the Newman-Watts networks.; citation_author=J Vukov; citation_author=G Szabó; citation_author=A Szolnoki; citation_journal_title=Phys. Rev. E; citation_volume=77; citation_number=8; citation_pages=026109; citation_date=2008; " />
      <meta name="citation_reference" content="citation_title=Evolutionary games and spatial chaos.; citation_author=MA Nowak; citation_author=RM May; citation_journal_title=Nature; citation_volume=359; citation_number=9; citation_pages=826-829; citation_date=1992; " />
      <meta name="citation_reference" content="citation_title=Spatial games and the maintenance of cooperation.; citation_author=MA Nowak; citation_author=S Bonhoeffer; citation_author=RM May; citation_journal_title=Proc. Natl. Acad. Sci. USA; citation_volume=91; citation_number=10; citation_pages=4877-4881; citation_date=1994; " />
      <meta name="citation_reference" content="citation_title=The role of social structure in the maintenance of cooperative regimes.; citation_author=MD Cohen; citation_author=RL Riolo; citation_author=R Axelrod; citation_journal_title=Rationality Society; citation_volume=13; citation_number=11; citation_pages=5-32; citation_date=2001; " />
      <meta name="citation_reference" content="citation_title=Scale-free networks provide a unifying framework for the emergence of cooperation.; citation_author=FC Santos; citation_author=JM Pacheco; citation_journal_title=Phys. Rev. Lett.; citation_volume=95; citation_number=12; citation_pages=098104; citation_date=2005; " />
      <meta name="citation_reference" content="citation_title=Hawks and Doves on small-world networks.; citation_author=M Tomassini; citation_author=L Luthi; citation_author=M Giacobini; citation_journal_title=Phys. Rev. E; citation_volume=73; citation_number=13; citation_pages=016132; citation_date=2006; " />
      <meta name="citation_reference" content="citation_title=Spatial structure often inhibits the evolution of cooperation in the snowdrift game.; citation_author=C Hauert; citation_author=M Doebeli; citation_journal_title=Nature; citation_volume=428; citation_number=14; citation_pages=643-646; citation_date=2004; " />
      <meta name="citation_reference" content="citation_title=A simple rule for the evolution of cooperation on graphs and social networks.; citation_author=H Ohtsuki; citation_author=C Hauert; citation_author=E Lieberman; citation_author=MA Nowak; citation_journal_title=Nature; citation_volume=441; citation_number=15; citation_pages=502-505; citation_date=2006; " />
      <meta name="citation_reference" content="citation_title=Effects of average degree on cooperation in networked evolutionary game.; citation_author=CL Tang; citation_author=WX Wang; citation_author=X Wu; citation_author=BH Wang; citation_journal_title=Eur. J. Phys. B; citation_volume=53; citation_number=16; citation_pages=411-415; citation_date=2006; " />
      <meta name="citation_reference" content="citation_title=Collective dynamics of ‘small-world’ networks.; citation_author=DJ Watts; citation_author=SH Strogatz; citation_journal_title=Nature; citation_volume=393; citation_number=17; citation_pages=440-442; citation_date=1998; " />
      <meta name="citation_reference" content="citation_title=Q-learning.; citation_author=CJCH Watkins; citation_author=P Dayan; citation_journal_title=Machine Learning; citation_volume=8; citation_number=18; citation_pages=279-292; citation_date=1992; " />
      <meta name="citation_reference" content="citation_title=Reinforcement learning: an introduction.; citation_author=RS Sutton; citation_author=AG Barto; citation_number=19; citation_date=1999; " />
      <meta name="citation_reference" content="citation_title=War and peace.; citation_author=RJ Aumann; citation_journal_title=Proc. Natl. Acad. Sci. USA; citation_volume=103; citation_number=20; citation_pages=17075-17078; citation_date=2006; " />
      <meta name="citation_reference" content="citation_title=Learning dynamics in social dilemmas.; citation_author=MW Macy; citation_author=A Flache; citation_journal_title=Proc. Natl. Acad. Sci. USA; citation_volume=99; citation_number=21; citation_pages=7229-7236; citation_date=2002; " />
      <meta name="citation_reference" content="citation_title=Evolvability.; citation_author=M Kirschner; citation_author=J Gerhart; citation_journal_title=Proc. Natl. Acad. Sci. USA; citation_volume=95; citation_number=22; citation_pages=8420-8427; citation_date=1998; " />
      <meta name="citation_reference" content="citation_title=Weak Links: Stabilizers of Complex Systems from Proteins to Social Networks (Springer, Heidelberg).; citation_author=P Csermely; citation_number=23; citation_date=2006; " />
      <meta name="citation_reference" content="citation_author=B Skyrms; citation_number=24; citation_date=2004; citation_publisher=Cambridge University Press; " />
      <meta name="citation_reference" content="citation_author=R Durrett; citation_number=25; citation_date=2006; citation_publisher=Cambridge University Press; " />
      <meta name="citation_reference" content="citation_title=Graph evolution: densification and shrinking diameters.; citation_author=J Leskovec; citation_author=J Kleinberg; citation_author=C Faloutsos; citation_journal_title=ACM TKDD; citation_volume=1; citation_number=26; citation_pages=1-40; citation_date=2007; " />
      <meta name="citation_reference" content="citation_title=Topological phase transitions of random networks.; citation_author=I Derenyi; citation_author=I Farkas; citation_author=G Palla; citation_author=T Vicsek; citation_journal_title=Physica A; citation_volume=334; citation_number=27; citation_pages=583-590; citation_date=2004; " />
      <meta name="citation_reference" content="citation_title=Network formation and social coordination.; citation_author=S Goyal; citation_author=F Vega-Redondo; citation_journal_title=Games Econ. Behav.; citation_volume=50; citation_number=28; citation_pages=178-207; citation_date=2005; " />
      <meta name="citation_reference" content="citation_title=Dynamics of networking agents competing for high centrality and low degree.; citation_author=P Holme; citation_author=G Ghoshal; citation_journal_title=Phys. Rev. Lett.; citation_volume=96; citation_number=29; citation_pages=098701; citation_date=2006; " />
      <meta name="citation_reference" content="citation_title=Coevolutionary games on networks.; citation_author=H Ebel; citation_author=S Bornholdt; citation_journal_title=Phys. Rev. E; citation_volume=66; citation_number=30; citation_pages=056118; citation_date=2002; " />
      <meta name="citation_reference" content="citation_title=Roles of mixing patterns in cooperation on a scale-free networked game.; citation_author=Z Rong; citation_author=X Li; citation_author=X Wang; citation_journal_title=Phys. Rev. E; citation_volume=76; citation_number=31; citation_pages=027101; citation_date=2007; " />
      <meta name="citation_reference" content="citation_title=Social dilemmas in an online social network: the structure and evolution of cooperation.; citation_author=F Fu; citation_author=X Chen; citation_author=L Liu; citation_author=L Wang; citation_journal_title=Phys. Lett. A; citation_volume=371; citation_number=32; citation_pages=58-64; citation_date=2007; " />
      <meta name="citation_reference" content="citation_title=Multi-agent reinforcement learning: independent vs. cooperative agents.; citation_author=M Tan; citation_journal_title=Proc. 10th Intl. Conf. Machine Learning; citation_number=33; citation_pages=330-337; citation_date=1993; " />
      <meta name="citation_reference" content="citation_title=Economic action and social structure. The problem of embeddedness.; citation_author=M Granovetter; citation_journal_title=Am. J. Sociol.; citation_volume=91; citation_number=34; citation_pages=481-510; citation_date=1985; " />
      <meta name="citation_reference" content="citation_title=Trust, cooperation, and market formation in the U.S. and Japan.; citation_author=MW Macy; citation_author=Y Sato; citation_journal_title=Proc. Natl. Acad. Sci. USA; citation_volume=99; citation_number=35; citation_pages=7214-7220; citation_date=2002; " />
      <meta name="citation_reference" content="citation_title=Stern-judging: a simple, successful norm, which promotes cooperation under indirect reciprocity.; citation_author=JM Pacheco; citation_author=FC Santos; citation_author=FACC Chalub; citation_journal_title=PLOS Comput. Biol.; citation_volume=2; citation_number=36; citation_pages=e178; citation_date=2006; " />
      <meta name="citation_reference" content="citation_title=Chromodynamics of cooperation in finite populations.; citation_author=A Traulsen; citation_author=MA Nowak; citation_journal_title=PLOS ONE; citation_volume=2; citation_number=37; citation_pages=e270; citation_date=2007; " />
      <meta name="citation_reference" content="citation_title=Water and molecular chaperones act as weak links of protein folding networks: energy landscape and punctuated equilibrium changes point towards a game theory of proteins.; citation_author=IA Kovacs; citation_author=MS Szalay; citation_author=P Csermely; citation_journal_title=FEBS Lett; citation_volume=579; citation_number=38; citation_pages=2254-2260; citation_date=2005; " />
      <meta name="citation_reference" content="citation_title=Social dilemmas and cooperation in complex networks.; citation_author=M Tomassini; citation_author=E Pestelacci; citation_author=L Luthi; citation_journal_title=Int. J. Mod. Physics C; citation_volume=18; citation_number=39; citation_pages=1173-1186; citation_date=2007; " />
      <meta name="citation_reference" content="citation_title=Evolutionary dilemmas in a social network.; citation_author=L Luthi; citation_author=E Pestelacci; citation_author=M Tomassini; citation_journal_title=Lect. Notes Comp. Sci.; citation_volume=4648; citation_number=40; citation_pages=545-554; citation_date=2007; " />
      <meta name="citation_reference" content="citation_title=Participation costs dismiss the advantage of heterogeneous networks in evolution of cooperation.; citation_author=N Masuda; citation_journal_title=Proc. Roy. Soc. B; citation_volume=274; citation_number=41; citation_pages=1815-1821; citation_date=2007; " />
      <meta name="citation_reference" content="citation_title=Multiagent reinforcement learning in the iterated prisoner's dilemma.; citation_author=TW Sandholm; citation_author=RH Crites; citation_journal_title=BioSystems; citation_volume=37; citation_number=42; citation_pages=147-166; citation_date=1996; " />
      <meta name="citation_reference" content="citation_author=A Szolnoki; citation_author=M Perc; citation_author=Z Danku; citation_volume=387; citation_number=43; citation_pages=2075-2082; citation_date=2008; " />
      <meta name="citation_reference" content="citation_title=Emergence of scaling in random networks.; citation_author=AL Barabasi; citation_author=R Albert; citation_journal_title=Science; citation_volume=286; citation_number=44; citation_pages=509-512; citation_date=1999; " />
      <meta name="citation_reference" content="citation_title=Community structure in social and biological networks.; citation_author=M Girvan; citation_author=MEJ Newman; citation_journal_title=Proc. Natl. Acad. Sci. USA; citation_volume=99; citation_number=45; citation_pages=7821-7826; citation_date=2002; " />
      <meta name="citation_reference" content="citation_title=Pajek - Program for Large Network Analysis.; citation_author=V Batagelj; citation_author=A Mrvar; citation_journal_title=Connections; citation_volume=21; citation_number=46; citation_pages=47-57; citation_date=1998; " />

  <link rel="canonical" href="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0001917" />

    <meta name="twitter:card" content="summary"/>
    <meta name="twitter:site" content="@plosone"/>
    <meta name="twitter:title" content="Learning and Innovative Elements of Strategy Adoption Rules Expand Cooperative Network Topologies"/>
    <meta name="twitter:description" content="Cooperation plays a key role in the evolution of complex systems. However, the level of cooperation extensively varies with the topology of agent networks in the widely used models of repeated games. Here we show that cooperation remains rather stable by applying the reinforcement learning strategy adoption rule, Q-learning on a variety of random, regular, small-word, scale-free and modular network models in repeated, multi-agent Prisoner's Dilemma and Hawk-Dove games. Furthermore, we found that using the above model systems other long-term learning strategy adoption rules also promote cooperation, while introducing a low level of noise (as a model of innovation) to the strategy adoption rules makes the level of cooperation less dependent on the actual network topology. Our results demonstrate that long-term learning and random elements in the strategy adoption rules, when acting together, extend the range of network topologies enabling the development of cooperation at a wider range of costs and temptations. These results suggest that a balanced duo of learning and innovation may help to preserve cooperation during the re-organization of real-world networks, and may play a prominent role in the evolution of self-organizing, complex systems."/>
      <meta name="twitter:image" content="http://dx.plos.org/10.1371/journal.pone.0001917.g003"/>

  <meta property="og:title" content="Learning and Innovative Elements of Strategy Adoption Rules Expand Cooperative Network Topologies" />
  <meta property="og:type" content="article" />
  <meta property="og:url" content="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0001917" />

 <!--end articleInfoX-->

  <link rel="pingback" href="http://www.plosone.org/pingback" />


  <link rel="shortcut icon" href="/images/favicon.ico" type="image/x-icon"/>
  <link rel="home" title="home" href="/"/>
  <link rel="alternate" type="application/rss+xml"
        title="PLOS ONE: New Articles"
        href="http://www.plosone.org/article/feed"/>
</head>
<body>

  <div id="page-wrap">
    <div id="topbanner" class="cf">

<!-- Div for the ad at the top of journal home page-->
<div class="center">
  <div class="title">Advertisement</div>
  <iframe id='a3ac9da4' name='a3ac9da4'
    src='http://ads.plos.org/www/delivery/afr.php?zoneid=345&amp;cb=6966'
    frameborder='0' scrolling='no' width='730' height='90'>
    <a href='http://ads.plos.org/www/delivery/ck.php?n=a3ac9da4&amp;cb=5433'
      target='_top'><img src='http://ads.plos.org/www/delivery/avw.php?zoneid=345&amp;cb=5756&amp;n=a3ac9da4'
      border='0' alt=''/>
    </a>
  </iframe>
</div>    </div>

    <div id="pagehdr-wrap">
      <div id="pagehdr">
        <div id="user" class="nav">
          <ul>
            <li><a href="http://www.plos.org">plos.org</a></li>
            <li><a href="https://register.plos.org/ambra-registration/register.action">create account</a></li>
            <li class="btn-style"><a
              href="/user/secure/secureRedirect.action?goTo=%2Farticle%2FfetchArticle.action%3FarticleURI%3Dinfo%253Adoi%252F10.1371%252Fjournal.pone.0001917">sign in</a>
            </li>
          </ul>
        </div>
        <div class="logo">
          <a href="/"><img src="/images/logo.png" alt="PLOS ONE"></a>
        </div>

<div id="nav-main" class="nav">
  <ul>
        <li id="mn-01"><a href="/taxonomy" class="areas-link">Subject Areas</a></li>
    <li id="mn-02"><a href="javascript:void(0);">For Authors</a>
      <div class="submenu" style="width: 540px; margin-left: -300px;">
        <div class="block">
          <div class="submit-script">
            <h3>Submit your Manuscript</h3>
            <ul>
              <li>Fair, rigorous peer review</li>
              <li>Broad scope and wide reach</li>
            </ul>
            <a href="/static/submissionInstructions" class="btn">get started</a>
          </div>
        </div>
        <div class="menu">
          <ul>
            <li><a href="/static/publish">Why Publish with PLOS ONE</a></li>
            <li><a href="/static/publication">Publication Criteria</a></li>
            <li><a href="/static/editorial">Editorial Policies</a></li>
            <li><a href="/static/guidelines">Preparing A Manuscript</a></li>
            <li><a href="/static/figureGuidelines">Figure and Table Guidelines</a></li>
          <li><a href="/static/supportingInformation">Supporting Information Guidelines</a></li>
            <li><a href="/static/submissionInstructions">Submitting a Manuscript</a></li>
          </ul>
        </div>
      </div>
    </li>

    <li id="mn-03"><a href="javascript:void(0);">About Us</a>
      <div class="submenu" style="width:248px; margin-left:-30px;">
        <div class="menu">
          <ul>
            <li><a href="/static/information">Journal Information</a></li>
            <li><a href="/static/edboard">Editorial Board</a></li>
            <li><a href="/static/reviewerGuidelines">Reviewer Guidelines</a></li>
            <li><a href="/static/almInfo">Article-Level Metrics</a></li>
            <li><a href="/static/license">Open-Access License</a></li>
            <li><a href="/static/downloads">Media Downloads</a></li>
            <li><a href="/static/commentGuidelines">Guidelines for Comments</a></li>
            <li><a href="/static/corrections">Corrections</a></li>
            <li><a href="/static/help">Help Using this Site</a></li>
            <li><a href="/static/contact">Contact Us</a></li>
          </ul>
        </div>
      </div>
    </li>
  </ul>
<div id="db">
  <form name="searchForm" action="/search/simple?noSearchFlag=true&amp;query=&amp;articleURI=info%3Adoi%2F10.1371%2Fjournal.pone.0001917" method="get" >
<input type="hidden" name="from" value="globalSimpleSearch" id="from"/><input type="hidden" name="filterJournals" value="PLoSONE" id="filterJournals"/>    <fieldset>
      <legend>Search</legend>
      <label for="search">Search</label>
      <div class="wrap">
        <input id="search" type="text" name="query" placeholder="Search">
        <input type="image" alt="SEARCH" src="/images/icon.search.gif">
      </div>
    </fieldset>
  </form>
    <a id="advSearch" href="/search/advanced?noSearchFlag=true&amp;query=&amp;articleURI=info%3Adoi%2F10.1371%2Fjournal.pone.0001917&filterJournals=PLoSONE">advanced search</a>
</div></div>

      </div>
      <!-- pagehdr-->
    </div>
    <!-- pagehdr-wrap -->

  <!--body and html tags gets closed in global_footer.ftl-->
<script type="text/javascript" src="/javascript/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<div id="pagebdy-wrap">
  <div id="pagebdy">

    <div id="article-block" class="cf">

<div class="article-meta cf">
  <ul id="almSignPost" style="display: none;"></ul>
  <div class="article-type">
    <span class="type oa">Open Access</span>
      <span class="type pr">Peer-Reviewed</span>
  </div>
</div>

<div class="header" id="hdr-article">

<div class="article-kicker">
      <span id="article-type-heading">
        Research Article
      </span>
</div>  <h1 property="dc:title" datatype="" rel="dc:type" href="http://purl.org/dc/dcmitype/Text">
    Learning and Innovative Elements of Strategy Adoption Rules Expand Cooperative Network Topologies
  </h1>

  <ul class="authors">
      <li>


        <span rel="dc:creator" class="author">
          <span class="person" property="foaf:name" typeof="foaf:Person">
            Shijun Wang, 
          </span>
        </span>

          <div class="author_meta">
            <div class="author_inner">


              
              

                <p>Affiliation:
                  Department of Automation, Tsinghua University, Beijing, China
                </p>

                <p>
                    Current address: Diagnostic Radiology Department, Clinical Center, National Institutes of Health, Bethesda, Maryland, United States of America
                </p>

              <span class="close">X</span>

            </div>
          </div>
      </li>
      <li>


        <span rel="dc:creator" class="author">
          <span class="person" property="foaf:name" typeof="foaf:Person">
            Máté S. Szalay, 
          </span>
        </span>

          <div class="author_meta">
            <div class="author_inner">


              
              

                <p>Affiliation:
                  Department of Medical Chemistry, Semmelweis University, Budapest, Hungary
                </p>


              <span class="close">X</span>

            </div>
          </div>
      </li>
      <li>


        <span rel="dc:creator" class="author">
          <span class="person" property="foaf:name" typeof="foaf:Person">
            Changshui Zhang, 
          </span>
        </span>

          <div class="author_meta">
            <div class="author_inner">


              
              

                <p>Affiliation:
                  Department of Automation, Tsinghua University, Beijing, China
                </p>


              <span class="close">X</span>

            </div>
          </div>
      </li>
      <li>


        <span rel="dc:creator" class="author">
          <span class="person" property="foaf:name" typeof="foaf:Person">
            Peter Csermely
              <span class="corresponding">mail</span>
          </span>
        </span>

          <div class="author_meta">
            <div class="author_inner">


              
              <p><span class="email">*</span>To whom correspondence should be addressed. E-mail: <a href="mailto:csermely@puskin.sote.hu">csermely@puskin.sote.hu</a></p>

                <p>Affiliation:
                  Department of Medical Chemistry, Semmelweis University, Budapest, Hungary
                </p>


              <span class="close">X</span>

            </div>
          </div>
      </li>
  </ul>
  <ul class="date-doi-line">
    <li>Published: April 09, 2008</li>
    <li>DOI: 10.1371/journal.pone.0001917</li>
  </ul>


</div><!--end header-->
<div class="main cf" id="pjax-container">
  

<div class="nav items-5" id="nav-article">
  <ul>
  <li>
        <span class="active" name="article">Article</span>
  </li>
  <li>
      <a href="/article/authors/info%3Adoi%2F10.1371%2Fjournal.pone.0001917" name="authors">About the Authors</a>
  </li>
  <li>
      <a href="/article/metrics/info%3Adoi%2F10.1371%2Fjournal.pone.0001917" name="metrics">Metrics</a>
  </li>
  <li>
      <a href="/article/comments/info%3Adoi%2F10.1371%2Fjournal.pone.0001917" name="comments">Comments</a>
  </li>
  <li>
      <a href="/article/related/info%3Adoi%2F10.1371%2Fjournal.pone.0001917" name="related">Related Content</a>
  </li>
  </ul>
</div>

<script type="text/javascript">
  var selected_tab = "article";
</script>
  <div id="figure-thmbs" class="carousel cf">
    <div class="wrapper">
      <div class="slider">
              <div class="item">
                <a href="#pone-0001917-g001" data-doi="info:doi/10.1371/journal.pone.0001917" data-uri="info:doi/10.1371/journal.pone.0001917.g001" title="Figure 1">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001917.g001&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001917-g002" data-doi="info:doi/10.1371/journal.pone.0001917" data-uri="info:doi/10.1371/journal.pone.0001917.g002" title="Figure 2">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001917.g002&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
              <div class="item">
                <a href="#pone-0001917-g003" data-doi="info:doi/10.1371/journal.pone.0001917" data-uri="info:doi/10.1371/journal.pone.0001917.g003" title="Figure 3">
                  <span class="thmb-wrap">
                    <img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001917.g003&representation=PNG_I" alt="">
                  </span>
                </a>
              </div>
      </div>
    </div>
  </div>

  <div class="nav-col">
    <div class="nav" id="nav-article-page">
      <ul>
        <li class="nav-col-comments"><a href="/article/comments/info%3Adoi%2F10.1371%2Fjournal.pone.0001917">Reader Comments (2)</a></li>
          <li id="nav-figures"><a data-doi="info:doi/10.1371/journal.pone.0001917" >Figures</a></li>
      </ul>
    </div>
  </div>

  <div class="article">







<div class="abstract"><a id="abstract0" name="abstract0" toc="abstract0" title="Abstract"></a><h2>Abstract</h2><a id="article1.front1.article-meta1.abstract1.p1" name="article1.front1.article-meta1.abstract1.p1"></a><p>Cooperation plays a key role in the evolution of complex systems. However, the level of cooperation extensively varies with the topology of agent networks in the widely used models of repeated games. Here we show that cooperation remains rather stable by applying the reinforcement learning strategy adoption rule, Q-learning on a variety of random, regular, small-word, scale-free and modular network models in repeated, multi-agent Prisoner's Dilemma and Hawk-Dove games. Furthermore, we found that using the above model systems other long-term learning strategy adoption rules also promote cooperation, while introducing a low level of noise (as a model of innovation) to the strategy adoption rules makes the level of cooperation less dependent on the actual network topology. Our results demonstrate that long-term learning and random elements in the strategy adoption rules, when acting together, extend the range of network topologies enabling the development of cooperation at a wider range of costs and temptations. These results suggest that a balanced duo of learning and innovation may help to preserve cooperation during the re-organization of real-world networks, and may play a prominent role in the evolution of self-organizing, complex systems.</p>
</div>


<div class="articleinfo"><p><strong>Citation: </strong>Wang S, Szalay MS, Zhang C, Csermely P (2008) Learning and Innovative Elements of Strategy Adoption Rules Expand Cooperative Network Topologies. PLoS ONE 3(4):
          e1917.
            doi:10.1371/journal.pone.0001917</p><p><strong>Editor: </strong>Enrico Scalas, University of East Piedmont, Italy</p><p><strong>Received:</strong> October 22, 2007; <strong>Accepted:</strong> February 25, 2008; <strong>Published:</strong> April 9, 2008</p><p><strong>Copyright:</strong> © 2008 Wang et al. This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</p><p><strong>Funding: </strong>Work in the authors' laboratory was supported by research grants from the EU (FP6-518230), Hungarian Science Foundation (OTKA- K69105) and the Hungarian National Research Initiative (NKFP-1A/056/2004 and KKK-0015/3.0). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p><p><strong>Competing interests:</strong> The authors have declared that no competing interests exist.</p></div>





<div id="section1" class="section"><a id="s1" name="s1" toc="s1" title="Introduction"></a><h3>Introduction</h3><a id="article1.body1.sec1.p1" name="article1.body1.sec1.p1"></a><p>Cooperation is necessary for the emergence of complex, hierarchical systems <a href="#pone.0001917-Axelrod1">[1]</a>–<a href="#pone.0001917-Santos1">[5]</a>. Why is cooperation maintained, when there is a conflict between self-interest and the common good? A set of answers emphasized agent similarity, in terms of kin- or group-selection and compact network communities, which is helped by learning of successful strategies <a href="#pone.0001917-Nowak1">[2]</a>, <a href="#pone.0001917-Szab1">[3]</a>. On the other hand, agent diversity in terms of noise, variation of behavior and innovation, as well as the changing environment of the agent-community all promoted cooperation in different games and settings <a href="#pone.0001917-Szab1">[3]</a>, <a href="#pone.0001917-McNamara1">[6]</a>–<a href="#pone.0001917-Vukov1">[8]</a>.</p>
<a id="article1.body1.sec1.p2" name="article1.body1.sec1.p2"></a><p>Small-world, scale-free or modular network models, which all give a chance to develop the complexity of similar, yet diverse agent-neighborhoods, provide a good starting point for the modeling of the complexity of cooperative behavior in real-world networks <a href="#pone.0001917-Nowak2">[9]</a>–<a href="#pone.0001917-Tomassini1">[13]</a>. However, the actual level of cooperation in various games, such as the Prisoner's Dilemma or Hawk-Dove games is very sensitive to the topology of the agent network model [14–16, <a href="#pone.0001917.s001">Electronic supplementary material S1</a> – ESM1 – Table S1.1]. In our work we applied a set of widely used network models and examined the stability of cooperation after repeated games using the reinforcement learning strategy adoption rule, Q-learning. To examine the surprising stability of cooperation observed, when using Q-learning, we approximated the complex rules of Q-learning by designing a long-term versions of the best-takes-over and other strategy adoption rules as well as introducing a low level of randomness to these rules. We found that none of these features alone results in a similar stability of cooperation in various network models. However, when applied together, long-term (‘learning’) and random (‘innovative’) elements of strategy adoption rules can make cooperation relatively stable under various conditions in a large number of network models. Our results have a wide application in various complex systems of biology from the cellular level to social networks and ecosystems.</p>
</div>

<div id="section2" class="section"><a id="s2" name="s2" toc="s2" title="Results"></a><h3>Results</h3>
<h4>Sensitivity of cooperation on network topology</h4>
<a id="article1.body1.sec2.sec1.p1" name="article1.body1.sec2.sec1.p1"></a><p>As an illustrative example for the sensitivity of cooperation on network topology, we show cooperating agents after the last round of a ‘repeated canonical Prisoner's Dilemma game’ (PD-game) on two, almost identical versions of a modified Watts-Strogatz-type small-world model network <a href="#pone.0001917-Tomassini1">[13]</a>, <a href="#pone.0001917-Watts1">[17]</a>. Comparison of the top panels of <a href="#pone-0001917-g001">Figure 1</a> shows that a minor change of network topology (replacement of 37 links from 900 links total) completely changed both the level and topology of cooperating agents playing with a best-takes-over short term strategy adoption rule. We have observed a similar topological sensitivity of cooperation in all combinations of (a) other short-term strategy adoption rules; (b) a large number of other network topologies; (c) other games, such as the extended Prisoner's Dilemma or Hawk-Dove games (ESM1 Figures S1.1 and S1.6).</p>
<div class="figure" id="pone-0001917-g001"><div class="img"><a name="pone-0001917-g001" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001917.g001&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001917" data-uri="info:doi/10.1371/journal.pone.0001917.g001"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001917.g001&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001917.g001/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001917.g001/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001917.g001/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001917.g001/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001917.g001.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001917.g001/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001917.g001/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001917.g001.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 1.  <span>A long-term learning adoption rule, Q-learning improves and stabilizes cooperation of agents forming various small-world networks in Prisoner’s Dilemma games.</span></strong></p><a id="article1.body1.sec2.sec1.fig1.caption1.p1" name="article1.body1.sec2.sec1.fig1.caption1.p1"></a><p>The modified Watts-Strogatz small-world network was built on a 15×15 lattice, where each node was connected to its eight nearest neighbors. The rewiring probabilities of the links placed originally on a regular lattice were 0.01 (left panels) and 0.04 (right panels), respectively. For the description of the canonical repeated Prisoner's Dilemma game, as well as the best-takes-over (top panels) and Q-learning (bottom panels) strategy adoption rules see <a href="#s4">Methods</a> and the ESM1. The temptation level, T was 3.6. Networks showing the last round of 5,000 plays were visualized using the Kamada-Kawai algorithm of the Pajek program <a href="#pone.0001917-Batagelj1">[46]</a>. Dark blue dots and diamonds correspond to cooperators and defectors, respectively. The Figure shows that both the extent and distribution of cooperators vary, when using the best-takes-over strategy adoption rule (see top panels), while they are rather stable with the Q-learning strategy update rule (see bottom panels).</p>
<span>doi:10.1371/journal.pone.0001917.g001</span></div>

<h4>Q-learning stabilizes cooperation in different network topologies</h4>
<a id="article1.body1.sec2.sec2.p1" name="article1.body1.sec2.sec2.p1"></a><p>On the contrary to the general sensitivity of cooperation to the topology of agent-networks in PD-games using the short-term strategy adoption rule shown above, when the long-term, reinforcement learning strategy adoption rule, Q-learning was applied, the level and configuration of cooperating agents showed a surprising stability (cf. the bottom panels of <a href="#pone-0001917-g001">Figure 1</a>). Just oppositely to the short-term strategy adoption rule shown on the top panels of <a href="#pone-0001917-g001">Figure 1</a>, the Q-learning strategy adoption rule (a) is based on the long-term experiences of the agents from all previous rounds allowing some agents to choose a cooperative strategy despite of the current adverse effects, and (b) is an ‘innovative’ strategy adoption rule <a href="#pone.0001917-Szab1">[3]</a> re-introducing cooperation even under conditions, when it has already been wiped out from the network-community completely <a href="#pone.0001917-Watkins1">[18]</a>, <a href="#pone.0001917-Sutton1">[19]</a>.</p>
<a id="article1.body1.sec2.sec2.p2" name="article1.body1.sec2.sec2.p2"></a><p>Extending the observations shown on <a href="#pone-0001917-g001">Figure 1</a> we decided to compare the level of cooperation in PD-games on small-world and scale-free networks at various levels of temptations (T, the defector's payoff, when it meets a cooperator) in detail. The top panel of <a href="#pone-0001917-g002">Figure 2</a> shows that the cooperation level of agents using the best-takes-over strategy adoption rule rapidly decreased with a gradual increase of their temptation to defect. This was generally true for both small-world, and scale-free networks leaving a negligible amount of cooperation at T-values higher than 4.5. However, at smaller temptation levels the level of cooperation greatly differed in the two network topologies. Initially, the small-world network was preferred, while at temptation values higher than 3.7, agents of the scale-free network developed a larger cooperation. The behavior of agents using the Q-learning strategy adoption rule was remarkably different (top panel of <a href="#pone-0001917-g002">Figure 2</a>). Their cooperation level remained relatively stable even at extremely large temptation values. Moreover, the cooperation levels of agents using Q-learning had no significant difference, if we compared small-world and scale-free networks. This behavior continued at temptation values higher than 6 (data not shown). We have observed the same differences in both the extent of cooperation at extremely high temptations (or gains of hawks meeting a dove in the Hawk-Dove game) and the topological sensitivity of cooperation in all combinations of (a) other short-term strategy adoption rules; (b) a large number of other network topologies; (c) other games, such as the extended Prisoner's Dilemma or Hawk-Dove games (ESM1 Figures S1.2 and S1.6).</p>
<div class="figure" id="pone-0001917-g002"><div class="img"><a name="pone-0001917-g002" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001917.g002&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001917" data-uri="info:doi/10.1371/journal.pone.0001917.g002"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001917.g002&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001917.g002/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001917.g002/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001917.g002/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001917.g002/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001917.g002.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001917.g002/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001917.g002/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001917.g002.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 2.  <span>Long-term learning elements of strategy update rules help, while a low level of randomness relatively stabilizes cooperation in Prisoner's Dilemma games played on various networks.</span></strong></p><a id="article1.body1.sec2.sec2.fig1.caption1.p1" name="article1.body1.sec2.sec2.fig1.caption1.p1"></a><p>Small-world (SW, filled, red symbols) networks were built as described in the legend of <a href="#pone-0001917-g001">Figure 1</a>. The Barabasi-Albert-type scale-free networks (SF, open, blue symbols) contained 2,500 nodes, where at each construction step a new node was added with 3 new links attached to the existing nodes. For the description of the canonical repeated Prisoner's Dilemma game, as well as that of the best-takes-over (triangles, all panels), the Q-learning (rectangles, top panel) the best-takes-over long (circles, middle panel), and the best-takes-over long innovative (crosses, P<sub>innovation</sub> = 0.0002, bottom panel) strategy adoption rules, see <a href="#s4">Methods</a> and the ESM1. For each strategy adoption rules and <em>T</em> temptation values 100 random runs of 5,000 time steps were executed. The figure shows that long-term, ‘learning-type’ elements of strategy update rules help cooperation in Prisoner's Dilemma games played on various networks. A low level of randomness (also called as ‘innovation’ in this paper) brings the level of cooperation closer in different network topologies.</p>
<span>doi:10.1371/journal.pone.0001917.g002</span></div>

<h4>Long-term strategy adoption rules improve but do not stabilize cooperation in different networks</h4>
<a id="article1.body1.sec2.sec3.p1" name="article1.body1.sec2.sec3.p1"></a><p>Next we wanted to see, if other long-term strategies besides Q-learning can also promote cooperation between agents. In Q-learning agents consider a long-term experience learned in all the past rounds of the play. Therefore, we modified the best-takes-over strategy adoption rule allowing the agents to use accumulative rewards of their neighbors in all past rounds instead of the reward received just in the last round. In agreement with our expectations, both on small-world and scale-free networks this long-term strategy adoption rule outperformed its short-term version allowing a larger number of agents to cooperate – especially at high temptation values. Importantly, the differences between cooperation levels observed in small-world and scale-free networks were even greater, when we applied the long-term strategy adoption rule compared to its short-term version (middle panel of <a href="#pone-0001917-g002">Figure 2</a>). We have received very similar results in all combinations of (a) other short- and long-term strategy adoption rule pairs; (b) a large number of other network topologies; (c) other games, such as the extended Prisoner's Dilemma or Hawk-Dove games. Long-term learning strategy adoption rules also promoted cooperation (albeit at lower efficiency than in case of complex network structures), when we used networks re-randomized after each play, or randomly picked agents (ESM1 Figures S1.3–S1.6). As a summary, we conclude that long-term strategy adoption rules (‘learning’ instead of simple imitation) allow a larger cooperation, but do not stabilize the cooperation-fluctuations inflicted by the different topologies of the underlying networks, which leaves the remarkable topological stability of the Q-learning strategy adoption rule still unexplained.</p>


<h4>Low level of randomness of the strategy adoption rules is needed to stabilize cooperation level in different network topologies</h4>
<a id="article1.body1.sec2.sec4.p1" name="article1.body1.sec2.sec4.p1"></a><p>Next we tested, if the innovative elements of the Q-learning strategy adoption rule may contribute to the stability of cooperation in various network topologies. For this, we constructed an ‘innovative’ version of the long-term version of the best-takes-over, ‘non-innovative’ strategy adoption rule by adding a low level of randomness instructing agents to follow the opposite of the selected neighbor's strategy with a pre-set <em>P<sub>innovation</sub></em> probability (see <a href="#s4">Methods</a>). Cooperation levels achieved by the innovative long-term best-takes-over strategy adoption rule are shown on the bottom panel of <a href="#pone-0001917-g002">Figure 2</a>. At temptation values smaller than T = 3.8 the innovative long-term version of the best-takes over strategy adoption rule outperformed Q-learning, which resulted in a larger proportion of cooperating agents (cf. top and bottom panels of <a href="#pone-0001917-g002">Figure 2</a>). However, at high temptation values Q-learning proved to be more efficient in maintaining cooperation. Most importantly, cooperation levels in small-world and scale-free networks were much closer to each other, when using the long-term innovative strategy-adoption rule, than either the ‘only long-term’, or short-term versions of the same strategy adoption rule (<a href="#pone-0001917-g002">Figure 2</a>). At high temptation values cooperation levels of long-term innovative strategy adoption rules on small-world and scale-free networks were converging to each other and even to the cooperation level observed, when using the Q-learning strategy adoption rule. We have received very similar results in combinations of (a) other innovative short- and long-term strategy adoption rules; (b) a large number of other network topologies; (c) other games, such as the extended Prisoner's Dilemma or Hawk-Dove games (ESM1 Figures S1.7 and S1.8). According to the expectations <a href="#pone.0001917-Vukov1">[8]</a>, the stabilizing role of the randomness in the strategy adoption rules depended on the actual value of the pre-set <em>P<sub>innovation</sub></em> probability, and showed an optimum at intermediary <em>P<sub>innovation</sub></em> levels, where the actual value of optimal <em>P<sub>innovation</sub></em> depended on the strategy adoption rule and network topology. The effect of changes in <em>P<sub>innovation</sub></em> was much more pronounced in case of scale-free networks than at small-world networks, which is a rather plausible outcome, since the larger irregularity of scale-free networks makes the re-introduction of extinct strategies a lot more crucial (ESM1 Figure S1.8).</p>
<a id="article1.body1.sec2.sec4.p2" name="article1.body1.sec2.sec4.p2"></a><p>We have shown so far that long-term, learning strategy adoption rules help the development of cooperation, while ‘innovative’ strategy adoption rules make the cooperation level more independent from the actual network topology. <a href="#pone-0001917-g003">Figure 3</a> illustrates how the cooperative network topologies were expanded, when we used long-term learning and ‘innovative’ versions of the best-takes-over strategy adoption rule as well as Q-learning at a high level of temptation, which made cooperation especially difficult. The application of the best-takes-over strategy adoption rule resulted in non-zero cooperation only sporadically. Cooperation levels using the long-term best-takes-over strategy adoption rule varied greatly, and still had several network configurations with zero cooperation. On the contrary, the two ‘innovative’ long-term learning strategy adoption rules had a much higher than zero cooperation in almost all networks tested, and the cooperation level remained fairly stable using a great variety of network topologies. This was especially true for Q-learning, which gave a stable level of cooperation even at regular networks (<a href="#pone-0001917-g003">Figure 3</a>), which result in a high instability of cooperation (see ESM1 Table S1.1). We have received very similar results in extended Prisoner's Dilemma and Hawk-Dove games (ESM1 Figures S1.9 and S1.10).</p>
<div class="figure" id="pone-0001917-g003"><div class="img"><a name="pone-0001917-g003" title="Click for larger image " href="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001917.g003&amp;representation=PNG_M" data-doi="info:doi/10.1371/journal.pone.0001917" data-uri="info:doi/10.1371/journal.pone.0001917.g003"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001917.g003&amp;representation=PNG_I" alt="thumbnail" class="thumbnail"></a></div><div class="figure-inline-download">
            Download:
            <ul><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001917.g003/powerpoint">
                    PPT
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001917.g003/powerpoint">
                  PowerPoint slide
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001917.g003/largerimage">
                    PNG
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001917.g003/largerimage">
                  larger image
                  (<span id="info:doi/10.1371/journal.pone.0001917.g003.PNG_L"></span>)
                </a></li><li><div class="icon"><a href="/article/info:doi/10.1371/journal.pone.0001917.g003/originalimage">
                    TIFF
                  </a></div><a href="/article/info:doi/10.1371/journal.pone.0001917.g003/originalimage">
                  original image
                  (<span id="info:doi/10.1371/journal.pone.0001917.g003.TIF"></span>)
                </a></li></ul></div><p><strong>Figure 3.  <span>Long-term learning and innovative elements of strategy adoption rules, when applied together allow cooperation in a large number of model networks.</span></strong></p><a id="article1.body1.sec2.sec4.fig1.caption1.p1" name="article1.body1.sec2.sec4.fig1.caption1.p1"></a><p>(Top middle panel) The small-world (spheres) and scale-free (cones) model networks were built as described in the legends of <a href="#pone-0001917-g001">Figures 1</a> and <a href="#pone-0001917-g002">2</a>. The rewiring probability, <em>p</em> of the links of the original regular lattices giving small-world networks was increased from 0 to 1 with 0.05 increments, the number of edges linking each new node to former nodes in scale-free networks was varied from 1 to 7, and the means of shortest path-lengths and clustering coefficients were calculated for each network. Cubes and cylinders denote regular (p = 0) and random (p = 1.0) extremes of the small-world networks, respectively. For the description of the canonical repeated Prisoner's Dilemma game, as well as the best-takes-over (green symbols); long-term learning best-takes-over (blue symbols); long-term learning innovative best-takes-over (magenta symbols) and Q-learning (red symbols) strategy adoption rules used, see <a href="#s4">Methods</a> and the ESM1. For each network 100 random runs of 5,000 time steps were executed at a fixed <em>T</em> value of 3.5. (Left and right panels) 2D side views of the 3D top middle panel showing the proportion of cooperators as the function of the mean length of shortest paths or the mean clustering coefficient, respectively. (Bottom middle panel) Color-coded illustration of the various network topologies used on the top middle panel. Here the same simulations are shown as on the top middle panel with a different color-code emphasizing the different network topologies. The various networks are represented by the following colors: regular networks – blue; small-world networks – green; scale-free networks – yellow; random networks – red (from the angle of the figure the random networks are behind some of the small-world networks and, therefore are highlighted with a red arrow to make there identification easier). The top middle panel and its side views show that the best-takes-over strategy adoption rule (green symbols) at this high temptation level results in a zero (or close-to-zero) cooperation. As opposed to this, the long-term best-takes-over strategy adoption rule (blue symbols) raise the level of cooperation significantly above zero, but the individual values vary greatly at the different network topologies. When the long-term strategy adoption rule is combined with a low level of randomness (magenta symbols) the cooperation level stays in most cases uniformly and its variation becomes high greatly diminished. Q-learning stabilizes cooperation further even at regular networks, which otherwise give an extremely variable outcome.</p>
<span>doi:10.1371/journal.pone.0001917.g003</span></div>
</div>

<div id="section3" class="section"><a id="s3" name="s3" toc="s3" title="Discussion"></a><h3>Discussion</h3><a id="article1.body1.sec3.p1" name="article1.body1.sec3.p1"></a><p>As a summary, our simulations showed that long-term learning strategy adoption rules promote cooperation, while innovative elements make the appearance of cooperation less dependent from the actual network topology in two different games using a large number of network topologies in model networks. We must emphasize that the term ‘learning’ is used in our paper in the sense of the collection and use of information enriching and diversifying game strategy and behavior, and not in the restricted sense of imitation, or directed information-flow from a dominant source (the teacher) pauperizing the diversity of game strategies. The help of learning in promoting cooperation is already implicitly involved in the folk theorem, which opens the theoretical possibility for the emergence of cooperation at infinitely repeated games <a href="#pone.0001917-Szab1">[3]</a>, <a href="#pone.0001917-Aumann1">[20]</a>. Learning, communication, negotiation, reputation-building mechanisms have all been shown to promote cooperation in various simulations as well as in games with groups of a variety of living organisms, including animals and humans (ESM1 Table S1.2). With the current work we have extended these findings showing that agents can markedly improve their cooperation, when they are allowed to consider long-term experiences either of their own (Q-learning) or their neighbors (other long-term strategies used), and this ‘shadow of the past’ <a href="#pone.0001917-Macy1">[21]</a> acts similarly at a great variety of network topologies.</p>
<a id="article1.body1.sec3.p2" name="article1.body1.sec3.p2"></a><p>We use the term ‘innovation’ in the sense of irregularities in the selection of adoption rules of game strategy. Therefore, ‘innovation’ may be caused by errors, mutations, mistakes, noise, randomness and temperature besides the <em>bona fide</em> innovation of conscious, intelligent agents. Our term, ‘innovation’ allows the change of the strategy adoption rules, therefore allows (increases) the evolvability <a href="#pone.0001917-Kirschner1">[22]</a> of our model system. Innovative strategies help to avoid ‘herding’, when agents start to use a uniform strategy and behavior forming synchronous clusters (ESM1 Figures S1.11, S1.12 and data not shown). Innovation increases game diversity and complexity, which, similarly to the stabilizing effect of weak links in a large variety of static networks, may significantly stabilize network dynamics (probably by helping the convergence of possible outcomes; <a href="#pone.0001917-Csermely1">[23]</a>). Irregularities in network topology, noise, stochastic resonance, stochastic focusing and innovative strategies were shown to promote cooperation in various simulations as well as in games of primates and humans (ESM1 Table S1.3). However, the innovation-driven relative stabilization of cooperation in various network topologies is a novel finding reported here.</p>
<a id="article1.body1.sec3.p3" name="article1.body1.sec3.p3"></a><p>Cooperation helps the development of complex network structures <a href="#pone.0001917-Michod1">[4]</a>, <a href="#pone.0001917-Santos1">[5]</a>, <a href="#pone.0001917-Skyrms1">[24]</a>. Network dynamics and evolution lead to a large variety of link re-arrangements <a href="#pone.0001917-Durrett1">[25]</a>, <a href="#pone.0001917-Leskovec1">[26]</a>. Network evolution is full of stochastic ‘errors’, and often results in the development of a higher average degree <a href="#pone.0001917-Durrett1">[25]</a>, which makes cooperation more difficult <a href="#pone.0001917-Ohtsuki1">[15]</a>, <a href="#pone.0001917-Tang1">[16]</a>. The highly similar cooperation levels of scale-free networks with different average degrees and of many other network topologies of model networks (<a href="#pone-0001917-g003">Figure 3</a>, ESM1 Figures S1.9 and S1.10) show that innovative long-term learning strategy adoption rules may provide a buffering safety-net to avoid the deleterious consequences of possible overshoots and errors in network development on cooperation. Our simulations showed (<a href="#pone-0001917-g002">Figure 2</a>, ESM1 Figures S1.2 and S1.6) that the help of innovative long-term learning is especially pronounced at conditions, where the relative cost of cooperation is the highest making cooperation most sensitive to the anomalies of network evolution <a href="#pone.0001917-Ohtsuki1">[15]</a>. This extreme situation is more easily reached, when the whole system becomes resource-poor, which makes all relative costs higher. Resource-poor networks develop a set of topological phase transitions in the direction of random → scale-free → star → fully connected subgraph topologies <a href="#pone.0001917-Derenyi1">[27]</a>. This further substantiates the importance of our findings that long-term, innovative learning allows a larger ‘cooperation-compatible’ window of these topologies, thus helps to avoid the decomposition of network structure in case of decreasing system resources due to e.g. an environmental stress. Further work is needed to show the validity of our findings in real-world networks as well as in combination with network evolution.</p>
<a id="article1.body1.sec3.p4" name="article1.body1.sec3.p4"></a><p>Our current work can be extended in a number of ways. The complexity of the game-sets and network topologies offers a great opportunity for a detailed equilibrium-analysis, similarly to that described by Goyal and Vega-Redondo <a href="#pone.0001917-Goyal1">[28]</a>. The cited study <a href="#pone.0001917-Goyal1">[28]</a> allows a choice of the interacting partners (an option denied in our model), which leads to another rich field of possible extensions, where the network topology is changing (evolving) during the games such as in the paper of Holme and Ghoshal <a href="#pone.0001917-Holme1">[29]</a>. Similarly, a detailed analysis of link rearrangement-induced perturbations, avalanches like in the paper of Ebel and Bornholdt <a href="#pone.0001917-Ebel1">[30]</a> as well as exploration of a number of other topological re-arrangements would also significantly extend the current results. Such topology-changes may include</p>


<ul class="bulletlist">

<li>hub-rewiring including the formation and resolution of ‘rich-clubs’, where hub-hub contacts are preferentially formed <a href="#pone.0001917-Rong1">[31]</a>, <a href="#pone.0001917-Fu1">[32]</a>;</li>

<li>emergence of modularity beyond to our data in ESM1 Figure S1.4;</li>

<li>appearance and disappearance of bridge-elements between modules;</li>

<li>changes of modular overlaps and module hierarchy, etc.</li>

</ul><a id="article1.body1.sec3.p5" name="article1.body1.sec3.p5"></a><p>Tan <a href="#pone.0001917-Tan1">[33]</a> showed that cooperation helps faster learning. This, when combined with our current findings may lead to a self-amplifying cycle between cooperation and learning, where cooperation-induced learning promotes cooperation. Emerging cooperation alleviates a major obstacle to reach a higher level of network hierarchy and complexity <a href="#pone.0001917-Michod1">[4]</a>. In social networks learning establishes trust, empathy, reputation and embeddedness <a href="#pone.0001917-Granovetter1">[34]</a>–<a href="#pone.0001917-Traulsen1">[37]</a>, and the benefits of learning by multiple generations are exemplified by the development of traditions, norms and laws. These give the members of the society further reasons for withholding their individual selfishness, thereby reaching a higher network complexity and stability. We believe that learning and innovation (in forms of repeated, interaction-driven, or random network remodeling steps, respectively or using the Baldwin-effect, see ESM1 Discussion) help the evolution of cooperation between agents other than human beings or animals, including proteins, cells or ecosystems <a href="#pone.0001917-Csermely1">[23]</a>, <a href="#pone.0001917-Kovacs1">[38]</a>, and were crucial in the development of multi-level, self-organizing, complex systems.</p>
</div>

<div id="section4" class="section"><a id="s4" name="s4" toc="s4" title="Methods"></a><h3>Methods</h3>
<h4></h4>
<h5>Games.</h5><a id="article1.body1.sec4.sec1.sec1.p1" name="article1.body1.sec4.sec1.sec1.p1"></a><p>In both the Hawk-Dove and the Prisoner's Dilemma games, each agent had two choices: to cooperate or to defect. In the repeated, multi-agent Hawk-Dove game the benefit of defectors is higher than that of cooperators, when they are at low abundance, but falls below cooperator benefit, when defectors reach a critical abundance <a href="#pone.0001917-Santos2">[12]</a>, <a href="#pone.0001917-Tomassini1">[13]</a>. On the contrary, in the Prisoner's Dilemma game defection always has a fitness advantage over cooperation. The canonical parameter-set of the Prisoner's Dilemma game (<em>R</em> = 3, <em>P</em> = 1, <em>S</em> = 0, the <em>T</em>, temptation value varies between 3 to 6; 3 is not included; where R is the reward for mutual cooperation, P is the punishment for mutual defection, S and T are the payoffs for the cooperator and defector, respectively, when meeting each other) restricts cooperation more, than the parameter set of the extended (also called as ‘weak’) Prisoner's Dilemma game (<em>R</em> = 1, <em>P</em> = 0, <em>S</em> = 0 with <em>T</em> values ranging from 1 to 2; <a href="#pone.0001917-Cohen1">[11]</a>–<a href="#pone.0001917-Tomassini1">[13]</a>). (When we tried the parameter set of <em>R</em> = 1, <em>P</em> = 0.2, <em>S</em> = 0.1 with T values ranging from 1.0 to 2.0, we have received very similar results; data not shown.)</p>
<a id="article1.body1.sec4.sec1.sec1.p2" name="article1.body1.sec4.sec1.sec1.p2"></a><p>In the Hawk-Dove games (or in the conceptually identical Snowdrift and Chicken games <a href="#pone.0001917-Tomassini1">[13]</a>, <a href="#pone.0001917-Tomassini2">[39]</a>, <a href="#pone.0001917-Luthi1">[40]</a>) each agent had two choices: to defect (to be a hawk) or to cooperate (to be a dove). When a hawk met a dove, the hawk gained <em>G</em> benefits, whereas the payoff for the dove was zero. Two hawks suffered a (<em>G</em>−<em>C</em>)/2 cost each upon encounter, where <em>C</em>&gt;<em>G</em> was the cost of their fight. When two doves met, the benefit for each dove was <em>G</em>/2. If not otherwise stated, the cost of injury (C, when a hawk met a hawk) was set to 1. The value of G varied from 0 to 1 with the increments of 0.1. If we want to compare the above, usually applied nomenclature of the Hawk-Dove games with that of the Prisoner's Dilemma games, R = G/2, P = (G−C)/2, S = 0 and T = G.</p>
<a id="article1.body1.sec4.sec1.sec1.p3" name="article1.body1.sec4.sec1.sec1.p3"></a><p>In Hawk-Dove games T&gt;R&gt;S&gt;P, in the extended (also called ‘weak’) Prisoner's Dilemma game T≥R&gt;P≥S, while in the canonical Prisoner's Dilemma game T&gt;R&gt;P&gt;S. This makes the following order of games from less to more stringent general conditions allowing less and less cooperation: Hawk-Dove game&gt;extended Prisoner's Dilemma game&gt;canonical Prisoner's Dilemma game. Due to this general order, we showed the results of the canonical Prisoner's Dilemma game in the main text, and inserted the results of the two other games to the <a href="#pone.0001917.s001">Electronic Supplementary Material S1 (ESMS1)</a>.</p>
<a id="article1.body1.sec4.sec1.sec1.p4" name="article1.body1.sec4.sec1.sec1.p4"></a><p>In our simulations each node in the network was an agent, and the agent could interact only with its direct neighbors. Agents remained at the same position throughout all rounds of the repeated games, and they were neither exchanged, nor allowed to migrate. If not otherwise stated, games started with an equal number of randomly mixed defectors and cooperators (hawks and doves in the Hawk-Dove game), and were run for 5,000 rounds (time steps). The payoff for each agent in each round of play was the average of the payoffs it received by playing with all its neighbors in the current round. In our long-term learning strategy adoption rules introduced below, the accumulative payoff means the accumulation of the average payoffs an agent gets in each round of play. Average payoff smoothes out possible differences in the degrees of agents, and in several aspects may simulate real-world situations better than non-averaged payoff, since in real-world situations agents usually have to observe a cost of maintaining a contact with their neighbors <a href="#pone.0001917-Tomassini2">[39]</a>–<a href="#pone.0001917-Masuda1">[41]</a>. Moreover, average payoff helps the convergence of cooperation levels as the rounds of the game (time steps) proceed, what we indeed observed in most of the cases (with a few exceptions noted in the text), and helps to avoid ‘late-conversions’ occurring mostly in scale-free networks after 10,000 or more time steps using non-averaged payoffs. With this method it was enough to calculate the proportion of cooperators as the average ratio of cooperators of the last 10 rounds of the game (if not otherwise stated) for 100 independent runs.</p>

<h5>Strategy adoption rules.</h5><a id="article1.body1.sec4.sec1.sec2.p1" name="article1.body1.sec4.sec1.sec2.p1"></a><p>In Prisoner's Dilemma and Hawk-Dove games our agents followed three imitation-type, short-term strategy adoption rules, the ‘pair-wise comparison dynamics’ (also called as ‘replicator dynamics’), ‘proportional updating’ and ‘best-takes-over’ (also called as ‘imitation of the best’) strategy adoption rules <a href="#pone.0001917-Tomassini1">[13]</a>. We call these rules strategy adoption rules and not evolution rules to avoid the mis-interpretation of our games as cellular automata-type games, where agents are replaced time-to-time. In our games no replacement took place, therefore these games were not evolutionary games in this strict sense. All strategy adoption rules had synchronous update, meaning that in each round of play the update took place after each agent had played with all their neighbors. To avoid the expansion of parameters with the differential placements of various agents in complex network structures all agents used the same strategy adoption rule in the agent-network. In the three strategy adoption rules we applied initially (‘best-takes-over’, ‘pair-wise comparison dynamics’ and ‘proportional updating’) all agents were myopic, and made their decisions based on the average payoffs gained in the previous round.</p>

<h5>Pair-wise comparison dynamics strategy adoption rule.</h5><a id="article1.body1.sec4.sec1.sec3.p1" name="article1.body1.sec4.sec1.sec3.p1"></a><p>In the ‘pair-wise comparison dynamics’ strategy adoption rule <a href="#pone.0001917-Tomassini1">[13]</a> for any agent <em>i</em>, a neighboring agent <em>j</em> was selected randomly, and agent <em>i</em> used the strategy of agent <em>j</em> with a probability of <em>p<sub>i</sub></em>. In our experiments the probability was determined as<a name="" id=""></a><span class="equation"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001917.e001&amp;representation=PNG" class="inline-graphic"></span><br>where <em>d</em><sub>max</sub> = (<em>G</em>+<em>C</em>)/2 (for Hawk-Dove games) or <em>d</em><sub>max</sub> = max(<em>T</em>, <em>R</em>) (for Prisoner's Dilemma games), which was the largest gap of gain between two agents in one round of play. <em>G<sub>i</sub></em> and <em>G<sub>j</sub></em> were the average payoffs received by agent <em>i</em> and <em>j</em> respectively in the current round of play.</p>

<h5>Proportional updating strategy adoption rule.</h5><a id="article1.body1.sec4.sec1.sec4.p1" name="article1.body1.sec4.sec1.sec4.p1"></a><p>For the ‘proportional updating’ strategy adoption rule <a href="#pone.0001917-Tomassini1">[13]</a> agent <em>i</em> and all its neighbors competed for the strategy of agent <em>i</em> with the probability <em>p<sub>i</sub></em>, which was determined as <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001917.e002&amp;representation=PNG" class="inline-graphic"></span> where <em>N</em>(<em>i</em>) was the neighborhood of agent <em>i</em> and <em>G<sub>i</sub></em> was the average payoff received by agent <em>i</em> in the current round of play. Since <em>p</em> is a probability, <em>C</em> was added to each <em>G<sub>i</sub></em> to avoid negative values. For Prisoner's Dilemma games, because the reward for an agent is always greater than or equal to zero, there was no need to increase the value of <em>G<sub>i</sub></em>.</p>

<h5>Best-takes-over strategy adoption rule.</h5><a id="article1.body1.sec4.sec1.sec5.p1" name="article1.body1.sec4.sec1.sec5.p1"></a><p>In the ‘best-takes-over’ strategy adoption rule (also called as imitation of the best strategy adoption rule, <a href="#pone.0001917-Tomassini1">[13]</a>) agent <em>i</em> adopted the strategy of that agent selected from <em>i</em> and its neighbors, who had the highest average payoff in the last round of play.</p>

<h5>Q-learning strategy adoption rule.</h5><a id="article1.body1.sec4.sec1.sec6.p1" name="article1.body1.sec4.sec1.sec6.p1"></a><p>As a reinforcement learning <a href="#pone.0001917-Sutton1">[19]</a> strategy adoption rule, we used Q-learning <a href="#pone.0001917-Watkins1">[18]</a>, where agents learned an optimal strategy maximizing their total discounted expected reward in the repeated game. In Q-learning we assumed that the environment constituted a discrete Markov process with finite states. An agent chose action <em>a<sub>t</sub></em> from a finite collection of actions at time step, <em>t</em>. The state of the environment changed from state <em>s<sub>t</sub></em> to <em>s<sub>t</sub></em><sub>+1</sub> after the action of the agent, and the agent received the reward <em>r<sub>t</sub></em> at the same time. The probability of state transition from <em>s<sub>t</sub></em> to <em>s<sub>t</sub></em><sub>+1</sub> when the agent chose action <em>a<sub>t</sub></em> was<a name="" id=""></a><span class="equation"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001917.e003&amp;representation=PNG" class="inline-graphic"></span><br></p>
<a id="article1.body1.sec4.sec1.sec6.p2" name="article1.body1.sec4.sec1.sec6.p2"></a><p>The task of the agent was to learn the optimal strategy to maximize the total discounted expected reward. The discounted reward meant that the rewards received by the agent in the future were worth less than that received in the current round. Under a policy π denoting how the agent selected the action at its actual state and reward, the value of state, <em>s<sub>t</sub></em> was<a name="" id=""></a><span class="equation"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001917.e004&amp;representation=PNG" class="inline-graphic"></span><br>where <em>R</em>(π(<em>s<sub>t</sub></em>)) is the expected reward of state <em>s<sub>t</sub></em> under policy π and γ(0&lt;γ&lt;1) is the discount factor.</p>
<a id="article1.body1.sec4.sec1.sec6.p3" name="article1.body1.sec4.sec1.sec6.p3"></a><p>The theory of Dynamic Programming <a href="#pone.0001917-Sutton1">[19]</a> guarantees that there is at least one optimal stationary policy, π<sup>*</sup>, which can be written as<a name="" id=""></a><span class="equation"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001917.e005&amp;representation=PNG" class="inline-graphic"></span><br></p>
<a id="article1.body1.sec4.sec1.sec6.p4" name="article1.body1.sec4.sec1.sec6.p4"></a><p>The task of Q-learning was to learn the optimal policy, π, when the initial conditions of both the reward function and transition probabilities were unknown. If the environment model (reward model and transition probabilities of states) is known, then the above problem can be solved by using Dynamic Programming. Watkins and Dayan <a href="#pone.0001917-Watkins1">[18]</a> introduced Q-learning as incremental Dynamic Programming. The idea of Q-learning is to optimize a Q-function, which can be calculated iteratively without the estimate of environment model. For this having a policy, π, we defined the Q-value as:<a name="" id=""></a><span class="equation"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001917.e006&amp;representation=PNG" class="inline-graphic"></span><br>Q-learning consisted of a sequence of distinct stages or episodes. The Q value of state-action pair (<em>s<sub>t</sub></em>, <em>a<sub>t</sub></em>) can be learned through the following iterative method:<a name="" id=""></a><span class="equation"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001917.e007&amp;representation=PNG" class="inline-graphic"></span><br>where <span class="inline-formula"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001917.e008&amp;representation=PNG" class="inline-graphic"></span> and α<em><sub>t</sub></em> controls the learning and convergence speed of Q-learning.</p>
<a id="article1.body1.sec4.sec1.sec6.p5" name="article1.body1.sec4.sec1.sec6.p5"></a><p>In repeated multi-agent games, the state of each agent was affected by the states of its direct neighbors. Those neighbors constituted the environment of the agent. The reward of the agent <em>i</em> after taking action <em>a<sub>t</sub></em>(<em>i</em>) was defined as:<a name="" id=""></a><span class="equation"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001917.e009&amp;representation=PNG" class="inline-graphic"></span><br>where <em>M</em> was the payoff matrix, <em>S<sub>t</sub></em>(<em>i</em>) was a column vector indicating the state of agent <em>i</em> at round <em>t</em>, <em>k<sub>i</sub></em> was the number of neighbors of agent <em>i</em> and <em>N</em>(<em>i</em>) was the set contains all the direct neighbors of agent <em>i</em>. The values of elements of <em>S<sub>t</sub></em>(<em>i</em>) were 0 or 1 and 1 indicated that agent <em>i</em> was in the corresponding state. In such a repeated multi-agent game, Q-learning meant that each agent tried to optimize its total discounted expected reward in the repeated game. The optimal strategy was approximated by an iterative annealing process. For this for each agent, the selection probability (Boltzmann-probability) of action <em>a<sub>i</sub></em> at time step <em>t</em> was defined as<a name="" id=""></a><span class="equation"><img src="/article/fetchObject.action?uri=info:doi/10.1371/journal.pone.0001917.e010&amp;representation=PNG" class="inline-graphic"></span><br>where <em>T</em> was the annealing temperature. In our experiments we selected the discount factor, γ<em><sub>t</sub></em> = 0.5, since in the initial experiments we found that this value is helpful to achieve high levels of cooperation. The initial annealing temperature was set to 100 in Hawk-Dove and extended Prisoner's Dilemma games, while it was raised to 10,000 in canonical Prisoner's Dilemma games to extend the annealing process <a href="#pone.0001917-Sandholm1">[42]</a>. In all cases the annealing temperature was decreased gradually by being divided by <em>t</em> in each round of the game till it reached a low bound of 0.001. In order to control the convergence speed of Q-learning, α = 1/(1+<em>TimesVisited</em>(<em>s</em>, <em>a</em>)) where <em>TimesVisited</em>(<em>s</em>, <em>a</em>) was the number of times that the state-action pair (<em>s</em>, <em>a</em>) had been visited at time step <em>t</em>. In this way α decreased gradually with the time.</p>

<h5>Long-term learning and innovative strategy adoption rules.</h5><a id="article1.body1.sec4.sec1.sec7.p1" name="article1.body1.sec4.sec1.sec7.p1"></a><p>Long-term learning strategy adoption rules were generated by considering the accumulative average payoffs instead of instantaneous average rewards in the update progress during each round of play for all strategy adoption rules used. In both short term and long-term innovative strategy adoption rules, agent <em>i</em> used the opposite strategy of the selected neighbor (for proportional updating and best-takes-over strategy adoption rules, the neighborhood included agent <em>i</em> itself) in the last round of play with probability of <em>P<sub>innovation</sub></em>, which was 0.0001 in case of Hawk-Dove and extended Prisoner's Dilemma games, while 0.0002 in case of canonical Prisoner's Dilemma games, if not otherwise stated (like in the legend of ESM1 Figure S1.8). In innovative strategy adoption rules agent <em>i</em> adopted the strategy of the selected neighbor with a probability of 1−<em>P<sub>innovation</sub></em>.</p>

<h5>Network construction.</h5><a id="article1.body1.sec4.sec1.sec8.p1" name="article1.body1.sec4.sec1.sec8.p1"></a><p>In our work we used a set of widely adopted model networks to simulate the complexity of real-world situations. Generation of the Watts-Strogatz-type small-world model network <a href="#pone.0001917-Watts1">[17]</a> was modified according to Tomassini <em>et al.</em> <a href="#pone.0001917-Tomassini1">[13]</a> to avoid the heterogeneity in node degrees, which arose during the Watts-Strogatz-type rewiring process changing the regular lattice to a small-world network. Such heterogeneity was shown to have a rather big influence on the level of cooperation <a href="#pone.0001917-Tomassini1">[13]</a>, <a href="#pone.0001917-Szolnoki1">[43]</a>. At the generation of the Barabasi-Albert-type scale-free network <a href="#pone.0001917-Barabasi1">[44]</a>, we started from an initial fully connected graph of ‘m’ nodes (where ‘m’ ranged from 1 to 7), and added the new nodes with ‘m’ novel links as specified at the individual Figure legends. In the modular networks described by Girvan and Newman <a href="#pone.0001917-Girvan1">[45]</a> each network had a scale-free degree distribution, contained 128 nodes, and was divided into 4 communities. The average degree was 16. Modularity (community structure) was gradually decreased at ‘levels’ 1, 5, 10 and 16, where ‘level 1’ meant that for each node in the network, the expected number of links between a node and the nodes which were in other communities was 1 (e.g. low compared to the average degree of 16). With increasing ‘level’ the community structure gradually decreased.</p>

<h5>Network visualization.</h5><a id="article1.body1.sec4.sec1.sec9.p1" name="article1.body1.sec4.sec1.sec9.p1"></a><p>At the visualization the coordinates of the small-world networks with a rewiring probability of p = 0.01 were used for the p = 0.04 networks to avoid the individual variations of the Pajek-figures <a href="#pone.0001917-Batagelj1">[46]</a> and to help direct comparison. With 15×15 agents the final representations of cooperators showed a moderate variability. This was almost negligible, when 50×50 agents were used (data not shown). However, 15×15 agents gave a better visual image than the crowded, bulky 50×50 version. Therefore, we opted to include this variant to <a href="#pone-0001917-g001">Figure 1</a>. We have selected those figures from the results of 15×15 agent games, which best represented the 50×50 versions.</p>


</div>

<div id="section5" class="section"><a id="s5" name="s5" toc="s5" title="Supporting Information"></a><h3>Supporting Information</h3><div class="figshare_widget" doi="10.1371/journal.pone.0001917"></div><a name="pone.0001917.s001" id="pone.0001917.s001"></a><p class="siTitle"><strong><a href="/article/fetchSingleRepresentation.action?uri=info:doi/10.1371/journal.pone.0001917.s001">Electronic Supplementary Material S1. </a></strong></p><a id="article1.body1.sec5.supplementary-material1.caption1.p1" name="article1.body1.sec5.supplementary-material1.caption1.p1"></a><p class="preSiDOI">This supporting information extends the major findings of the paper to two different games (the extended Prisoner's Dilemma Game and the Hawk-Dove/Snowdrift game) and a wide parameter set, and gives additional methods, discussion and references.</p>
<p class="siDoi">doi:10.1371/journal.pone.0001917.s001</p><a id="article1.body1.sec5.supplementary-material1.caption1.p2" name="article1.body1.sec5.supplementary-material1.caption1.p2"></a><p class="postSiDOI">(0.74 MB PDF)</p>
</div>





<div><a id="ack" name="ack" toc="ack" title="Acknowledgments"></a><h3>Acknowledgments</h3>
<a id="article1.back1.ack1.p1" name="article1.back1.ack1.p1"></a><p>The useful comments of our Editor, Enrico Scalas, referees, including Michael König and Bence Toth, as well as Robert Axelrod, János Kertész, István A. Kovács, Robin Palotai, György Szabó, Attila Szolnoki, Tamás Vicsek and members of the LINK-Group (<a href="http://www.linkgroup.hu">www.linkgroup.hu</a>) are gratefully acknowledged.</p>
</div><div class="contributions"><a id="authcontrib" name="authcontrib" toc="authcontrib" title="Author Contributions"></a><h3>Author Contributions</h3><p>Conceived and designed the experiments: PC SW CZ. Performed the experiments: MS SW. Analyzed the data: PC MS SW. Wrote the paper: PC SW.</p></div><div><a id="references" name="references" toc="references" title="References"></a><h3>References</h3><ol class="references"><li><span class="label">1.
              </span><a name="pone.0001917-Axelrod1" id="pone.0001917-Axelrod1"></a>Axelrod R, Hamilton WD (1981) The evolution of cooperation. Science  211: 1390–1396.  <ul class="find" data-citedArticleID="1085154" data-doi="10.1126/science.7466396"><li><a href="http://dx.doi.org/10.1126/science.7466396" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+evolution+of+cooperation." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+evolution+of+cooperation.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">2.
              </span><a name="pone.0001917-Nowak1" id="pone.0001917-Nowak1"></a>Nowak MA (2006) Five rules for the evolution of cooperation. Science  314: 1560–1563.  <ul class="find" data-citedArticleID="1085202" data-doi="10.1126/science.1133755"><li><a href="http://dx.doi.org/10.1126/science.1133755" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Five+rules+for+the+evolution+of+cooperation." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Five+rules+for+the+evolution+of+cooperation.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">3.
              </span><a name="pone.0001917-Szab1" id="pone.0001917-Szab1"></a>Szabó G, Fáth G (2006) Evolutionary games on graphs. Physics Reports  446: 97–216.  <ul class="find" data-citedArticleID="1085224" data-doi="10.1016/j.physrep.2007.04.004"><li><a href="http://dx.doi.org/10.1016/j.physrep.2007.04.004" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Evolutionary+games+on+graphs." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Evolutionary+games+on+graphs.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">4.
              </span><a name="pone.0001917-Michod1" id="pone.0001917-Michod1"></a>Michod RE (2006) The group covariance effect and fitness trade-offs during evolutionary transitions in individuality. Proc. Natl Acad. Sci. USA  103: 9113–9117.  <ul class="find" data-citedArticleID="1085200" data-doi="10.1073/pnas.0601080103"><li><a href="http://dx.doi.org/10.1073/pnas.0601080103" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+group+covariance+effect+and+fitness+trade-offs+during+evolutionary+transitions+in+individuality." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+group+covariance+effect+and+fitness+trade-offs+during+evolutionary+transitions+in+individuality.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">5.
              </span><a name="pone.0001917-Santos1" id="pone.0001917-Santos1"></a>Santos FC, Pacheco JM, Lenaerts T (2006) Cooperation prevails when individuals adjust their social ties. PLOS Comput. Biol.  2: e140.  <ul class="find" data-citedArticleID="1085216" data-doi="10.1371/journal.pcbi.0020140"><li><a href="http://dx.doi.org/10.1371/journal.pcbi.0020140" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Cooperation+prevails+when+individuals+adjust+their+social+ties." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Cooperation+prevails+when+individuals+adjust+their+social+ties.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">6.
              </span><a name="pone.0001917-McNamara1" id="pone.0001917-McNamara1"></a>McNamara JM, Barta Z, Houston AI (2004) Variation in behaviour promotes cooperation in the Prisoner's Dilemma game. Nature  428: 745–748.  <ul class="find" data-citedArticleID="1085198" data-doi="10.1038/nature02432"><li><a href="http://dx.doi.org/10.1038/nature02432" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Variation+in+behaviour+promotes+cooperation+in+the+Prisoner%27s+Dilemma+game." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Variation+in+behaviour+promotes+cooperation+in+the+Prisoner%27s+Dilemma+game.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">7.
              </span><a name="pone.0001917-Feigel1" id="pone.0001917-Feigel1"></a>Feigel A (2006) Evolution of cooperation and communication skills as a consequence of environment fluctuations.   <a href="http://www.arxiv.org/q-bio.PE/0609034">www.arxiv.org/q-bio.PE/0609034</a>.  <ul class="find-nolinks"></ul></li><li><span class="label">8.
              </span><a name="pone.0001917-Vukov1" id="pone.0001917-Vukov1"></a>Vukov J, Szabó G, Szolnoki A (2008) Evolutionary Prisoner's Dilemma game on the Newman-Watts networks. Phys. Rev. E  77: 026109.  <ul class="find" data-citedArticleID="1085238" data-doi="10.1103/physreve.77.026109"><li><a href="http://dx.doi.org/10.1103/physreve.77.026109" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Evolutionary+Prisoner%27s+Dilemma+game+on+the+Newman-Watts+networks." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Evolutionary+Prisoner%27s+Dilemma+game+on+the+Newman-Watts+networks.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">9.
              </span><a name="pone.0001917-Nowak2" id="pone.0001917-Nowak2"></a>Nowak MA, May RM (1992) Evolutionary games and spatial chaos. Nature  359: 826–829.  <ul class="find" data-citedArticleID="1085204" data-doi="10.1038/359826a0"><li><a href="http://dx.doi.org/10.1038/359826a0" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Evolutionary+games+and+spatial+chaos." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Evolutionary+games+and+spatial+chaos.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">10.
              </span><a name="pone.0001917-Nowak3" id="pone.0001917-Nowak3"></a>Nowak MA, Bonhoeffer S, May RM (1994) Spatial games and the maintenance of cooperation. Proc. Natl. Acad. Sci. USA  91: 4877–4881.  <ul class="find" data-citedArticleID="1085206" data-doi="10.1073/pnas.91.11.4877"><li><a href="http://dx.doi.org/10.1073/pnas.91.11.4877" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Spatial+games+and+the+maintenance+of+cooperation." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Spatial+games+and+the+maintenance+of+cooperation.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">11.
              </span><a name="pone.0001917-Cohen1" id="pone.0001917-Cohen1"></a>Cohen MD, Riolo RL, Axelrod R (2001) The role of social structure in the maintenance of cooperative regimes. Rationality Society  13: 5–32.  <ul class="find" data-citedArticleID="1085160" data-doi="10.1177/104346301013001001"><li><a href="http://dx.doi.org/10.1177/104346301013001001" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=The+role+of+social+structure+in+the+maintenance+of+cooperative+regimes." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22The+role+of+social+structure+in+the+maintenance+of+cooperative+regimes.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">12.
              </span><a name="pone.0001917-Santos2" id="pone.0001917-Santos2"></a>Santos FC, Pacheco JM (2005) Scale-free networks provide a unifying framework for the emergence of cooperation. Phys. Rev. Lett.  95: 098104.  <ul class="find" data-citedArticleID="1085218" data-doi="10.1103/physrevlett.95.098104"><li><a href="http://dx.doi.org/10.1103/physrevlett.95.098104" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Scale-free+networks+provide+a+unifying+framework+for+the+emergence+of+cooperation." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Scale-free+networks+provide+a+unifying+framework+for+the+emergence+of+cooperation.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">13.
              </span><a name="pone.0001917-Tomassini1" id="pone.0001917-Tomassini1"></a>Tomassini M, Luthi L, Giacobini M (2006) Hawks and Doves on small-world networks. Phys. Rev. E  73: 016132.  <ul class="find" data-citedArticleID="1085232" data-doi="10.1103/physreve.73.016132"><li><a href="http://dx.doi.org/10.1103/physreve.73.016132" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Hawks+and+Doves+on+small-world+networks." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Hawks+and+Doves+on+small-world+networks.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">14.
              </span><a name="pone.0001917-Hauert1" id="pone.0001917-Hauert1"></a>Hauert C, Doebeli M (2004) Spatial structure often inhibits the evolution of cooperation in the snowdrift game. Nature  428: 643–646.  <ul class="find" data-citedArticleID="1085180" data-doi="10.1038/nature02360"><li><a href="http://dx.doi.org/10.1038/nature02360" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Spatial+structure+often+inhibits+the+evolution+of+cooperation+in+the+snowdrift+game." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Spatial+structure+often+inhibits+the+evolution+of+cooperation+in+the+snowdrift+game.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">15.
              </span><a name="pone.0001917-Ohtsuki1" id="pone.0001917-Ohtsuki1"></a>Ohtsuki H, Hauert C, Lieberman E, Nowak MA (2006) A simple rule for the evolution of cooperation on graphs and social networks. Nature  441: 502–505.  <ul class="find" data-citedArticleID="1085208" data-doi="10.1038/nature04605"><li><a href="http://dx.doi.org/10.1038/nature04605" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=A+simple+rule+for+the+evolution+of+cooperation+on+graphs+and+social+networks." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22A+simple+rule+for+the+evolution+of+cooperation+on+graphs+and+social+networks.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">16.
              </span><a name="pone.0001917-Tang1" id="pone.0001917-Tang1"></a>Tang CL, Wang WX, Wu X, Wang BH (2006) Effects of average degree on cooperation in networked evolutionary game. Eur. J. Phys. B  53: 411–415.  <ul class="find" data-citedArticleID="1085230" data-doi="10.1140/epjb/e2006-00395-2"><li><a href="http://dx.doi.org/10.1140/epjb/e2006-00395-2" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Effects+of+average+degree+on+cooperation+in+networked+evolutionary+game." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Effects+of+average+degree+on+cooperation+in+networked+evolutionary+game.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">17.
              </span><a name="pone.0001917-Watts1" id="pone.0001917-Watts1"></a>Watts DJ, Strogatz SH (1998) Collective dynamics of ‘small-world’ networks. Nature  393: 440–442.  <ul class="find" data-citedArticleID="1085242" data-doi="10.1038/30918"><li><a href="http://dx.doi.org/10.1038/30918" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Collective+dynamics+of+%E2%80%98small-world%E2%80%99+networks." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Collective+dynamics+of+%E2%80%98small-world%E2%80%99+networks.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">18.
              </span><a name="pone.0001917-Watkins1" id="pone.0001917-Watkins1"></a>Watkins CJCH, Dayan P (1992) Q-learning. Machine Learning  8: 279–292.  <ul class="find" data-citedArticleID="1085240" data-doi="10.1023/a:1022676722315"><li><a href="http://dx.doi.org/10.1023/a:1022676722315" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Q-learning." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Q-learning.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">19.
              </span><a name="pone.0001917-Sutton1" id="pone.0001917-Sutton1"></a>Sutton RS, Barto AG (1999) Reinforcement learning: an introduction.   (Cambridge University Press, Cambridge).  <ul class="find-nolinks"></ul></li><li><span class="label">20.
              </span><a name="pone.0001917-Aumann1" id="pone.0001917-Aumann1"></a>Aumann RJ (2006) War and peace. Proc. Natl. Acad. Sci. USA  103: 17075–17078.  <ul class="find" data-citedArticleID="1085152" data-doi="10.1073/pnas.0608329103"><li><a href="http://dx.doi.org/10.1073/pnas.0608329103" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=War+and+peace." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22War+and+peace.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">21.
              </span><a name="pone.0001917-Macy1" id="pone.0001917-Macy1"></a>Macy MW, Flache A (2002) Learning dynamics in social dilemmas. Proc. Natl. Acad. Sci. USA  99: 7229–7236.  <ul class="find" data-citedArticleID="1085192" data-doi="10.1073/pnas.092080099"><li><a href="http://dx.doi.org/10.1073/pnas.092080099" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Learning+dynamics+in+social+dilemmas." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Learning+dynamics+in+social+dilemmas.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">22.
              </span><a name="pone.0001917-Kirschner1" id="pone.0001917-Kirschner1"></a>Kirschner M, Gerhart J (1998) Evolvability. Proc. Natl. Acad. Sci. USA  95: 8420–8427.  <ul class="find" data-citedArticleID="1085184" data-doi="10.1073/pnas.95.15.8420"><li><a href="http://dx.doi.org/10.1073/pnas.95.15.8420" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Evolvability." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Evolvability.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">23.
              </span><a name="pone.0001917-Csermely1" id="pone.0001917-Csermely1"></a>Csermely P (2006) Weak Links: Stabilizers of Complex Systems from Proteins to Social Networks (Springer, Heidelberg).  <ul class="find" data-citedArticleID="1085162" data-doi="10.1162/artl.2007.13.2.207"><li><a href="http://dx.doi.org/10.1162/artl.2007.13.2.207" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Weak+Links%3A+Stabilizers+of+Complex+Systems+from+Proteins+to+Social+Networks+%28Springer%2C+Heidelberg%29." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Weak+Links%3A+Stabilizers+of+Complex+Systems+from+Proteins+to+Social+Networks+%28Springer%2C+Heidelberg%29.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">24.
              </span><a name="pone.0001917-Skyrms1" id="pone.0001917-Skyrms1"></a>Skyrms B (2004) The Stag Hunt and the Evolution of Social Structure. New York: Cambridge University Press.   <ul class="find-nolinks"></ul></li><li><span class="label">25.
              </span><a name="pone.0001917-Durrett1" id="pone.0001917-Durrett1"></a>Durrett R (2006) Random graph dynamics. New York: Cambridge University Press.   <ul class="find-nolinks"></ul></li><li><span class="label">26.
              </span><a name="pone.0001917-Leskovec1" id="pone.0001917-Leskovec1"></a>Leskovec J, Kleinberg J, Faloutsos C (2007) Graph evolution: densification and shrinking diameters. ACM TKDD  1: 1–40.  <ul class="find" data-citedArticleID="1085188" data-doi="10.1145/1217299.1217301"><li><a href="http://dx.doi.org/10.1145/1217299.1217301" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Graph+evolution%3A+densification+and+shrinking+diameters." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Graph+evolution%3A+densification+and+shrinking+diameters.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">27.
              </span><a name="pone.0001917-Derenyi1" id="pone.0001917-Derenyi1"></a>Derenyi I, Farkas I, Palla G, Vicsek T (2004) Topological phase transitions of random networks. Physica A  334: 583–590.  <ul class="find" data-citedArticleID="1085164" data-doi="10.1016/j.physa.2003.10.083"><li><a href="http://dx.doi.org/10.1016/j.physa.2003.10.083" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Topological+phase+transitions+of+random+networks." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Topological+phase+transitions+of+random+networks.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">28.
              </span><a name="pone.0001917-Goyal1" id="pone.0001917-Goyal1"></a>Goyal S, Vega-Redondo F (2005) Network formation and social coordination. Games Econ. Behav.  50: 178–207.  <ul class="find" data-citedArticleID="1085176" data-doi="10.1016/j.geb.2004.01.005"><li><a href="http://dx.doi.org/10.1016/j.geb.2004.01.005" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Network+formation+and+social+coordination." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Network+formation+and+social+coordination.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">29.
              </span><a name="pone.0001917-Holme1" id="pone.0001917-Holme1"></a>Holme P, Ghoshal G (2006) Dynamics of networking agents competing for high centrality and low degree. Phys. Rev. Lett.  96: 098701.  <ul class="find" data-citedArticleID="1085182" data-doi="10.1103/physrevlett.96.098701"><li><a href="http://dx.doi.org/10.1103/physrevlett.96.098701" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Dynamics+of+networking+agents+competing+for+high+centrality+and+low+degree." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Dynamics+of+networking+agents+competing+for+high+centrality+and+low+degree.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">30.
              </span><a name="pone.0001917-Ebel1" id="pone.0001917-Ebel1"></a>Ebel H, Bornholdt S (2002) Coevolutionary games on networks. Phys. Rev. E  66: 056118.  <ul class="find" data-citedArticleID="1085168" data-doi="10.1103/physreve.66.056118"><li><a href="http://dx.doi.org/10.1103/physreve.66.056118" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Coevolutionary+games+on+networks." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Coevolutionary+games+on+networks.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">31.
              </span><a name="pone.0001917-Rong1" id="pone.0001917-Rong1"></a>Rong Z, Li X, Wang X (2007) Roles of mixing patterns in cooperation on a scale-free networked game. Phys. Rev. E  76: 027101.  <ul class="find" data-citedArticleID="1085212" data-doi="10.1103/physreve.76.027101"><li><a href="http://dx.doi.org/10.1103/physreve.76.027101" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Roles+of+mixing+patterns+in+cooperation+on+a+scale-free+networked+game." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Roles+of+mixing+patterns+in+cooperation+on+a+scale-free+networked+game.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">32.
              </span><a name="pone.0001917-Fu1" id="pone.0001917-Fu1"></a>Fu F, Chen X, Liu L, Wang L (2007) Social dilemmas in an online social network: the structure and evolution of cooperation. Phys. Lett. A  371: 58–64.  <ul class="find" data-citedArticleID="1085172" data-doi="10.1016/j.physleta.2007.05.116"><li><a href="http://dx.doi.org/10.1016/j.physleta.2007.05.116" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Social+dilemmas+in+an+online+social+network%3A+the+structure+and+evolution+of+cooperation." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Social+dilemmas+in+an+online+social+network%3A+the+structure+and+evolution+of+cooperation.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">33.
              </span><a name="pone.0001917-Tan1" id="pone.0001917-Tan1"></a>Tan M (1993) Multi-agent reinforcement learning: independent vs. cooperative agents. Proc. 10<sup>th</sup> Intl. Conf. Machine Learning 330–337.  <ul class="find" data-citedArticleID="1085228"><li><a href="http://www.crossref.org/guestquery/?auth2=&amp;atitle2=Multi-agent+reinforcement+learning%3A+independent+vs.+cooperative+agents.&amp;auth=&amp;atitle=Multi-agent+reinforcement+learning%3A+independent+vs.+cooperative+agents." target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Multi-agent+reinforcement+learning%3A+independent+vs.+cooperative+agents." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Multi-agent+reinforcement+learning%3A+independent+vs.+cooperative+agents.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">34.
              </span><a name="pone.0001917-Granovetter1" id="pone.0001917-Granovetter1"></a>Granovetter M (1985) Economic action and social structure. The problem of embeddedness. Am. J. Sociol.  91: 481–510.  <ul class="find" data-citedArticleID="1085178" data-doi="10.1086/228311"><li><a href="http://dx.doi.org/10.1086/228311" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Economic+action+and+social+structure.+The+problem+of+embeddedness." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Economic+action+and+social+structure.+The+problem+of+embeddedness.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">35.
              </span><a name="pone.0001917-Macy2" id="pone.0001917-Macy2"></a>Macy MW, Sato Y (2002) Trust, cooperation, and market formation in the U.S. and Japan. Proc. Natl. Acad. Sci. USA  99: 7214–7220.  <ul class="find" data-citedArticleID="1085194" data-doi="10.1073/pnas.082097399"><li><a href="http://dx.doi.org/10.1073/pnas.082097399" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Trust%2C+cooperation%2C+and+market+formation+in+the+U.S.+and+Japan." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Trust%2C+cooperation%2C+and+market+formation+in+the+U.S.+and+Japan.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">36.
              </span><a name="pone.0001917-Pacheco1" id="pone.0001917-Pacheco1"></a>Pacheco JM, Santos FC, Chalub FACC (2006) Stern-judging: a simple, successful norm, which promotes cooperation under indirect reciprocity. PLOS Comput. Biol.  2: e178.  <ul class="find" data-citedArticleID="1085210" data-doi="10.1371/journal.pcbi.0020178"><li><a href="http://dx.doi.org/10.1371/journal.pcbi.0020178" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Stern-judging%3A+a+simple%2C+successful+norm%2C+which+promotes+cooperation+under+indirect+reciprocity." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Stern-judging%3A+a+simple%2C+successful+norm%2C+which+promotes+cooperation+under+indirect+reciprocity.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">37.
              </span><a name="pone.0001917-Traulsen1" id="pone.0001917-Traulsen1"></a>Traulsen A, Nowak MA (2007) Chromodynamics of cooperation in finite populations. PLOS ONE  2: e270.  <ul class="find" data-citedArticleID="1085236" data-doi="10.1371/journal.pone.0000270"><li><a href="http://dx.doi.org/10.1371/journal.pone.0000270" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Chromodynamics+of+cooperation+in+finite+populations." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Chromodynamics+of+cooperation+in+finite+populations.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">38.
              </span><a name="pone.0001917-Kovacs1" id="pone.0001917-Kovacs1"></a>Kovacs IA, Szalay MS, Csermely P (2005) Water and molecular chaperones act as weak links of protein folding networks: energy landscape and punctuated equilibrium changes point towards a game theory of proteins. FEBS Lett  579: 2254–2260.  <ul class="find" data-citedArticleID="1085186" data-doi="10.1016/j.febslet.2005.03.056"><li><a href="http://dx.doi.org/10.1016/j.febslet.2005.03.056" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Water+and+molecular+chaperones+act+as+weak+links+of+protein+folding+networks%3A+energy+landscape+and+punctuated+equilibrium+changes+point+towards+a+game+theory+of+proteins." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Water+and+molecular+chaperones+act+as+weak+links+of+protein+folding+networks%3A+energy+landscape+and+punctuated+equilibrium+changes+point+towards+a+game+theory+of+proteins.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">39.
              </span><a name="pone.0001917-Tomassini2" id="pone.0001917-Tomassini2"></a>Tomassini M, Pestelacci E, Luthi L (2007) Social dilemmas and cooperation in complex networks. Int. J. Mod. Physics C  18: 1173–1186.  <ul class="find" data-citedArticleID="1085234" data-doi="10.1142/s0129183107011212"><li><a href="http://dx.doi.org/10.1142/s0129183107011212" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Social+dilemmas+and+cooperation+in+complex+networks." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Social+dilemmas+and+cooperation+in+complex+networks.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">40.
              </span><a name="pone.0001917-Luthi1" id="pone.0001917-Luthi1"></a>Luthi L, Pestelacci E, Tomassini M (2007) Evolutionary dilemmas in a social network. Lect. Notes Comp. Sci.  4648: 545–554.  <ul class="find" data-citedArticleID="1085190" data-doi="10.1007/978-3-540-74913-4_55"><li><a href="http://dx.doi.org/10.1007/978-3-540-74913-4_55" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Evolutionary+dilemmas+in+a+social+network." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Evolutionary+dilemmas+in+a+social+network.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">41.
              </span><a name="pone.0001917-Masuda1" id="pone.0001917-Masuda1"></a>Masuda N (2007) Participation costs dismiss the advantage of heterogeneous networks in evolution of cooperation. Proc. Roy. Soc. B  274: 1815–1821.  <ul class="find" data-citedArticleID="1085196" data-doi="10.1098/rspb.2007.0294"><li><a href="http://dx.doi.org/10.1098/rspb.2007.0294" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Participation+costs+dismiss+the+advantage+of+heterogeneous+networks+in+evolution+of+cooperation." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Participation+costs+dismiss+the+advantage+of+heterogeneous+networks+in+evolution+of+cooperation.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">42.
              </span><a name="pone.0001917-Sandholm1" id="pone.0001917-Sandholm1"></a>Sandholm TW, Crites RH (1996) Multiagent reinforcement learning in the iterated prisoner's dilemma. BioSystems  37: 147–166.  <ul class="find" data-citedArticleID="1085214" data-doi="10.1016/0303-2647(95)01551-5"><li><a href="http://dx.doi.org/10.1016/0303-2647(95)01551-5" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Multiagent+reinforcement+learning+in+the+iterated+prisoner%27s+dilemma." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Multiagent+reinforcement+learning+in+the+iterated+prisoner%27s+dilemma.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">43.
              </span><a name="pone.0001917-Szolnoki1" id="pone.0001917-Szolnoki1"></a>Szolnoki A, Perc M, Danku Z (2008) Physica A. 387. : 2075–2082.  <ul class="find-nolinks"></ul></li><li><span class="label">44.
              </span><a name="pone.0001917-Barabasi1" id="pone.0001917-Barabasi1"></a>Barabasi AL, Albert R (1999) Emergence of scaling in random networks. Science  286: 509–512.  <ul class="find" data-citedArticleID="1085156" data-doi="10.1126/science.286.5439.509"><li><a href="http://dx.doi.org/10.1126/science.286.5439.509" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Emergence+of+scaling+in+random+networks." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Emergence+of+scaling+in+random+networks.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">45.
              </span><a name="pone.0001917-Girvan1" id="pone.0001917-Girvan1"></a>Girvan M, Newman MEJ (2002) Community structure in social and biological networks. Proc. Natl. Acad. Sci. USA  99: 7821–7826.  <ul class="find" data-citedArticleID="1085174" data-doi="10.1073/pnas.122653799"><li><a href="http://dx.doi.org/10.1073/pnas.122653799" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Community+structure+in+social+and+biological+networks." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Community+structure+in+social+and+biological+networks.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li><li><span class="label">46.
              </span><a name="pone.0001917-Batagelj1" id="pone.0001917-Batagelj1"></a>Batagelj V, Mrvar A (1998) Pajek - Program for Large Network Analysis. Connections  21: 47–57.  <ul class="find" data-citedArticleID="1085158" data-doi="10.1017/cbo9780511996368"><li><a href="http://dx.doi.org/10.1017/cbo9780511996368" target="_new" title="Go to article in CrossRef">
                          View Article
                        </a></li><li><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=PubMed&amp;cmd=Search&amp;doptcmdl=Citation&amp;defaultField=Title+Word&amp;term=Pajek+-+Program+for+Large+Network+Analysis." target="_new" title="Go to article in PubMed">
                          PubMed/NCBI
                        </a></li><li><a href="http://scholar.google.com/scholar?hl=en&amp;safe=off&amp;q=%22Pajek+-+Program+for+Large+Network+Analysis.%22" target="_new" title="Go to article in Google Scholar">
                          Google Scholar
                        </a></li></ul></li></ol></div>

  </div>

      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.XML" value="85845"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.PDF" value="839153"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.g001.PNG_L" value="1874074"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.g001.PNG_M" value="380205"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.g001.PNG_S" value="17502"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.g001.TIF" value="1912008"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.g001.PNG_I" value="139543"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.g002.PNG_L" value="625535"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.g002.PNG_M" value="109224"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.g002.PNG_S" value="17463"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.g002.TIF" value="833222"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.g002.PNG_I" value="142211"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.g003.PNG_L" value="804737"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.g003.PNG_M" value="132427"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.g003.PNG_S" value="10113"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.g003.TIF" value="1269796"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.g003.PNG_I" value="46908"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.e001.PNG" value="12150"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.e001.TIF" value="27468"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.e002.PNG" value="9371"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.e002.TIF" value="25244"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.e003.PNG" value="8858"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.e003.TIF" value="25072"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.e004.PNG" value="10817"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.e004.TIF" value="26916"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.e005.PNG" value="12884"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.e005.TIF" value="29332"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.e006.PNG" value="10796"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.e006.TIF" value="26756"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.e007.PNG" value="9626"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.e007.TIF" value="25932"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.e008.PNG" value="9407"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.e008.TIF" value="25468"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.e009.PNG" value="10744"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.e009.TIF" value="26568"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.e010.PNG" value="11208"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.e010.TIF" value="26720"/>
      <input type="hidden" class="assetSize" name="info:doi/10.1371/journal.pone.0001917.s001.PDF" value="739740"/>

</div>
<div class="sidebar">

  <div class="article-actions cf">
      <div class="download">
        <span class="btn"><a href="/article/fetchObject.action?uri=info%3Adoi%2F10.1371%2Fjournal.pone.0001917&amp;representation=PDF" title="Download" target="_blank">Download PDF</a></span>
      </div>
      <div class="btn-reveal dropdown">
        <div class="dropdown-icon">
          <span class="btn">&nbsp;</span>
        </div>

        <div class="content">
          <ul class="bullet">
            <li><a href="/article/citationList.action?articleURI=info%3Adoi%2F10.1371%2Fjournal.pone.0001917" title="Download citations">Citation</a></li>
            <li><a href="/article/fetchObjectAttachment.action?uri=info%3Adoi%2F10.1371%2Fjournal.pone.0001917&amp;representation=XML" title="Download article XML">XML</a></li>
          </ul>
        </div>
      </div> <!-- end btn-reveal dropdown-->


    <div class="btn-reveal flt-l">
        <span class="btn">Print</span>
        <div class="content">
            <ul class="bullet">
                <li id="print-article"><a href="#" onclick="if(typeof(_gaq) != 'undefined'){ _gaq.push(['_trackEvent','Article', 'Print', 'Click']); } window.print(); return false;" title="Print Article">Print article</a></li>
                <li>
                  <a href="https://www.odysseypress.com/onlinehost/reprint_order.php?type=A&page=0&journal=7&doi=10.1371/journal.pone.0001917&volume=&issue=&title=Learning and Innovative Elements of Strategy Adoption Rules Expand Cooperative Network Topologies&author_name=Shijun%20Wang%2C%20M%C3%A1t%C3%A9%20S.%20Szalay%2C%20Changshui%20Zhang%2C%20Peter%20Csermely&start_page=1&end_page=9" title="Odyssey Press">EzReprint</a>
                </li>
            </ul>
        </div>
    </div>

    <div class="btn-reveal flt-r">
        <span class="btn">Share</span>
        <div class="content">
            <ul class="social">
                <li><a href="http://www.reddit.com/submit?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001917" target="_blank" title="Submit to Reddit"><img src="/images/icon.reddit.16.png" width="16" height="16" alt="Reddit">Reddit</a></li>

                <li><a href="https://plus.google.com/share?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001917" target="_blank" title="Share on Google+"><img src="/images/icon.gplus.16.png" width="16" height="16" alt="Google+">Google+</a></li>

                <li><a href="http://www.stumbleupon.com/submit?url=http%3A%2F%2Fwww.plosone.org%2Farticle%2Finfo%253Adoi%252F10.1371%252Fjournal.pone.0001917" target="_blank" title="Add to StumbleUpon"><img src="/images/icon.stumble.16.png" width="16" height="16" alt="StumbleUpon">StumbleUpon</a></li>

                <li><a href="http://www.facebook.com/share.php?u=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001917&amp;t=Learning%20and%20Innovative%20Elements%20of%20Strategy%20Adoption%20Rules%20Expand%20Cooperative%20Network%20Topologies" target="_blank" title="Share on Facebook"><img src="/images/icon.fb.16.png" width="16" height="16" alt="Facebook">Facebook</a></li>

                <li><a href="http://www.linkedin.com/shareArticle?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001917&title=Learning%20and%20Innovative%20Elements%20of%20Strategy%20Adoption%20Rules%20Expand%20Cooperative%20Network%20Topologies&summary=Checkout%20this%20article%20I%20found%20at%20PLOS" target="_blank" title="Add to LinkedIn"><img src="/images/icon.linkedin.16.png" width="16" height="16" alt="Mendeley">LinkedIn</a></li>

                <li><a href="http://www.citeulike.org/posturl?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001917&amp;title=Learning%20and%20Innovative%20Elements%20of%20Strategy%20Adoption%20Rules%20Expand%20Cooperative%20Network%20Topologies" target="_blank" title="Add to CiteULike"><img src="/images/icon.cul.16.png" width="16" height="16" alt="CiteULike">CiteULike</a></li>

                <li><a href="http://www.mendeley.com/import/?url=http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001917" target="_blank" title="Add to Mendeley"><img src="/images/icon.mendeley.16.png" width="16" height="16" alt="Mendeley">Mendeley</a></li>

                <li><a href="https://www.pubchase.com/library?add_aid=10.1371%2Fjournal.pone.0001917&amp;source=plos" target="_blank" title="Add to PubChase"><img src="/images/icon.pc.16.png" width="16" height="16" alt="PubChase">PubChase</a></li>


                <script type="text/javascript">
                    // replace tweet with one that's pre-shortened to 140 chars
                    function truncateTweetText() {
                        var twtTitle = 'Learning and Innovative Elements of Strategy Adoption Rules Expand Cooperative Network Topologies';
                        var twtUrl = 'http://dx.plos.org/10.1371/journal.pone.0001917';
                        // all URLs posted to twitter get auto-shortened to 20 chars.
                        var maxLength = 140 - (20 + 1);
                        // truncate the title to include space for twtTag and ellipsis (here, 10 = tag length + space + ellipsis)
                        if (twtTitle.length > maxLength) { twtTitle = twtTitle.substr(0, (maxLength - 10)) + '...'; }
                        // set the href to use the shortened tweet
                        $('#twitter-share-link').prop('href', 'http://twitter.com/intent/tweet?text=' + encodeURIComponent('#PLOSONE: ' + twtTitle + ' ' + twtUrl));
                    }
                </script>
                <li><a href="http://twitter.com/intent/tweet?text=#PLOSONE%3A%20Learning%20and%20Innovative%20Elements%20of%20Strategy%20Adoption%20Rules%20Expand%20Cooperative%20Network%20Topologies http%3A%2F%2Fdx.plos.org%2F10.1371%2Fjournal.pone.0001917" onclick="truncateTweetText();" target="_blank" title="Share on Twitter" id="twitter-share-link"><img src="/images/icon.twtr.16.png" width="16" height="16" alt="Twitter">Twitter</a></li>

                <li><a href="/article/email/info%3Adoi%2F10.1371%2Fjournal.pone.0001917" title="Email this article"><img src="/images/icon.email.16.png" width="16" height="16" alt="Email">Email</a></li>
            </ul>
        </div>
    </div><!--end btn-reveal flt-r-->
</div><!-- end article-actions-->

<!-- begin Crossmark -->

<a id="open-crossmark" href="#" style="margin-top: -28px; display:block"><img style="border: 0; display: none;
 padding: 10px 0 18px 0;"  id="crossmark-icon" src="/images/logo-crossmark-bw.png" /></a>
<div id="crossmark-dialog" style="display: none;" title="">
    <!-- the external CrossMark data is loaded inside this iframe -->
    <iframe id="crossmark-dialog-frame" frameborder="0"></iframe>
</div>

<!-- end crossmark -->


<div class="block" id="subject-area-sidebar-block">
    <div class="header">
        <h3>Subject Areas</h3><div title="More information" id="subject-area-sidebar-block-help-icon"><img align="right"
                                                                                                           alt="info" src="/images/button_info.png"/><div id="subject-area-sidebar-block-help"><img align="right"
                                                                                                                                                                                                    src="/images/button_info.png"/><p>
        <b>We want your feedback.</b> Do these subject areas make sense for this article? If not, click the flag
        next to the incorrect subject area and we will review it. Thanks for your help!
    </p></div></div>
    </div>


    <ul id="subject-area-sidebar-list">

















          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Agent-based+modeling%22" title="Search for articles in the subject area:'Agent-based modeling'"><div class="flagText">Agent-based modeling</div></a>
              <div data-categoryid="33853" data-articleid="26658"
                   data-categoryname="Agent-based modeling"
                   class="flagImage" title="Flag 'Agent-based modeling' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Game+theory%22" title="Search for articles in the subject area:'Game theory'"><div class="flagText">Game theory</div></a>
              <div data-categoryid="34099" data-articleid="26658"
                   data-categoryname="Game theory"
                   class="flagImage" title="Flag 'Game theory' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Human+learning%22" title="Search for articles in the subject area:'Human learning'"><div class="flagText">Human learning</div></a>
              <div data-categoryid="34727" data-articleid="26658"
                   data-categoryname="Human learning"
                   class="flagImage" title="Flag 'Human learning' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Learning%22" title="Search for articles in the subject area:'Learning'"><div class="flagText">Learning</div></a>
              <div data-categoryid="20059" data-articleid="26658"
                   data-categoryname="Learning"
                   class="flagImage" title="Flag 'Learning' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Prisoner%27s+dilemma%22" title="Search for articles in the subject area:'Prisoner's dilemma'"><div class="flagText">Prisoner's dilemma</div></a>
              <div data-categoryid="49891" data-articleid="26658"
                   data-categoryname="Prisoner's dilemma"
                   class="flagImage" title="Flag 'Prisoner's dilemma' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Scale-free+networks%22" title="Search for articles in the subject area:'Scale-free networks'"><div class="flagText">Scale-free networks</div></a>
              <div data-categoryid="22077" data-articleid="26658"
                   data-categoryname="Scale-free networks"
                   class="flagImage" title="Flag 'Scale-free networks' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Social+networks%22" title="Search for articles in the subject area:'Social networks'"><div class="flagText">Social networks</div></a>
              <div data-categoryid="33149" data-articleid="26658"
                   data-categoryname="Social networks"
                   class="flagImage" title="Flag 'Social networks' as inappropriate"></div>
          </li>
          <li>
              <a href="/search/advanced?unformattedQuery=subject%3A%22Topology%22" title="Search for articles in the subject area:'Topology'"><div class="flagText">Topology</div></a>
              <div data-categoryid="32019" data-articleid="26658"
                   data-categoryname="Topology"
                   class="flagImage" title="Flag 'Topology' as inappropriate"></div>
          </li>
    </ul>
</div>

<div class="ad">
    <div class="title">Advertisement</div>






  <iframe id='a0852f54' name='a0852f54'
    src='http://ads.plos.org/www/delivery/afr.php?zoneid=381&amp;cb=8990'
    frameborder='0' scrolling='no' width='160' height='600'>
    <a href='http://ads.plos.org/www/delivery/ck.php?n=a0852f54&amp;cb=2273'
      target='_top'><img src='http://ads.plos.org/www/delivery/avw.php?zoneid=381&amp;cb=4937&amp;n=a0852f54'
      border='0' alt=''/>
    </a>
  </iframe>



</div>

<div id="twitter-alm-timeline" class="twitter-alm-timeline"></div>

<div class="block sidebar-comments">
    <div class="header">
        <h3>Comments</h3>
    </div>
      <p><a href="/annotation/listThread.action?root=15943">Acknowledgment of additional support</a><br>Posted by csermely</p>
      <p><a href="/annotation/listThread.action?root=9047">Referee comments: Referee 1 (Bence Toth)</a><br>Posted by PLoS_ONE_Group</p>
</div>

</div><!-- sidebar -->
    </div>
  </div>
</div>
<script src="http://wl.figshare.com/static/p_widget.js" type="text/javascript"></script><div id="pageftr">
  <div class="ftr-cols cf">
    <div class="col col-1">
      <img src="/images/logo-plos-footer.png" alt="PLOS Logo" class="logo" />
      <p><a href="/static/releaseNotes">Ambra 2.9.16</a> Managed Colocation provided <br />by <a href="http://www.isc.org/">Internet Systems Consortium</a>.<p>
      <div class="nav nav-aux">
        <a href="/static/privacy">Privacy Policy</a> |
        <a href="/static/terms">Terms of Use</a> |
        <a href="http://www.plos.org/advertise/">Advertise</a> |
        <a href="http://www.plos.org/about/media-inquiries/">Media Inquiries</a>
      </div>
    </div>
    <div class="col col-2">
      <p><a href="http://www.plos.org/publications/journals/">Publications</a></p>
      <div class="nav">
        <ul>
          <li><a href="http://www.plosbiology.org">PLOS Biology</a></li>
          <li><a href="http://www.plosmedicine.org">PLOS Medicine</a></li>
          <li><a href="http://www.ploscompbiol.org">PLOS Computational Biology</a></li>
          <li><a href="http://currents.plos.org">PLOS Currents</a></li>
          <li><a href="http://www.plosgenetics.org">PLOS Genetics</a></li>
          <li><a href="http://www.plospathogens.org">PLOS Pathogens</a></li>
          <li><a href="http://www.plosone.org">PLOS ONE</a></li>
          <li><a href="http://www.plosntds.org">PLOS Neglected Tropical Diseases</a></li>
        </ul>
      </div>
    </div>
    <div class="col col-3">
      <div class="nav">
        <p><a href="http://www.plos.org">plos.org</a></p>
        <p><a href="http://blogs.plos.org">Blogs</a></p>
        <p><a href="http://www.ploscollections.org">Collections</a></p>
        <p><a href="/feedback/new">Send us feedback</a></p>

        <p>California (US) corporation #C2354500, based in San Francisco</p>
      </div>
    </div>
  </div>
</div><!-- pageftr -->

</div><!-- end page-wrap, this div is in header.ftl -->
<script type="text/javascript" src="/javascript/jquery-1.8.1-min.js?v=Tm7VCOzZz3lE03ghpkS6SWkHbyI"></script>
<script type="text/javascript" src="/javascript/ga-min.js?v=lNQ4gt8QcPDatjsdOFl_FGpPhLY"></script>
<script type="text/javascript" src="/javascript/jquery.hoverIntent-min.js?v=mRiGNYY9cIXxVb8u0K_MdW7hHnc"></script>
<script type="text/javascript" src="/javascript/jquery.placeholder-min.js?v=21Pn56Ur9h1N4K4VZDa0nqI3Pxo"></script>
<script type="text/javascript" src="/javascript/jquery.jsonp-2.4.0-min.js?v=lqTpzoHfSq3I5Ygo01qq5WankEo"></script>
<script type="text/javascript" src="/javascript/jquery-ui-1.9.2.custom-min.js?v=raSSlfNO0YsV5uUpAKmTB9n5VTc"></script>
<script type="text/javascript" src="/javascript/jquery.tooltip-min.js?v=cw+6Smh+mdryIA25xvqIvHMrnZM"></script>
<script type="text/javascript" src="/javascript/jquery.uniform-min.js?v=kYUAnX6W2W_2fK3RIuQ2m_YFG9U"></script>
<script type="text/javascript" src="/javascript/jquery.pjax-min.js?v=939kLBjL5_YKbx71T1RHjYaD4l8"></script>
<script type="text/javascript" src="/javascript/imagesloaded-min.js?v=XeuAp8Gc3mvQUo+wZCSF8ttPwvw"></script>
<script type="text/javascript" src="/javascript/figviewer-min.js?v=yPUa0sUQ_iHkI+IRv2i9bjyZJFo"></script>
<script type="text/javascript" src="/javascript/global-min.js?v=0Q3PwjeaWtXYDnqIsQvnL_ou0qs"></script>
<script type="text/javascript" src="/javascript/jquery.touchswipe-min.js?v=huaek_e6HqTduvCNAN91dJolTyw"></script>
<script type="text/javascript" src="/javascript/jquery.base64-min.js?v=VwV1zeVqKZj5FCAdlK0q5NRxbBg"></script>
<script type="text/javascript" src="/javascript/alm-min.js?v=Y5gm6B0b4Kx2YHNObNrgEeBgXlY"></script>
<script type="text/javascript" src="/javascript/taxonomy-browser-min.js?v=vBVMuDMYkGJCXIUxLe35GoyiJNw"></script>
<script type="text/javascript" src="/javascript/jquery.filterize-min.js?v=j0ZKVnHyk2nhFy8eIuNJkp7xaM0"></script>
<script type="text/javascript" src="/javascript/plosone-min.js?v=TK4H4arL_XBSwwJq+K1N3kqYfAI"></script>
<script type="text/javascript" src="/javascript/twitter-min.js?v=xKgcxLsQFXy+at1ao1NVke8nFlM"></script>
<script type="text/javascript" src="/javascript/crossmark.1.4-min.js?v=3FO4k0SjwTaGNnKGNSqthar1080"></script>
<script type="text/javascript">
  var _sf_async_config={uid:16579,domain:"plosone.org"};
  (function(){
    function loadChartbeat() {
      window._sf_endpt=(new Date()).getTime();
      var e = document.createElement('script');
      e.setAttribute('language', 'javascript');
      e.setAttribute('type', 'text/javascript');
      e.setAttribute('src',
          (("https:" == document.location.protocol) ? "https://a248.e.akamai.net/chartbeat.download.akamai.com/102508/" : "http://static.chartbeat.com/") +
              "js/chartbeat.js");
      document.body.appendChild(e);
    }
    var oldonload = window.onload;
    window.onload = (typeof window.onload != 'function') ?
        loadChartbeat : function() { oldonload(); loadChartbeat(); };
  })();
</script>
<!-- <script type="application/javascript" src="http://crossmark.crossref.org/javascripts/v1.3/crossmark.min.js"></script> -->

</body>
</html>
